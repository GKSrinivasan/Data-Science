{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block(in_feat, out_feat, ksize, stride, padding, \n",
    "               activation=nn.LeakyReLU(0.2, inplace=True), use_batchnorm=True):\n",
    "    layers = [nn.Conv2d(in_feat, out_feat, ksize, stride, padding, bias=not use_batchnorm)]\n",
    "    if use_batchnorm:\n",
    "        layers.append(nn.BatchNorm2d(out_feat)) \n",
    "    if activation:\n",
    "        layers.append(activation)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class BASIC_D(nn.Module):\n",
    "    def __init__(self, nc_in, nc_out, ndf, max_layers=3):\n",
    "        super(BASIC_D, self).__init__()       \n",
    "        main = nn.Sequential()\n",
    "        # input is nc x isize x isize\n",
    "        main.add_module('initial.{0}-{1}'.format(nc_in+nc_out, ndf),\n",
    "                        conv_block(nc_in+nc_out, ndf, 4, 2, 1, use_batchnorm=False))\n",
    "        out_feat = ndf\n",
    "        for layer in range(1, max_layers):\n",
    "            in_feat = out_feat\n",
    "            out_feat = ndf * min(2**layer, 8)\n",
    "            main.add_module('pyramid.{0}-{1}'.format(in_feat, out_feat),\n",
    "                                conv_block(in_feat, out_feat, 4, 2, 1, ))           \n",
    "        in_feat = out_feat\n",
    "        out_feat = ndf*min(2**max_layers, 8)\n",
    "        main.add_module('last.{0}-{1}'.format(in_feat, out_feat),\n",
    "                        conv_block(in_feat, out_feat, 4, 1, 1))\n",
    "        \n",
    "        in_feat, out_feat = out_feat, 1        \n",
    "        main.add_module('output.{0}-{1}'.format(in_feat, out_feat),\n",
    "                        conv_block(in_feat, out_feat, 4, 1, 1, nn.Sigmoid(), False))\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, a, b):\n",
    "        x = torch.cat((a, b), 1)        \n",
    "        output = self.main(x)                    \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UBlock(nn.Module):\n",
    "    def __init__(self, s, nf_in, max_nf, use_batchnorm=True, nf_out=None, nf_next=None):\n",
    "        super(UBlock, self).__init__()\n",
    "        assert s>=2 and s%2==0\n",
    "        nf_next = nf_next if nf_next else min(nf_in*2, max_nf)\n",
    "        nf_out = nf_out if nf_out else nf_in            \n",
    "        self.conv = nn.Conv2d(nf_in, nf_next, 4, 2, 1, bias=not (use_batchnorm and s>2) )\n",
    "        if s>2:\n",
    "            next_block = [nn.BatchNorm2d(nf_next)] if use_batchnorm else []\n",
    "            next_block += [nn.LeakyReLU(0.2, inplace=True), UBlock(s//2, nf_next, max_nf)]\n",
    "            self.next_block = nn.Sequential(*next_block)\n",
    "        else:\n",
    "            self.next_block = None\n",
    "        convt = [nn.ReLU(), \n",
    "                 nn.ConvTranspose2d(nf_next*2 if self.next_block else nf_next, nf_out,\n",
    "                                        kernel_size=4, stride=2,padding=1, bias=not use_batchnorm)]    \n",
    "        if use_batchnorm:\n",
    "            convt += [nn.BatchNorm2d(nf_out)]        \n",
    "        if s <= 8:\n",
    "            convt += [nn.Dropout(0.5, inplace=True)]\n",
    "        self.convt = nn.Sequential(*convt)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.next_block:\n",
    "            x2 = self.next_block(x)\n",
    "            x = torch.cat((x,x2),1)\n",
    "        return self.convt(x)        \n",
    "\n",
    "\n",
    "def UNET_G(isize, nc_in=3, nc_out=3, ngf=64):\n",
    "    return nn.Sequential(\n",
    "                  UBlock(isize, nc_in, 8*ngf, False, nf_out=nc_out, nf_next=ngf),\n",
    "                  nn.Tanh() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nc_in = 3\n",
    "nc_out = 3\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "Î» = 10\n",
    "\n",
    "loadSize = 286\n",
    "imageSize = 256\n",
    "batchSize = 1\n",
    "lrD = 2e-4\n",
    "lrG = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netD = BASIC_D(nc_in, nc_out, ndf)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netG = UNET_G(imageSize, nc_in, nc_out, ngf)\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputA = torch.FloatTensor(batchSize, nc_in, imageSize, imageSize)\n",
    "inputB = torch.FloatTensor(batchSize, nc_out, imageSize, imageSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netD.cuda()\n",
    "netG.cuda()\n",
    "inputA = inputA.cuda()\n",
    "inputB = inputB.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "from random import randint, shuffle\n",
    "\n",
    "def load_data(file_pattern):\n",
    "    return glob.glob(file_pattern)\n",
    "def read_image(fn, direction=0):\n",
    "    im = Image.open(fn)\n",
    "    im = im.resize( (loadSize*2, loadSize), Image.BILINEAR )\n",
    "    arr = np.array(im)/255*2-1\n",
    "    w1,w2 = (loadSize-imageSize)//2,(loadSize+imageSize)//2\n",
    "    h1,h2 = w1,w2\n",
    "    imgA = arr[h1:h2, loadSize+w1:loadSize+w2, :]\n",
    "    imgB = arr[h1:h2, w1:w2, :]\n",
    "    if randint(0,1):\n",
    "        imgA=imgA[:,::-1]\n",
    "        imgB=imgB[:,::-1]\n",
    "    if channel_first:\n",
    "        imgA = np.moveaxis(imgA, 2, 0)\n",
    "        imgB = np.moveaxis(imgB, 2, 0)\n",
    "    if direction==0:\n",
    "        return imgA, imgB\n",
    "    else:\n",
    "        return imgB,imgA\n",
    "\n",
    "data = \"edges2shoes\"\n",
    "data = \"facades\"\n",
    "direction = 0\n",
    "trainAB = load_data('pix2pix/{}/train/*.jpg'.format(data))\n",
    "valAB = load_data('pix2pix/{}/val/*.jpg'.format(data))\n",
    "assert len(trainAB) and len(valAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minibatch(dataAB, batchsize, direction=0):\n",
    "    length = len(dataAB)\n",
    "    epoch = i = 0\n",
    "    tmpsize = None    \n",
    "    while True:\n",
    "        size = tmpsize if tmpsize else batchsize\n",
    "        if i+size > length:\n",
    "            shuffle(dataAB)\n",
    "            i = 0\n",
    "            epoch+=1        \n",
    "        dataA = []\n",
    "        dataB = []\n",
    "        for j in range(i,i+size):\n",
    "            imgA,imgB = read_image(dataAB[j], direction)\n",
    "            dataA.append(imgA)\n",
    "            dataB.append(imgB)\n",
    "        dataA = np.float32(dataA)\n",
    "        dataB = np.float32(dataB)\n",
    "        i+=size\n",
    "        tmpsize = yield epoch, dataA, dataB        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "def showX(X, rows=1):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')\n",
    "    if channel_first:\n",
    "        int_X = np.moveaxis(int_X.reshape(-1,3,imageSize,imageSize), 1, 3)\n",
    "    else:\n",
    "        int_X = int_X.reshape(-1,imageSize,imageSize, 3)\n",
    "    int_X = int_X.reshape(rows, -1, imageSize, imageSize,3).swapaxes(1,2).reshape(rows*imageSize,-1, 3)\n",
    "    display(Image.fromarray(int_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channel_first=True\n",
    "channel_axis=1\n",
    "train_batch = minibatch(trainAB, 6, direction=direction)\n",
    "_, trainA, trainB = next(train_batch)\n",
    "showX(trainA)\n",
    "showX(trainB)\n",
    "#del train_batch, trainA, trainB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(netD.parameters(), lr = lrD, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lrG, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "lossL1 = nn.L1Loss()\n",
    "one = None\n",
    "zero = None\n",
    "def netD_train(A, B):    \n",
    "    global one, zero\n",
    "    netD.zero_grad()\n",
    "    output_D_real = netD(A, B)\n",
    "    if one is None:\n",
    "        one = Variable(torch.ones(*output_D_real.size()).cuda())\n",
    "    errD_real = loss(output_D_real, one)\n",
    "    errD_real.backward()\n",
    "\n",
    "    output_G = netG(A)\n",
    "    output_D_fake = netD(A, output_G)\n",
    "    if zero is None:\n",
    "        zero = Variable(torch.zeros(*output_D_fake.size()).cuda())\n",
    "    errD_fake = loss(output_D_fake, zero)\n",
    "    errD_fake.backward()\n",
    "    optimizerD.step()\n",
    "    return (errD_fake.data[0]+errD_real.data[0])/2,\n",
    "\n",
    "\n",
    "def netG_train(A, B):\n",
    "    global one\n",
    "    netG.zero_grad()\n",
    "    output_G = netG(A)\n",
    "    output_D_fake = netD(A, output_G)\n",
    "    if one is None:\n",
    "        one = Variable(torch.ones(*output_D_fake.size()).cuda())\n",
    "    errG_fake = loss(output_D_fake, one)    \n",
    "    errG_L1 = lossL1(output_G, B)\n",
    "    errG = errG_fake + 100 * errG_L1\n",
    "    errG.backward()\n",
    "        \n",
    "    optimizerG.step()\n",
    "    return errG_fake.data[0], errG_L1.data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def V(x):\n",
    "    return Variable(torch.from_numpy(x).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def netG_gen(A):\n",
    "    return np.concatenate([netG(A[i:i+1]).data.cpu().numpy() for i in range(A.size()[0])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "t0 = time.time()\n",
    "niter = 150\n",
    "gen_iterations = 0\n",
    "errL1 = epoch = errG = 0\n",
    "errL1_sum = errG_sum = errD_sum = 0\n",
    "\n",
    "display_iters = 500\n",
    "val_batch = minibatch(valAB, 6, direction)\n",
    "train_batch = minibatch(trainAB, batchSize, direction)\n",
    "\n",
    "while epoch < niter: \n",
    "    epoch, trainA, trainB = next(train_batch)   \n",
    "    vA, vB = V(trainA), V(trainB)\n",
    "    errD,  = netD_train(vA, vB)\n",
    "    errD_sum +=errD\n",
    "\n",
    "    # epoch, trainA, trainB = next(train_batch)\n",
    "    errG, errL1 = netG_train(vA, vB)\n",
    "    errG_sum += errG\n",
    "    errL1_sum += errL1\n",
    "    gen_iterations+=1\n",
    "    if gen_iterations%display_iters==0:\n",
    "        if gen_iterations%(5*display_iters)==0:\n",
    "            clear_output()\n",
    "        print('[%d/%d][%d] Loss_D: %f Loss_G: %f loss_L1: %f'\n",
    "        % (epoch, niter, gen_iterations, errD_sum/display_iters, \n",
    "           errG_sum/display_iters, errL1_sum/display_iters), time.time()-t0)\n",
    "        _, valA, valB = train_batch.send(6)\n",
    "        vA, vB = V(valA),V(valB)\n",
    "        fakeB = netG_gen(vA)\n",
    "        showX(np.concatenate([valA, valB, fakeB], axis=0), 3)\n",
    "        \n",
    "        errL1_sum = errG_sum = errD_sum = 0\n",
    "        _, valA, valB = next(val_batch)\n",
    "        fakeB = netG_gen(V(valA))\n",
    "        showX(np.concatenate([valA, valB, fakeB], axis=0), 3)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
