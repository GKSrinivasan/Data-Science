{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/pytorch/tnt.git@master\n",
      "  Cloning https://github.com/pytorch/tnt.git (to master) to /tmp/pip-28_hz95j-build\n",
      "Requirement already satisfied: torch in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from torchnet==0.0.1)\n",
      "Requirement already satisfied: six in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from torchnet==0.0.1)\n",
      "Requirement already satisfied: visdom in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from torchnet==0.0.1)\n",
      "Requirement already satisfied: pyyaml in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from torch->torchnet==0.0.1)\n",
      "Requirement already satisfied: numpy in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from torch->torchnet==0.0.1)\n",
      "Requirement already satisfied: pillow in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: pyzmq in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: requests in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: tornado in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: torchfile in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.1)\n",
      "Installing collected packages: torchnet\n",
      "  Running setup.py install for torchnet ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed torchnet-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/pytorch/tnt.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as FXN\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torchnet.engine import Engine\n",
    "from torchnet.logger import VisdomPlotLogger, VisdomLogger\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from tqdm import tqdm\n",
    "import torchnet as tnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_35a50f4aee18dc'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing Visdom server out put\n",
    "vis = visdom.Visdom()\n",
    "vis.text(\"Hello World\")\n",
    "vis.image(np.ones((3, 10, 10)))\n",
    "\n",
    "Y = np.random.rand(100)\n",
    "vis.scatter(\n",
    "    X=np.random.rand(100, 2),\n",
    "    Y=(Y[Y > 0] + 1.5).astype(int),\n",
    "    opts=dict(\n",
    "        legend=['Apples', 'Pears'],\n",
    "        xtickmin=-5,\n",
    "        xtickmax=5,\n",
    "        xtickstep=0.5,\n",
    "        ytickmin=-5,\n",
    "        ytickmax=5,\n",
    "        ytickstep=0.5,\n",
    "        markersymbol='cross-thin-open',\n",
    "    ),\n",
    ")\n",
    "\n",
    "vis.scatter(\n",
    "    X=np.random.rand(100, 3),\n",
    "    Y=(Y + 1.5).astype(int),\n",
    "    opts=dict(\n",
    "        legend=['Men', 'Women'],\n",
    "        markersize=5,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size    = 128\n",
    "num_classes   = 10\n",
    "num_epochs    = 100\n",
    "num_rout_iter = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define softmax function\n",
    "def softmax(input, dim=1):\n",
    "    transposed_input = input.transpose(dim, len(input.size()) -1)\n",
    "    softmaxed_output = FXN.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)))\n",
    "    return softmaxed_output.view(*transposed_input.size()).transpose(dim, len(input.size()) -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define augmentation\n",
    "def augmentation(x, max_shift=2):\n",
    "    _, _, height, width = x.size()\n",
    "\n",
    "    h_shift, w_shift = np.random.randint(-max_shift, max_shift + 1, size=2)\n",
    "    source_height_slice = slice(max(0, h_shift), h_shift + height)\n",
    "    source_width_slice  = slice(max(0, w_shift), w_shift + width)\n",
    "    target_height_slice = slice(max(0, -h_shift), -h_shift + height)\n",
    "    target_width_slice  = slice(max(0, -w_shift), -w_shift + width)\n",
    "\n",
    "    shifted_image = torch.zeros(*x.size())\n",
    "    shifted_image[:, :, source_height_slice, source_width_slice] = x[:, :, target_height_slice, target_width_slice]\n",
    "    return shifted_image.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Capsule Layer Class\n",
    "class capsuleLayer(nn.Module):\n",
    "    def __init__(self, num_capsules, num_route_nodes, in_channels,\n",
    "                 out_channels, kernel_size=None, stride=None, num_iterations=num_rout_iter):\n",
    "        super(capsuleLayer, self).__init__()\n",
    "        \n",
    "        self.num_route_nodes = num_route_nodes\n",
    "        self.num_iterations  = num_iterations\n",
    "        self.num_capsules    = num_capsules\n",
    "        \n",
    "        if num_route_nodes != -1:\n",
    "            self.route_weights = nn.Parameter(torch.randn(num_capsules, num_route_nodes, in_channels, out_channels))\n",
    "        else:\n",
    "            self.capsules = nn.ModuleList(\n",
    "            [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=0) \n",
    "             for _ in range(num_capsules)])\n",
    "    \n",
    "    def squashing(self, tensor, dim=1):\n",
    "        squared_norm = (tensor**2).sum(dim=dim, keepdim=True)\n",
    "        scale        = squared_norm / (1 + squared_norm)\n",
    "        return scale * tensor / torch.sqrt(squared_norm)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.num_route_nodes != -1:\n",
    "            priors = x[None, :, :, None, :] @ self.route_weights[:, None, :, :, :]\n",
    "\n",
    "            logits = Variable(torch.zeros(*priors.size())).cuda()\n",
    "            for i in range(self.num_iterations):\n",
    "                probs = softmax(logits, dim=2)\n",
    "                outputs = self.squashing((probs * priors).sum(dim=2, keepdim=True))\n",
    "\n",
    "                if i != self.num_iterations - 1:\n",
    "                    delta_logits = (priors * outputs).sum(dim=-1, keepdim=True)\n",
    "                    logits = logits + delta_logits\n",
    "        else:\n",
    "            outputs = [capsule(x).view(x.size(0), -1, 1) for capsule in self.capsules]\n",
    "            outputs = torch.cat(outputs, dim=-1)\n",
    "            outputs = self.squashing(outputs)\n",
    "\n",
    "        return outputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class capsuleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(capsuleNet, self).__init__()\n",
    "\n",
    "        self.conv1            = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9, stride=1)\n",
    "        self.primary_capsules = capsuleLayer(num_capsules=8, num_route_nodes=-1, in_channels=256, out_channels=32,\n",
    "                                             kernel_size=9, stride=2)\n",
    "        self.digit_capsules   = capsuleLayer(num_capsules=num_classes, num_route_nodes=32 * 6 * 6, in_channels=8,\n",
    "                                           out_channels=16)\n",
    "\n",
    "        self.decoder          = nn.Sequential(\n",
    "            nn.Linear(16 * num_classes, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = FXN.relu(self.conv1(x), inplace=True)\n",
    "        x = self.primary_capsules(x)\n",
    "        x = self.digit_capsules(x).squeeze().transpose(0, 1)\n",
    "\n",
    "        classes = (x ** 2).sum(dim=-1) ** 0.5\n",
    "        classes = FXN.softmax(classes)\n",
    "\n",
    "        if y is None:\n",
    "            # In all batches, get the most active capsule.\n",
    "            _, max_length_indices = classes.max(dim=1)\n",
    "            y = Variable(torch.sparse.torch.eye(num_classes)).cuda().index_select(dim=0, index=max_length_indices.data)\n",
    "\n",
    "        reconstructions = self.decoder((x * y[:, :, None]).view(x.size(0), -1))\n",
    "\n",
    "        return classes, reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class capsuleLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(capsuleLoss, self).__init__()\n",
    "        self.reconstruction_loss = nn.MSELoss(size_average=False)\n",
    "\n",
    "    def forward(self, images, labels, classes, reconstructions):\n",
    "        left        = FXN.relu(0.9 - classes, inplace=True) ** 2\n",
    "        right       = FXN.relu(classes - 0.1, inplace=True) ** 2\n",
    "        margin_loss = labels * left + 0.5 * (1. - labels) * right\n",
    "        margin_loss = margin_loss.sum()\n",
    "        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n",
    "\n",
    "        return (margin_loss + 0.0005 * reconstruction_loss) / images.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [02:35<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Training Loss: 0.6666 (Accuracy: 70.17%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Testing Loss: 0.6622 (Accuracy: 89.92%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 126/469 [00:42<01:55,  2.98it/s]"
     ]
    }
   ],
   "source": [
    "# Building and Running the model\n",
    "model = capsuleNet()\n",
    "model.cuda()\n",
    "# print(\"# parameters: \", sum(param.numel() for param in model.parameters))\n",
    "\n",
    "optimizer = Adam(model.parameters())\n",
    "engine = Engine()\n",
    "meter_loss = tnt.meter.AverageValueMeter()\n",
    "meter_accuracy = tnt.meter.ClassErrorMeter(accuracy=True)\n",
    "confusion_meter = tnt.meter.ConfusionMeter(num_classes, normalized=True)\n",
    "\n",
    "train_loss_logger     = VisdomPlotLogger('line', opts={'title': 'Train Loss'})\n",
    "train_error_logger    = VisdomPlotLogger('line', opts={'title': 'Train Accuracy'})\n",
    "test_loss_logger      = VisdomPlotLogger('line', opts={'title': 'Test Loss'})\n",
    "test_accuracy_logger  = VisdomPlotLogger('line', opts={'title': 'Test Accuracy'})\n",
    "confusion_logger      = VisdomLogger('heatmap', opts={'title': 'Confusion matrix',\n",
    "                                                     'columnnames': list(range(num_classes)),\n",
    "                                                     'rownames': list(range(num_classes))})\n",
    "ground_truth_logger   = VisdomLogger('image', opts={'title': 'Ground Truth'})\n",
    "reconstruction_logger = VisdomLogger('image', opts={'title': 'Reconstruction'})\n",
    "\n",
    "capsule_loss = capsuleLoss()\n",
    "\"\"\"\n",
    "Defining a bunch of other functions such as \n",
    "\n",
    "get_iterator\n",
    "processor\n",
    "reset_meters\n",
    "on_sample\n",
    "on_forward\n",
    "on_start_epoch\n",
    "on_end_epoch\n",
    "\n",
    "\"\"\" \n",
    "def get_iterator(mode):\n",
    "        dataset        = MNIST(root='./data', download=True, train=mode)\n",
    "        data           = getattr(dataset, 'train_data' if mode else 'test_data')\n",
    "        labels         = getattr(dataset, 'train_labels' if mode else 'test_labels')\n",
    "        tensor_dataset = tnt.dataset.TensorDataset([data, labels])\n",
    "\n",
    "        return tensor_dataset.parallel(batch_size=batch_size, num_workers=4, shuffle=mode)\n",
    "\n",
    "\n",
    "def processor(sample):\n",
    "    data, labels, training = sample\n",
    "\n",
    "    data   = augmentation(data.unsqueeze(1).float() / 255.0)\n",
    "    labels = torch.LongTensor(labels)\n",
    "    labels = torch.sparse.torch.eye(num_classes).index_select(dim=0, index=labels)\n",
    "    data   = Variable(data).cuda()\n",
    "    labels = Variable(labels).cuda()\n",
    "\n",
    "    if training:\n",
    "        classes, reconstructions = model(data, labels)\n",
    "    else:\n",
    "        classes, reconstructions = model(data)\n",
    "\n",
    "    loss = capsule_loss(data, labels, classes, reconstructions)\n",
    "\n",
    "    return loss, classes\n",
    "\n",
    "\n",
    "def reset_meters():\n",
    "    meter_accuracy.reset()\n",
    "    meter_loss.reset()\n",
    "    confusion_meter.reset()\n",
    "\n",
    "\n",
    "def on_sample(state):\n",
    "    state['sample'].append(state['train'])\n",
    "\n",
    "\n",
    "def on_forward(state):\n",
    "    meter_accuracy.add(state['output'].data, torch.LongTensor(state['sample'][1]))\n",
    "    confusion_meter.add(state['output'].data, torch.LongTensor(state['sample'][1]))\n",
    "    meter_loss.add(state['loss'].data[0])\n",
    "\n",
    "\n",
    "def on_start_epoch(state):\n",
    "    reset_meters()\n",
    "    state['iterator'] = tqdm(state['iterator'])\n",
    "\n",
    "\n",
    "def on_end_epoch(state):\n",
    "    print('[Epoch %d] Training Loss: %.4f (Accuracy: %.2f%%)' % (\n",
    "        state['epoch'], meter_loss.value()[0], meter_accuracy.value()[0]))\n",
    "\n",
    "    train_loss_logger.log(state['epoch'], meter_loss.value()[0])\n",
    "    train_error_logger.log(state['epoch'], meter_accuracy.value()[0])\n",
    "\n",
    "    reset_meters()\n",
    "\n",
    "    engine.test(processor, get_iterator(False))\n",
    "    test_loss_logger.log(state['epoch'], meter_loss.value()[0])\n",
    "    test_accuracy_logger.log(state['epoch'], meter_accuracy.value()[0])\n",
    "    confusion_logger.log(confusion_meter.value())\n",
    "\n",
    "    print('[Epoch %d] Testing Loss: %.4f (Accuracy: %.2f%%)' % (\n",
    "        state['epoch'], meter_loss.value()[0], meter_accuracy.value()[0]))\n",
    "\n",
    "    torch.save(model.state_dict(), 'epochs/epoch_%d.pt' % state['epoch'])\n",
    "    \n",
    "    # Reconstruction visualization\n",
    "    test_sample = next(iter(get_iterator(False)))\n",
    "\n",
    "    ground_truth = (test_sample[0].unsqueeze(1).float() / 255.0)\n",
    "    _, reconstructions = model(Variable(ground_truth).cuda())\n",
    "    reconstruction = reconstructions.cpu().view_as(ground_truth).data\n",
    "\n",
    "    ground_truth_logger.log(\n",
    "        make_grid(ground_truth, nrow=int(batch_size ** 0.5), normalize=True, range=(0, 1)).numpy())\n",
    "    reconstruction_logger.log(\n",
    "        make_grid(reconstruction, nrow=int(batch_size ** 0.5), normalize=True, range=(0, 1)).numpy())\n",
    "\n",
    "# Running it\n",
    "\n",
    "engine.hooks['on_sample'] = on_sample\n",
    "engine.hooks['on_forward'] = on_forward\n",
    "engine.hooks['on_start_epoch'] = on_start_epoch\n",
    "engine.hooks['on_end_epoch'] = on_end_epoch\n",
    "\n",
    "# Training it\n",
    "\n",
    "engine.train(processor, get_iterator(True), maxepoch=num_epochs, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
