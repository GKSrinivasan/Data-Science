{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visdom\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as FXN\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_35a492df975528'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing Visdom server out put\n",
    "vis = visdom.Visdom()\n",
    "vis.text(\"Hello World\")\n",
    "vis.image(np.ones((3, 10, 10)))\n",
    "\n",
    "Y = np.random.rand(100)\n",
    "vis.scatter(\n",
    "    X=np.random.rand(100, 2),\n",
    "    Y=(Y[Y > 0] + 1.5).astype(int),\n",
    "    opts=dict(\n",
    "        legend=['Apples', 'Pears'],\n",
    "        xtickmin=-5,\n",
    "        xtickmax=5,\n",
    "        xtickstep=0.5,\n",
    "        ytickmin=-5,\n",
    "        ytickmax=5,\n",
    "        ytickstep=0.5,\n",
    "        markersymbol='cross-thin-open',\n",
    "    ),\n",
    ")\n",
    "\n",
    "vis.scatter(\n",
    "    X=np.random.rand(100, 3),\n",
    "    Y=(Y + 1.5).astype(int),\n",
    "    opts=dict(\n",
    "        legend=['Men', 'Women'],\n",
    "        markersize=5,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size    = 128\n",
    "num_classes   = 10\n",
    "num_epochs    = 100\n",
    "num_rout_iter = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define softmax function\n",
    "def softmax(input, dim=1):\n",
    "    transposed_input = input.transpose(dim, len(input.size()) -1)\n",
    "    softmaxed_output = FXN.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)))\n",
    "    return softmaxed_output.view(*transposed_input.size()).transpose(dim, len(input.size()) -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define augmentation\n",
    "def augmentation(x, max_shift=2):\n",
    "    _, _, height, width = x.size()\n",
    "\n",
    "    h_shift, w_shift = np.random.randint(-max_shift, max_shift + 1, size=2)\n",
    "    source_height_slice = slice(max(0, h_shift), h_shift + height)\n",
    "    source_width_slice  = slice(max(0, w_shift), w_shift + width)\n",
    "    target_height_slice = slice(max(0, -h_shift), -h_shift + height)\n",
    "    target_width_slice  = slice(max(0, -w_shift), -w_shift + width)\n",
    "\n",
    "    shifted_image = torch.zeros(*x.size())\n",
    "    shifted_image[:, :, source_height_slice, source_width_slice] = x[:, :, target_height_slice, target_width_slice]\n",
    "    return shifted_image.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Capsule Layer Class\n",
    "class capsuleLayer(nn.Module):\n",
    "    def __init__(self, num_capsules, num_route_nodes, in_channels,\n",
    "                 out_channels, kernel_size=None, stride=None, num_iterations=num_rout_iter):\n",
    "        super(capsuleLayer, self).__init__()\n",
    "        \n",
    "        self.num_route_nodes = num_route_nodes\n",
    "        self.num_iterations  = num_iterations\n",
    "        self.num_capsules    = num_capsules\n",
    "        \n",
    "        if num_route_nodes != -1:\n",
    "            self.route_weights = nn.Parameter(torch.randn(num_capsules, num_route_nodes, in_channels, out_channels))\n",
    "        else:\n",
    "            self.capsules = nn.ModuleList(\n",
    "            [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=0) \n",
    "             for _ in range(num_capsules)])\n",
    "    \n",
    "    def squashing(self, tensor, dim=1):\n",
    "        squared_norm = (tensor**2).sum(dim=dim, keepdim=True)\n",
    "        scale        = squared_norm / (1 + squared_norm)\n",
    "        return scale * tensor / torch.sqrt(squared_norm)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.num_route_nodes != -1:\n",
    "            priors = x[None, :, :, None, :] @ self.route_weights[:, None, :, :, :]\n",
    "\n",
    "            logits = Variable(torch.zeros(*priors.size())).cuda()\n",
    "            for i in range(self.num_iterations):\n",
    "                probs = softmax(logits, dim=2)\n",
    "                outputs = self.squash((probs * priors).sum(dim=2, keepdim=True))\n",
    "\n",
    "                if i != self.num_iterations - 1:\n",
    "                    delta_logits = (priors * outputs).sum(dim=-1, keepdim=True)\n",
    "                    logits = logits + delta_logits\n",
    "        else:\n",
    "            outputs = [capsule(x).view(x.size(0), -1, 1) for capsule in self.capsules]\n",
    "            outputs = torch.cat(outputs, dim=-1)\n",
    "            outputs = self.squash(outputs)\n",
    "\n",
    "        return outputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class capsuleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(capsuleNet, self).__init__()\n",
    "\n",
    "        self.conv1            = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9, stride=1)\n",
    "        self.primary_capsules = capsuleLayer(num_capsules=8, num_route_nodes=-1, in_channels=256, out_channels=32,\n",
    "                                             kernel_size=9, stride=2)\n",
    "        self.digit_capsules   = capsuleLayer(num_capsules=num_classes, num_route_nodes=32 * 6 * 6, in_channels=8,\n",
    "                                           out_channels=16)\n",
    "\n",
    "        self.decoder          = nn.Sequential(\n",
    "            nn.Linear(16 * num_classes, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = F.relu(self.conv1(x), inplace=True)\n",
    "        x = self.primary_capsules(x)\n",
    "        x = self.digit_capsules(x).squeeze().transpose(0, 1)\n",
    "\n",
    "        classes = (x ** 2).sum(dim=-1) ** 0.5\n",
    "        classes = F.softmax(classes)\n",
    "\n",
    "        if y is None:\n",
    "            # In all batches, get the most active capsule.\n",
    "            _, max_length_indices = classes.max(dim=1)\n",
    "            y = Variable(torch.sparse.torch.eye(NUM_CLASSES)).cuda().index_select(dim=0, index=max_length_indices.data)\n",
    "\n",
    "        reconstructions = self.decoder((x * y[:, :, None]).view(x.size(0), -1))\n",
    "\n",
    "        return classes, reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class capsuleLoss(nn.Module):\n",
    "    def __inti__(self):\n",
    "        super(capsuleLoss, self).__init()\n",
    "        self.reconstruction_loss = nn.MSELoss(size_average=False)\n",
    "    def forward(self, images, labels, classes, reconstructions):\n",
    "        lef                 = FXN.relu(0.9 - classes, inplace=True) ** 2 \n",
    "        right               = FXN.relu(classes, - 0.1, inplace=True) ** 2\n",
    "        margin_loss         = labels * lef + 0.5 * (1. - labels) * right\n",
    "        margin_loss         = margin_loss.sun()\n",
    "        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n",
    "        \n",
    "        return(margin_loss + 0.0005 * reconstruction_loss) / images.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/pytorch/tnt.git@master\n",
      "  Cloning https://github.com/pytorch/tnt.git (to master) to /tmp/pip-28_hz95j-build\n",
      "Requirement already satisfied: torch in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from torchnet==0.0.1)\n",
      "Requirement already satisfied: six in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from torchnet==0.0.1)\n",
      "Requirement already satisfied: visdom in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from torchnet==0.0.1)\n",
      "Requirement already satisfied: pyyaml in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from torch->torchnet==0.0.1)\n",
      "Requirement already satisfied: numpy in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from torch->torchnet==0.0.1)\n",
      "Requirement already satisfied: pillow in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: pyzmq in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: requests in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: tornado in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: torchfile in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/deeplearn/anaconda3/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.1)\n",
      "Installing collected packages: torchnet\n",
      "  Running setup.py install for torchnet ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed torchnet-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/pytorch/tnt.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torchnet.engine import Engine\n",
    "from torchnet.logger import VisdomPlotLogger, VisdomLogger\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from tqdm import tqdm\n",
    "import torchnet as tnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/THC/generic/THCStorage.cu:66",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7e1566290153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Building and Running the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapsuleNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# parameters: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mcopied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;31m# Variables stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mcopied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/THC/generic/THCStorage.cu:66"
     ]
    }
   ],
   "source": [
    "# Building and Running the model\n",
    "model = capsuleNet()\n",
    "model.cuda()\n",
    "print(\"# parameters: \", sum(param.numel() for param in model.parameters))\n",
    "\n",
    "optimizer = Adam(model.parameters())\n",
    "engine = Engine()\n",
    "meter_loss = tnt.meter.AverageValueMeter()\n",
    "meter_accuracy = tnt.meter.ClassErrorMeter(accuracy=True)\n",
    "confusion_meter = tnt.meter.ConfusionMeter(num_classes, normalized=True)\n",
    "\n",
    "train_loss_logger     = VisdomPlotLogger('line', opts={'title': 'Train Loss'})\n",
    "train_error_logger    = VisdomPlotLogger('line', opts={'title': 'Train Accuracy'})\n",
    "test_loss_logger      = VisdomPlotLogger('line', opts={'title': 'Test Loss'})\n",
    "test_accuracy_logger  = VisdomPlotLogger('line', opts={'title': 'Test Accuracy'})\n",
    "confusion_logger      = VisdomLogger('heatmap', opts={'title': 'Confusion matrix',\n",
    "                                                     'columnnames': list(range(num_classes)),\n",
    "                                                     'rownames': list(range(num_classes))})\n",
    "ground_truth_logger   = VisdomLogger('image', opts={'title': 'Ground Truth'})\n",
    "reconstruction_logger = VisdomLogger('image', opts={'title': 'Reconstruction'})\n",
    "\n",
    "capsule_loss = capsuleLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining a bunch of other functions such as \n",
    "\n",
    "get_iterator\n",
    "processor\n",
    "reset_meters\n",
    "on_sample\n",
    "on_forward\n",
    "on_start_epoch\n",
    "on_end_epoch\n",
    "\n",
    "\"\"\" \n",
    "def get_iterator(mode):\n",
    "        dataset = MNIST(root='./data', download=True, train=mode)\n",
    "        data = getattr(dataset, 'train_data' if mode else 'test_data')\n",
    "        labels = getattr(dataset, 'train_labels' if mode else 'test_labels')\n",
    "        tensor_dataset = tnt.dataset.TensorDataset([data, labels])\n",
    "\n",
    "        return tensor_dataset.parallel(batch_size=BATCH_SIZE, num_workers=4, shuffle=mode)\n",
    "\n",
    "\n",
    "def processor(sample):\n",
    "    data, labels, training = sample\n",
    "\n",
    "    data = augmentation(data.unsqueeze(1).float() / 255.0)\n",
    "    labels = torch.LongTensor(labels)\n",
    "\n",
    "    labels = torch.sparse.torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
    "\n",
    "    data = Variable(data).cuda()\n",
    "    labels = Variable(labels).cuda()\n",
    "\n",
    "    if training:\n",
    "        classes, reconstructions = model(data, labels)\n",
    "    else:\n",
    "        classes, reconstructions = model(data)\n",
    "\n",
    "    loss = capsule_loss(data, labels, classes, reconstructions)\n",
    "\n",
    "    return loss, classes\n",
    "\n",
    "\n",
    "def reset_meters():\n",
    "    meter_accuracy.reset()\n",
    "    meter_loss.reset()\n",
    "    confusion_meter.reset()\n",
    "\n",
    "\n",
    "def on_sample(state):\n",
    "    state['sample'].append(state['train'])\n",
    "\n",
    "\n",
    "def on_forward(state):\n",
    "    meter_accuracy.add(state['output'].data, torch.LongTensor(state['sample'][1]))\n",
    "    confusion_meter.add(state['output'].data, torch.LongTensor(state['sample'][1]))\n",
    "    meter_loss.add(state['loss'].data[0])\n",
    "\n",
    "\n",
    "def on_start_epoch(state):\n",
    "    reset_meters()\n",
    "    state['iterator'] = tqdm(state['iterator'])\n",
    "\n",
    "\n",
    "def on_end_epoch(state):\n",
    "    print('[Epoch %d] Training Loss: %.4f (Accuracy: %.2f%%)' % (\n",
    "        state['epoch'], meter_loss.value()[0], meter_accuracy.value()[0]))\n",
    "\n",
    "    train_loss_logger.log(state['epoch'], meter_loss.value()[0])\n",
    "    train_error_logger.log(state['epoch'], meter_accuracy.value()[0])\n",
    "\n",
    "    reset_meters()\n",
    "\n",
    "    engine.test(processor, get_iterator(False))\n",
    "    test_loss_logger.log(state['epoch'], meter_loss.value()[0])\n",
    "    test_accuracy_logger.log(state['epoch'], meter_accuracy.value()[0])\n",
    "    confusion_logger.log(confusion_meter.value())\n",
    "\n",
    "    print('[Epoch %d] Testing Loss: %.4f (Accuracy: %.2f%%)' % (\n",
    "        state['epoch'], meter_loss.value()[0], meter_accuracy.value()[0]))\n",
    "\n",
    "    torch.save(model.state_dict(), 'epochs/epoch_%d.pt' % state['epoch'])\n",
    "    \n",
    "    # Reconstruction visualization\n",
    "    test_sample = next(iter(get_iterator(False)))\n",
    "\n",
    "    ground_truth = (test_sample[0].unsqueeze(1).float() / 255.0)\n",
    "    _, reconstructions = model(Variable(ground_truth).cuda())\n",
    "    reconstruction = reconstructions.cpu().view_as(ground_truth).data\n",
    "\n",
    "    ground_truth_logger.log(\n",
    "        make_grid(ground_truth, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n",
    "    reconstruction_logger.log(\n",
    "        make_grid(reconstruction, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# engine.hooks['on_sample'] = on_sample\n",
    "# engine.hooks['on_forward'] = on_forward\n",
    "# engine.hooks['on_start_epoch'] = on_start_epoch\n",
    "# engine.hooks['on_end_epoch'] = on_end_epoch\n",
    "\n",
    "# engine.train(processor, get_iterator(True), maxepoch=NUM_EPOCHS, optimizer=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
