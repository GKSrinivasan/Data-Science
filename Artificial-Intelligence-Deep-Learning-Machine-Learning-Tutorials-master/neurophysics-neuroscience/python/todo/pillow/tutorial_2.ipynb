{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Looks like this would be best done with the Spykes package...\n",
    "# It is still in matlab below (except for comment symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tutorial2_spikehistcoupledGLM.m\n",
    "#\n",
    "# This is an interactive tutorial designed to walk you through the steps of\n",
    "# fitting an autoregressive Poisson GLM (i.e., a spiking GLM with\n",
    "# spike-history) and a multivariate autoregressive Poisson GLM (i.e., a\n",
    "# GLM with spike-history AND coupling between neurons).\n",
    "#\n",
    "# (Data from Uzzell & Chichilnisky 2004 see README.txt file in data\n",
    "# directory for details). \n",
    "#\n",
    "# Last updated: Nov 10, 2016 (JW Pillow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instructions: Execute each section below separately using cmd-enter.\n",
    "# For detailed suggestions on how to interact with this tutorial, see\n",
    "# header material in tutorial1_PoissonGLM.m\n",
    "\n",
    "## ====  1. Load the raw data ============\n",
    "\n",
    "datdir = 'data_RGCs/'  # directory where stimulus lives\n",
    "load([datdir, 'Stim'])     # stimulus (temporal binary white noise)\n",
    "load([datdir,'stimtimes']) # stim frame times in seconds (if desired)\n",
    "load([datdir, 'SpTimes'])  # load spike times (in units of stimulus frames)\n",
    "ncells = length(SpTimes)  # number of neurons (4 for this dataset).\n",
    "# Neurons #1-2 are OFF, #3-4 are ON.\n",
    "\n",
    "# Compute some basic statistics on the stimulus\n",
    "dtStim = (stimtimes(2)-stimtimes(1)) # time bin size for stimulus (s)\n",
    "nT = size(Stim,1) # number of time bins in stimulus\n",
    "\n",
    "# See tutorial 1 for some code to visualize the raw data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ==== 2. Bin the spike trains =========================\n",
    "#\n",
    "# For now we will assume we want to use the same time bin size as the time\n",
    "# bins used for the stimulus. Later, though, we'll wish to vary this.\n",
    "tbins = (.5:nT)*dtStim # time bin centers for spike train binnning\n",
    "sps = zeros(nT,ncells)\n",
    "for jj = 1:ncells\n",
    "    sps(:,jj) = hist(SpTimes{jj},tbins)'  # binned spike train\n",
    "end\n",
    "\n",
    "# Let's just visualize the spike-train auto and cross-correlations\n",
    "# (Comment out this part if desired!)\n",
    "clf\n",
    "nlags = 30 # number of time-lags to use \n",
    "for ii = 1:ncells\n",
    "    for jj = ii:ncells\n",
    "        # Compute cross-correlation of neuron i with neuron j\n",
    "        xc = xcorr(sps(:,ii),sps(:,jj),nlags,'unbiased')\n",
    "\n",
    "        # remove center-bin correlation for auto-correlations (for ease of viz)\n",
    "        if ii==jj, xc(nlags+1) = 0\n",
    "        end\n",
    "        \n",
    "        # Make plot\n",
    "        subplot(ncells,ncells,(ii-1)*ncells+jj)\n",
    "        plot((-nlags:nlags)*dtStim,xc,'.-','markersize',20) \n",
    "        axis tight drawnow\n",
    "        title(sprintf('cells (#d,#d)',ii,jj)) axis tight\n",
    "    end\n",
    "end\n",
    "xlabel('time shift (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ==== 3. Build design matrix: single-neuron GLM with spike-history =========\n",
    "\n",
    "# Pick the cell to focus on (for now).\n",
    "cellnum = 3  # 1-2: OFF, 3-4: ON\n",
    "\n",
    "# Set the number of time bins of stimulus to use for predicting spikes\n",
    "ntfilt = 25  # Try varying this, to see how performance changes!\n",
    "# Set number of time bins of auto-regressive spike-history to use\n",
    "nthist = 20\n",
    "\n",
    "# Build stimulus design matrix (using 'hankel')\n",
    "paddedStim = [zeros(ntfilt-1,1) Stim] # pad early bins of stimulus with zero\n",
    "Xstim = hankel(paddedStim(1:end-ntfilt+1), Stim(end-ntfilt+1:end))\n",
    "\n",
    "# Build spike-history design matrix\n",
    "paddedSps = [zeros(nthist,1) sps(1:end-1,cellnum)]\n",
    "# SUPER important: note that this doesn't include the spike count for the\n",
    "# bin we're predicting? The spike train is shifted by one bin (back in\n",
    "# time) relative to the stimulus design matrix\n",
    "Xsp = hankel(paddedSps(1:end-nthist+1), paddedSps(end-nthist+1:end))\n",
    "\n",
    "# Combine these into a single design matrix\n",
    "Xdsgn = [Xstim,Xsp]\n",
    "\n",
    "# Let's visualize the design matrix just to see what it looks like\n",
    "subplot(1,10,1:9) \n",
    "imagesc(1:(ntfilt+nthist), 1:50, Xdsgn(1:50,:))\n",
    "xlabel('regressor')\n",
    "ylabel('time bin of response')\n",
    "title('design matrix (including stim and spike history)')\n",
    "subplot(1,10,10) \n",
    "imagesc(sps(1:50,cellnum))\n",
    "set(gca,'yticklabel', []) \n",
    "title('spike count')\n",
    "\n",
    "# The left part of the design matrix has the stimulus values, the right\n",
    "# part has the spike-history values.  The image on the right is the spike\n",
    "# count to be predicted.  Note that the spike-history portion of the design\n",
    "# matrix had better be shifted so that we aren't allowed to use the spike\n",
    "# count on this time bin to predict itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## === 4. fit single-neuron GLM with spike-history ==================\n",
    "\n",
    "# First fit GLM with no spike-history\n",
    "fprintf('Now fitting basic Poisson GLM...\\n')\n",
    "pGLMwts0 = glmfit(Xstim,sps(:,cellnum),'poisson') # assumes 'log' link and 'constant'='on'.\n",
    "pGLMconst0 = pGLMwts0(1)\n",
    "pGLMfilt0 = pGLMwts0(2:end)\n",
    "\n",
    "# Then fit GLM with spike history (now use Xdsgn design matrix instead of Xstim)\n",
    "fprintf('Now fitting Poisson GLM with spike-history...\\n')\n",
    "pGLMwts1 = glmfit(Xdsgn,sps(:,cellnum),'poisson')\n",
    "pGLMconst1 = pGLMwts1(1)\n",
    "pGLMfilt1 = pGLMwts1(2:1+ntfilt)\n",
    "pGLMhistfilt1 = pGLMwts1(ntfilt+2:end)\n",
    "\n",
    "##  Make plots comparing filters\n",
    "ttk = (-ntfilt+1:0)*dtStim # time bins for stim filter\n",
    "tth = (-nthist:-1)*dtStim # time bins for spike-history filter\n",
    "\n",
    "clf subplot(221) # Plot stim filters\n",
    "h = plot(ttk,ttk*0,'k--',ttk,pGLMfilt0, 'o-',ttk,pGLMfilt1,'o-','linewidth',2)\n",
    "legend(h(2:3), 'GLM', 'sphist-GLM','location','northwest')axis tight\n",
    "title('stimulus filters') ylabel('weight')\n",
    "xlabel('time before spike (s)')\n",
    "\n",
    "subplot(222) # Plot spike history filter\n",
    "colr = get(h(3),'color')\n",
    "h = plot(tth,tth*0,'k--',tth,pGLMhistfilt1, 'o-')\n",
    "set(h(2), 'color', colr, 'linewidth', 2) \n",
    "title('spike history filter') \n",
    "xlabel('time before spike (s)')\n",
    "ylabel('weight') axis tight\n",
    "\n",
    "## Plot predicted rate out of the two models\n",
    "\n",
    "# Compute predicted spike rate on training data\n",
    "ratepred0 = exp(pGLMconst0 + Xstim*pGLMfilt0)\n",
    "ratepred1 = exp(pGLMconst1 + Xdsgn*pGLMwts1(2:end))\n",
    "\n",
    "# Make plot\n",
    "iiplot = 1:60 ttplot = iiplot*dtStim\n",
    "subplot(212)\n",
    "stem(ttplot,sps(iiplot,cellnum), 'k') hold on\n",
    "plot(ttplot,ratepred0(iiplot),ttplot,ratepred1(iiplot), 'linewidth', 2)\n",
    "hold off  axis tight\n",
    "legend('spikes', 'GLM', 'hist-GLM')\n",
    "xlabel('time (s)')\n",
    "title('spikes and rate predictions')\n",
    "ylabel('spike count / bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## === 5. fit coupled GLM for multiple-neuron responses ==================\n",
    "\n",
    "# First step: build design matrix containing spike history for all neurons\n",
    "\n",
    "Xspall = zeros(nT,nthist,ncells) # allocate space\n",
    "# Loop over neurons to build design matrix, exactly as above\n",
    "for jj = 1:ncells\n",
    "    paddedSps = [zeros(nthist,1) sps(1:end-1,jj)]\n",
    "    Xspall(:,:,jj) = hankel(paddedSps(1:end-nthist+1),paddedSps(end-nthist+1:end))\n",
    "end\n",
    "\n",
    "# Reshape it to be a single matrix\n",
    "Xspall = reshape(Xspall,nT,[])\n",
    "Xdsgn2 = [Xstim, Xspall] # full design matrix (with all 4 neuron spike hist)\n",
    "\n",
    "clf # Let's visualize 50 time bins of full design matrix\n",
    "imagesc(1:1:(ntfilt+nthist*ncells), 1:50, Xdsgn2(1:50,:))\n",
    "title('design matrix (stim and 4 neurons spike history)')\n",
    "xlabel('regressor')\n",
    "ylabel('time bin of response')\n",
    "\n",
    "## Fit the model (stim filter, sphist filter, coupling filters) for one neuron \n",
    "\n",
    "fprintf('Now fitting Poisson GLM with spike-history and coupling...\\n')\n",
    "\n",
    "pGLMwts2 = glmfit(Xdsgn2,sps(:,cellnum),'poisson')\n",
    "pGLMconst2 = pGLMwts2(1)\n",
    "pGLMfilt2 = pGLMwts2(2:1+ntfilt)\n",
    "pGLMhistfilts2 = pGLMwts2(ntfilt+2:end)\n",
    "pGLMhistfilts2 = reshape(pGLMhistfilts2,nthist,ncells)\n",
    "\n",
    "# So far all we've done is fit incoming stimulus and coupling filters for\n",
    "# one neuron.  To fit a full population model, redo the above for each cell\n",
    "# (i.e., to get incoming filters for 'cellnum' = 1, 2, 3, and 4 in turn).  \n",
    "\n",
    "\n",
    "## Plot the fitted filters and rate prediction\n",
    "\n",
    "clf subplot(221) # Plot stim filters\n",
    "h = plot(ttk,ttk*0,'k--',ttk,pGLMfilt0, 'o-',ttk,pGLMfilt1,...\n",
    "    ttk,pGLMfilt2,'o-','linewidth',2) axis tight \n",
    "legend(h(2:4), 'GLM', 'sphist-GLM','coupled-GLM', 'location','northwest')\n",
    "title(['stimulus filter: cell ' num2str(cellnum)]) ylabel('weight') \n",
    "xlabel('time before spike (s)')\n",
    "\n",
    "subplot(222) # Plot spike history filter\n",
    "colr = get(h(3),'color')\n",
    "h = plot(tth,tth*0,'k--',tth,pGLMhistfilts2,'linewidth',2)\n",
    "legend(h(2:end),'from 1', 'from 2', 'from 3', 'from 4', 'location', 'northwest')\n",
    "title(['coupling filters: into cell ' num2str(cellnum)]) axis tight\n",
    "xlabel('time before spike (s)')\n",
    "ylabel('weight')\n",
    "\n",
    "# Compute predicted spike rate on training data\n",
    "ratepred2 = exp(pGLMconst2 + Xdsgn2*pGLMwts2(2:end))\n",
    "\n",
    "# Make plot\n",
    "iiplot = 1:60 ttplot = iiplot*dtStim\n",
    "subplot(212)\n",
    "stem(ttplot,sps(iiplot,cellnum), 'k') hold on\n",
    "plot(ttplot,ratepred0(iiplot),ttplot,ratepred1(iiplot),...\n",
    "    ttplot,ratepred2(iiplot), 'linewidth', 2)\n",
    "hold off  axis tight\n",
    "legend('spikes', 'GLM', 'sphist-GLM', 'coupled-GLM', 'location', 'northwest')\n",
    "xlabel('time (s)')\n",
    "title('spikes and rate predictions')\n",
    "ylabel('spike count / bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 6. Model comparison: log-likelihoood and AIC\n",
    "\n",
    "# Let's compute loglikelihood (single-spike information) and AIC to see how\n",
    "# much we gain by adding each of these filter types in turn:\n",
    "\n",
    "LL_stimGLM = sps(:,cellnum)'*log(ratepred0) - sum(ratepred0)\n",
    "LL_histGLM = sps(:,cellnum)'*log(ratepred1) - sum(ratepred1)\n",
    "LL_coupledGLM = sps(:,cellnum)'*log(ratepred2) - sum(ratepred2)\n",
    "\n",
    "# log-likelihood for homogeneous Poisson model\n",
    "nsp = sum(sps(:,cellnum))\n",
    "ratepred_const = nsp/nT  # mean number of spikes / bin\n",
    "LL0 = nsp*log(ratepred_const) - nT*sum(ratepred_const)\n",
    "\n",
    "# Report single-spike information (bits / sp)\n",
    "SSinfo_stimGLM = (LL_stimGLM - LL0)/nsp/log(2)\n",
    "SSinfo_histGLM = (LL_histGLM - LL0)/nsp/log(2)\n",
    "SSinfo_coupledGLM = (LL_coupledGLM - LL0)/nsp/log(2)\n",
    "\n",
    "fprintf('\\n empirical single-spike information:\\n ---------------------- \\n')\n",
    "fprintf('stim-GLM: #.2f bits/sp\\n',SSinfo_stimGLM)\n",
    "fprintf('hist-GLM: #.2f bits/sp\\n',SSinfo_histGLM)\n",
    "fprintf('coupled-GLM: #.2f bits/sp\\n',SSinfo_coupledGLM)\n",
    "\n",
    "# Compute AIC\n",
    "AIC0 = -2*LL_stimGLM + 2*(1+ntfilt) \n",
    "AIC1 = -2*LL_histGLM + 2*(1+ntfilt+nthist)\n",
    "AIC2 = -2*LL_coupledGLM + 2*(1+ntfilt+ncells*nthist)\n",
    "AICmin = min([AIC0,AIC1,AIC2]) # the minimum of these\n",
    "\n",
    "fprintf('\\n AIC comparison (smaller is better):\\n ---------------------- \\n')\n",
    "fprintf('stim-GLM: #.1f\\n',AIC0-AICmin)\n",
    "fprintf('hist-GLM: #.1f\\n',AIC1-AICmin)\n",
    "fprintf('coupled-GLM: #.1f\\n',AIC2-AICmin)\n",
    "\n",
    "# These are whopping differencess! Clearly coupling has a big impact in\n",
    "# terms of log-likelihood, though the jump from stimulus-only to\n",
    "# own-spike-history is greater than the jump from spike-history to\n",
    "# full coupling.\n",
    "\n",
    "\n",
    "## Advanced exercises:\n",
    "# --------------------\n",
    "# 1. Write code to simulate spike trains from the fitted spike-history GLM.\n",
    "# Simulate a raster of repeated responses from the stim-only GLM and\n",
    "# compare to raster from the spike-history GLM\n",
    "\n",
    "# 2. Write code to simulate the 4-neuron population-coupled GLM. There are\n",
    "# now 16 spike-coupling filters (including self-coupling), since each\n",
    "# neuron has 4 incoming coupling filters (its own spike history coupling\n",
    "# filter plus coupling from three other neurons.  How does a raster of\n",
    "# responses from this model compare to the two single-neuron models?\n",
    "\n",
    "# 3. Compute a non-parametric estimate of the spiking nonlinearity for each\n",
    "# neuron. How close does it look to exponential now that we have added\n",
    "# spike history? Rerun your simulations using different non-parametric\n",
    "# nonlinearity for each neuron. How much improvement do you see in terms of\n",
    "# log-likelihood, AIC, or PSTH # variance accounted for (R^2) when you\n",
    "# simulate repeated responses?"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
