rm(list=ls(all=TRUE))

#setwd("~/Desktop/GNQ3 Machine   Learning/20170212_Batch25_CSE7405c_EnsembleLab")

# Load required libraries
#library(vegan)
#library(dummies)
#library(ada) 
#library(rpart)
#library(ROCR)
#library(C50)
#library(randomForest)
#library(e1071)
#library(h2o)
#library(DMwR)

if (!"install.load" %in% rownames(installed.packages()))
  install.packages("install.load")
library(install.load)
#install the required packages
pkgs_to_install_load <- c("readr","dplyr","tidyr","lubridate","ggplot2","car",
                          "Hmisc","ROCR","caret","dummies","caTools",
                          "MASS", "gridExtra", "e1071", "klaR", "arules", "class", "scales", 
                          "purrr","kernlab","doParallel","png","vegan","dummies","ada","rpart","ROCR","C50","randomForest",
                          "e1071","h2o","DMwR","xgboost")
sapply(pkgs_to_install_load,install_load)



#install.packages("ada")
attr = c('id', 'age', 'exp', 'inc', 'zip', 'family', 
         'ccavg', 'edu', 'mortgage', 'loan', 
         'securities', 'cd', 'online', 'cc')

# Read the data using csv file
data = read.csv(file = "UniversalBank.csv", 
                header = TRUE, col.names = attr)

# Removing the id, zip and experience. 
drop_Attr = c("id", "zip", "exp")
attr = setdiff(attr, drop_Attr)
data = data[, attr]
rm(drop_Attr)

# Convert attribute to appropriate type  
cat_Attr = c("family", "edu", "securities", 
             "cd", "online", "cc", "loan")
num_Attr = setdiff(attr, cat_Attr)
rm(attr)

cat_Data <- data.frame(sapply(data[,cat_Attr], as.factor))
num_Data <- data.frame(sapply(data[,num_Attr], as.numeric))

data = cbind(num_Data, cat_Data)
rm(cat_Data, num_Data)

# Do the summary statistics and check for missing values and outliers.
summary(data)

#------------------------------------------------------

# Build the classification model.
ind_Num_Attr = num_Attr
rm(num_Attr)
ind_Cat_Attr = setdiff(cat_Attr, "loan")
rm(cat_Attr)

# Standardizing the numeric data
cla_Data = decostand(data[,ind_Num_Attr], "range") 
rm(ind_Num_Attr)

# Convert all categorical attributes to numeric 
# 1. Using dummy function, convert education and family categorical attributes into numeric attributes 
edu = dummy(data$edu)
family = dummy(data$family)
cla_Data = cbind(cla_Data, edu, family)
ind_Cat_Attr = setdiff(ind_Cat_Attr, c("edu", "family"))
rm(edu, family)

# 2. Using as.numeric function, convert remaining categorical attributes into numeric attributes 
cla_Data = cbind(cla_Data, sapply(data[,ind_Cat_Attr], as.numeric))
rm(ind_Cat_Attr)
ind_Attr = names(cla_Data)

# Append the Target attribute 
cla_Data = cbind(cla_Data, loan=data[,"loan"]) 

str(cla_Data)
summary(cla_Data)

# Divide the data into test and train
set.seed(123)

train_RowIDs = sample(1:nrow(cla_Data), nrow(cla_Data)*0.6)
train_Data = cla_Data[train_RowIDs,]
test_Data = cla_Data[-train_RowIDs,]
rm(train_RowIDs)

# Check how records are split with respect to target attribute.
table(cla_Data$loan)
table(train_Data$loan)
table(test_Data$loan)
rm(cla_Data)




# Convert taget attribute as factor
train_Data$loan<-as.factor(as.character(train_Data$loan))



# Build Logistic regression and interpret the results
LogReg <- glm(loan ~ ., data=train_Data, family=binomial)
summary(LogReg)

# train results
prob<-predict(LogReg, type="response")
pred_class <- ifelse(prob> 0.5, 1, 0)
table(train_Data$loan,pred_class)

# Test results 
fitted.results <- predict(LogReg,test_Data,type='response')
fitted.class <- ifelse(fitted.results > 0.5,1,0)
table(test_Data$loan,fitted.class)



#As a last step, we are going to plot the ROC curve and calculate the AUC 
#(area under the curve) which are typical performance measurements 
#for a binary classifier.
#The ROC (Receiver Operating Characteristic curve) is a curve generated by plotting the true positive rate (TPR = sensitivity) against
# the false positive rate (FPR= specificity) at various threshold settings while the AUC is
# the area under the ROC curve. As a rule of thumb, a model with good 
#predictive ability should have an AUC closer to 1 (1 is ideal) than to 0.5.



p <- predict(LogReg,test_Data, type="response")
pr <- prediction(p, test_Data$loan)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf,colorize = TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))

abline(a=0, b= 1)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc  # very low


# Error Metric

conf.mat = table(test_Data$loan,fitted.class)
accuracy = sum(diag(conf.mat))/sum(conf.mat)
precision = conf.mat[2,2]/sum(conf.mat[,2])
recall = conf.mat[2,2]/sum(conf.mat[2,])

cat("Confusion Matrix : ")
conf.mat
cat("Accuracy : ",accuracy)
cat("Precision : ",precision)
cat("Recall : ",recall)










# Classification Trees using CART 
dtCart=rpart(loan~., data=train_Data, method="class")    
plot(dtCart,main="Classification Tree for loan Class",margin=0.15,uniform=TRUE)
text(dtCart,use.n=T)
summary(dtCart)

a = table(train_Data$loan, predict(dtCart, newdata=train_Data, type="class"))
(a[2,2])/(a[2,1]+a[2,2])*100

# Classification Trees using C5.0 

dtC50 = C5.0(loan ~ ., data = train_Data, rules=TRUE)
summary(dtC50)
C5imp(dtC50, pct=TRUE)


a=table(train_Data$loan, predict(dtC50, newdata=train_Data, type="class"))
rcTrain=(a[2,2])/(a[2,1]+a[2,2])*100
a=table(test_Data$loan, predict(dtC50, newdata=test_Data, type="class"))
rcTest=(a[2,2])/(a[2,1]+a[2,2])*100


cat("Recall in Training", rcTrain, '\n',
    "Recall in Testing", rcTest
)


#RandomForest


# Build the classification model using randomForest
set.seed(123)
#keep.forest=TRUE keep the rules as it is to test in test data 
model = randomForest(train_Data$loan ~ ., data=train_Data, 
                     keep.forest=TRUE, ntree=50) 

# Print and understand the model
print(model)

# Important attributes

model$importance  
round(importance(model), 2)   

# Extract and store important variables obtained from the random forest model
rf_Imp_Attr = data.frame(model$importance)
rf_Imp_Attr = data.frame(row.names(rf_Imp_Attr),rf_Imp_Attr[,1])
colnames(rf_Imp_Attr) = c('Attributes', 'Importance')
rf_Imp_Attr = rf_Imp_Attr[order(rf_Imp_Attr$Importance, decreasing = TRUE),]

# plot (directly prints the important attributes) 
varImpPlot(model)


# Predict on Train data 
pred_Train = predict(model, train_Data[,setdiff(names(train_Data),"loan")],
                     type="response", norm.votes=TRUE)


# Build confusion matrix and find accuracy   
cm_Train = table("actual"= train_Data$loan, "predicted" = pred_Train);
accu_Train= sum(diag(cm_Train))/sum(cm_Train)
rm(pred_Train, cm_Train)

# Predicton Test Data
pred_Test = predict(model, test_Data[,setdiff(names(test_Data),"loan")],
                    type="response", norm.votes=TRUE)

# Build confusion matrix and find accuracy   
cm_Test = table("actual"= test_Data$loan, "predicted" = pred_Test);
accu_Test= sum(diag(cm_Test))/sum(cm_Test)
rm(pred_Test, cm_Test)

accu_Train
accu_Test

# Build randorm forest using top 9 important attributes. 
top_Imp_Attr = as.character(rf_Imp_Attr$Attributes[1:9])

# Build the classification model using randomForest
model_Imp = randomForest(train_Data$loan ~ ., data=train_Data[,c(top_Imp_Attr,"loan")], 
                         keep.forest=TRUE, ntree=50) 

# Print and understand the model
print(model_Imp)

# Important attributes
model_Imp$importance  

# Predict on Train data 
pred_Train = predict(model_Imp, train_Data[,top_Imp_Attr],
                     type="response", norm.votes=TRUE)


# Build confusion matrix and find accuracy   
cm_Train = table("actual"= train_Data$loan, "predicted" = pred_Train);
accu_Train_Imp = sum(diag(cm_Train))/sum(cm_Train)
rm(pred_Train, cm_Train)

# Predicton Test Data
pred_Test = predict(model_Imp, test_Data[,top_Imp_Attr],
                    type="response", norm.votes=TRUE)

# Build confusion matrix and find accuracy   
cm_Test = table("actual"= test_Data$loan, "predicted" = pred_Test);
accu_Test_Imp = sum(diag(cm_Test))/sum(cm_Test)
rm(pred_Test, cm_Test)

accu_Train
accu_Test
accu_Train_Imp
accu_Test_Imp

top_Imp_Attr = as.character(rf_Imp_Attr$Attributes[1:9])

# Build the classification model using randomForest
model_Imp = randomForest(loan ~ ., data=train_Data[,c(top_Imp_Attr,"loan")], 
                         keep.forest=TRUE, ntree=50) 

# Print and understand the model
print(model_Imp)

# Important attributes
model_Imp$importance  

# Predict on Train data 
pred_Train = predict(model_Imp, train_Data[,top_Imp_Attr],
                     type="response", norm.votes=TRUE)


# Build confusion matrix and find accuracy   
cm_Train = table("actual"= train_Data$loan, "predicted" = pred_Train);
accu_Train_Imp = sum(diag(cm_Train))/sum(cm_Train)
rm(pred_Train, cm_Train)

# Predicton Test Data
pred_Test = predict(model_Imp, test_Data[,top_Imp_Attr],
                    type="response", norm.votes=TRUE)

# Build confusion matrix and find accuracy   
cm_Test = table("actual"= test_Data$loan, "predicted" = pred_Test);
accu_Test_Imp = sum(diag(cm_Test))/sum(cm_Test)
rm(pred_Test, cm_Test)

accu_Train
accu_Test
accu_Train_Imp
accu_Test_Imp








###################################################

model = svm(x = train_Data[,ind_Attr], 
            y = train_Data$loan, 
            type = "C-classification", 
            kernel = "linear", cost = 10, gamma = 0.1) 

# Look at the model summary
summary(model)

model$index

plot(cmdscale(dist(train_Data[,ind_Attr])),
     col = as.integer(train_Data$loan),
     pch = c("o","+")[1:nrow(train_Data) %in% model$index + 1])

# Predict on train data  
pred_Train  =  predict(model, train_Data[,ind_Attr])  

# Build confusion matrix and find accuracy   
cm_Train = table(train_Data$loan, pred_Train)
accu_Train= sum(diag(cm_Train))/sum(cm_Train)
rm(pred_Train, cm_Train)

# Predict on test data
pred_Test = predict(model, test_Data[,ind_Attr]) 

# Build confusion matrix and find accuracy   
cm_Test = table(test_Data$loan, pred_Test)
accu_Test= sum(diag(cm_Test))/sum(cm_Test)
rm(pred_Test, cm_Test)

accu_Train
accu_Test

rm(model, accu_Test, accu_Train, ind_Attr, train_Data, test_Data)



#####################################################

#XGBOOST
attr = c('id', 'age', 'exp', 'inc', 'zip', 'family', 
         'ccavg', 'edu', 'mortgage', 'loan', 
         'securities', 'cd', 'online', 'cc')

# Read the data using csv file
data = read.csv(file = "UniversalBank.csv", 
                header = TRUE, col.names = attr)

# Removing the id, zip and experience. 
drop_Attr = c("id", "zip", "exp")
attr = setdiff(attr, drop_Attr)
data = data[, attr]
rm(drop_Attr)

# Convert attribute to appropriate type  
cat_Attr = c("family", "edu", "securities", 
             "cd", "online", "cc", "loan")
num_Attr = setdiff(attr, cat_Attr)
rm(attr)

cat_Data <- data.frame(sapply(data[,cat_Attr], as.factor))
num_Data <- data.frame(sapply(data[,num_Attr], as.numeric))

data = cbind(num_Data, cat_Data)
rm(cat_Data, num_Data)

# Do the summary statistics and check for missing values and outliers.
summary(data)
#------------------------------------------------------

# Build the xgboost classification model.

# Standardizing the numeric data
final_Data = decostand(data[,num_Attr], "range") 
rm(num_Attr)

# Convert all categorical attributes to numeric 
# 1. Using dummy function, convert education and family categorical attributes into numeric attributes 
edu = dummy(data$edu)
family = dummy(data$family)
final_Data = cbind(final_Data, edu, family)
cat_Attr = setdiff(cat_Attr, c("edu", "family"))
rm(edu, family)

# 2. Using as.numeric function, convert remaining categorical attributes into numeric attributes 
final_Data = cbind(final_Data, sapply(data[,cat_Attr], 
                                      function(x){as.numeric(as.character(x))}))
rm(cat_Attr)

ind_Attr = setdiff(names(final_Data), "loan")

str(final_Data)
summary(final_Data)
# Divide the data into test, train and eval
set.seed(123)

rowIDs = 1:nrow(final_Data)
train_RowIDs =  sample(rowIDs, length(rowIDs)*0.6)
test_RowIDs = sample(setdiff(rowIDs, train_RowIDs), length(rowIDs)*0.2)
eval_RowIDs = setdiff(rowIDs, c(train_RowIDs, test_RowIDs))
rm(rowIDs)

train_Data = final_Data[train_RowIDs,]
test_Data = final_Data[test_RowIDs,]
eval_Data = final_Data[eval_RowIDs,]
rm(train_RowIDs, test_RowIDs, eval_RowIDs)

# Check how records are split with respect to target attribute.
table(final_Data$loan)
table(train_Data$loan)
table(test_Data$loan)
table(eval_Data$loan)
rm(final_Data)

# fit the model
dtrain = xgb.DMatrix(data = as.matrix(train_Data[,ind_Attr]),
                     label = train_Data$loan)
model = xgboost(data = dtrain, max.depth = 2, 
                eta = 1, nthread = 2, nround = 2, 
                objective = "binary:logistic", verbose = 1)

# objective = "binary:logistic": we will train a binary classification model ;
# max.deph = 2: the trees won't be deep, because our case is very simple ;
# nthread = 2: the number of cpu threads we are going to use;
# nround = 2: there will be two passes on the data
# eta = 1: It controls the learning rate
# verbose = 1: print evaluation metric

# Both xgboost (simple) and xgb.train (advanced) functions train models.

# Because of the way boosting works, there is a time when having too many rounds lead to an overfitting. One way to measure progress in learning of a model is to provide to XGBoost a second dataset already classified. Therefore it can learn on the first dataset and test its model on the second one. Some metrics are measured after each round during the learning.

#Use watchlist parameter. It is a list of xgb.DMatrix, each of them tagged with a name.
dtest = xgb.DMatrix(data = as.matrix(test_Data[,ind_Attr]),
                    label = test_Data$loan)

watchlist = list(train=dtrain, test=dtest)

model = xgb.train(data=dtrain, max.depth=2,
                  eta=1, nthread = 2, nround=25, 
                  watchlist=watchlist,
                  eval.metric = "error", 
                  objective = "binary:logistic")
# eval.metric allows us to monitor two new metrics for each round, logloss and error.

importance <- xgb.importance(feature_names = ind_Attr, model = model)
print(importance)
xgb.plot.importance(importance_matrix = importance)

# Gain is the improvement in accuracy brought by a feature to the branches it is on. 
# Cover measures the relative quantity of observations concerned by a feature.
# Frequency is the number of times a feature is used in all generated trees. 

# save model to binary local file
xgb.save(model, "xgboost.model")
rm(model)

# load binary model to R
model <- xgb.load("xgboost.model")

# predict
pred <- predict(model, as.matrix(eval_Data[,ind_Attr]))

# size of the prediction vector
print(length(pred))

# limit display of predictions to the first 10
print(head(pred))

# The numbers we get are probabilities that a datum will be classified as 1. 
# Therefore, we will set the rule that if this probability for a 
# specific datum is > 0.5 then the observation is classified as 1 (or 0 otherwise).

prediction <- as.numeric(pred > 0.5)
print(head(prediction))


###############################################



# Build best ada boost model 
model = ada(x = train_Data[,ind_Attr], 
            y = train_Data$loan, 
            iter=20, loss="logistic",verbose=TRUE) # 20 Iterations 

# Look at the model summary
model
summary(model)

# Predict on train data  
pred_Train  =  predict(model, train_Data[,ind_Attr])  

# Build confusion matrix and find accuracy   
cm_Train = table(train_Data$loan, pred_Train)
accu_Train= sum(diag(cm_Train))/sum(cm_Train)
rm(pred_Train, cm_Train)

# Predict on test data
pred_Test = predict(model, test_Data[,ind_Attr]) 

# Build confusion matrix and find accuracy   
cm_Test = table(test_Data$loan, pred_Test)
accu_Test= sum(diag(cm_Test))/sum(cm_Test)
rm(pred_Test, cm_Test)

accu_Train
accu_Test

rm(model, accu_Test, accu_Train, ind_Attr, train_Data, test_Data)


#################################################################################################

attr = c('id', 'age', 'exp', 'inc', 'zip', 'family', 
         'ccavg', 'edu', 'mortgage', 'loan', 
         'securities', 'cd', 'online', 'cc')

# Read the data using csv file
data = read.csv(file = "UniversalBank.csv", 
                header = TRUE, col.names = attr)

# Removing the id, zip and experience. 
drop_Attr = c("id", "zip", "exp")
attr = setdiff(attr, drop_Attr)
data = data[, attr]
rm(drop_Attr)

# Convert attribute to appropriate type  
cat_Attr = c("family", "edu", "securities", 
             "cd", "online", "cc", "loan")
num_Attr = setdiff(attr, cat_Attr)
rm(attr)

cat_Data <- data.frame(sapply(data[,cat_Attr], as.factor))
num_Data <- data.frame(sapply(data[,num_Attr], as.numeric))

data = cbind(num_Data, cat_Data)
rm(cat_Data, num_Data, cat_Attr, num_Attr)

# Do the summary statistics and check for missing values and outliers.
summary(data)

# Divide the data in to test and train
set.seed(123)
train_rowIDs = sample(1:nrow(data), nrow(data)*.8)
train = data[train_rowIDs,] 
test = data[-train_rowIDs,] 

rm(data, train_rowIDs)

# Load H2o library


# Start H2O on the local machine using all available cores and with 4 gigabytes of memory
h2o.init(nthreads = -1, max_mem_size = "2g")

# Import a local R train data frame to the H2O cloud
train.hex <- as.h2o(x = train, destination_frame = "train.hex")


# Prepare the parameters for the for H2O gbm grid search
ntrees_opt <- c(5, 10, 15, 20, 30)
maxdepth_opt <- c(2, 3, 4, 5)
learnrate_opt <- c(0.01, 0.05, 0.1, 0.15 ,0.2, 0.25)
hyper_parameters <- list(ntrees = ntrees_opt, 
                         max_depth = maxdepth_opt, 
                         learn_rate = learnrate_opt)

# Build H2O GBM with grid search
grid_GBM <- h2o.grid(algorithm = "gbm", grid_id = "grid_GBM.hex",
                     hyper_params = hyper_parameters, 
                     y = "loan", x = setdiff(names(train.hex), "loan"),
                     training_frame = train.hex)

# Remove unused R objects
rm(ntrees_opt, maxdepth_opt, learnrate_opt, hyper_parameters)

# Get grid summary
summary(grid_GBM)

# Fetch GBM grid models
grid_GBM_models <- lapply(grid_GBM@model_ids, 
                          function(model_id) { h2o.getModel(model_id) })

# Function to find the best model with respective to AUC
find_Best_Model <- function(grid_models){
  best_model = grid_models[[1]]
  best_model_AUC = h2o.auc(best_model)
  for (i in 2:length(grid_models)) 
  {
    temp_model = grid_models[[i]]
    temp_model_AUC = h2o.auc(temp_model)
    if(best_model_AUC < temp_model_AUC)
    {
      best_model = temp_model
      best_model_AUC = temp_model_AUC
    }
  }
  return(best_model)
}

# Find the best model by calling find_Best_Model Function
best_GBM_model = find_Best_Model(grid_GBM_models)

rm(grid_GBM_models)

# Get the auc of the best GBM model
best_GBM_model_AUC = h2o.auc(best_GBM_model)

# Examine the performance of the best model
best_GBM_model

# View the specified parameters of the best model
best_GBM_model@parameters

# Important Variables.
varImp_GBM <- h2o.varimp(best_GBM_model)

# Import a local R test data frame to the H2O cloud
test.hex <- as.h2o(x = test, destination_frame = "test.hex")


# Predict on same training data set
predict.hex = h2o.predict(best_GBM_model, 
                          newdata = test.hex[,setdiff(names(test.hex), "loan")])

data_GBM = h2o.cbind(test.hex[,"loan"], predict.hex)

# Copy predictions from H2O to R
pred_GBM = as.data.frame(data_GBM)

# Shutdown H2O
h2o.shutdown(F)

# Hit Rate and Penetration calculation
conf_Matrix_GBM = table(pred_GBM$loan, pred_GBM$predict) 

Accuracy = (conf_Matrix_GBM[1,1]+conf_Matrix_GBM[2,2])/sum(conf_Matrix_GBM)


##################################################################################################
##Regression
#install.packages("ada")
attr = c('id', 'age', 'exp', 'inc', 'zip', 'family', 
         'ccavg', 'edu', 'mortgage', 'loan', 
         'securities', 'cd', 'online', 'cc')

# Read the data using csv file
data = read.csv(file = "UniversalBank.csv", 
                header = TRUE, col.names = attr)

# Removing the id, zip and experience. 
drop_Attr = c("id", "zip", "exp")
attr = setdiff(attr, drop_Attr)
data = data[, attr]
rm(drop_Attr)

# Convert attribute to appropriate type  
cat_Attr = c("family", "edu", "securities", 
             "cd", "online", "cc", "loan")
num_Attr = setdiff(attr, cat_Attr)
rm(attr)

cat_Data <- data.frame(sapply(data[,cat_Attr], as.factor))
num_Data <- data.frame(sapply(data[,num_Attr], as.numeric))

data = cbind(num_Data, cat_Data)
rm(cat_Data, num_Data)

# Do the summary statistics and check for missing values and outliers.
summary(data)

#------------------------------------------------------

# Build the classification model.
ind_Num_Attr = num_Attr
rm(num_Attr)
ind_Cat_Attr = setdiff(cat_Attr, "loan")
rm(cat_Attr)

# Standardizing the numeric data
cla_Data = decostand(data[,ind_Num_Attr], "range") 
rm(ind_Num_Attr)

# Convert all categorical attributes to numeric 
# 1. Using dummy function, convert education and family categorical attributes into numeric attributes 
edu = dummy(data$edu)
family = dummy(data$family)
cla_Data = cbind(cla_Data, edu, family)
ind_Cat_Attr = setdiff(ind_Cat_Attr, c("edu", "family"))
rm(edu, family)

# 2. Using as.numeric function, convert remaining categorical attributes into numeric attributes 
cla_Data = cbind(cla_Data, sapply(data[,ind_Cat_Attr], as.numeric))
rm(ind_Cat_Attr)
ind_Attr = names(cla_Data)

# Append the Target attribute 
cla_Data = cbind(cla_Data, loan=data[,"loan"]) 

str(cla_Data)
summary(cla_Data)

# Divide the data into test and train
set.seed(123)

train_RowIDs = sample(1:nrow(cla_Data), nrow(cla_Data)*0.6)
train_Data = cla_Data[train_RowIDs,]
test_Data = cla_Data[-train_RowIDs,]
rm(train_RowIDs)


#Input all attributes into model 
LinReg3<- lm(inc ~ ., data=train_Data)
summary(LinReg3)

# Error metrics evaluation on train data and test data

#Error verification on train data
regr.eval(train_Data$inc, LinReg3$fitted.values) 
#Error verification on test data
Pred<-predict(LinReg3,test_Data)
regr.eval(test_Data$inc, Pred)





# Regression Trees using CART 
dtCart = rpart(inc ~., data=train_Data, method="anova")    
plot(dtCart, main="Decision Tree for Income", margin=0.15, uniform=TRUE,)
text(dtCart, use.n=T)

predCartTrain = predict(dtCart, newdata=train_Data, type="vector")
predCartTest = predict(dtCart, newdata=test_Data, type="vector")


regr.eval(train_Data[,"inc"], predCartTrain, train.y = train_Data[,"inc"])
regr.eval(test_Data[,"inc"], predCartTest, train.y = train_Data[,"inc"])


dtCart=rpart(inc ~.,data=train_Data,method="anova", cp=0.001)

predCartTrain = predict(dtCart, newdata=train_Data, type="vector")
predCartTest = predict(dtCart, newdata=test_Data, type="vector")

regr.eval(train_Data[,"inc"], predCartTrain, train.y = train_Data[,"inc"])
regr.eval(test_Data[,"inc"], predCartTest, train.y = train_Data[,"inc"])


dtCart=rpart(inc ~.,data=train_Data,method="anova", cp=0.002)

predCartTrain = predict(dtCart, newdata=train_Data, type="vector")
predCartTest = predict(dtCart, newdata=test_Data, type="vector")

regr.eval(train_Data[,"inc"], predCartTrain, train.y = train_Data[,"inc"])
regr.eval(test_Data[,"inc"], predCartTest, train.y = train_Data[,"inc"])


dtCart=rpart(inc ~.,data=train_Data,method="anova", cp=0.005)

predCartTrain = predict(dtCart, newdata=train_Data, type="vector")
predCartTest = predict(dtCart, newdata=test_Data, type="vector")

regr.eval(train_Data[,"inc"], predCartTrain, train.y = train_Data[,"inc"])
regr.eval(test_Data[,"inc"], predCartTest, train.y = train_Data[,"inc"])

