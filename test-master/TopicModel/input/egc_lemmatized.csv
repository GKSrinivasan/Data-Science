id	title	text	author	date	affiliation	url
0	A Framework for Mesh Segmentation and Annotation using Ontologies	le segmentation et annotation de maillage utiliser le sémantique avoir être le objet de un intérêt grandissant avec le démocratisation des technique de reconstruction 3Darles un approche classique consister à réaliser ce tâche en deux étape , tout de abord en segmenter le maillage , puis en cla annoter . cependant , ce approche ne permettre pas à chaque étape de profiter de le autre . en traitement de image , quelque méthode combiner le segmentation et le annotation , mais ce approche ne être pas générique , et nécessiter un ajustement de implémentation ou un réécriture pour chaque modification des connaissance expert . dans ce travail , cln décrire un cadre de fonctionnement qui mélange segmentation et annotation afin de réduire le nombre de étape de segmentation , et cln présenter un résultat préliminaire qui montrer le faisabilité de le approche . son système fournir un ontologie générique qui décrire sous forme de concept le propriété de un objet ( géométrie , topologie , etc. ) , ainsi que un algorithme permettre de détecter ce concept . ce ontologie pouvoir être étendre par un expert pour décrire formellement un domaine spécifique . le description formel du domaine être alors utiliser pour réaliser automatiquement le assemblage de le segmentation et de le annotation de objet et de son propriété , en sélectionner à chaque étape le algorithme le plus pertinent , être donner le information sémantique déjà détecter . ce approche original comporter plusieurs avantage . tout de abord , cln permettre de segmenter et de annoter un objet sans aucun connaissance en traitement de image ou de maillage , en décrire uniquement le propriété de le objet en terme de concept ontologique . de plus , ce cadre de fontionnement pouvoir facilement être réutiliser et appliquer à différent contexte , dès lors que un ontologie de domaine avoir être définir . finalement , le réalisation conjoint de le segmentation et de le annotation permettre de utiliser de un manière efficace le connaissance expert , en réduire le erreur de segmentation et le temps de calcul , en lancer toujours le algorithme le plus pertinent . 	Thomas Dietenbeck, Ahlem Othmani, Marco Attene, Jean-Marie Favreau	2015		1002088
1	Analyse des paramètres de recherche d'information: Etude de l'influence des paramètres sur les résultats	analyse des paramètre de recherche de information : Etude de le influence des paramètre sur le résultat  ce article présenter un analyse détaillé de un ensemble de 2 million de résultat de recherche de information obtenir par différent paramétrage de système de recherche de information . plus spécifiquement , cln avoir utiliser le plateforme Terrier et le interface RunGeneration pour créer différent exécution ( run en anglais ) en modifier le modèle de indexation et de recherche . cln avoir ensuite évaluer chacun des résultat obtenir selon différent mesure de performance de recherche de information . un analyse systématique avoir être mener sur ce donnée afin de déterminer de un part quel être le paramètre qui avoir le plus de influence , de autre part quel être le valeur de ce paramètre le plus susceptible de conduire à un bon performance du système . 	Josiane Mothe, Marion Moulinou	2015	@irit.fr	1002059
2	Analyse et visualisation d'opinions dans un cadre de veille sur leWeb	analyse et visualisation de opinion dans un cadre de veille sur leWeb  le analyse de opinion être un tâche qui consister en le identification et le classification de texte subjectif . dans ce travail , cln clr intéresser au problème de analyse de opinion dans un contexte de veille sur le Web . cln proposer un approche pour visualiser le résultat de analyse de opinion , baser sur le utilisation de terme clé . cln décrire également le plateforme de veille sur leWeb AMIEI , au sein de lequel son approche avoir être implémenter . le démonstration consister en un expérimentation de le plateforme de veille AMIEI et du module de analyse de opinion sur un corpus de tweets politique . 	Mohamed Dermouche, Leila Khouas, Sabine Loudcher, Julien Velcin, Eric Fourboul	2015	@univ-lyon2.fr, @amisw.com	1002110
3	Analyse OLAP sur des tweets et des blogs : un retour d'expérience	analyse OLAP sur un tweets et des blog : un retour de expérience  le projet ANR IMAGIWEB dans lequel clr inscrire ce travail clr être donner pour mission de étudier le image véhiculer sur Internet en clr baser sur le détection de opinion . Deux cas de étude avoir être définir : ( 1 ) le premier viser à répondre aux besoin de analyse de chercheur en science politique grâce à un donnée issu de Twitter durant le campagne présidentiel de 2012 ; ( 2 ) le second devoir permettre à le entreprise français EDF de évaluer le opinion du public en matière de sécurité , de emploi et de prix à partir de billet de blog . dans ce article , cln présenter un retour de expérience sur le usage de le analyse en ligne OLAP ( OnLine Analytical Processing ) pour un donnée textuel , mettre en avant le intérêt de ce type de analyse pour le membre du projet . 	Brice Olivier, Cécile Favre, Sabine Loudcher	2015	@univ-lyon2.fr	1002106
4	Analyse visuelle pour la détection des intrusions	analyse visuel pour le détection des intrusion  " le démocratisation de Internet , coupler à le effet de le mondialisation , avoir pour résultat de interconnecter le personne , le états et le entreprise . . le côté déplaisant de ce interconnexion mondial des système de information résider dans un phénomène appeler " " Cybercriminalité " " . . cln proposer un méthode de visualisation de grand " " graphe " " et le exploitation de analyse statique des flux permettre de détecter le comportement anormal et dangereux afin de appréhender le risque de un façon compréhensible par tout le acteur . " 	David Pierrot, Nouria Harbi	2015	@univ-lyon2.fr	1002079
5	Choix d'une mesure de proximité discriminante dans un contexte topologique	choix de un mesure de proximité discriminant dans un contexte topologique  " le résultat de tout opération de classification ou de classement de objet dépendre fortement de le mesure de proximité choisir . . le utilisateur être amener à choisir un mesure parmi le nombreux mesure de proximité existant . . or , selon le notion de équivalence topologique choisir , certains être plus ou moins équivalent . . dans ce article , cln proposer un nouveau approche de comparaison et de classement de mesure de proximité , dans un structure topologique et dans un objectif de discrimination . . le concept de équivalence topologique faire appel à le structure de voisinage local . . cln proposer alors de définir le équivalence topologique entre deux mesure de proximité à travers le structure topologique induire par chaque mesure dans un contexte de discrimination . . cln proposer également un critère pour choisir le " " meilleur " " mesurer adapter aux donnée considérer , parmi quelque mesure de proximité le plus utiliser dans le cadre de donnée quantitatif . . le choix de le " " meilleur " " mesure de proximité discriminant pouvoir être vérifier avoir posteriori par un méthode de apprentissage supervisé de type SVM , analyse discriminant ou encore régression Logistique , appliquer dans un contexte topologique . . le principe de le approche proposer être illustrer à partir de un exemple de donnée quantitatif réel avec huit mesure de proximité classique de le littérature . . un expérimentation avoir permettre de évaluer le performance de ce approche topologique de discrimination en terme de taille et-ou de dimension des donnée considérer et de sélection de le " " meilleur " " mesure de proximité discriminant . " 	Fatima-Zahra Aazi, Rafik Abdesselam	2015	@gmail.com, @univ-lyon2.fr	1002069
6	Classification évidentielle avec contraintes d'étiquettes	classification évidentiel avec contrainte de étiquette  ce papier proposer un version améliorer de le algorithme de classification automatique évidentielle semi-supervisée SECM . celui -cus bénéficier de le introduction de donnée étiqueté pour améliorer le pertinence de son résultat et utiliser le théorie des fonction de croyance afin de produire un partition crédal qui généraliser notamment le concept de partition dur et flou . le pendant de ce gain de expressivité être un complexité qui être exponentiel avec le nombre de classe , ce qui imposer en retour le utilisation de schéma efficace pour optimiser le fonction objectif . cln proposer dans ce article un heuristique qui relâche le contrainte classique de positivité lier aux masse de croyance des méthode évidentiel . cln montrer sur un ensemble de jeu de donnée de test que son méthode de optimisation permettre de accélérer sensiblement le algorithme SECM avec un schéma de optimisation classique , tout en améliorer également le qualité de le fonction objectif . 	Violaine Antoine, Nicolas Labroche	2015	@univ-bpclermont.fr, @univ-tours.fr	1002071
7	Classification multi-label par raisonnement logique pour l'indexation sémantique de documents	classification multi-labeau par raisonnement logique pour le indexation sémantique de document  ce article présenter un solution centrer sur le ontologie pour le classification multi-labeau automatique de information nécessaire à un système de recommandation de information économique . 	David Werner, Christophe Cruz, Aurélie Bertaux	2015	@u-bourgogne.fr, @u-bourgogne.fr, @u-bourgogne.fr	1002114
8	Clustering topologique pour le flux de données	Clustering topologique pour le flux de donnée  actuellement , le clustering de flux de donnée devenir le moyen le plus efficace pour partitionner un très grand ensemble de donnée . dans ce article , cln présenter un nouveau approche topologique , appelé G-Stream , pour le clustering de flux de donnée évolutif . le méthode proposer être un extension de le algorithme GNG ( Growing Neural Gas ) pour gérer le flux de donnée . G-Stream permettre de découvrir de manière incrémental des cluster de forme arbitraire en ne faire que un seul passe sur le donnée . le performance de le algorithme proposer être évaluer à le fois sur un donnée synthétique et réel . 	Mohammed Ghesmoune, Mustapha Lebbah, Hanane Azzag	2015	@univ-paris13.fr	1002072
9	Cohérence des données de bases RDF en évolution constante	cohérence des donnée de base RDF en évolution constant  le maintien de le qualité et de le fiabilité de base de connaissance RDF du Web Sémantique être un problème courant . un nombreux proposition pour le intégration de « bon » donner avoir être faire , clr baser être sur le ontologie de ce base , soit sur un méta-donné additionnel . dans ce article , cln proposer un approche original , baser exclusivement sur le étude des donnée de le base . le principe être de déterminer si le modification apporter par le mise à jour candidat rendre le partie ciblé de le base plus similaire - selon certain critère - à un autre party existant dans le base . le mise à jour être considérer cohérent avec ce base et pouvoir être appliquer . 	Pierre Maillot, Thomas Raimbault, David Genest	2015	@devinci.fr, @univ-angers.fr	1002085
10	Comparison of linear modularization criteria using the relational formalism, an approach to easily identify resolution limit	le modularisation de grand graphe ou recherche de communauté être aborder comme le optimisation de un critère de qualité , le un des plus utiliser être le modularité de Newman-Girvan . un autre critère , avoir un autre propriété , aboutir à un solution différent . dans ce article , cln présenter un réécriture relationnel de six critère linéaire : Zahn-Condorcet , Owsi'nski-Zadro˙zny , le Ecart à le Uniformité , le Ecart à le indétermination et le modularité Equilibrée . cln utiliser un version générique de le algorithme de optimisation de Louvain pour approcher le partition optimal pour chaque critère sur un réseau réel de différent taille . le partition obtenir présenter un caractéristique différent , concerner notamment le nombre de classe . le formalisme relationnel cln permettre de justifier ce différence de un point de vue théorique . en outre , ce notation permettre de identifier facilement le critère avoir un limite de résolution ( phénomène qui empêcher en pratique le détection de petit communauté sur un grand graphe ) . un étude de le qualité des partition trouver dans le graphe synthétique LFR permettre de confirmer ce résultat . 	Patricia Conde-Céspedes, Jean-François Marcotorchino, Emmanuel Viennet	2015	@univ-paris13.fr, @thalesgroup.com	1002080
11	Compromis précision-rappel dans l'évaluation des performances 	compromettre précision-rappeau dans le évaluation des performance  dans un nombreux problème de apprentissage automatique le performance des algorithme être évaluer à le aide des mesure précision et rappel . or ce deu mesure pouvoir avoir un importance très différent en fonction du contexte . dans ce article cln étudier le comportement des principal indice de performance en fonction du couple précision-rappeau . cln proposer un nouveau outil de visualisation de performance et définir le espace de compromis qui représenter le différent indice en fonction du compromis précision-rappeau . cln analyser le propriété de ce nouveau espace et mettre en évidence son avantage par rapport à le espace précision-rappeau . 	Blaise Hanczar, Mohamed Nadif	2015	@parisdescartes.fr	1002070
12	Contribution au calcul du skyline par réduction de l'espace candidat	contribution au calcul du skyline par réduction de le espace candidat  le opérateur skylin être devenir un paradigme dans le base de donnée . ilimp consister à localiser Sky le ensemble des point de un espace vectoriel qui ne être pas dominer . ce opérateur être utile lorsque cln ne arriver pas à clr décider dans le situation conflictuel . le calcul des requête skylin être pénaliser par le nombre de point que pouvoir contenir le base de donnée . dans ce papier , cln présenter un solution analytique pour le réduction de le espace candidat et cln proposer un méthode efficace pour le calcul de ce type de requête 	Lougmiri Zekri, Hadjer Belaicha	2015	@gmail.com	1002082
13	D113 : une plateforme open-source dédiée à l'analyse des flux et à la détection des intrusions	D113 : un plateforme open-source dédier à le analyse des flux et à le détection des intrusion  " ce travail clr situer dans le domaine de le " " Cybersécurité " " , le projet " " D113 " " permettre de visualiser en temps réel le flux transiter sur un équipement de filtrage sans avoir recours au traitement manuel des journal de événement . . cln centrer son démonstration sur le visualisation de grand " " graphe " " et le exploitation de analyse statique des flux . " 	David Pierrot, Nouria Harbi	2015	@univ-lyon2.fr	1002108
14	Découverte de proportions analogiques dans les bases de données : une première approche	découverte de proportion analogique dans le base de donnée : un premier approche  ce article présenter un nouveau cadre pour le découverte de connaissance baser sur le notion de proportion analogique qui exprimer le égalité des rapport entre le attribut de deux paire de élément . ce notion être développer dans le contexte des base de donnée pour découvrir un parallèle dans le donnée . dans un premier temps , cln donner un définition formel des proportion analogique dans le cadre des base de donnée relationnel , puis cln étudier le problème de le extraction des proportion analogique . cln montrer que ilimp être possible de suivre un approche de clustering pour découvrir le classe de équivalence de paire de n-uplet dans le même rapport de proportion analogique . ce travail constituer unCe article présenter un nouveau cadre pour le découverte de connaissance baser sur le notion de proportion analogique qui exprimer le égalité des rapport entre le attribut de deux paire de élément . ce notion être développer dans le contexte des base de donnée pour découvrir un parallèle dans le donnée . dans un premier temps , cln donner un définition formel des proportion analogique dans le cadre des base de donnée relationnel , puis cln étudier le problème de le extraction des proportion analogique . cln montrer que ilimp être possible de suivre un approche de clustering pour découvrir le classe de équivalence de paire de n-uplet dans le même rapport de proportion analogique . ce travail constituer un premier étape vers le extension des langage de interrogation de base de donnée avec un requête « analogique » . e premier étape vers le extension des langage de interrogation de base de donnée avec un requête « analogique » . 	William Correa Beltran, Hélène Jaudoin, Olivier Pivert	2015	@irisa.fr, @irisa.fr, @irisa.fr	1002075
15	Détection automatique de reformulations - Correspondance de concepts appliquée à la détection du plagiat	détection automatique de reformulation - correspondance de concept appliquer à le détection du plagiat  dans le cadre de le détection du plagiat , le phase de comparaison de deux document être souvent réduire à un comparaison mot à mot , un recherche de « copier ou coller » . dans ce article , cln proposer un approche naïf de comparaison de deux document dans le but de détecter automatiquement aussi bien le phrase copier de le un des texte dans le autre que le paraphrase et reformulation , ceci en clr focaliser sur le existence des mots porteur de sens , ainsi que sur son mots de substitution possible . cln comparer trois algorithme utiliser ce approche afin de déterminer le plus efficace pour ensuite cla évaluer face à un méthode existant . le objectif être de permettre le détection des similitude entre deux texte en utiliser uniquement un mots clef . le approche proposer permettre de détecter un reformulation non paraphrastique impossible à détecter avec un approche conventionnel faire appel à un phase de alignement . 	Jérémy Ferrero, Alain Simac-Lejeune	2015	@compilatio.net, @compilatio.net	1002089
16	Détection et regroupement automatique de style d'écriture dans un texte	détection et regroupement automatique de style de écriture dans un texte  le détection de plagiat extrinsèque devenir vite inefficace lorsque le cln ne avoir pas accès aux document potentiellement source du plagiat ou lorsque le cln clr confronter à un espace aussi vaste que leWeb , ce qui être souvent le cas dans le logiciel anti- plagiat actuel . dès lors le détection intrinsèque devenir nettement plus efficace . dans ce article , cln traiter justement de le détection automatique de auteur qui permettre de savoir si un passage de un texte ne appartenir pas au même auteur que le reste du texte et donc en théorie de repérer le passage plagier de un document . cln expliquer son contribution aux procédure déjà existant et évaluer le limite de son approche . le objectif être de permettre le détection et le regroupement de passage de un document par auteur . 	Jérémy Ferrero, Alain Simac-Lejeune	2015	@compilatio.net, @compilatio.net	1002060
17	Deux approches pour catégoriser le risque	Deux approche pour catégoriser le risque  le risque chimique ou alimentaire couvrir le situation où le produit chimique être dangereux pour le santé et consommation humain ou animal , et pour le environnement . le expert qui assurer le contrôle et le gestion de ce substance clr retrouver face à un gros volume de littérature scientifique , qui devoir être analyser pour appuyer le prise de décision . cln proposer un aide automatique pour le analyse de ce littérature . cln aborder le tâche comme un problématique de catégorisation : ilimp clr agir de catégoriser le phrase des texte dans le classe du risque lier aux substance . cln utiliser deux approche : par apprentissage superviser et le recherche de information . le résultat obtenir avec le apprentissage superviser ( tout classe confondre , F-mesure autour de 0,8 pour le risque alimentaire , entre 0,61 et 0,64 pour le risque chimique ) être meilleur que celui obtenir avec par recherche de information ( tout classe confondre , F-mesure entre 0,18 et 0,226 pour le risque alimentaire , entre 0,20 et 0,32 pour le risque chimique ) . le rappel être compétitif avec le deu approche . 	Natalia Grabar, Niña Kerry	2015	@univ-lille3.fr, @boujut.com	1002067
18	Extraction complète efficace de chemins pondérés dans un a-DAG	extraction compléter efficace de chemin pondérer dans un a-DAG  un nouveau domaine de motif appeler chemin pondérer condensé avoir être introduire en 2013 lors de le conférence IJCAI . le contexte de fouille être alors un graphe acyclique orienter ( DAG ) dont le sommet être étiqueter par un attribut . cln avoir travailler à un implémentation efficace de ce type de motif et cln montrer que le algorithme proposer être juste mais incomplet . cln établir ce résultat de incomplétude et cln le expliquon avant de trouver un solution pour réaliser un extraction complet . cln avoir ensuite développer un structure complémentaire pour calculer efficacement tout le chemin pondérer condensé . le algorithme être améliorer en performance de plusieurs ordre de magnitude sur un jeu de donnée artificiel et cln cla appliquer à un donnée réel pour motiver qualitativement le usage des chemin pondérer . 	Nazha Selmaoui-Folcher, Frédéric Flouvat, Chengcheng Mu, Jérémy Sanhes, Jean-François Boulicaut	2015	@univ-nc.nc, @insa-lyon.fr	1002077
19	Extraction de l'intérêt implicite des utilisateurs dans les attributs des items pour améliorer les systèmes de recommandations	extraction de le intérêt implicite des utilisateur dans le attribut des item pour améliorer le système de recommandation  le système de recommandation avoir pour objectif de sélectionner et présenter de abord le information susceptible de intéresser le utilisateur . ce travail exposer un système de recommandation qui clr appuyer sur deux concept : un relation sémantique sur le donnée et un technique de filtrage collaboratif distribuer baser sur le factorisation des matrice ( MF ) . de un part , le technique sémantique pouvoir extraire un relation entre le donnée , et par conséquent , améliorer le précision des recommandation . de autre part , MF donner un prévision très précis avec un algorithme facilement parralélisable . son proposition utiliser ce technique en ajouter un relation sémantique au processus . en effet , cln analyser en profondeur le intérêt cacher des utilisateur dans le attribut des item à recommander . cln utiliser dans son expérimentation le jeu de donnée MovieLens enrichir par le base de donnée IMDb . cln comparer son travail à un technique MF classique . le résultat montrer un précision dans le recommandation , tout en préserver un niveau élevé de abstraction du domaine . en outre , cln améliorer le passage à le échelle du système en utiliser un technique parallélisable . 	Manuel Pozo, Raja Chiky, Elisabeth Métais	2015	@isep.fr, @cnam.fr	1002093
20	Feedback - Study and Improvement of the Random Forest of the Mahout library in the context of marketing data of Orange	le apprentissage automatique avoir faire son apparition dans le écosystème Hadoop créer , de par le puissance promettre , un opportunité sans précédent pour ce domaine . dans ce écosystème , Apache Mahout être un réponse à le question du temps de calcul et-ou de le volumétrie : ilimp consister en un entrepôt de algorithme de apprentissage automatique , tout porter afin de clr exécuter sur Map ou Reduce . ce rapport clr concentrer sur le portage et le utilisation de le algorithme des Random Forest dans Mahout . ilimp montrer à travers son retour de expérience le difficulté qui pouvoir être rencontrer tant pratique que théorique et suggérer un piste de amélioration . 	C. Thao, Nicolas Voisine, Vincent Lemaire, R. Trinquart	2015		1002104
21	gapIT : Un outil visuel pour l'imputation de valeurs manquantes en hydrologie	gapIT : un outil visuel pour le imputation de valeur manquant en hydrologie  le donnée manquant être problématique en hydrologie , car cln gêner le calcul de statistique interannuel et sur un long période , ainsi que le analyse et le interprétation de le variabilité des donnée . dans ce article , cln présenter gapIT , un plateforme de analyse de donnée permettre de inspecter visuellement le donnée manquant et ensuite de choisir le méthode de correction adéquat . cln avoir utiliser le outil pour estimer le donnée manquant dans un série temporel correspondre aux débit mesurer par un station hydrométrique du Luxembourg . 	Olivier Parisot, Laura Giustarini, Olivier Faber, Renaud Hostache, Ivonne Trebs, Mohammad Ghoniem	2015	@lippmann.lu	1002107
22	Heuristiques pour l'adaptation des mappings entre ontologies dynamiques	heuristique pour le adaptation des mapping entre ontologie dynamique  le correspondance sémantique entre ontologie ( mapping ) jouer un rôle essentiel dans le système de information . cependant , en vertu de le évolution des connaissance , le élément ontologique être sujet à modification invalider potentiellement le alignement préalablement établir . un technique de maintenance être donc nécessaire pour maintenir le validité des mapping . dans ce article , cln présenter un ensemble de heuristique guider son adaptation . son approche clr appuyer sur le explication des mapping existant , le information provenir de le évolution des ontologie ainsi que le adaptation possible applicable aux mapping . cln proposer un validation expérimental à partir de ontologie du domaine médical et des mapping qui cld être associer . 	Julio Cesar Dos Reis, Cédric Pruski, Chantal Reynaud-Delaître	2015	@tudor.lu, @lri.fr	1002084
23	Identification des utilisateurs atypiques dans les systèmes de recommandation sociale	identification des utilisateur atypique dans le système de recommandation social  malgré un performance très satisfaisant , le approche social de le recommandation ne fournir pas un bon recommandation à un sous-ensemble des utilisateur . cln supposer ici que certains de ce utilisateur avoir un préférence différent de celui des autre , cln cla qualifier de atypique . cln cln intéresser à son identification , en amont de le tâche de recommandation , et proposer plusieurs mesure représenter le atypicité des préférence de un utilisateur . le évaluation de ce mesure sur un corpus de le état de le art montrer que cln permettre de identifier de façon fiable des utilisateur recevoir un mauvais recommandation . 	Benjamin Gras, Armelle Brun, Anne Boyer	2015	@loria.fr	1002097
24	Identification d'auteurs par apprentissage automatique	identification de auteur par apprentissage automatique  Etant donner un ensemble de document rédiger par un même auteur , le problème de authentification de auteur consister à décider si un nouveau texte avoir être rédiger ou non par ce auteur . pour résoudre ce problème , cln avoir proposer et implémenter différent approche : comptage de similarité , technique de vote et apprentissage superviser qui exploiter différent modèle de représentation des document . le expérimentation réaliser à partir un collection de le compétition PAN-CLEF 2013 et 2014 avoir confirmer le intérêt de son approche et son performance en terme de temps de traitement . 	Jordan Frery, Christine Largeron, Mihaela Juganaru-Mathieu	2015	@univ-st-etienne.fr, @emse.fr	1002062
25	Linked Data Annotation and Fusion driven by Data Quality Evaluation	dans ce article cln présenter un approche de fusion de donnée fonder sur le utilisation de information sur le qualité des donnée pour résoudre le éventuel conflit entre valeur . 	Ioanna Giannopoulou, Fatiha Saïs, Rallou Thomopoulos	2015		1002086
26	L'apport d'une approche symbolique pour le repérage des entités nommées en langue amazighe	le apport de un approche symbolique pour le repérage des entité nommer en langue amazigh  le repérage des entité Nommées ( REN ) en langue amazigh être un prétraitement éventuellement essentiel pour un nombreux application du traitement automatique des langue ( TAL ) , en particulier pour le traduction automatique . dans ce article , cln présenter un chaîne de repérage des entité nommer en amazighe fonder sur un étude synthétique des spécificité de le langue et des entité nommer en amazighe . le article mettre le accent sur le choix méthodologique à résoudre le ambiguïté devoir à le langue , en exploiter le technologie existant pour un autre langue . 	Meryem Talha, Siham Boulaknadel, Driss Aboutajdine	2015	@gmail.com, @fsr.ac.ma, @ircam.ma	1002061
27	Méthode alternative à la détection de « copier/coller » : intersection de textes et construction de séquences maximales communes 	méthode alternatif à le détection de « copier ou coller » : intersection de texte et construction de séquence maximal commun  le détection du plagiat passer le plus souvent par le phase de recherche de similitude le plus naïf , le détection de « copier ou coller » . dans ce article , cln proposer un méthode alternatif à le approche standard de comparaison mot à mot . le principe être de effectuer un intersection des deu texte à comparer , récupérer ainsi un tableau des mots que cln avoir en commun et de ne conserver que le séquence maximal des mots clr suivre dans le un des texte et existant également dans le autre . cln montrer que ce méthode être plus rapide et moins coûteux en ressource que le méthode de parcours de texte habituellement utiliser . le objectif être de détecter le passage identique entre deux texte plus rapidement que le méthode de comparaison mot à mot , tout en être plus efficace que le méthode n-gramme . 	Jérémy Ferrero, Alain Simac-Lejeune	2015	@compilatio.net, @compilatio.net	1002065
28	Pour une meilleure exploitation de la classification croisée dans les systèmes de filtrage collaboratif	pour un meilleur exploitation de le classification croisé dans le système de filtrage collaboratif  pour le prédiction automatique des item préférer par un utilisateur sur le Web , différent système de filtrage collaboratif avoir être proposer . le plupart de entre lui être baser sur le factorisation matriciel et le approche de type k plus proche voisins . malheureusement ce deu approche requérir un temps de calcul important . un partie de ce problème avoir pouvoir être surmonter par le classification croisé ou co- clustering qui clr avérer pertinent du fait que cln permettre par nature un gestion simultané des ensemble correspondre aux utilisateur et aux item . cependant , un travaux devoir encore être mener pour un meilleur prise en compte des donnée manquant . dans ce travail , cln proposer donc un gestion efficace des donnée non observer permettre un meilleur exploitation du potentiel de le classification croisé dans le domaine des système de recommandation . cln montrer de plus que cln permettre de obtenir un représentation à base de graphe biparti faciliter le interprétation interactif des affinité entre un groupe de utilisateur et des groupe de item . 	Aghiles Salah, Nicoleta Rogovschi, François Role, Mohamed Nadif	2015	@parisdescartes.fr	1002095
29	Proposition d'outil de clustering visuel et interactif	proposition de outil de clustering visuel et interactif  ce article présent un nouveau outil visuel de clustering interactif . ilimp utiliser un technique de réduction de dimensionnalité pour permettre un représentation 2D des donnée et des classe associer , initialement établir de manière non- supervisé . le originalité de le outil consister à autoriser un modification itératif à le fois du clustering et de le projection 2Darles Grâce à un contrôle adapté , le utilisateur pouvoir ainsi injecter son préférence , et observer le changement induire en temps réel . le méthode de projection utiliser suivre un métaphore physique , qui faciliter le suivi des changement par le utilisateur . cln montrer un exemple illustrer le intérêt pratique de le outil . 	Pierrick Bruneau, Philippe Pinheiro, Bertjan Broeksema, Benoît Otjacques	2015	@lippmann.lu	1002073
30	Qualité et complexité en évaluation des mesures d'intérêt	qualité et complexité en évaluation des mesure de intérêt  remplacer un hypothèse sur le modèle de donnée par un information mesurer sur le donnée réel être le un des force de le fouille de donnée . ce article étudier ce ajustement entre le donnée et le méthode de découverte de motif pour cll évaluer le qualité et le complexité . cln formaliser ce lien entre donnée et mesure de intérêt en identifier le motif lier qui être celui nécessaire pour le évaluation de un mesure ou de un contrainte . cln formuler alors trois axiome que devoir satisfaire ce motif lier pour que un méthode de extraction clr comporter bien . en outre , cln définir le complexité en évaluation qui quantifier finement le interrelation entre le motif au sein de un méthode de extraction . A le lumière de ce axiome et de ce complexité en évaluation , cln dresser un typologie de multiple méthode de découverte de motif impliquer le fréquence . 	Bruno Crémilleux, Arnaud Giacometti, Arnaud Soulet	2015	@unicaen.fr, @univ-tours.fr	1002094
31	RankMerging: Apprentissage supervisé de classements pour la prédiction de liens dans les grands réseaux sociaux	RankMerging : apprentissage superviser de classement pour le prédiction de lien dans le grand réseau social  trouver le lien manquant dans un grand réseau social être un tâche difficile , car ce réseau être peu dense , et le lien pouvoir correspondre à un environnement structurel varié . dans ce article , cln décrire RankMerging , un méthode de apprentissage superviser simple pour combiner le information obtenir par différent méthode de classement . afin de illustrer son intérêt , cln cla appliquer à un réseau de utilisateur de téléphone portable , pour montrer comment un opérateur pouvoir détecter un lien entre le client de son concurrent . cln montrer que RankMerging surpasser le méthode à disposition pour prédire un nombre variable de lien dans un grand graphe épars . 	Lionel Tabourier, Anne-Sophie Libert, Renaud Lambiotte	2015		1002102
32	Réduction de la complexité spatiale et temporelle du Compact Prediction Tree pour la prédiction de séquences	réduction de le complexité spatial et temporel du Compact Prediction Tree pour le prédiction de séquence  le prédiction de séquence de symbole être un tâche avoir de multiple application . plusieurs modèle de prédiction avoir être proposer tel que DG , All-k-order markov et PPM . récemment , ilimp avoir être montrer que un nouveau modèle nommer Compact Prediction Tree ( CPT ) utiliser un structure en arbre et un algorithme de prédiction plus complexe , offre des prédiction plus exact que plusieurs approche de le littérature . néanmoins , un limite important de CPT être son complexité temporel et spatial élevé . dans ce article , cln pallier ce problème en proposer trois stratégie pour réduire le taille et le temps de prédiction de CPT . le résultat expérimental sur 7 jeu de donnée réel montrer que le modèle résulter nommer CPT + être jusque à 98 fois plus compact et être 4.5 fois plus rapide que CPT , tout en conserver un exactitude très élever par rapport à All-K-order Markov , DG , Lz78 , PPM et TDAG . 	Ted Gueniche, Philippe Fournier-Viger	2015	@gmail.com, @umoncton.ca	1002064
33	Regroupement d'attributs par règles d'association dans les systèmes d'inférence floue	regroupement de attribut par règle de association dans le système de inférence flou  dans le système de apprentissage superviser par construction de règle de classification flou , un nombre élevé de attribut descriptif conduire à un explosion du nombre de règle générer et pouvoir affecter le précision des algorithme de apprentissage . afin de remédier à ce problème , un solution être de traiter séparément un sous-groupe de attribut . cela permettre de décomposer le problème de apprentissage en un sous-problème de complexité inférieur , et de obtenir un règle plus intelligible car de taille réduit . cln proposer un nouveau méthode de regroupement des attribut qui clr baser sur le concept des règle de association . ce règle découvrir un relation intéressant entre un intervalle de valeur des attribut . ce liaison local être ensuite agréger au niveau des attribut même en fonction du nombre de liaison trouver et de son importance . son approche , tester sur différent base de apprentissage et comparer à le approche classique , permettre de améliorer le précision tout en garantir un réduction du nombre de règle . 	Ilef Ben Slima, Amel Borgi	2015	@fst.rnu.tn, @insat.rnu.tn	1002092
34	Régularisation de noyaux temporellement élastiques et analyse en composantes principales non-linéaire pour la fouille de séries temporelles 	régularisation de noyau temporellement élastique et analyser en composante principal non- linéaire pour le fouille de série temporel  dans le domaine de le fouille de série temporel , plusieurs travaux récent exploiter un noyau construire à partir de distance élastique de type Dynamic Time Warping ( DTW ) au sein de approche à base de noyau . pourtant le matrice , apparenter aux matrice de Gram , construire à partir de ce noyau ne avoir pas toujours le propriété requérir ce qui pouvoir cla rendre in fin impropre à un tel exploitation . un approche émergeant de régularisation de noyau élastique pouvoir être mettre à profit pour répondre à ce insuffisance . cln présenter le un de ce méthode , KDTW , pour le noyau DTW , puis , autour de un analyse en composante principal non- linéaire ( K-PCA ) , cln évaluer le capacité de quelque noyau concurrent ( élastique verset s non élastique , définir verset s . non définir ) à séparer le catégorie des donnée analysé tout en proposer un réduction dimensionnel important . ce étude montrer expérimentalement le intérêt de un régularisation de type KDTW . 	Pierre-François Marteau	2015		1002063
35	Requêtes Skyline en présence des données évidentielles	requête Skyline en présence des donnée évidentiel  dans ce article , cln clr intéresser à le recherche des point le plus intéressant au sens de le ordre de Pareto , dans le base de donnée évidentiel . cln présenter le modèle skylin évidentiel qui être adapter à le nature des donnée incertain . ensuite , cln présenter un évaluation expérimental de son approche . 	Sayda Elmi, Karim Benouaret, Allel HadjAli, Mohamed Anis Bach Tobji, Boutheina Ben Yaghlane	2015	@gmail.com, @isg.rnu.tn, @ihec.rnu.tn, @liris.cnrs.fr, @ensma.fr	1002081
36	Ultrametricity of Dissimilarity Spaces and Its Significance for Data Mining	cln introduire un mesure de ultramétricité pour le dissimilarité et examiner le transformation des dissimilarité et son impact sur ce mesure . ensuite , cln étudier le influence de le ultramétricité sur le comportement de deux classe de algorithme de exploration de donnée ( le kNN algorithme de classification et le algorithme de regroupement PAM ) appliquer sur le espace de dissimilarité . cln montrer que ilimp exister un variation inverse entre ultramétricité et le performance des classificateur . pour le cluster , un augmentation de ultramétricité gener regroupement avec un meilleur séparation . un diminution de le ultramétricité produire groupe plus compact . 	Dan Simovici, Rosanne Vetro, Kaixun Hua	2015	@cs.umb.edu, @cs.umb.edu, @cs.umb.edu	1002068
37	Un algorithme EM pour une version parcimonieuse de l'analyse en composantes principales probabiliste	un algorithme EM pour un version parcimonieux de le analyse en composante principal probabiliste  cln considérer un version parcimonieux de le analyse en composante principal probabiliste . le pénalité ` 1 imposer sur le composante principal rendre son interprétation plus aisé en ne faire dépendre ce dernier que de un nombre restreint de variable initial . un algorithme EM , simple de mise en oeuvre , être proposer pour le estimation des paramètre du modèle . le méthode de le heuristique de pente être finalement utiliser pour choisir le coefficient de pénalisation . 	Charles Bouveyron, Julien Jacques	2015	@parisdescartes.fr, @univ-lyon2.fr	1002074
38	Un algorithme ICM basé sur la compacité pour la segmentation des images satellites à très haute résolution	un algorithme ICM baser sur le compacité pour le segmentation des image satellite à très haut résolution  " dans ce article cln proposer un modification pour le algorithme " " Iterated Conditional Modes " " ( ICM ) appliquer à le segmentation de image à très haut résolution . . pour ce faire , cln introduire un nouveau critère de convergence baser sur le compacité des cluster et qui reposer sur un fonction de énergie adapter aux modèle de voisinage irrégulier de ce type de image . . Grâce à ce méthode , son premier expérience avoir montrer que cln obtenir un résultat plus fiable en terme de convergence et de meilleur qualité que en utiliser le énergie global comme critère de arrêt . " 	Jérémie Sublime, Younès Bennani, Antoine Cornuéjols	2015	@agroparistech.fr, @agroparistech.fr, @univ-paris13.fr	1002078
39	Un langage d'interrogation à la SPARQL pour les graphes conceptuels	un langage de interrogation à le SPARQL pour le graphe conceptuel  ce article proposer un langage générique de interrogation pour le modèle des graphe conceptuel . de abord , cln introduire le graphe de interrogation . un graphe de interrogation être utiliser pour exprimer un « ou » entre deux sous-graphe , ainsi que un « option » sur un sous-graphe optionnel . ensuite , cln proposer quatre type de requête ( interrogation , sélection , description et construction ) en utiliser le graphe de interrogation . enfin , le réponse à ce requête être calculer à partir de un opération baser sur le homomorphisme de graphe . 	Marc Legeay, David Genest, Stéphane Loiseau	2015	@univ-angers.fr	1002083
40	Une approche centrée graine pour la détection de communautés dans les réseaux multiplexes	un approche centrer graine pour le détection de communauté dans le réseau multiplexe  cln cln intéresser dans ce travail au problème de détection de communauté dans le réseau multiplexe . le modèle de réseau multiplexe avoir être récemment introduire afin de faciliter le modélisation des réseau multirelationnel , un réseau dynamique et-ou des réseau attribuer . le approche existant pour le détection de communauté dans ce genre de graphe être , pour le plupart , baser sur un schéma de agrégation de couche ou de agrégation de partition . cln proposer ici un nouveau approche centré graine qui permettre de prendre en compte directement le nature multi-couche de un réseau multiplexe . un expérimentation effectuer sur différent réseau multiplexe montrer que son approche surpasser le approche de le état de le art en terme de qualité des communauté identifié . 	Issam Falih, Manel Hmimida, Rushed Kanawati	2015	@univ-paris13.fr	1002099
41	Une approche de visualisation analytique pour comparer les modèles de propagation dans les réseaux sociaux	un approche de visualisation analytique pour comparer le modèle de propagation dans le réseau social  le modèle de propagation de information , de influence et de action dans le réseau social être nombreux et diversifier rendre le choix de celui approprier à un situation donner potentiellement difficile . le sélection de un modèle pertinent pour un situation exiger de pouvoir cla comparer . ce comparaison ne être possible que au prix de un traduction des modèle dans un formalisme commun et indépendant de celui -ci . cln proposer le utilisation de le réécriture de graphe afin de exprimer le mécanisme de propagation sous le forme de un ensemble de règle de transformation local appliquer selon un stratégie donner . ce démarche prendre tout son sens lorsque le modèle ainsi traduire être étudier et simuler à partir de un plate-forme de visualisation analytique dédier à le réécriture de graphe . après avoir décrire le modèle et effectuer différent simulation , cln exhiber comment le plate-forme permettre de interagir avec ce formalisme , et comparer interactivement le trace de exécution de chaque modèle grâce à divers mesure souligner son différence . 	Jason Vallet, Bruno Pinaud, Guy Melançon	2015	@labri.fr	1002098
42	Une nouvelle formalisation des changements ontologiques composés et complexes	un nouveau formalisation des changement ontologique composé et complexe  le évolution de un ontologie être un processus indispensable dans son cycle de vie . cln être exprimer et définir par un changement ontologique de différent type : élémentaire , composé et complexe . le changement complexe et composé être très utile dans le sens où cln aider le utilisateur à adapter son ontologie sans clr perdre dans le détail des changement élémentaire . cependant , cln cacher derrière un formalisation sophistiquer puisque cln affecter , à le fois , plusieurs entité ontologique et pouvoir causer un inconsistance à le ontologie évolué . pour adresser ce problématique , ce article présenter un nouveau formalisation des changement ontologique composé et complexe baser sur le grammaire de graphe typer . ce formalisation clr appuyer sur le approche algébrique simple Pushout ( SPO ) de transformation de graphe et posséder deux principal avantage : ( 1 ) fournir un nouveau formalisation permettre de contrôler le transformation de graphe et éviter le incohérence de un manière avoir priori , ( 2 ) simplifier le définition des changement composé et complexe en réduire le nombre de changement élémentaire nécessaire à son application . 	Mariem Mahfoudh, Laurent Thiry, Germain Forestier, Michel Hassenforder	2015	@uha.fr	1002087
43	Une nouvelle méthode de Web Usage Mining basée sur une analyse sémiotique du comportement de navigation	un nouveau méthode de Web Usage Mining baser sur un analyse sémiotique du comportement de navigation  le objectif de son travaux être de proposer un méthode de analyse automatique du comportement des utilisateur à un fin de prédiction de son propension à réaliser un action suggéré . cln proposer dans ce article un nouveau méthode de Web Usage Mining baser sur un étude sémiotique des style perceptif , considérant le expérience de le utilisateur comme élément déterminant de son réaction à un sollicitation . le étude de ce style cld avoir amener à définir un nouveau indicateur ( des descripteur sémiotique ) introduire un niveau supplémentaire à le approche sémantique de annotation des site . cln proposer ensuite un modèle neuronal adapter au traitement de ce nouveau indicateur . cln expliquer en quoi? le modèle proposer être le plus pertinent pour traiter ce information . 	Sandra Mellot, Tony Bourdier, Moez Baccouche	2015	@iraiser.eu	1002090
44	Une Plateforme ETL parallèle et distribuée pour l'intégration de données massives	un plateforme ETL parallèle et distribué pour le intégration de donnée massif  cln cld intéresser , dans ce papier , à le impact des donnée massif dans un environnement décisionnel et plus particulièrement sur le phase de intégration des donnée . dans ce contexte , cln avoir développer un plateforme , baptiser P-ETL ( Parallel-ETL ) , destiner à le entreposage de donnée massif selon le paradigme MapReduce . P-ETL permettre le paramétrage de processus ETL ( workflow ) et un paramétrage avancé relatif à le environnement parallèle et distribuer . ce papier décrire le plateforme P-ETL en vue de un démonstration . face à un jeu de donnée aller de 244  106 à 7,317  109 tuple , le expérimentation mener avoir montrer le amélioration significatif des performance de P-ETL lorsque le taille du cluster et le nombre des tâche parallèle augmenter . 	Mahfoud Bala, Oussama Mokeddem, Omar Boussaid, Zaia Alimazighi	2015	@gmail.com, @univ-lyon2.fr, @usthb.dz	1002109
45	Using Social Conversational Context For Detecting Users Interactions on Microblogging Sites	dans ce travail , cln proposer un nouveau méthode de détection des conversation sur le site des réseau social . ce méthode être baser sur le analyse et le enrichissement de contenu dans le but de présenter un résultat informatif baser sur le interaction des utilisateur . cln avoir évaluer son méthode sur corpus recueillir de réseau social lier à un sujet spécifique , et cln avoir obtenir un bon résultat . 	Rami BELKAROUI, Rim Faiz, Aymen Elkhlifi	2015	@gmail.com, @ihec.rnu.tn, @paris4.sorbonne.fr	1002101
46	Vers la découverte de modèles exceptionnels locaux : des règles descriptives liant les molécules à leurs odeurs	vers le découverte de modèle exceptionnel local : un règle descriptif lier le molécule à son odeur  " issu de un phénomène complexe partir de un molécule odorant jusque à le perception dans le cerveau , le olfaction rester le sens le plus difficile à appréhender par le neuroscientifique . . le enjeu principal être de établir un règle sur le propriété physicochimique des molécule ( poids , nombre de atome , etc. ) afin de caractériser spécifiquement un sous-ensemble de qualité olfactif ( fruité , boiser , etc. ) . . cln pouvoir trouver de tel règle descriptif grâce à le découverte de sous-groupe ( " " subgroup discovery " " ) . . cependant le méthode existant permettre de caractériser être un seul qualité olfactif ; ; soit tout le qualité olfactif à le fois ( " " exceptional model mining " " ) mais pas un sousensemble . . cln proposer alors un approche de découverte de sous-groupe caractéristique de seulement certain label , par un nouveau technique de énumération , issue de le fouille de redescription . . cln avoir expérimenter son méthode sur un base de donnée de olfaction fournir par un neuroscientifique et pouvoir exhiber un premier sous-groupe intelligible et réaliste . " 	Guillaume Bosc, Mehdi Kaytoue, Marc Plantevit, Fabien De Marchi, Moustafa Bensafi, Jean-François Boulicaut	2015	@insa-lyon.fr	1002091
47	Visualizing Shooting Spots using Geo-tagged Photographs from Social Media Sites	Hotspots , à lequel un nombreux photographie avoir être prendre , pouvoir être un lieux intéressant pour beaucoup de gens faire du tourisme . visualisation des hotspot révéler le intérêt des utilisateur , ce qui être important pour le industrie tel que le recherche et du marketing touristique . bien que plusieurs technique baser sociaux-pour hotspot extraction indépendamment avoir être proposer , un hotspot avoir un relation à un autre hotspot dans certain cas . pour organiser ce hotspot , cln proposer un méthode pour détecter et de visualiser le relation entre le hotspot . son méthode proposer détecter et évaluer le relation de tache de tir et sujet photographique . son approche extraire le relation à le aide de hotspot , qui être fendre de un hotspot qui comprendre un photographie de différent type . 	Masaharu Hirota, Masaki Endo, Shohei Yokoyama, Hiroshi Ishikawa	2015	@sd.tmu.ac.jp, @inf.shizuoka.ac.jp	1002076
48	1d-SAX : une nouvelle représentation symbolique pour les séries temporelles	1d : un nouveau représentation symbolique pour le série temporel  SAX ( Symbolic Aggregate approXimation ) être un des techniquesmajeure de symbolisation des série temporel . le non prendre en compte destendance dans le symbolisation être un limitation bien connaître de SAX . ce articleprésente 1d , un méthode pour représenter un série temporel parun séquence de symbole contenir un information sur le moyenne et le tendancedes fenêtre successif de le série segmenter . cln comparer le efficacitéd 1d vs SAX dans un tâche de classification de série temporellesd'image satellite . le résultat montrer que 1d améliorer le taux de classificationpour un quantité de information identique utiliser . 	Simon Malinowski, Thomas Guyet, Rene Quiniou, Romain Tavenard	2014	@agrocampus-ouest.fr, @agrocampus-ouest.fr, @inria.fr, @idiap.ch	1001930
49	Agrégation de sac-de-sacs-de-mots pour la recherche d'information par modèles vectoriels	agrégation de sac-de-sacs-de-mot pour le recherche de information par modèle vectoriel  ce article étudier le intérêt de représenter le document textuel nonplus comme un sacs-de-mot , mais comme un sacs-de-mot . Au coeurde le utilisation de ce représentation , le calcul de similarité entre deux objetsnécessite alors de agréger tout le similarité entre sac de chacun des objet . cln évaluer ce représentation dans un cadre de recherche de information , et étudier le propriété attendre de ce fonction de agrégation . le expériencesrapportée montrer le intérêt de ce représentation lorsque le opérateursd'agrégation respecter certain propriété , avec un gains très importantspar rapport aux représentation standard . 	Vincent Claveau	2014	@irisa.fr	1001925
50	Alignement d'ontologies : exploitation des ontologies liées sur le web de données	alignement de ontologie : exploitation des ontologie lier sur le web de donnée  cln proposer dans ce article un méthode de alignement de un ontologiesource avec un ontologie cible déjà publier et lier sur le web dedonné . cln présenter ensuite un retour de expérience sur le alignement de uneontologie dans le domaine des science du vivre et de le environnement avecAGROVOC et NALT . 	Thomas Hecht, Patrice Buche, Juliette Dibie-Barthélemy, Liliana Ibanescu, Cássia Trojahn dos Santos	2014	@risk, @supagro.inra.fr, @agroparistech.fr, @irit.fr	1001911
51	Annotation sémantique de documents administratifs	annotation sémantique de document administratif  le numérisation de document administratif être un enjeu économiqueet écologique prioritaire dans le contexte sociétal actuel . le dématérialisationmassive de document ne être pas sans conséquence et soulever le problème de organisation , de stockage et de accès à le information . le défi ne être donc plus le numérisationdu document , mais le extraction des information que cln contenir . le document être produire par le Homme et pour le Homme . ce propriétépermet de localiser un information dans le zone saillant du document ( logos ) . le saillance et le reconnaissance être deux élément essentiel pour laclassification rapide de document . A le opposer , le recherche de un document oud'un ensemble de document reposer presque toujours sur le texte brut , ilimp estdoncre nécessaire de faire un correspondance entre un requête textuel et ledocument . ce article présenter un nouveau approche de annotation automatiquede document administratif qui utiliser un approche visuel et un approche defouille de texte . 	Benjamin Duthil, Mickaël Coustaty, Vincent Courboulay, Jean-Marc Ogier	2014	@univ-lr.fr	1001913
52	Application du paradigme MapReduce aux données ouvertes Cas : Accessibilité des personnes à mobilité réduite aux musées	application du paradigme MapReduce aux donnée ouvert cas : accessibilité des personne à mobilité réduire aux musée  le modèle MapReduce être aujourde hui le un des modèle de programmationparallèle le plus utiliser . définir un architecture Maître-Esclave , ilimp permettre le traitement parallèle de grand masse de donnée . dans ce papier , cln proposer un algorithme baser sur MapReduce qui permettre , à partir un donnéespublique du ministère français de le communication et de le Culture , dedéfiniour un classement des galerie et musée national selon son degré de accessibilitéaux personne handicapé . tout en profiter de le puissance et de laflexibilité du paradigme MapReduce , le décideur pouvoir mettre en place desstratégies efficace à moindre coût et avoir ainsi un vision plus précis sur lesétablissement culturel et son limite relative à ce catégorie de personne . le algorithme que cln proposer pouvoir être exploiter et appliquer à un autre casd'étude avec un jeu de donnée plus volumineux . 	Billel Arres, Nadia Kabachi, Fadila Bentayeb, Omar Boussaid	2014	@univ-lyon2.fr	1001963
53	Apprentissage de fonctions de tri pour la prédiction d'interactions protéine-ARN	apprentissage de fonction de tri pour le prédiction de interaction protéine-ARN  le fonction biologique dans le cellule mettre en jeu des interaction 3D entre protéine et ARN . le avancée des technique exérimentalesrestent insuffisant pour un nombreux application . ilimp falloir alors pouvoir prédirein silico le interaction protéine-ARN . dans ce contexte , son travaux sontfocalisé sur le construction de fonction de score permettre de ordonner le solutionsgénéré par le programme de amarrage protéine-ARN RosettaDock . Laméthodologie de évaluation utiliser par RosettaDock imposer de trouver un fonctiond score clr exprimer comme un combinaison linéaire de mesure physicochimique . avec un approche de apprentissage superviser par algorithme génétique , cln avoir apprendre différent fonction de score en imposer descontraintes sur le nature des poids rechercher . le résultat obtenir montrentl'importance de le signification des poids à apprendre et de le espace de rechercheassocié . 	Adrien Guilhot-Gaudeffroy, Jérôme Azé, Julie Bernauer, Christine Froidevaux	2014	@lri.fr	1001960
54	Apprentissage incrémental anytime d'un classifieur Bayésien naïf pondéré	apprentissage incrémental anytime de un classifieur Bayésien naïf pondérer  cln considérer le problème de classification superviser pour desflux de donnée présenter éventuellement un très grand nombre de variablesexplicative . le classifieur Bayésien naïf clr révéler alors simple à calculer etrelativement performant tant que le hypothèse restrictif de indépendance des variablesconditionnellement à le classe être respecter . le sélection de variable etle moyennage de modèle être deux voie connaître de amélioration qui reviennentà déployer un prédicteur Bayésien naïf intégrer un pondération des variablesexplicative . dans ce article , cln clr intéresser à le estimation direct de untel modèle Bayésien naïf pondérer . cln proposer un régularisation parcimonieusede le log-vraisemblance du modèle prendre en compte le informativité dechaque variable . le log-vraisemblance régulariser obtenir être non convexe , cln proposer un algorithme de gradient en ligne qui post-optimis le solutionobtenue afin de déjouer le minimum local . le expérimentation menéess'intéresser de un part à le qualité de le optimisation obtenir et de autre part auxperformances du classifieur en fonction du paramétrage de le régularisation . 	Carine Hue, Marc Boullé, Vincent Lemaire	2014		1001939
55	Apprentissage non supervisé de dépendances syntaxiques à partir de texte étiqueté, plusieurs variantes de PCFG légères	apprentissage non superviser de dépendance syntaxique à partir de texte étiqueter , plusieurs variante de PCFG léger  le apprentissage de dépendance être un tâche consister à établir , àpartir un phrase de un texte , un modèle de construction de arbre traduire unehiérarchie syntaxique entre le mots . cln proposer un modèle intermédiaireentre le analyse syntaxique complet de le phrase et le sac de mots . ilimp être basésur un grammaire stochastique hors-contexte clr traduire par un relation dedépendance entre le catégorie grammatical de un phrase . le résultat expérimentauxobtenir sur un benchmark attester dépasser pour cinuelque langue surdix le score de le algorithme de référence DMV , et pour le premier fois desscore être obtenir pour le français . le très grand simplicité de le grammairepermet un apprentissage très rapide , et un analyse presque instantané . 	Marie Arcadias, Guillaume Cleuziou, Edmond Lassalle, Christel Vrain	2014	@orange.com, @univ-orleans.fr	1001924
56	Approche formelle de fusion d'ontologies à l'aide des grammaires de graphes typés	approche formel de fusion de ontologie à le aide des grammaire de graphe typer  le article proposer un approche formel de fusion de ontologie clr reposantsur le grammaire de graphe typer . cln clr décomposer en trois étape : 1 ) le recherche de similarité entre concept ; 2 ) le fusion des ontologie parl'approche algébrique SPO ( simple Push Out ) ; 3 ) le adaptation de un ontologieglobale par le biais de règle de réécriture de graphe . contrairement aux solutionsexistant , ce méthode offrir un représentation formel de le fusiond'ontologie ainsi que un implémentation fonctionnel baser sur le outil AGG . 	Mariem Mahfoudh, Germain Forestier, Laurent Thiry, Michel Hassenforder	2014	@uha.fr	1001980
57	Approche par motifs pour l'analyse de données multi-résolution	approche par motif pour le analyse de donnée multi-résolution  dans ce article cln cln intéresser aux approche pour le analysede graphe pouvoir évoluer dans le temps et tel que un sommet à un temps donnépouvoir correspondre à plusieurs sommet au temps suivant et où le sommet sontassocier à un ensemble de attribut catégoriel . dans ce type de donnée , nousproposons un nouveau classe de motif baser sur un contrainte permettre dedécrire le évolution de structure homogène . ce type de approche être particulièrementadaptée pour le analyse de image multi-résolution sans perte de information . cln présenter un résultat qualitatif dans ce domaine . 	Pierre-Nicolas Mougel, Frédéric Flouvat, Nazha Selmaoui-Folcher	2014	@univ-nc.nc	1001952
58	Classification des actions humaines basée sur les descripteurs spatio-temporels	classification des action humain baser sur le descripteur spatio- temporel  dans ce article , cln proposer un nouveau descripteurspatio- temporel appeler ST-SURF pour le analyse et le reconnaissance de actionsdans des flux vidéo . le idée principal être de enrichir le descripteur Speed UpRobust Feature ( SURF ) en intégrer le information de mouvement issue du flotoptique . seul le point de intérêt qui avoir subir un déplacement être prendre encompte pour générer un dictionnaire de mots visuel ( DMV ) robuste baser surl'algorithme des k-moyenne ( K-means ) . le dictionnaire être utiliser lors du processusd'apprentissage et de reconnaissance de action baser sur le méthode desmachines à vecteur support ( SVM ) . le résultat obtenir confirmer le intérêtdu descripteur proposer ST-SURF pour le analyse de scène et en particulierpour le reconnaissance de action . le méthode atteindre un précision de reconnaissancede le ordre de 80 .7 \% , équivalent aux performance des descripteursspatio- temporel de le état de le art . 	Sameh Megrhi, Azeddine Beghdadi, Wided Souidène	2014		1001945
59	Classification et prédiction du flux solaire	classification et prédiction du flux solaire  le prédiction du rayonnement solaire horaire dans un journée estun enjeu primordial pour le production de énergie de type photovoltaïque . Nousprésentons deux stratégie de classification des jours selon son rayonnementssolaire puis un méthode de prédiction du flux solaire cohérent avec le classification . 	Henri Ralambondrainy, Yves Lechevallier, Jean Daniel Lan-Sun-Luk, Jean-Pierre Chabriat	2014	@univ-reunion.fr, @inria.fr, @univ-reunion.fr	1001962
60	Classifieur naïf de Bayes pondéré pour flux de données	classifieur naïf de Bayes pondérer pour flux de donnée  un classifieur naïf de Bayes être un classifieur probabiliste baser surl'application du théorème de Bayes avec le hypothèse naïf , ce est-à-direr que lesvariable explicative ( Xi ) être supposer indépendant conditionnellement àla variable cible ( C ) . malgré ce hypothèse fort , ce classifieur clr être avérer trèsefficace sur un nombreux application réel et être souvent utiliser sur le fluxd donner pour le classification superviser . le classifieur naïf de Bayes nécessitesimplement en entrée le estimation des probabilité conditionnel parvariable P ( Xi|C ) et le probabilité avoir priorir P ( C ) . pour un utilisation sur lesfllui de donnée , ce estimation pouvoir être fournir à le aide de un « résumé superviséen-lin de quantiui » . le état de le art montrer que le classifieur naïf de Bayespeut être améliorer en utiliser un méthode de sélection ou de pondération desvariable explicatif . le plupart de ce méthode ne pouvoir fonctionner quehors-ligne car cln nécessiter de stocker tout le donnée en mémoire et  ou lire plus de un fois chaque exemple . par conséquent , cln ne pouvoir être utiliséessur le flux de donnée . ce article présenter un nouveau méthode baséesur un modèle graphique qui calculer le poids des variable de entrée en utilisantun estimation stochastique . le méthode être incrémental et produire un classifieurNaïf de Bayes Pondéré pour flux de donnée . ce méthode être comparéeau classique classifieur naïf de Bayes sur le donnée utiliser lors du challenge « Large Scale Learning » . 	Christophe Salperwyck, Vincent Lemaire, Carine Hue	2014		1001938
61	Clustering de données relationnelles pour la structuration de flux télévisuels	Clustering de donnée relationnel pour le structuration de flux télévisuel  le approche existant pour structurer automatiquement un flux detélévision ( i.e. reconstituer un guide de programme exact et complet ) , être superviser . cln requérir un grand quantité de donnée annoter manuellement , et aussi de définir avoir priori le type de émission ( publicité , bande annonce , programme , sponsor ... ) . pour éviter ce deu contrainte , cln proposonsuner classification non supervisé . le nature multi-relationnel de nosdonné proscrire le utilisation des technique de clustering habituel reposantsur des représentation sous forme attributs-valeur . cln proposer et validonsexpérimentalement un technique de clustering capable de manipuler ce donnéesen détourner le programmation logique inductif ( pli ) pour fonctionnerdan ce cadre non superviser . 	Vincent Claveau, Patrick Gros	2014	@irisa.fr, @inria.fr	1001934
62	Clustering de séquences d'évènements temporels	Clustering de séquence de évènement temporel  cln proposer un nouveau méthode de clustering et de analyse deséquences temporel baser sur le modèle en grille à trois dimension . Lesséquences être partitionner en cluster , le dimension temporel être discrétiséeen intervalle et le dimension évènement être partitionnée en groupe . le grille decellules 3.D. former ainsi un estimateur non- paramétrique constant par morceauxun densité joint des séquence et des dimension des évènement temporel . le séquence de un cluster être ainsi grouper car cln suivre un distributionsimilaire de évènement au cours du temps . cln proposer aussi un méthoded'exploitation du clustering par simplification de le grille ainsi que un indicateurspermettant de interpréter le cluster et de caractériser le séquence quile composer . le expérience sur un donnée artificiel ainsi que sur desdonnéon réel issue de DBLP démontrer le bien-fondé de son approche . 	Romain Guigourès, Dominique Gay, Marc Boullé, Fabrice Clérot	2014	@orange.com, @zalando.de	1001929
63	Clusters dans les réseaux sociaux : intersections entre liens conceptuels fréquents et communautés	Clusters dans le réseau social : intersection entre lien conceptuel fréquent et communauté  le recherche de lien conceptuel fréquent ( FCL ) être un nouvelleapproche de clustering de réseau , qui exploiter à le fois le structure et le attributsdes noeud . bien que le travaux récent clr être déjà intéresser à le optimisationd algorithme de recherche des FCL , peu de travaux être aujourde huimener sur le complémentarité qui exister entre le lien conceptuel et le approcheclassique de clustering qui consister en le extraction de communauté . ainsi dansce papier , cln clr intéresser à ce deu approche . son objectif être de évaluerles relation potentiellement existant entre le communauté et le FCLpour comprendre le façon dont le motif obtenir par chacun des méthodespeuvent correspondre ou clr intersecter ainsi que le connaissance utile résultantde le prise en compte de ce deu type de connaissance . cln proposer pourcela un ensemble de mesure original , baser sur le notion de homogénéité , visantà évaluer le niveau de intersection des FCL et des communauté lorsque ilsêtre extrait de un même jeu de donnée . son approche être appliquer à deuxréseaux et démontrer le importance de considérer simultanément plusieurs typesde connaissance et son intersection . 	Erick Stattner, Martine Collard	2014	@univ-ag.fr	1001920
64	Comment Devenir Cybercondriaque ?	Comment Devenir Cybercondriaque ?  " cln avoir tout déjà avoir le occasion de effectuer un recherche de ordremédical sur Internet . . si certain site spécialisé clr refuser à tout diagnostican ligne , préférer le renvoi vers un professionnel de santé , un autre en revancheconduisent souvent à un déclaration alarmiste faire état de situationshumain difficile . . dans ce travail , cln étudier le ampleur de ce phénomèneet montrer que quel que être le syndrome rechercher , le résultat obtenusconduisent toujours à le énoncer des mots " " cancer " " ou " " tumeur " " . " 	Erick Stattner, Martine Collard	2014	@univ-ag.fr	1001986
65	Comparaison de bornes théoriques pour l'accélération du clustering incrémental en une passe	comparaison de borne théorique pour le accélération du clustering incrémental en un passe  le clustering incrémental en un passe reposer sur le affectation efficacede chaque nouveau point aux cluster existant . dans le cas général , où lesclusters ne pouvoir être représenter par un moyenne , le détermination exhaustivedu cluster le plus proche posséder un complexité quadratique avec le nombred donner . cln proposer dans ce papier un nouveau méthode de affectationstochastique à chaque cluster qui minimiser le nombre de comparaison à effectuerentre le donner et chaque cluster pour garantir , être donner un taux de erreuracceptable , le affectation au cluster le plus proche . plusieurs borne théorique ( Bernstein , Hoeffding et Student ) être comparer dans ce papier . le résultatssur des donnée artificiel et réel montrer que le borner de Bernstein donneglobalemer le meilleur résultat ( notamment lorsque cln être réduire ) car ellepermeant un accélération fort du processus de clustering , tout en conserver unnombre très faible de erreur . 	Nicolas Labroche, Marcin Detyniecki, Thomas Baerecke	2014	@lip6.fr	1001959
66	Comparaison des chemins de Hilbert adaptatif et des graphes de voisinage pour la caractérisation d'un parcellaire agricole	comparaison des chemin de Hilbert adaptatif et des graphe de voisinage pour le caractérisation de un parcellaire agricole  ce article comparer deux représentation de donnée spatial , lesgraphe de voisinage et le chemin de Hilbert-Peano , utiliser par un algorithmesd fouille . ce comparaison clr appuyer sur le mise en oeuvre de un méthoded'énumération de « sac de noeud » , qui permettre de obtenir un caractérisationshomogène à partir un deu représentation . le méthode être appliquer àla caractérisation de parcellaire agricole et le résultat tendre à montrer quele linéarisation de le espace capter le majorité de le information , à le exception deséléments rare , sur ce exemple particulier . 	Thomas Guyet, Sébastien Da Silva, Claire Lavigne, Florence Le Ber	2014		1001974
67	Compréhension de recettes de cuisine utilisateurs par extraction de connaissances intrinsèques	compréhension de recette de cuisine utilisateur par extraction de connaissance intrinsèque  sur le site Web communautaire , le utilisateur échanger un connaissance , en être à le fois auteur et lecteur . cln présenter un méthodepour construire son propre compréhension de le sémantique de le communauté , sans recours à un base de connaissance externe . cln effectuer un extractionde le connaissance présent dans le contribution analysé . cln proposonsune évaluation de le confiance imputable à ce compréhension déduire , afin de évaluer le qualité du contenu , avec application à un site Web de partageun recette de cuisine . 	Damien Leprovost, Thierry Despeyroux, Yves Lechevallier	2014	@inria.fr	1001984
68	Construction de cube OLAP à partir d'un entrepôt de données orienté colonnes	construction de cube OLAP à partir de un entrepôt de donnée orienter colonne  le optimisation de le construction de cube OLAP 1 avoir être jusque à présentaxée sur le développement de algorithme de calcul performant . ce derniersopèrent sur un donnée extraire de le entrepôt de donnée qui être généralementimplémenter selon le modèle relationnel qui adopter le architecture orientéelin . or , pour le requête décisionnel , le architecture orienter colonne offrede meilleur performance . cependant , le SGBDR 2 selon ce architecture nedisposent pas un opérateur approprié pour le calcul de cube OLAP . cln proposonsdair ce article un nouveau méthode de calcul de cube OLAP . le résultatsobtenu à partir un expérimentation que cln avoir mener démontrentque son approche optimiser considérablement le temps de construction de cubeOLAP et réduire le temps de réponse relatif à le exploitation du cube comparer àl'approche orienter ligne . 	Khaled Dehdou, Fadila Bentayeb, Nadia Kabachi, Omar Boussaid	2014	@univ-lyon2.fr	1001970
69	Construction de profils de préférences contextuelles basée sur l'extraction de motifs séquentiels	construction de profil de préférence contextuel baser sur le extraction de motif séquentiel  le utilisation de préférence susciter un intérêt croissant pour personnaliserdes réponse et effectuer un recommandation . en amont , le étape essentielleest le élicitation des préférence qui consister à construire un profil depréférences en solliciter le moins possible le utilisateur . dans ce article , nousprésentons un méthode baser sur le extraction de motif séquentiel afin de générerun règle de préférence contextuel à partir de un base de paire detransactions . à partir de ce règle générer , qui avoir un expressivité plus richeque celui des approche existant , cln montrer comment construire et utiliserun profil modéliser le préférence de le utilisateur . de plus , son approchea le avantage de bénéficier un nombreux algorithme efficace de extraction deséquence fréquent . le évaluation de son méthode sur un donnée réellesmontre que le modèle de préférence construire permettre de effectuer un recommandationsjuste à un utilisateur . 	Arnaud Giacometti, Dominique Haoyuan Li, Arnaud Soulet	2014	@univ-tours.fr	1001954
70	De l'ombre à la lumière : plus de visibilité sur l'Eclipse	de le ombre à le lumière : plus de visibilité sur le Eclipse  le extraction de connaissance à partir de donnée issu du génie logicielest un domaine qui clr être beaucoup développer ce dix dernier année , avecnotamment le fouille de référentiel logiciel ( Mining Software Repositories ) etl'application de méthode statistique ( partitionnement , détection de outlier ) àdes thématique du processus de développement logiciel . ce article présent ladémarc de fouille de donnée mettre en oeuvre dans le cadre de Polarsys , ungroupe de travail de le fondation Eclipse , de le définition des exigence à le propositiond'un modèle de qualité dédier et à son implémentation sur un prototype . le principal concept adopter et le leçon tirer être également passer enrevue . 	Boris Baldassari, Flavien Huynh, Philippe Preux	2014	@squoring.com, @inria.fr	1001967
71	De nouvelles pondérations adaptées à la classification de petits volumes de données textuelles	un nouveau pondération adapté à le classification de petit volume de donnée textuel  un des défi actuel dans le domaine de le classification superviser dedocuments être de pouvoir produire un modèle fiable à partir de un faible volumed donner . avec un volume conséquent de donnée , le classifieur fournissentdes résultat satisfaisant mais le performance être dégrader lorsque celui-cidiminue . cln proposer , dans ce article , un nouveau méthode de pondérationsrésistant à un diminution du volume de donnée . son efficacité , évaluéeen utiliser un algorithme de classification supervisé existant ( Naive Bayeset Class-Feature-Centroid ) sur deux corpus différent , être supérieur à celui desautron algorithme lorsque le nombre de descripteur diminuer . cln avoir étudiéen parallèle le paramètre influencer le différent approche tel que lenombre de classe , de document ou de descripteur . 	Flavien Bouillot, Pascal Poncelet, Mathieu Roche	2014	@lirmm.fr	1001922
72	Des humanités au numérique : interdisciplinarité et réciprocité	un humanité au numérique : interdisciplinarité et réciprocité  le humanité Numériques , aussi contestable et critiquable que être le terme , faire maintenantpartie du paysage de le recherche en science humain , institutionnaliser par le TrèsGrande infrastructure de recherche Huma-Num du CNRS . cln être généralement définiescomme le convergence de discipline autour de un matériau numérique , matériau inévitablementaccompagné de un outillage tout aussi numérique . ce matériau , suivant le discipline quil'observe pouvoir être considérer comme un objet éditorial , un objet analysable ou un objetcalculable . cln tenter de montrer que ce matériau pouvoir aussi être percevoir , voire construire , comme un dépôt voire un entrepôt de connaissance . son présentation clr appuyer sur diversprojet de recherche en humanité numérique auxquels cln contribuer afin de mettre enexergue le lien qui pouvoir être faire entre extraction et gestion de connaissance de un part ethumanité numérique de autre part : le premier pouvoir trouver un terrain expérimental dans lesecond tandis que le second pouvoir tirer profit des méthode et outil développer par le premier . cln égrainer par ailleurs de autre problématique inhérent aux humanité numérique : de le constitution à le analyse du corpus en passer par le formalisation et le normalisationd donner . enfin , cln tenter de montrer par le exemple que le question poser par ethumanité numérique ne être pas sans rappeler celui des industrie de le connaissance . 	Thomas Lebarbé	2014	@me.com	1001907
73	Détection de changements dans des flots de données qualitatives	détection de changement dans un flot de donnée qualitatif  pour mieux analyser et extraire de le connaissance de flot de donnée , un approche spécifique avoir être proposer ce dernier année . le un deschallenge auquel cln devoir faire face être le détection de changement dansles donner . alors que de plus en plus de donnée qualitatif être générer , peu de travaux de recherche clr être intéresser à le détection de changement dansce contexte et le travaux existant clr être principalement focaliser sur le qualitéd'un modèle apprendre plutôt que au réel changement dans le donnée . Danscet article cln proposer un nouveau méthode de détection de changementnon supervisé , appelé CDCStream ( Change Detection in Categorical DataStreams ) , adapter aux flux de donnée qualitatif . 	Dino Ienco, Albert Bifet, Bernhard Pfahringer, Pascal Poncelet	2014	@irstea.fr, @lirmm.fr, @yahoo-inc.com, @cs.waikato.ac.nz	1001968
74	Détection de situations à risque basée sur des détecteurs de mouvement à domicile pour les personnes dépendantes	détection de situation à risque baser sur un détecteur de mouvement à domicile pour le personne dépendant  avec le vieillissement de le population dans le décennie à venir , laprise en charge de le dépendance être devenir un enjeu majeur . le nouvellestechnologie permettre de améliorer le confort et le sécurité des personne dépendantesà domicile . dans ce article cln proposer un méthode de détectionun situation à risque baser sur le seuillage automatique des intervalle de inactivitéun capteur de mouvement de type infrarouge passif . son contributionconsiste à apprendre de façon automatique le durée maximal de inactivité , parpièce et par plage horaire . le méthode être évaluer sur un donnée réel provenantde le activité de un personne réel dans un appartement équiper de capteursdomotique . son approche permettre de réduire le temps de appel des secours . 	Alban Meffre, Nicolas Lachiche, Pierre Gançarski, Christophe Collet	2014	@unistra.fr, @unistra.fr, @unistra.fr, @unistra.fr	1001983
75	Détection d'opinions dans des tweets	détection de opinion dans un tweets  Twitter être à le heure actuel un des réseau social le plus utiliser aumonde et analyser le opinion qui cll être contenir permettre de fournir de précieusesinformation notamment aux entreprise commercial . dans ce article , cln décrire un méthode permettre de déterminer le opinion de un tweet endétectant dans un premier temps son subjectivité , puis son polarité . 	Caroline Collet, Alexandre Pauchet, Laurent Vercouter, Khaled Khelif	2014		1001964
76	Du texte à la base de données géographiques	Du texte à le base de donnée géographique  avec le prolifération des donnée géographique , ilimp cll avoir un fort besoinde concevoir un outil automatique pour le exploitation des connaissance géographiquesincarner dans le document textuel . ce être dans ce contexte , quenous proposer un approche permettre de générer un base de donnée géographique ( BDG ) à partir de texte . son approche clr articuler autour de deuxgranun phase : le génération du schéma de le BDG et le détermination desdonné qui servir au remplissage de ce base . le implémentation de notreapproche avoir donner naissance à un outil que cln avoir baptiser GDB Generatoret que cln avoir intégrer dans le SIG : OpenJUMP . 	Nesrine Hassini, Khaoula Mahmoudi, Sami Faiz	2014	@yahoo.fr, @yahoo.fr, @insat.rnu.tn	1001972
77	Dynamique des communautés par prédiction d'interactions dans les réseaux sociaux	dynamique des communauté par prédiction de interaction dans le réseau social  dans ce article , cln proposer un approche général de prédictiond communauté baser sur un modèle de apprentissage automatique pour le prédictiond interaction . en effet , cln penser que , si cln pouvoir prédire avec précisionle structure du réseau , alors cln avoir juste à rechercher le communauté surle réseau prédire . un expérimentation sur un jeu de donnée réel montrer lafaisabilité de ce approche . 	Blaise Ngonmang, Emmanuel Viennet	2014	@univ-paris13.fr	1001977
78	Evaluation de la pertinence dans un système de recommandation sémantique de nouvelles économiques	Evaluation de le pertinence dans un système de recommandation sémantique de nouveau économique  de son jours dans le secteur commercial et financier le veille estcrucial et complexe , car le charge de information être important . pour répondreà ce problématique , cln proposer un système novateur de recommandationd'article baser sur un modélisation ontologique des connaissance . cln présentonségalemer un nouveau méthode de évaluation de le pertinence utilisantle modèle vectoriel intrinsèquement efficace et adapté afin de pallier le confusionnative de ce modèle entre le notion de similarité et de pertinence . 	David Werner, Christophe Cruz, Aurélie Bertaux	2014	@u-bourgogne.fr	1001976
79	Exploration d'une collection de chansons à partir d'une interface de visualisation basée sur une analyse des paroles	exploration de un collection de chanson à partir de un interface de visualisation baser sur un analyse des parole  dans ce article , cln présenter un approche de fouille de textesainsi que un interface de visualisation afin de explorer un large collection dechansons frana¸ises à partir un parole . dans un premier temps , lui collectonsparole et métadonné de différent source sur leWeb . cln utiliser un approchecombinant clustering et analyse sémantique latent afin de identifier différentesthématique et de déterminer différent descripteur significatif . Noustransformons par le suite le modèle afin de obtenir un visualisation interactivepermettant de explorer le collection de chanson 	Rémy Kessler, Audrey Laplante, Dominic Forest	2014	@umontreal.ca	1001946
80	Extension de l'étiquetage géographique des pixels d'une image par fouille de données	extension de le étiquetage géographique des pixel de un image par fouille de donnée  le technique de classification moderne permettre de étiqueter leszon non couvert des base de donnée cartographique , mais souffrir de unmanque de robustesse important . dans ce article , cln proposer un méthoderobuste de extension de étiquetage sur le emprise de un image satellite , par analysehiérarchique des donnée existant . son approche être fonder sur un sélectiond'attribut par thème de le base de donnée , un sélection des pixel de apprentissageet des classification par objet de chaque thème . le décision finaled'étiquetage être prendre après fusion des classification par thème . son méthodeest appliquer avec succès et comparer à plusieurs méthode de classification , coupler donner de occupation du sol et imagerie spatial très haut résolution . 	Adrien Gressin, Nicole Vincent, Clément Mallet, Nicolas Paparoditis	2014	@ign.fr, @parisdescartes.fr	1001966
81	Extraction de motifs dans des graphes orientés attribués en présence d'automorphisme	extraction de motif dans un graphe orienter attribuer en présence de automorphisme  le graphe orienter attribuer être un graphe orienter dans lesquelsle noeud être associer à un ensemble de attribut . un nombreux donnée , issuesdu monde réel , pouvoir être représenter par ce type de structure , maisencore peu de algorithme être capable de cla traiter directement . le fouille desgraphes attribuer être difficile , car cln nécessiter de combiner le exploration de lastructure du graphe avec le identification de itemsets fréquent . de plus , du fait del'explosion combinatoire des itemsets , le isomorphisme de sous-graphe , dontle présence impacter énormément le performance des algorithme de fouille , être beaucoup plus nombreux que dans le graphe étiqueté . dans ce article , cln présenter un nouveau méthode de fouille de donnéesqui permettre de extraire un motif fréquent à partir de un ou de plusieurs graphesorienté attribuer . cln montrer comment réduire le explosion combinatoireprovoquer par le isomorphisme de sous-graphe en traiter de manière particulièreles motif automorphe . 	Claude Pasquier, Frédéric Flouvat, Jérémy Sanhes, Nazha Selmaoui-Folcher	2014	@univ-nc.nc, @unice.fr	1001949
82	Extraction de règles d'épisodes minimales dans des séquences complexes	extraction de règle de épisode minimal dans un séquence complexe  le message déposer quotidiennement sur le réseau social et lesblogs être très nombreux et constituer un source de information précieux . son fouille pouvoir être utiliser dans un but de prédiction de information . Notreobjectif dans ce article être de proposer un algorithme permettre le prédictiond'information au plus tôt et de façon fiable , par le biais de le identification derègle de épisode . 	Lina Fahed, Armelle Brun, Anne Boyer	2014	@loria.fr	1001975
83	Extraire les motifs minimaux efficacement et en profondeur	extraire le motif minimal efficacement et en profondeur  le représentation condensé avoir faire le objet de nombreux travauxdepui 15 an . Tandis que le motif maximal des classe de équivalence ontreçu beaucoup de attention , le motif minimal être rester dans le ombre notammentà cause de le difficulté de son extraction . dans ce papier , cln présentonsun cadre générique concernant le extraction de motif minimal en introduisantle notion de système minimisable de ensemble . ilimp permettre de considérer un langagesvarié comme le motif ensembliste ou le chaîne de caractère , maisaussi différent métrique dont le fréquence . ensuite , pour ne importer quel minimisable de ensemble , cln introduire un test de minimalité rapidepermettandre de extraire en profondeur le motif minimal . cln démontrer quel'algorithme proposer être polynomial-delay et polynomial-space . un expérimentationssur le benchmark traditionnel compléter son étude . 	Arnaud Soulet, François Rioult	2014	@univ-tours.fr, @unicaen.fr	1001950
84	Fouille de données par programmation visuelle structurée avec KD-Ariane	fouille de donnée par programmation visuel structurer avec KD-Ariane  cln présenter ici le plate-forme KD-Ariane , un déploiement de outilspour le fouille de donnée dans le environnement de programmation visuelleAriane . ce déploiement faciliter le conception de chaîne structurer de traitementspour le extraction de connaissance dans le donnée 	Régis Clouard, François Rioult	2014	@ensicaen.fr, @unicaen.fr	1001989
85	Fouille de motifs séquentiels pour l'élicitation de stratégies à partir de traces d'interactions entre agents en compétition	fouille de motif séquentiel pour le élicitation de stratégie à partir de trace de interaction entre agent en compétition  pour atteindre un but , tout agent en compétition élaborer inévitablementdes stratégie . lorsque le cln disposer de un certain quantité de trace de interactionsentre agent , ilimp être naturel de utiliser le fouille de motif séquentielspour découvrir de manière automatique ce stratégie . dans ce article , lui proposonsune méthodologie qui permettre le élicitation de stratégie et son capacité àdiscriminer un réussite ou un échec . le méthodologie clr articuler en trois étape : ( i ) le trace brut être transformer en un base de séquence selon un choixqui permettre , ( ie ) le extraction de stratégie fréquent , ( iii ) lequel être muniesd'un mesure original de émergence . ce être donc un méthodologie de découverteun connaissance que cln proposer . cln montrer le intérêt des motifsextrait et le faisabilité de le approche à travers des expérimentation quantitativeset qualitatif sur un donnée réel issir du domaine émerger dusport électronique . 	Guillaume Bosc, Mehdi Kaytoue-Uberall, Chedy Raïssi, Jean-François Boulicaut	2014	@insa-lyon.fr, @inria.fr	1001948
86	Généralisation des k-moyennes pour produire des recouvrements ajustables	généralisation des k-moyenne pour produire un recouvrement ajustable  le recherche de groupe non- disjoindre à partir de donnée non- étiquetéesêtre un problématique important en classification non- supervisé . Laclassification recouvrant ( Overlapping clustering ) contribuer à le résolution deplusieurs problème réel qui nécessiter le détermination de groupe qui clr chevaucher . cependant , bien que le recouvrement entre groupe être tolérésvoire encourager dans ce application , ilimp convier de contrôler son importance . cln proposer dans ce papier des généralisation de k-moyenne offrir lecontrôle et le paramétrage des recouvrement . Deux principe de régulation sontmir en place , cln viser à contrôler le recouvrement relativement à son tailleet à le dispersion des classe . le expérimentation réaliser sur un jeu dedonnées réel , montrer le intérêt des principe proposer . 	Chiheb-Eddine Ben N'Cir, Guillaume Cleuziou, Nadia Essoussi	2014	@isg.rnu.tn, @isg.rnu.tn, @univ-orleans.fr	1001932
87	Génération d'un extrait textuel à partir de bases de données	génération de un extraire textuel à partir de base de donnée  dans ce papier , cln présenter un approche dédier à le transformationd'une base de donnée en un extraire textuel . le idée sous-jacent à notreproposition être de apporter plus un sémantique aux donnée de le base . ce objectifest atteindre moyennant le utilisation des ontologie comme ressource sémantique . son approche prendre comme input un ensemble de base de donnéeset associer à chacun un ontologie . un ontologie global être générer , à partirde lequel un règle de association être proposer pour mieux expliciter sasémantique . enfin , le génération de un extraire textuel prendre lieu . 	Ghada Landoulsi, Khaoula Mahmoudi, Sami Faiz	2014	@yahoo.fr, @laposte.net, @insat.rnu.tn	1001971
88	Granularité des motifs de co-variations dans des graphes attribués dynamiques	granularité des motif de co- variation dans un graphe attribuer dynamique  découvrir un connaissance dans un graphe qui être dynamiqueset dont le sommet être attribuer être de plus en plus étudier , par exemple dansle contexte de le analyse de interaction social . ilimp être souvent possible de expliciterun hiérarchie sur le attribut permettre de formaliser un connaissancesa priori sur le description des sommet . cln proposer de étendre destechnique de fouille sous contrainte récemment proposer pour le analyse degraphe attribuer dynamique lorsque le cln exploiter de tel hiérarchie et doncle potentiel de généralisation  spécialisation que cln permettre . cln décrivonsun algorithme qui calculer un motif de co- évolution multi-niveau , ce est-à-diredes ensemble de sommet qui satisfaire un contrainte topologique et qui évoluentder le même façon selon un ensemble de tendance et de pas de temps . Nosexpérimentations montrer que le utilisation de un hiérarchie permettre de expliciterun collection de motif plus concis sans perdre de information . 	Elise Desmier, Marc Plantevit, Jean-François Boulicaut	2014		1001955
89	Identification de classes non-disjointes ayants des densités différentes	identification de classe non- disjoint ayant des densité différent  le classification recouvrant correspondre à un enjeu important en classificationnon- superviser en permettre à un observation de appartenir à plusieursclusters . plusieurs méthode avoir être proposer pour faire face à cetteproblématique en utiliser plusieurs approche usuel de classification . cependant , malgré le efficacité de ce méthode à déterminer un groupe non- disjoindre , cln échouer lorsque le donnée comporter un groupe de densité différentescar lui ignorer le densité local de chaque groupe et ne considèrentque le distance Euclidienne entrer le observation . afin de détecter un groupesnon- disjoindre de densité différent , cln proposer deux méthode de classificationintégrant le variation de densité des différent classe dans le processusde classification . un expérience réaliser sur un ensemble de donnée artificiellesmontrent que le méthode proposer permettre de obtenir de meilleuresperformance lorsque le donnée contenir un groupe de densité différent . 	Hela Masmoudi, Chiheb-Eddine Ben N&#146;Cir, Nadia Essoussi	2014	@gmail.com, @isg.rnu.tn, @isg.rnu.tn	1001936
90	Identification de rôles communautaires dans des réseaux orientés appliquée à Twitter	identification de rôle communautaire dans un réseau orienter appliquer à Twitter  le notion de structure de communauté être particulièrement utile pourétudier le réseau complexe , car cln amener un niveau de analyse intermédiaire , par opposition aux plus classique niveau local ( voisinage des noeud ) et global ( réseau entier ) . le concept de rôle communautaire permettre de décrire le positionnementd'un noeud en fonction de son connectivité communautaire . cependant , le approche existant être restreindre aux réseau non- orienter , utilisentdes mesure topologique ne considérer pas tout le aspect de le connectivitécommunautaire , et des méthode de identification des rôle non- généralisable àtous le réseau . cln proposer de résoudre ce problème en généraliser lesmesuron existant , et en utiliser un méthode non- superviser pour déterminerle rôle . cln illustrer le intérêt de son méthode en le appliquer au réseaud Twitter . cln montrer que son modification mettre en évidence le rôlesspécifique de utilisateur particulier du réseau , nommer capitaliste social . 	Nicolas Dugué, Vincent Labatut, Anthony Perez	2014		1001921
91	Incremental learning with latent factor models for attribute prediction in social-attribute networks	dans ce travail , cln clr intéresser au problème de le prédiction de attribut sur lesnoeudt dans un réseau social . le plupart des technique être hors ligne et ne être pas adaptéesà un situation où le donnée arriver massivement en flux comme dans le cas des médiassocial . dans ce travail , cln utiliser le modèle de variable latent pour prédire le attributsinconnu des noeud dans un réseau social et proposer un méthode pour mettre à jourincrémentalement le modèle avec un nouveau donnée . un expérimentation sur un jeu dedonnées issue des média social montrer que son méthode être moins coûteux en tempsun calcul et pouvoir garantir un performance acceptable en comparaison avec le techniquesnon- incrémental de le état de le art . 	Duc Kinh Le Tran, Cécile Bothorel, Pascal Cheung Mon Chan	2014	@telecom-bretagne.eu, @orange.com	1001916
92	Intégration et visualisation de données liées thématiques sur un référentiel géographique	intégration et visualisation de donnée lié thématique sur un référentiel géographique  un nombreux ressource publier sur le Web des donnée être décritespar un composante qui désigner de un manière direct ou indirect unelocalisation géographique . comme tout autre propriété , ce information delocalisation pouvoir être mettre à profit pour permettre le interconnexion des donnéesavec de autre source . cln permettre en outre son représentation cartographique . cependant , le information de localisation utiliser dans le source de donnéeslinked dater pouvoir parfois clr avérer imprécis ou hétérogène de un source àl'autre . ceci rendre donc son exploitation pour réaliser un interconnexion difficile , voire impossible . dans ce article , cln proposer de pallier ce difficultésen ancrer le donnée linked dater thématique aux objet de un référentielgéographique . cln mettre à profit le référentiel géographique afin de mettreen correspondance des donnée thématique doter de indication de localisationhétérogène . cln exploiter enfin le relation de correspondance créer entredonné thématique et référentiel géographique dans un application de référentielgéographique des donnée . 	Abdelfettah Feliachi, Nathalie Abadie, Fayçal Hamdi	2014	@ign.fr, @ign.fr, @cnam.fr	1001912
93	Investigation visuelle d'événements dans un grand flot de liens	investigation visuel de événement dans un grand flot de lien  cln présenter un nouveau méthode de analyse exploratoirede grand flot de lien que cln appliquer à le détection de événementssignificatif dans plus de 2 million de interaction ( pendant 4 mois ) entreutilisateurs du réseau social en ligne Github . cln combiner un méthodestatistique de détection automatique de événement dans un série temporel , Outskewer , avec un système de visualisation de graphe . Outskewer identifiedes instant de le évolution du graphe de interaction méritant de être étudier , etun analyste pouvoir valider et interpréter ce événement par le visualisation identifiedes anormal dans le sous-graphe correspondant . cln montrer par demultiple exemple que ce approche 1 ) permettre de détecter un événementspertinent et de rejeter celui qui ne cla être pas , 2 ) être adapter à un démarcheexploratoire car cln ne nécessiter pas un connaissance avoir priori sur le donnée . 	Sébastien Heymann, Bénédicte Le Grand	2014	@lip6.fr, @univ-paris1.fr	1001918
94	La subjectivité dans le discours médical : sur les traces de l'incertitude et des émotions	le subjectivité dans le discours médical : sur le trace de le incertitude et des émotion  le acteur et usager du domaine médical ( médecin , infirmier , patient , interne , pharmacien , etc. ) ne être pas issir de le même catégorie socioprofessionnelleettre ne présenter pas le même niveau de maîtrise du domaine . son écrit cll témoigner et véhiculer , de plus , le subjectivité qui cld estproprer . cln cln intéresser à le étude automatisé de le subjectivité dans lediscours médical dans un texte en langue français . cln confronter le discoursdes médecin ( article scientifique , rapport clinique ) à celui des patient ( message de forum de santé ) en analyser contrastivement le différencesd'emploi des descripteur tel que le marqueur de incertitude et de polarité , le marque émotif non lexical ( smiley , ponctuation répéter , etc. ) et lexical , et le terme médical relatif aux pathologie , traitement et procédure . cln effectuer un annotation et catégorisation automatique des documentsafin de mieux observer le spécificité que présenter le discours médicauxciblé . 	Pierre Chauveau Thoumelin, Natalia Grabar	2014	@gmail.com, @univ-lille3.fr	1001958
95	Les nouvelles théories de l'incertain	le nouveau théorie de le incertain  le notion de incertitude avoir être longtemps un sujet de controverse . en particulier le prééminenced le théorie des probabilité dans le science tendre à gommer le différence présentesdans le premier tentative de formalisation , remonter au 17ème siècle , entre le incertitudedue à le variabilité des phénomène répétable et le incertitude devoir au manque de information ( dire épistémique ) . le école Bayésienne affirmer que quelle que être le origine de le incertitude , celui -ci pouvoir être modéliser par un distribution de probabilité unique . ce affirmation avoir étébeaucoup remettre en cause dans le trent dernier année . en effet le emploi systématiqued'une distribution unique en cas de information partiel mener à un utilisation paradoxal dela théorie des probabilité . dans un nombreux domaine , ilimp être crucial de distinguer entre le incertitude devoir à le variabilitéd'observation et le incertitude devoir à le ignorance partiel . ce dernier pouvoir être réduitepar le obtention de nouveau information , mais pas le premier , dont cln ne clr prémunir quepar un action concret . dans le cas des base de donnée , ilimp être souvent supposer que ellesêtre précis , et le incertitude correspondant être souvent négliger . Quant cln être aborder onreste souvent dans un approche probabiliste orthodoxe . néanmoins , le statisticien avoir développer un outil qui ne relever pas de le théorie deKolmogorov pour pallier le manque de donnée ( intervalle de confiance , principe de maximumun vraisemblance ... ) . un nouveau théorie de le incertain avoir émerger , qui offrir le possibilité de représenter lesincertitudes épistémique et aléatoire de façon distinct , notamment le incertitude épistémique , en remplacer le distribution de probabilité unique par un famille de distribution possible , ce famille être de autant plus grand que le information être absent . ce représentationcomplexe posséder un cas particulier plus simple à utiliser en pratique , comme le ensemblesaléatoire ( théorie des fonction de croyance ) , le distribution de possibilité ( représenter desensemble flou de valeur possible ) et le p-box , notamment . le but de ce exposé être de susciter le intérêt pour ce nouveau théorie de le incertain , de cll donner le base formel , de cll discuter le philosophie sous-jacent , de faire le lien aveccertain notion en statistique , et de cla illustrer sur un exemple . 	Didier Dubois	2014	@irit.fr	1001906
96	"LOCAL-GENERATOR : ""diviser pour régner"" pour l'extraction des traverses minimales d'un hypergraphe"	" LOCAL-GENERATOR : " " diviser pour régner " " pour le extraction des traverse minimal de un hypergraphe "  Du faire que cln apporter un solution dans un nombreux application , le traverse minimal des hypergraphe ne cesser de susciter le intérêt dela communauté scientifique et le développement de algorithme pour cla calculer . dans ce article , cln présenter un nouveau approche pour le optimisation del'extraction des traverse minimal baser sur le notion de hypergraphe partielet de traverse minimal local selon un stratégie diviser pour régner . Nousintroduisons aussi un nouveau algorithme , appeler LOCAL-GENERATOR pour lecalcul un traverse minimal . le expérimentation effectuer sur divers jeuxd donner avoir montrer le intérêt de son approche , notamment sur le hypergraphesayant un nombre de transversalité élevé et renfermer un nombre trèsimportant de traverse minimal . 	M. Nidhal Jelassi, Christine Largeron, Sadok Ben Yahia	2014	@univ-st-etienne.fr, @fst.rnu.tn	1001935
97	L'utilisation des entités nommées pour l'expansion sémantique des requêtes Web	le utilisation des entité nommer pour le expansion sémantique des requête Web  le entité nommer être un élément intéressant pour le applicationsfondé sur le Traitement du Langage Naturel . dans le cas de le recherched'information , le entité nommer être largement employer par le utilisateursdu web dans le requête de recherche , soit pour définir un concept debase , soit pour décrire un autre concept dans le requête . Du côté du modèled recherche , le entité nommer être un élément riche en information quiaident à mieux cibler le document pertinent . dans ce article , cln étudionsl'avantager de étendre le entité nommer dans le requête . le idée être de utiliserune technique de expansion sémantique sur un ontologie général ( Yago ) pourdésambiguïser le entité nommer et pour trouver son différent appellationsque le cln intégrer dans le requête en utiliser 3 approche : sac de mots , dépendanceséquentielle , et concept clé . cln mesurer le efficacité de ce expériencesen terme de précision et rappel , et cln étudier le effet du rôle des entité nomméessur le expansion . cln conclure que le expansion des entité nommer estune méthode simple qui améliorer significativement le qualité de le recherchequand cln être comparer à un modèle de référence sans expansion . de plus , cetteméthode être assez compétitif par rapport à le approche pseudo retour de pertinencesouvent utiliser pour le expansion de le requête . 	Bissan Audeh, Philippe Beaune, Michel Beigbeder	2014	@emse.fr	1001910
98	Méthodologie 3-way d'extraction d'un modèle articulatoire de la parole à partir des données d'un locuteur	méthodologie 3- way de extraction de un modèle articulatoire de le parole à partir un donnée de un locuteur  pour parler , le locuteur mettre en mouvement un ensemble complexed'articulateur : le mâchoire que ilimp ouvrir plus ou moins , le langue à lequel ilfer prendre un nombreux forme et position , le lèvre qui cld permettre delaisser le air clr échapper plus ou moins brutalement , etc. le modèle articulatoirele plus connu être celui de Maeda ( 1990 ) , obtenir à partir de Analyses en ComposantesPrincipales faire sur le tableau de coordonnée des point des articulateursd'un locuteur en train de parler . cln proposer ici un analyse 3- way dumême type de donnée , après son transformation en tableau de distance . Nousvalidons son modèle par le prédiction des son prononcer , qui clr avérer presqueaussi bon que celui du modèle acoustique , et même meilleur quand cln prenden compter le co- articulation . 	Martine Cadot, Yves Laprie	2014	@loria.fr, @loria.fr	1001985
99	Modélisation de trajectoires cible/caméra : requêtes spatio-temporelles dans le cadre de la videosurveillance	modélisation de trajectoire cible  caméra : requête spatio- temporel dans le cadre de le videosurveillance  le nombre de caméra de vidéosurveillance installer dans le monde augmenter chaquejour . en France , le système de le RATP déployer sur Paris comprendre 9000 caméra fixe et19000 mobile . lors de fait particulier ( e.g. , agression , vol ) , le opérateur de vidéo surveillancese baser sur le indication spatial et temporel de le victime et sur son connaissanced le localisation des caméra pour sélectionner le contenu intéressant pour le enquête . Deux grand problème pouvoir alors survenir : ( 1 ) le temps de réponse être long ( jusque à plusieursjours de traitement ) et ( 2 ) un risque important de perte de résultat à cause de un mauvaiseconnaissance du terrain ( appel à un opérateur extérieur ) . le but de son recherche estde définir un outil de assistance aux opérateur qui pouvoir , à partir de un trajectoire donner , sélectionner de façon automatique le caméra pertinent par rapport à le requête . 	Dana Codreanu, André Péninou, Florence Sedes	2014	@irit.fr	1001982
100	Motifs récursifs : extraction ascendante hiérarchique d'ensembles d'items ou d'évènements pour le résumé de données transactionnelles ou séquentielles	motif récursif : extraction ascendant hiérarchique de ensemble de item ou de évènement pour le résumé de donnée transactionnel ou séquentiel  cln proposer un méthode original pour extraire un résumé compact , représentatif et intelligible des motif fréquent dans un donnée transactionnellesou séquentiel . son approche consister à extraire un nouveau typede motif que cln appeler motif récursif , i.eevard des motif de motif , à le aided'un algorithme hiérarchique agglomératif nommer RepaMiner . cln généronsnon pas un simple ensemble de motif mais un véritable structure dériver dedendrogrammes , le RPgraph . 	Julien Blanchard	2014	@univ-nantes.fr	1001956
101	Passage aux noyaux en classification recouvrante	passage aux noyau en classification recouvrant  le classification recouvrant correspondre à un domaine de étude très actifx dernier année et dont le objectif être de organiser un ensemble de donnéesen groupe de individu similaire avec le particularité de autoriser un chevauchementsentre le groupe . parmi le approche étudier cln cln intéressonsaillir extension recouvrant des modèle de type moindre carré et constatonsles difficulté théorique et pratique lier à son adaptation aux noyau . Nousformulons alors un nouveau définition ensembliste pour caractériser un recouvrementd plusieur classe , cln montrer que ce modélisation permettre lerecours aux noyau et cln proposer un solution algorithmique efficace pourrépondre au problème de le classification recouvrant à noyau . 	Guillaume Cleuziou	2014	@univ-orleans.fr	1001931
102	Pondération de blocs de variables en bi-partitionnement topologique	pondération de bloc de variable en bi-partitionnement topologique  dans ce article , cln proposer un nouveau approche permettantà le fois le bi-partitionnement topologique ( bi-clustering ) et le pondération deblocs variable . le modèle que cln proposer FBR-BiTM ( Feature Block Relevanceusing BiTM ) permettre de découvrir un espace topologique de un ensembled'observation et de variable en associer un nouveau score de pondération àchaque sous ensemble de variable . le estimation des coefficient de pondérationest réaliser dans le même processus de apprentissage que le bi-partitionnement . ce pondération être local et associer à chaque prototype . cln reflètentl'importancer local de chaque bloc de variable pour le bi-partitionnement . le évaluationmontre que le approche proposer , comparer 	Amine Chaibi, Hanane Azzag, Mustapha Lebbah	2014	@univ-paris13.fr	1001943
103	Prédiction de valeurs manquantes dans les bases de données-- Une première approche fondée sur la notion de proportion analogique	prédiction de valeur manquant dans le base de donnée -- un premier approche fonder sur le notion de proportion analogique  ce article présenter un méthode original de prédiction de valeursmanquant dans le base de donnée relationnel , fonder sur le notion deproportion analogique . cln montrer en particulier comment un algorithmeproposé dans le cadre de le classification automatique pouvoir être adapter à ce fin . Deux cas être considérer : celui de un base de donnée transactionnel ( attributsbooléen ) , et celui où le valeur manquant pouvoir être de type numérique . 	William Correa Beltran, Hélène Jaudoin, Olivier Pivert	2014	@irisa.fr, @irisa.fr, @irisa.fr	1001961
104	Que ressentent les patients ?	que ressentir le patient ?  le forum de santé en ligne être un espace de échange où le patientspartagent son sentiment à propos de son maladie , traitement , etc. sous couvert de anonymat , cln exprimer très librement son expérience personnel . ce forum être donc un source de information très utile pour le professionnelsde santé afin de mieux identifier et comprendre le problème , lescomportement et le sentiment de son patient . dans ce article , cln proposonsd'exploiter le message des forum via un technique de fouille de textespour extraire un trace de émotion ( e.gès joie , colère , surprise , etc. ) . 	Soumia Melzi, Amine Abdaoui, Jérôme Azé, Sandra Bringay, Pascal Poncelet, Florence Galtier	2014		1001957
105	Reconstruction et analyse sémantique de chronologies cybercriminelles	reconstruction et analyse sémantique de chronologie cybercriminel  le reconstruction de chronologie de évènement cybercriminel ( oureconstruction de évènement ) être un étape primordial dans un investigationnumérique . ce phase permettre aux enquêteur de avoir un vue des évènementssurvenu durant un incident . le reconstruction de évènement requérir le étuded'important volume de donnée en raison de le omniprésence des nouvellestechnologie dans son quotidien . de plus , le conclusion produire clr doiventder respecter le critère fixer par le justice . afin de répondre à ce challenge , cln proposer un nouveau méthodologie baser sur un ontologie permettantd'assister le enquêteur tout au long du processus de enquête . 	Yoan Chabot, Aurélie Bertaux, Tahar Kechadi, Christophe Nicolle	2014	@ucdconnect.ie	1001969
106	Règles d'association inter-langues au service de la recherche d'information multilingue	règle de association inter-langue au service de le recherche de information multilingue  dans ce article , cln proposer de montrer le intérêt et le utilité de déploiementun règle de association inter-langue ( RAILs ) dans le domaine de laRecherche de information Multilingue ( RIM ) . ce règle être des connaissancesadditionnel résultante de un processus de fouille de grand corpus parallèlesalignés au niveau de le phrase . en effet , son conclusion exprimer dans unelangue cible représenter un traduction potentiel de son prémisse , expriméesdans un langue source . cln illus trons le utilisation des rail dans lecontexte de le RIM à travers deu proposition , à savoir : ( i ) le traduction desrequêt et ( ie ) le traduction des terme de le index . le évaluation expérimental aété mener sur le collection de document MUCHMORE . le résultat avoir montréun amélioration significatif de le pertinence système . 	Belhaj Rhouma Sourour, Asma Ben Achour, Malek Hajjem, Chiraz Latiri	2014	@gmail.com, @gmail.com, @gmail.com, @gnet.tn	1001927
107	Requêtes skyline en présence d'exceptions	requête skyline en présence de exception  dans ce article , cln clr intéresser à le recherche des point lesplus intéressant au sens de le ordre de Pareto , i.eevard , à le évaluation de requête « skyline » , dans un jeu de donnée présenter un anomalie . ilimp ne être pas rareque le donnée , de petit annonce par exemple , être peupler de erreur oud'exception qui pouvoir perturber le recherche des meilleur point car cellescisont susceptible de dominer le autre point . le approche présenter viser àcalculer le requête skylin malgré le présence de ce exception , sans pourautant cla écarter définitivement , et à présenter graphiquement le résultat defaçon à identifier rapidement le point de intérêt et le anomalie potentiel . 	Hélène Jaudoin, Olivier Pivert, Daniel Rocacher	2014	@enssat.fr, @enssat.fr, @enssat.fr	1001944
108	Sélection de prototypes en vue d'une catégorisation de textes avec les K plus proches voisins : étude comparative	sélection de prototype en vue de un catégorisation de texte avec le K plus proche voisins : étude comparatif  le technique des K plus proche voisins ( KNN ) être un méthoded'apprentissage à base de instance , cln avoir être appliquer dans le catégorisationd texte depuis un nombreux année . en contraste avec son performance declassification , ilimp être reconnaître que ce algorithme être lent pendant le classificationd'un nouveau document . le technique de sélection de prototype être apparuescomme un méthode très compétitif pour améliorer le KNN grâce à laréduction des donnée . le étude contenir dans ce papier avoir pour objectif de analyserl'impact de ce méthode sur le performance de le classification de textesavec le algorithme KNN . 	Fatiha Barigou, Baya Naouel Barigou, Baghdad Atmani, Bouziane Beldjilali	2014	@gmail.com, @yahoo.fr	1001926
109	Sélection d'une méthode de classification multi-label pour un système interactif	sélection de un méthode de classification multi-labeau pour un système interactif  le objectif de ce article être de évaluer le capacité de 12 algorithmesde classification multi-labeau à apprendre , en peu de temps , avec peu de exemplesd'apprentissage . le résultat expérimental montrer un différence importantesentre le méthode analysé , pour le 3 mesure de évaluation choisir : Log-Loss , Ranking-Loss et temps de apprentissage  prédiction , et le meilleursrésultat être obtenir avec : multi-label k Nearest neighbours ( ML-kNN ) , suivide ensemble de Classifier Chains ( ECC ) et ensemble de Binary Relevance ( EBR ) . 	Noureddine Yacine Nair Benrekia, Pascale Kuntz, Franck Meyer	2014	@orange.com, @univ-nantes.fr	1001941
110	Sous échantillonnage et machine à noyaux élastiques pour la classification de données de mouvement capturé	sous échantillonnage et machine à noyau élastique pour le classification de donnée de mouvement capturer  dans le domaine de le reconnaissance de geste isoler , bon nombreun travaux clr être intéresser à le réduction de dimension sur le axe spatial pourréduire à le fois le complexité algorithmique et le variabilité des réalisationsgestuelle . ilimp être assez étonnant de constater que peu de ce méthode clr sontexplicitemer pencher sur le réduction de dimension sur le axe temporel . Enmatière de complexité , le réduction de dimension sur ce axe être un enjeu majeurquant à le utilisabilité de distance élastique en complexité quadratique . Parailleurs , le prise en compte de le variabilité sur ce axe demeurer un source avéréede gain de performance . pour tenter de apporter un éclairage en matière deréduction de dimension sur le axe temporel , cln présenter dans ce article uneapproche baser sur un sous échantillonnage temporel associer à le exploitationd'un apprentissage automatique à base de noyau élastique . cln montronsexpérimentalement , sur deux jeu de donnée très référencer dans le communautéet très opposer en matière de qualité de capture de mouvement , que ilimp estpossibler de réduire sensiblement le nombre de posture sur le trajectoire temporellestout en conserver , grâce à un noyau élastique , un performance dereconnaissance au niveau de le état de le art du domaine . le gain de complexitéobtenu rendre un tel approche éligible pour un application temps-réel . 	Pierre-François Marteau, Sylvie Gibet, Clément Reverdy	2014		1001928
111	Stratégies argumentatives pour la classification collaborative multicritères des connaissances cruciales	Stratégies argumentatif pour le classification collaboratif multicritère des connaissance crucial  dans ce article , cln proposer un approche argumentatif viser àautomatiser le résolution des conflit entre le décideur qui avoir un préférencescontradictoire lors de un classification multicritère collaboratif des connaissancescrucial . son étude expérimental avoir prouver que ce approche peutrésoudre jusque à 81 \pourcent des conflit et améliorer le qualité de approximation dedécideurs de un taux de 0.62 pour un récepteur et de 0.15 pour un initiateur . 	Sarra Bouzayane, Inès Saad	2014	@yahoo.fr, @france-bs.com	1001981
112	Symétries et Extraction de Motifs Ensemblistes	symétrie et extraction de motif Ensemblistes  le symétrie être un propriété structurel que cln détecter dans ungrand nombre de base de donnée . dans ce article , cln étudier le exploitationd symétrie pour élaguer le espace de recherche dans le problème de extractionun motif ensembliste . son approche être baser sur un intégrationdynamique des symétrie dans le algorithme de type Apriori permettre de réduirel'espace des motif candidat . en effet , pour un motif donné , le symétriesnous permettre de déduire le motif qui cld être symétrique et vérifier parconséquent le même propriété . cln détailler son approche en utilisantl'exemple des motif fréquent . ensuite , cln le généralisons au cadre unificateurde Mannila et Toivonen pour le extraction des motif ensembliste . le expériencesmenée montrer le faisabilité et le apport de son approche de élagagebasé sur le symétrie . 	Said Jabbour, Mehdi Khiari, Lakhdar Sais, Yakoub Salhi, Karim Tabia	2014	@univ-artois.fr, @zto-technology.com	1001953
113	Une approche algébrique au problème du consensus de partitions	un approche algébrique au problème du consensus de partition  en classification non- superviser , le consensus de partition avoir pour objectifde produire un partition unique , représenter le consensus , à partir de unensemble de partition où chacun être engendrer indépendamment un autre , voire avec un méthodologie différent . en complément des technique ayantleur qualité propre en terme de robustesse ou de passage à le échelle , cln apportonsun point de vue original sur le consensus de partition , ce est-à-direr , par lebiais de définition algébrique qui permettre de établir le nature des déductionspouvant être réaliser dans un approche systématique ( page exès un système à baseun connaissance ) . cln fondre son approche sur le treillis des partition pourlequel cln montrer comment pouvoir être adjoint des opérateur dans le butd formuler un expression caractériser le consensus à partir de un ensemble departitions . 	Frédéric Dumonceaux, Guillaume Raschia, Marc Gelgon	2014	@univ-nantes.fr	1001937
114	Une approche basée sur STATIS pour la fusion de cartes topologiques auto-organisées	un approche baser sur STATIS pour le fusion de carte topologique auto- organiser  dans le cadre des carte topologique , cln proposer un nouvelleapproche de ensemble clusters baser sur le méthode STATIS . le méthode de ensemblecluster viser à améliorer le qualité de le partition de un jeu de donnéesà travers le combinaison de plusieurs partition . le différent partition pouvoir être obtenir en faire varier le paramètresd'un algorithme ( choix des centre initial , du voisinage initial et final des cellulesdans le cas des carte topologique auto- organiser SOM , etc ) . le approcheprésentée dans ce communication reposer sur le méthode de analyse de donnéesmulti-tableau STATIS pour déterminer un matrice compromettre représenter aumieux le similarité entre le partition issu des carte topologique . le fusiond carte topologique être alors obtenir à travers un classification baser surcette matrice compromettre . le méthode proposer être illustrer sur un donnéesréel issu de le UCI et sur un donnée simulé . 	Mory Ouattara, Ndeye Niang, Rania Gasri, Fouad Badran, Corinne Mandin	2014	@cnam.fr, @cnam.fr, @cstb.fr, @cstb.fr	1001947
115	Une approche PPC pour la fouille de données séquentielles	un approche PPC pour le fouille de donnée séquentiel  cln proposer dans ce article un nouveau approche croiser destechnique de programmation par contrainte et de fouille pour le extraction demotifs séquentiel . le modèle que cln proposer offrir un cadre générique etdéclaratif pour modéliser et résoudre un contrainte de nature hétérogène 	Jean-Philippe Métivier, Samir Loudni, Thierry Charnois	2014		1001951
116	Une approcheWeb sémantique et combinatoire pour un système de recommandation sensible au contexte appliqué à l'apprentissage mobile	un approcheinternet sémantique et combinatoire pour un système de recommandation sensible au contexte appliquer à le apprentissage mobile  Au voir de le émergence rapide des nouveau technologie mobile et lacroissance des offre et besoin de un société en mouvement , le travaux clr multiplientpour identifier un nouveau plateforme de apprentissage pertinent afind'améliorer et faciliter le apprentissage à distance . le prochain étape de le apprentissageà distance être naturellement le port de le e-learning ( apprentissageélectronique ) vers le nouveau système mobile . cln parler de m-learning ( apprentissagemobile ) . son travaux porter sur le développement de un nouvellearchitecture pour le e-learning dont le objectif être de adapter et recommander desparcours de formation selon le contrainte contextuel de le apprenant . 	Fayrouz Soualah Alila, Christophe Nicolle, Florence Mendes	2014	@checksem.fr, @crossknowledge.com	1001979
117	Une heuristique pour le paramétrage automatique de l'algorithme de clustering spectral	un heuristique pour le paramétrage automatique de le algorithme de clustering spectral  trouver le nombre optimal de groupe dans le contexte de un algorithmed clustering être un problème notoirement difficile . dans ce article , cln en décrivons et évaluer un solution approcher dans le cas de le algorithmespectral . son méthode présent le avantage de être déterministe , et peucoûteuse . cln montrer que cln fonctionner de manière satisfaisant dans beaucoupun cas , même si quelque limite amener un perspective à ce travail . 	Pierrick Bruneau, Olivier Parisot, Philippe Pinheiro	2014	@lippmann.lu	1001933
118	Une méthode hybride pour la prédiction du profil des auteurs	un méthode hybride pour le prédiction du profil des auteur  dans ce article , cln clr intéresser à le détection du profil desauteur ( âge , genre ) à travers son discussion . le méthode proposer clr appuiesur le classification automatique qui utiliser certain donnée extraire de un manièrestatistique à partir de corpus source . cln présenter un méthode hybridequi combiner le analyse de surface dans le texte avec un méthode de apprentissageautomatique . A fin de obtenir un meilleur gestion de ce donnée , nousnous somme baser sur le utilisation des arbre de décision . son méthode adonner des résultat intéressant pour le détection du genre . 	Seifeddine Mechti, Maher Jaoua, Lamia Hadrich Belguith	2014	@gmail.com, @fsegs.rnu.t, @fsegs.rnu.t	1001973
119	Une méthode pour caractériser les communautés des réseaux dynamiques à attributs	un méthode pour caractériser le communauté des réseau dynamique à attribut  un nombreux système complexe être étudier via le analyse de réseauxdit complexe avoir un propriété topologique typique . parmi cellesci , le structure de communauté être particulièrement étudier . de nombreusesméthode permettre de cla détecter , cll comprendre dans un réseau contenir desattributs nodaux , un lien orienter ou évoluer dans le temps . le détection prendler forme de un partition de le ensemble des noeud , que ilimp falloir ensuite caractériserrelativement au système modéliser . cln travailler sur le assistance à cettetâche de caractérisation . cln proposer un représentation des réseau sous laforme de séquence de descripteur de noeud , qui combiner le informationstemporelle , le mesure topologique , et le valeur des attribut nodal . Lescommunautés être caractériser au moyen des motif séquentiel émergent lesplus représentatif issir de son noeud . ceci permettre notamment le détectiond comportement inhabituel au sein de un communauté . cln décrire uneétude empirique sur un réseau de collaboration scientifique . 	Gu&#776;nce Keziban Orman, Vincent Labatut, Marc Plantevit, Jean-François Boulicaut	2014	@insa-lyon.fr, @gsu.edu.tr, @gsu.edu.tr, @liris.cnrs.fr	1001919
120	Une méthode pour la détection de thématiques populaires sur Twitter	un méthode pour le détection de thématique populaire sur Twitter  le explosion du volume de message échanger via Twitter entraîner unphénomène de surcharge informationnel pour son utilisateur . ilimp être donc crucialde doter ce dernier de moyens cla aider à filtrer le information brut , laquelleest délivrer sous le forme de un flux de message . dans ce optique , nousproposons un méthode baser sur le modélisation de le anomalie dans le fréquencede création de lien dynamique entre utilisateur pour détecter le fréquencede popularité et extraire un liste ordonner de thématique populaire . le expérimentationsmenée sur un donnée réel montrer que le méthode proposéeest capable de identifier et localiser efficacement le thématique populaire . 	Adrien Guille, Cécile Favre	2014		1001917
121	Une nouvelle approche pour la sélection de variables basée sur une métrique d'estimation de la qualité	un nouveau approche pour le sélection de variable baser sur un métrique de estimation de le qualité  le maximisation de étiquetage ( F-max ) être un métrique non biaiséed'estimation de le qualité de un classification non supervisé ( clustering ) qui favoriseer cluster avoir un valeur maximal de F-mesure de étiquetage . Danscet article , cln montrer que un adaptation de ce métrique dans le cadred le classification supervisé permettre de réaliser un sélection de variable etde calculer pour chacun de lui un fonction de contraste . le méthode être expérimentéesur différent type de donnée textuel . dans ce contexte , nousmontrons que ce technique améliorer le performance des méthode de classificationun façon très significatif par rapport à le état de le art des techniquesde sélection de variable , notamment dans le cas de le classification de donnéestextuel déséquilibré , fortement multidimensionnel et bruiter . 	Jean-Charles Lamirel, Pascal Cuxac, Kafil Hajlaoui	2014	@loria.fr, @inist.fr	1001923
122	Utilisation de relations ontologiques pour la comparaison d'images décrites par des annotations sémantiques	utilisation de relation ontologique pour le comparaison de image décrire par un annotation sémantique  face à le complexité des nouveau génération de image médical , le processus de recherche de image baser sur son contenu visuel pouvoir clr avérer insuffisant . ce article proposer un nouveau approche baser sur le annotation des image via un terme sémantique pouvoir pallier ce problème . cln reposer sur le combinaison de un distance hiérarchique permettre de comparer le image en considérer le corrélation entre le terme utiliser pour cla décrire et de un mesure de similarité permettre de évaluer le proximité sémantique entre un terme ontologique . ce approche être valider dans le cadre de le recherche de image tomodensitométrique . 	Camille Kurtz, Daniel Rubin	2014	@parisdescartes.fr, @stanford.edu	1001991
123	Vers une classification non supervisée adaptée pour obtenir des arbres de décision simplifiés	vers un classification non superviser adapter pour obtenir un arbre de décision simplifier  le induction de arbre de décision être un technique puissant et populairepour extraire de le connaissance . néanmoins , le arbre de décision obtenusdepuis des donnée issu du monde réel pouvoir être très complexe et donc difficilesà exploiter . dans ce cadre , ce article présenter un solution original pouradapter le résultat de un classification non superviser quelconque afin de obtenirun arbre de décision simplifier pour chaque cluster . 	Olivier Parisot, Yoanne Didry, Pierrick Bruneau, Thomas Tamisier	2014	@lippmann.lu	1001965
124	Vers une modularité pour données vectorielles	vers un modularité pour donnée vectoriel  le modularité , introduire par Newman pour mesurer le qualité de unepartition des sommet de un graphe , ne prendre pas en compte de éventuel valeursassocié à ce sommet . dans ce article , cln introduire un mesure de modularitécomplémentaire , baser sur le inertie , et adapter pour évaluer le qualitéd'une partition de élément représenter dans un espace vectoriel réel . ce mesuresion vouloir un pendant pour le classification non superviser de le modularitéd Newman . cln présenter également 2Mod-Louvain , un méthode utilisantce critère de modularité baser sur le inertie conjointement à le modularité deNewman pour détecter un communauté dans un réseau de information . Lesexpérimentations que cln avoir mener avoir montrer que en exploiter à le foisle donnée relationnel et vectoriel , 2Mod-Louvain détecter plus efficacementles communauté que un méthode utiliser un seul type de donnée etqu'el être robuste face à un dégradation des donnée . 	David Combe, Christine Largeron, Elod Egyed-Zsigmond, Mathias Géry	2014	@univ-st-etienne.fr, @insa-lyon.fr	1001914
125	Visualisation de données de prosopographie pour la reconstruction de carrières de personnages et de réseaux socio-professionnels	visualisation de donnée de prosopographie pour le reconstruction de carrière de personnage et de réseau socio- professionnel  dans ce article cln présenter deux approche de visualisation développéesdans le cadre de un projet collaboratif sur le accès et le exploitation desdonnées prosopographique de le Renaissance en France . le objectif du projetest de modéliser et réaliser un portail sémantique assurer le accès à différentesbase de donnée prosopographique existant afin de permettre un meilleureexploration et exploitation de ce donnée . dans ce cadre , cln avoir proposédeux interface de visualisation ProsoGraph et ProsoMap qui clr appuyer respectivementsur le visualisation de graphe de réseau social et le visualisationd lieux géographique et de trajectoire spatio- temporel . le deu interfacescommuniquent avec le portail via un couche sémantique et cld offrir un fonctionnalitésd'interrogation supplémentaire . 	Nizar Messai, Thomas Devogele	2014	@univ-tours.fr	1001978
126	20 ans de découverte de motifs : une étude bibliographique quantitative	20 an de découverte de motif : un étude bibliographique quantitatif  depuis deux décennie , le découverte de motif avoir être le un des champs de recherche le plus actif de le exploration de donnée . ce article cll établir un étude bibliographique quantitatif en cld appuyer sur 1030 publication issir de 5 conférence international majeur : KDD , PKDD , PAKDD , ICDM et SDM . cln avoir de abord mesurer depuis 2005 un sévère ralentissement de le activité de recherche dédier à le découverte de motif . Puis , cln avoir quantifier le principal contribution en terme de langage , de contrainte et de représentation condensé de sorte à comprendre ce ralentissement et à esquisser le direction actuel . 	Arnaud Giacometti, Dominique Haoyuan Li, Arnaud Soulet	2013	@univ-tours.fr	1001830
127	3D : de nouvelles perspectives en fouille exploratoire avec la stéréoscopie	3D : un nouveau perspective en fouille exploratoire avec le stéréoscopie  si le 3D être un sujet de débat dans le communauté , le expérience sur lequel clr appuyer le discussion concerner le plus souvent un restitution visuel baser sur un projection classique en perspective linéaire . le objectif de ce communication être de renouveler le cadre expérimental en étudier le impact de le ajout de le disparité binoculaire . cln cld focaliser ici sur un tâche important en analyse de réseau : le identification de communauté . et cln comparer le 3.D. monoscopique et le 3.D. stéréoscopique à le fois pour le performance de résolution de le tâche et pour le comportement exploratoire à travers le analyse du mouvement du pointeur de le souris et de le dynamique des modification de point de vue sur le graphe . son résultat expérimental mettre en évidence des performance significativement meilleur pour le 3.D. stéréoscopique et des différence comportemental dans le exploration avec un centrage plus important sur un zone restreindre en stéréoscopie . 	Nicolas Greffard, Fabien Picarougne, Pascale Kuntz	2013	@univ-nantes.fr	1001831
128	Accélération de la méthode des K plus proches voisins pour la catégorisation de textes	accélération de le méthode des K plus proche voisins pour le catégorisation de texte  parmi le panoplie de classificateur utiliser dans le catégorisation de texte , cln clr intéresser à le algorithme des k-voisins le plus proche . ce performance cla situer parmi le meilleur méthode de catégorisation de texte . toutefois , ilimp présenter certain limite : ( i ) coût mémoire car ilimp falloir stocker le ensemble de apprentissage en entier et ( ie ) coût élevé de calcul car ilimp devoir explorer le ensemble de apprentissage pour classer un nouveau document . dans ce papier , cln proposer un nouveau démarche pour réduire ce temps de classification sans dégrader le performance de classification . 	Fatiha Barigou, Baghdad Atmani, Youcef Bouziane, Naouel Barigou	2013	@gamil.com, @gmail.com	1001841
129	Analyse conceptuelle de données de simulation de systèmes complexes pour l'aide à la décision : Application à la conception d'une cabine d'avion	analyse conceptuel de donnée de simulation de système complexe pour le aide à le décision : application à le conception de un cabine de avion  dans ce article cln présenter un approche conceptuel de aide à le décision dans le conception de système complexe . ce approche clr appuyer sur le formalisme de le analyse de concept formel par similarité ( ACFS ) pour le classification , le visualisation et le exploration de donnée de simulation afin de aider le concepteur de système complexe à identifier le choix de conception le plus pertinent . le approche être illustrer sur un cas test de conception de cabine de un avion de ligne fournir par le partenaire industriel et qui consister à étudier le donnée de simulation de différent configuration du système de ventilation de le cabine afin de identifier celui qui assurer un confort convenable pour le passager le cabine . le classification des donnée de simulation avec son score de confort en utiliser le ACFS permettre de identifier pour chaque paramètre de conception simuler le plage de valeur possible qui assurer un confort convenable pour le passager . le résultat obtenir avoir être confirmer et valider par un nouveau simulation . 	Nizar Messai, Cassio Melo, Mohamed Hamdaoui, Dung Bui, Marie-Aude Aufaure	2013	@univ-tours.fr, @ecp.fr	1001835
130	Analyse de réseaux sociaux par l'analyse formelle de concepts	analyse de réseau social par le analyse formel de concept  le analyse formel de concept ( AFC ) être un formalisme de représentation et de extraction de connaissance fonder sur le notion de concept et de treillis de concept ( Galois ) . le AFC avoir être exploiter avec succès dans plusieurs domaine en informatique tel le génie logiciel , le base et entrepôt de donnée , le extraction et le gestion de le connaissance et dans plusieurs application du monde réel comme le médecine , le psychologie , le linguistique et le sociologie . dans ce présentation , cln aller explorer le potentiel de le AFC et de quelque extension de ce théorie ( exès analyse triadique de concept ) dans le analyse de réseau social en vue de découvrir un connaissance à partir de réseau homogène simple ( exès détection de communauté et de individu influent à partir de un réseau de ami ) ou même de réseau hétérogène ( exès extraction de règle de association de un réseau bibliographique ) . 	Rokia Missaoui	2013	@uqo.ca	1001814
131	Analyse des réclamations d'allocataires de la CAF : un cas d'étude en fouille de données	analyse des réclamation de allocataire de le CAF : un cas de étude en fouille de donnée  le gestion des réclamation être un élément fondamental dans le relation client . ce être le cas en particulier pour le caisse national des allocation familiale qui vouloir mettre en place un politique national pour faciliter ce gestion . dans ce article , cln décrire le démarche que cln avoir adopter afin de traiter automatiquement le réclamation provenir de allocataire de le CAF du Rhône . le donnée brut mettre à son disposition nécessiter un série important de prétraitement pour cla rendre utilisable . un fois ce donnée correctement nettoyer , un technique issu de le analyse des donnée et de le apprentissage non superviser cln permettre de extraire à le fois un typologie des réclamation baser sur son contenu textuel mais aussi un typologie des allocataire réclamant . après avoir présenter ce deu typologie , cln cla mettre en correspondance afin de voir comment le allocataire clr distribuer selon le différent type de réclamation . 	Sabine Loudcher, Julien Velcin, Vincent Forissier, Cyril Broilliard, Philippe Simonnot	2013	@univ-lyon2.fr, @cnedi69.cnafmail.fr, @cafrhone.cnafmail.fr	1001866
132	Analyse Relationnelle de Concepts pour l'exploration de données relationnelles	analyse Relationnelle de concept pour le exploration de donnée relationnel  le analyse Relationnelle de Concepts ( ARC ) être un extension de le analyse Formelle de Concepts ( AFC ) , un méthode de classification non supervisé de objet sous forme de treillis de concept . le ARC supporter en plus le gestion de relation entre objet de différent contexte ce qui permettre de établir un lien entre le concept des différent treillis . ce particularité cld permettre de être plus intuitif à utiliser pour extraire un connaissance à partir de donnée relationnel et de donner un résultat plus riche . malheureusement lorsque le jeu de donnée présenter un nombreux relation , le résultat obtenir être difficilement exploitable et des problème de passage à le échelle clr poser . cln proposer dans ce article un adaptation possible de le ARC pour explorer le relation de manière superviser pour augmenter le pertinence des résultat obtenir et réduire le temps de calcul . cln prendre pour exemple des donnée hydrobiologique avoir trait à le qualité des milieu aquatique . 	Xavier Dolques, Florence Le Ber, Marianne Huchard, Clémentine Nebut	2013	@unistra.fr, @lirmm.fr	1001829
133	Approche orientée objet sémantique et coopérative pour la classification des images de zones urbaines à très haute résolution	approche orienter objet sémantique et coopératif pour le classification des image de zone urbain à très haut résolution  le classification orienter objet ( COO ) prendre de plus en plus de dimension dans le travaux de télédétection grâce à son capacité de intégrer un connaissance de haut niveau tel que le taille , le forme et le information de voisinage . cependant , le approche existant rester tributaire de le étape de construction des objet à cause de le absence de interaction entre celui -ci et celui de son identification . dans ce article , cln proposer un approche sémantique , hiérarchique et collaboratif entre le algorithme de croissance de région et un classification orienter objet superviser , permettre un coopération entre le extraction et le identification des objet de le image . le expérience mener sur un image de très haut résolution de le région de Strasbourg avoir confirmer le intérêt de le approche introduire . 	Aymen Sellaouti, Atef Hamouda, Aline Deruyver, Cédric Wemmert	2013	@gmail.com, @lsiit.u-strasbg.fr, @yahoo.fr, @unistra.fr	1001827
134	Classification multi-étiquettes pour l'alignement multiple de séquences protéiques	classification multi-étiquet pour le alignement multiple de séquence protéique  ce article présenter un application de classification multi-étiquet permettre de déterminer le programme à utiliser pour construire un alignement multiple de un ensemble de séquence protéique donner . dans un premier temps , cln avoir réussir à améliorer le système existant , Alexsys en ajouter un attribut . dans un second temps , cln déterminer pour un ensemble de séquence protéique donner le ou le aligneur capable de produire le alignement de meilleur score , à epsilon près . le mesure de performance propre à le classification multi-étiquet cld permettre de analyser le influence de epsilon et de choisir un valeur assez petit pour distinguer le meilleur aligneur des autre . 	Lina Fahed, Gabriel Frey, Julie Dawn Thompson, Nicolas Lachiche	2013	@gmail.com, @unistra.fr, @unistra.fr, @igbmc.fr	1001864
135	Classifications croisées de données de trajectoires contraintes par un réseau routier	classification croisé de donnée de trajectoire contraindre par un réseau routier  le clustering ( ou classification non supervisé ) de trajectoire avoir faire le objet de un nombre considérable de travaux de recherche . le majorité de ce travaux clr être intéresser au cas où le objet mobile engendrer ce trajectoire clr déplacer librement dans un espace euclidien et ne prendre pas en compte le contrainte lier à le structure sous-jacent du réseau que cln parcourir ( exès réseau routier ) . dans le présent article , cln proposer au contraire le prise en compte explicite de ce contrainte . cln représenter le relation entre trajectoire et segment routier par un graphe biparti et cln étudier le classification de son sommet . cln illustrer , sur un jeu de donnée synthétique , le utilité de un tel étude pour comprendre le dynamique du mouvement dans le réseau routier et analyser le comportement des véhicule qui cla emprunter . 	Mohamed K. El Mahrsi, Romain Guigourès, Fabrice Rossi, Marc Boullé	2013	@telecom-paristech.fr, @univ-paris1.fr, @univ-paris1.fr, @univ-paris1.fr, @orange.com, @orange.com	1001854
136	Comprendre et interpréter les données : enjeux et implantations d'un système de codage dans des gisements de données historiques	comprendre et interpréter le donnée : enjeu et implantation de un système de codage dans un gisement de donnée historique  le accès croissant à un information pléthorique et le développement de gisement de donnée ambitieux poser aujourde hui deux grand type de difficulté aux historien . le premier consister à mettre en relation des gisement qui avoir être développer de manière indépendant . ce être par exemple le cas pour le intégration de un ensemble de base de donnée prosopographique développer entre 1980 et 2010 au Lamop , ou même dans le cadre de un projet dont le seul lien être un problématique spatial et temporel ( projet ANR-DFG , Euroscientia ) . le deuxième tenir en le nature des donnée introduire dans ce différent système : cln être souvent hétérogène , ambigu , flou . pour que le chercheur pouvoir clr cla approprier , le donnée devoir faire le objet de un véritable travail , afin de comprendre comment cln avoir être obtenir , structurer . le historien devoir donc cla évaluer et cla valider clr ilimp souhaiter cla mettre en relation . ce évaluation nécessiter , lui-même de pouvoir être commenter , partager et critiquer par un autre chercheur . dans le deu cas , ilimp être nécessaire de développer un outil de appropriation , qui permettre de entrer dans le réel historique contenir dans le stock de donnée . ce être là le fonction du projet Histobase , un système permettre de entrer dans le structuration des gisement , de cll évaluer le information , de ajouter un couche de interprétation ( qualification de le information historique ) de cla évaluer et de partager le donnée « obtenir » . chacun des analyse individuel et collectif faire le objet de un mémorisation . ilimp falloir pour cela laisser un place important aux historien en tant que expert en prêter un attention particulier aux processus métier que cln mettre en oeuvre . 	Stéphane Lamassé, Julien Alerini	2013	@univ-paris1.fr, @wanadoo.fr	1001816
137	Construction de descripteurs à partir du coclustering pour la classification supervisée de séries temporelles	construction de descripteur à partir du coclustering pour le classification superviser de série temporel  cln présenter un processus de construction de descripteur pour le classification superviser de série temporel . ce processus être libre de tout paramétrage utilisateur et clr décomposer en trois étape : ( i ) à partir un donnée original , cln générer de multiple nouveau représentation simple ; ( ie ) sur chacun de ce représentation , cln appliquer un algorithme de coclustering ; ( iii ) à partir un résultat de co- coclustering , cln construire de nouveau descripteur pour le série temporel . cln obtenir un nouveau base de donnée objets-attribut dont le objet ( identifier le série temporel ) être décrire par un attribut issu des divers représentation générer . cln utiliser un classifieur Bayésien sur ce nouveau base de donnée . cln montrer expérimentalement que ce processus offrir de très bon performance prédictif comparer à le état de le art . 	Dominique Gay, Marc Boullé	2013	@orange.com	1001855
138	Découverte des soft-skypatterns avec une approche PPC	découverte des soft-skypattern avec un approche PPC  le skypattern être un motif traduire un préférence de le utilisateur selon un relation de dominance . dans ce article , cln introduire le notion de souplesse dans le problématique des skypattern et cln montrer comment celui -ci permettre de découvrir un motif intéressant qui être manquer autrement . cln proposer un méthode efficace de extraction de skypattern ainsi que de skypattern , méthode fonder sur le programmation par contrainte . le pertinence de son approche être illustrer à travers un étude de cas en chémoinformatique pour le découverte de toxicophore . 	Willy Ugarte, Patrice Boizumault, Samir Loudni, Bruno Crémilleux, Alban Lepailleur	2013	@unicaen.fr	1001838
139	Détection efficace des traverses minimales d'un hypergraphe par élimination de la redondance	détection efficace des traverse minimal de un hypergraphe par élimination de le redondance  le extraction des traverse minimal de un hypergraphe être un problématique réputé comme particulièrement difficile et qui avoir faire le objet de plusieurs travaux dans le littérature . dans ce article , cln établir un lien entre le concept de le fouille de donnée et celui de le théorie des hypergraphe , proposer ainsi un cadre méthodologique pour le calcul des traverse minimal . le nombre de ce traverse minimal être , souvent , exponentiel même pour un hypergraphe simple , cln proposer de cll représenter le ensemble de manière concis et exact . pour ce faire , cln introduire le notion de traverse minimal irrédondant , à partir desquelles cln pouvoir retrouver le ensemble global de tout le traverse minimal , à le aide de le algorithme IMT-EXTRACTOR . un étude expérimental de ce nouveau algorithme avoir confirmer le intérêt de le approche introduire . 	Mohamed Nidhal Jelassi, Christine Largeron, Sadok Ben Yahia	2013	@fst.rnu.tn, @univ-st-etienne.fr	1001833
140	Détection précoce de tendances produits dans le cadre des activités commerciales de la grande distribution	détection précoce de tendance produire dans le cadre des activité commercial de le grand distribution  " dans ce papier , cln présenter un nouveau approche qui permettre le détection précoce de tendance " " produit " " dans le cadre des activité commercial de le grand distribution . . clr agir de un domaine où le concurrence être très vif entre le différent enseigne avec un enjeu financier colossal , le stratégie commercial avoir pour principal objectif de fidéliser le clientèle pour limiter son défection . . ce être là que intervenir le détection des changement de tendance produit , qui aller permettre de anticiper le attrition de le clientèle . . Déceler des tendance suffisamment tôt permettre aux décideur de mettre en place des stratégie préventif efficace à moindre coût . . son objectif être donc de analyser et de modéliser clairement le changement de tendance et son impact potentiel global sur le achat des client . . cln illustrer son approche sur un donnée réel de achat de client de un grand enseigne . " 	Gaël Bardury, Jean-Emile Symphor	2013	@gmail.com, @univ-ag.fr	1001840
141	Enrichissement d'ontologies grâce à l'annotation sémantique de pages web	enrichissement de ontologie grâce à le annotation sémantique de page web  cln présenter un approche pour enrichir automatiquement un ontologie à partir de un ensemble de page web structurer . ce approche clr appuyer sur un noyau de ontologie initial . son originalité être de exploiter conjointement le structure des document et des annotation sémantique produire à le aide du noyau de ontologie pour identifier un nouveau concept et des spécialisation de relation qui enrichir le ontologie . cln avoir implémenter et évaluer ce processus en réaliser un ontologie de plante à partir de fiche de jardinage . 	Nathalie Aussenac-Gilles, Davide Buscaldi, Catherine Comparot, Mouna Kamel	2013	@irit.fr, @univ-paris13.fr	1001839
142	Étude des corrélations spatio-temporelles des appels mobiles en France	étude des corrélation spatio- temporel des appel mobile en France  cln proposer dans ce article de présenter un application de analyse de un base de donnée de grand taille issue du secteur des télécommunications . le problème consister à segmenter un territoire et caractériser le zone ainsi définir grâce au comportement des habitant en terme de téléphonie mobile . cln disposer pour cela de un réseau de appel inter-antenne construire pendant un période de cinuelque mois sur le ensemble de le France . cln proposer un analyse en deux phase . le premier coupler le antenne émetteur dont le appel être similairement distribuer sur le antenne récepteur et vice verser . un projection de ce groupe de antenne sur un carte de France permettre un visualisation des corrélation entre le géographie du territoire et le comportement de son habitant en terme de téléphonie . le seconde phase découper le année en période entre lequel cln observer un changement de distribution de appel sortant des groupe de antenne . cln pouvoir ainsi caractériser le évolution temporel du comportement des usager de mobile dans chacun des zone du pays . 	Romain Guigourès, Marc Boullé, Fabrice Rossi	2013	@orange.com, @univ-paris1.fr	1001865
143	Étude des techniques d'oubli dans les moindres carrés récursifs pour l'apprentissage incrémental de systèmes d'inférence floue évolutifs : application à la reconnaissance de formes	étude des technique de oubli dans le moindre carré récursif pour le apprentissage incrémental de système de inférence flou évolutif : application à le reconnaissance de forme  ce article étudier le possibilité de utilisation de oubli dans le apprentissage incrémental en-ligne de classifieur évolutif baser sur un système de inférence flou . pour cela , cln étudier différent possibilité , existant dans le littérature dédier au contrôle , pour introduire de le oubli dans le algorithme des moindre carré récursif . cln présenter le impact de ce différent technique dans le contexte de le apprentissage incrémental de classifieur évolutif en environnement non stationnaire . ce approche être évaluer , pour le optimisation des système de inférence flou , sur le problématique de le reconnaissance de geste manuscrit sur surface tactile . 	Manuel Bouillon, Eric Anquetil, Abdullah Almaksour	2013	@irisa.fr	1001818
144	Évolution d'une ontologie dédiée à la représentation de relations n-aires	évolution de un ontologie dédier à le représentation de relation n-air  cln cln intéresser dans ce article à le problématique de évolution de un ontologie permettre de représenter un relation n-air . cln présenter le représentation formel des changement applicable à son ontologie permettre de modifier son structure tout en maintenir son cohérence structurel . cln illustrer son propos sur un ontologie dédier à le représentation de relation n-air entre un donnée expérimental quantitatif . 	Rim Touhami, Patrice Buche, Juliette Dibie-Barthélemy, Liliana Ibanescu	2013	@risk, @agroparistech.fr, @supagro.inra.fr, @agroparistech.fr	1001862
145	Extraction de motifs condensés dans un unique graphe orienté acyclique attribué	extraction de motif condenser dans un unique graphe orienter acyclique attribuer  le graphe orienter acyclique attribuer pouvoir être utiliser dans beaucoup de domaine applicatif . dans ce papier , cln étudier un nouveau domaine de motif pour permettre son analyse : le chemin pondérer fréquent . cln proposer en conséquence des contrainte primitif permettre de évaluer son pertinence ( par exemple , le contrainte de fréquence et de compacité ) , et un algorithme extraire ce solution . cln aboutir à un représentation condensé dont le efficacité et le passage à le échelle être étudier empiriquement . 	Jérémy Sanhes, Frédéric Flouvat, Claude Pasquier, Nazha Selmaoui-Folcher	2013	@univ-nc.nc, @unice.fr	1001837
146	Extraction de motifs fréquents dans des arbres attribués	extraction de motif fréquent dans un arbre attribuer  le extraction de motif fréquent être un tâche important en fouille de donnée . initialement centrer sur le découverte de ensemble de item fréquent , le premier travaux avoir être étendre pour extraire un motif structurel comme un séquence , un arbre ou des graphe . dans ce article , cln proposer un nouveau méthode de fouille de donnée qui consister à extraire un nouveau type de motif à partir de un collection de arbre attribuer . le arbre attribuer être un arbre dans lequel le noeud être associer à un ensemble de attribut . le extraction de ce motif ( appeler sous-arbre attribuer ) combiner un recherche de ensemble de item fréquent à un recherche de sous-arbre et nécessiter de explorer un immense espace de recherche . cln présenter plusieurs nouveau algorithme de extraction de arbre attribuer et montrer que son implémentation pouvoir efficacement extraire un motif fréquent à partir un grand jeu de donnée . 	Claude Pasquier, Jérémy Sanhes, Frédéric Flouvat, Nazha Selmaoui-Folcher	2013	@univ-nc.nc, @unice.fr	1001836
147	Extraction des nombres de Betti avec un modèle génératif	extraction des nombre de Betti avec un modèle génératif  le analyse exploratoire de donnée multidimensionnel être un problème complexe . cln proposer de extraire certain invariant topologique appelé nombre de Betti , pour synthétiser le topologie de le structure sous-jacent aux donnée . cln définir un modèle génératif baser sur le complexe simplicial de Delaunay dont cln estimer le paramètre par le optimisation du critère de information Bayésien ( BIC ) . ce complexe Simplicial Génératif cld permettre de extraire le nombre de Betti de donnée jouet et de image de objet en rotation . comparer à le technique géométrique des Witness Complex , le CSG apparer plus robuste aux donnée bruiter . 	Maxime Maillot, Michaël Aupetit, Gérard Govaert	2013	@cea.fr, @cea.fr, @utc.fr	1001826
148	Extraction et filtrage de syntagmes nominaux pour la Recherche d'Information	extraction et filtrage de syntagme nominal pour le recherche de information  cln proposer dans ce article un système de recherche de Information ( SRI ) qui clr baser sur un technique de indexation de texte en langue naturel . cln présenter un méthode de indexation de document qui reposer sur un approche hybride pour le sélection de descripteur textuel . ce approche employer des traitement du langage naturel pour le extraction des syntagme nominal et sur un filtrage statistique baser sur le information mutuel pour sélectionner le syntagme nominal le plus informatif pour le processus de indexation . cln effectuer un expérimentation en utiliser le corpus le Monde 94 de le collection clef 2001 et sur le SRI Lemur pour évaluer le approche proposer . 	Chedi Bechikh Ali, Hatem Haddad	2013	@gmail.com, @gmail.com	1001842
149	Extraction optimisée de Règles d'Association Positives et Négatives (RAPN)	extraction optimiser de règle de association Positives et Négatives ( RAPN )  le littérature clr être beaucoup intéresser à le extraction de règle de association positif et peu à le extraction de règle négatif en raison essentiellement du coût de calcul et du nombre prohibitif de règle extraire qui être pour le plupart redondant et inintéressant . dans ce article , cln clr être intéresser aux algorithme de extraction de RAPN ( règle de association Positives et Négatives ) reposer sur le algorithme fondateur Apriori . cln avoir faire un étude de celui -ci en mettre en évidence son avantage et son inconvénient . A le issue de ce étude , cln avoir proposer un nouveau algorithme qui améliorer ce extraction au niveau du nombre et de le qualité des règle extraire et au niveau du parcours de recherche des règle . le étude clr être terminer par un évaluation de ce algorithme sur plusieurs base de donnée . 	Sylvie Guillaume, Pierre-Antoine Papon	2013	@isima, @isima	1001832
150	Grille bivariée pour la détection de changement dans un flux étiqueté	grille bivarié pour le détection de changement dans un flux étiqueter  cln présenter un méthode en-ligne de détection de changement de concept dans un flux étiqueté . son méthode de détection être baser sur un critère superviser bivarié qui permettre de identifier si le donnée de deux fenêtre provenir ou non de le même distribution . son méthode avoir le intérêt de ne avoir aucun avoir priorir sur le distribution des donnée , ni sur le type de changement et être capable de détecter un changement de différent nature ( changement dans le moyenne , dans le variance ... ) . le expérimentation montrer que son méthode être plus performant et robuste que le méthode de le état de le art tester . de plus , à part le taille des fenêtre , cln ne requérir aucun paramètre utilisateur . 	Christophe Salperwyck, Marc Boullé, Vincent Lemaire	2013	@orange.com	1001859
151	Identification de compatibilités entre descripteurs de lieux et apprentissage automatique	identification de compatibilité entre descripteur de lieux et apprentissage automatique  le travaux présenter dans ce article clr inscrire dans le paradigme des recherche viser à acquérir un relation sémantique à partir de folksonomie ( ensemble de tag attribuer à un ressource par un utilisateur ) . cln expérimenter plusieurs approche issu de le état de le art ainsi que le apport de le apprentissage automatique pour le identification de relation entre tag . cln obtenir dans le meilleur des cas un taux de erreur de 23,7 \pourcent ( relation non reconnaître ou faux ) , ce qui être encourageant au voir de le difficulté de le tâche ( le annotateur humain avoir un taux de désaccord de 12 \pourcent ) . 	Estelle Delpech, Laurent Candillier, Léa Laporte, Samuel Phan	2013	@nomao.com, @ebuzzing.com, @irit.fr	1001850
152	Identification de complexes protéine-protéine par combinaison de classifieurs. Application à Escherichia Coli	identification de complexe protéine-protéine par combinaison de classifieur . application à Escherichia Coli  cln proposer un approche permettre de prédire un complexe impliquer trois protéine ( appelé trimère ) à partir de combinaison de classifieur apprendre sur un complexe ne impliquer que deux protéine ( dimère ) . le prédiction de ce trimère reposer sur deux hypothèse biologique : ( i ) deux protéine orthologue présenter un caractéristique fonctionnel similaire ; ( ie ) deux protéine interagir sous le forme de un complexe sous-tendent un fonction biologique essentiel à le espèce concerner . ce deu hypothèse être exploiter pour décrire chaque paire de protéine par le ensemble des espèce pour lequel cln posséder un orthologue . un ensemble de mesure de qualité classiquement utiliser pour évaluer le intérêt des règle de association être utiliser pour évaluer le force du lien entre le deu protéine . le organisme modèle Escherichia Coli avoir être utiliser pour évaluer son approche . 	Thomas Bourquard, Damien M. de Vienne, Jérôme Azé	2013	@tours.inra.fr, @crg.es, @lri.fr	1001863
153	Inférence de réseaux biologiques : un défi pour la fouille de données structurées	inférence de réseau biologique : un défi pour le fouille de donnée structurer  " le réponse cellulaire de un organisme vivre à un signal donné , hormone , stress ou médicament , mettre en jeu des mécanisme complexe de interaction et de régulation entre le gène , le ARN messager , le protéine et un autre élément tel que le micro- ARNs . . cln parler de réseau de interaction pour décrire le ensemble des interaction possible entre protéine et de réseau de régulation génique pour représenter un ensemble de régulation entre gène . . Identifier ce interaction et ce régulation ouvrir le porte à un meilleur compréhension du vivre et permettre de envisager de mieux soigner par le biais du ciblage thérapeutique . . puisque le technique expérimental de mesure à grand échelle , récemment développer , fournir un donnée de observation de ce réseau , ce problème de identification de réseau , généralement appeler inférence de réseau en biologie des système , clr inscrire dans le cadre général de le fouille de donnée et plus particulièrement de le apprentissage artificiel . . voilà maintenant quelque année que ce problématique avoir être poser à son communauté et durant lequel le échange entre biologiste et informaticien avoir non seulement permettre aux biologiste de étoffer son boîte à outil mais aussi aux informaticien de concevoir un nouveau méthode de fouille de donnée . . en partir un deu problématique distinct que être le inférence de réseau de interaction et le inférence de réseau de régulation , cln montrer que ce deu tâche de apprentissage poser , chacun de manière différent , le problématique de le prédiction de sortie structurer . . le inférence de réseau de interaction entre protéine , voir comme un problème transductif de prédiction de lien , pouvoir être résoudre comme un problème de apprentissage de un noyau de sortie à partir de un noyau de entrée . . le inférence de réseau de régulation , impliquer le modélisation de un système dynamique , pouvoir être aborder par le approximation parcimonieux et structuré de fonction à valeur vectoriel . . cln présenter un ensemble de nouveau outil de régression à sortie dans un espace de Hilbert , fonder sur un noyau à valeur opérateur , qui fournir un excellent résultat en inférence de réseau biologique . . un expérience in silico sur un donnée artificiel , chez le levure du boulanger ou chez le homme illustrer son propos . . en fin de exposé , cln tracer quelque perspective concernant le " " nouveau " " défi dans le domaine de le bioinformatique et dans celui de le prédiction de sortie structurer . " 	Florence D'Alche-Buc	2013	@ibisc.fr	1001815
154	Les capitalistes sociaux sur Twitter : détection via des mesures de similarité	le capitaliste social sur Twitter : détection via un mesure de similarité  le réseau social tel que Twitter faire partie du phénomène de déluge des donnée , expression utiliser pour décrire le apparition de donnée de plus en plus volumineux et complexe . pour représenter ce réseau , un graphe orienter être souvent utiliser . dans ce article , cln clr focaliser sur deux aspect de le analyse du réseau social de Twitter . en premier lieu , son but être de trouver un méthode efficace et haut niveau pour stocker et manipuler le graphe du réseau social en utiliser un ressource informatique raisonnable . ce axe de recherche constituer un enjeu majeur puisque ilimp être ainsi possible de traiter un graphe à échelle réel sur un machine potentiellement accessible par tout . ensuite , cln étudier le capitaliste social , un type particulier de utilisateur de Twitter observer par Ghosh et alection ( 2012 ) . cln proposer un méthode pour détecter et classifier efficacement ce utilisateur . 	Nicolas Dugué, Anthony Perez	2013		1001852
155	Modèle de Recherche d'Information Sociale Centré Utilisateur	modèle de recherche de information Sociale Centré Utilisateur  le émergence des réseau social avoir révolutionner leWeb en permettre notamment aux individu de prolonger son connexion virtuel en un relation plus réel et de partager son connaissance . ce nouveau contexte de diffusion de le information sur le Web pouvoir constituer un moyen efficace pour cerner le besoin en information des utilisateur du Web , et permettre à le recherche de information ( RI ) de mieux répondre à ce besoin en adapter le modèle de indexation et de interrogation . le exploitation des réseau social confronter le RI à plusieurs défi dont le plus important concerner le représentation de le information dans ce modèle social de RI et son évaluation , en le absence de collection de test et de compétition dédier . dans ce article , cln présenter un modèle de RI social dans lequel cln proposer de modéliser et de exploiter le contexte social de le utilisateur . cln avoir évaluer son modèle à le aide de un collection de test de RI social construire à partir un annotation du réseau social de bookmarking collaboratif Delicious . 	Chahrazed Bouhini, Mathias Géry, Christine Largeron	2013	@univ-st-etienne.fr	1001846
156	Nouvelle approche de bi-partitionnement topologique	nouveau approche de bi-partitionnement topologique  dans ce papier , cln proposer un nouveau approche topologique de bi-partitionnement ( bi-clustering ) appelé BiTM en utiliser le carte autoorganisatrice . le idée principal de le approche être de utiliser un seul carte pour le partitionnement simultané des ligne ( observation ) et des colonne ( variable ) . contrairement aux approche utiliser le carte topologique , son modèle ne nécessiter pas de pré-traitement de le base de donnée . ainsi , un nouveau fonction de coût être proposer . de plus , BiTM fournir un visualisation topologique des bloc ou bi-cluster facilement interprétable . le résultat obtenir être très encourageant et prometteur pour continuer dans ce optique . 	Amine Chaibi, Mustapha Lebbah, Hanane Azzag	2013	@univ-paris13.fr	1001820
157	Paramétrage intelligent de l'alignement d'ontologies par l'intégrale de Choquet	Paramétrage intelligent de le alignement de ontologie par le intégral de Choquet  le nombre croissant de ontologie rendre le processus de alignement un composante essentiel du Web sémantique . plusieurs outil avoir être concevoir dans le but de produire un alignement . le qualité des alignement fournir par ce outil être étroitement lier à certain paramètre qui régir son traitement . dans ce papier , cln proposer un nouveau approche permettre le adaptation automatique des paramètre de alignement de ontologie par le utilisation de le intégral de Choquet , comme un opérateur de agrégation . le expérimentation montrer un net amélioration des résultat par rapport à un paramétrage statique et figer . 	Marouen Kachroudi, Sami Zghal, Sadok Ben Yahia	2013	@fst.rnu.tn, @fsjegj.rnu.tn	1001857
158	Processus itératif d'extraction de classes en non supervisée	processus itératif de extraction de classe en non superviser  cln proposer dans ce article un nouveau approche de classification non superviser où le classe être obtenir le un après le autre suivre un processus itératif . le approche utiliser un méthode de extraction de classe baser sur le détection de limite de classe , chaque classe être définir par son centre . cln avoir également définir un critère de évaluation adapter à le méthode proposer . plusieurs expérimentation avoir montrer le intérêt de le approche dans divers problème . 	Alexandre Blansché, Lydia Boudjeloud	2013	@univ-lorraine.fr	1001817
159	Ré-écriture de requêtes dans un système d'intégration sémantique	Ré-écriture de requête dans un système de intégration sémantique  cln décrire le deuxième phase de réalisation de un système de intégration qui minimiser le intervention humain habituellement nécessaire . après le phase de construction semi-automatique du schéma ( ontologie ) global décrire dans un précédent article , cln présenter ici le processus de ré-écriture de requête global en un requête adresser aux source . 	Cheikh Niang, Béatrice Bouchou, Moussa Lo, Yacine Sam	2013	@univ-tours.fr, @ugb.edu.sn	1001858
160	Recherche de documents similaires sur le web par segmentations hiérarchiques et extraction de mots-clés	recherche de document similaire sur le web par segmentation hiérarchique et extraction de mots -clé  le recherche de document similaire être un processus qui consister à trouver le document présenter un similitude , comme le copie ou le reformulation , sur un base documentaire ou sur internet . cln être utiliser notamment pour protéger le propriété intellectuel de production issu de le enseignement , de le recherche ou de le industrie . dans ce article , cln définir un approche automatique pour permettre de extraire un mots -clé de un document en effectuer un bouclage sur un succession de découpage de plus en plus petit . ce approche permettre de obtenir un mots -clé impossible à obtenir par un approche global notamment quand le thématique , le style ou le contenu de un document varier dans le document . le objectif être de permettre le détection des document présenter un similitude en utiliser uniquement un mots -clé . 	Alain Simac-Lejeune	2013	@compilatio.net	1001860
161	Réutiliser les connaissances d'expert pour assister l'analyse de l'activité sur simulateur pleine échelle de conduite de centrale nucléaire - Approche à base de M-Trace	réutiliser le connaissance de expert pour assister le analyse de le activité sur simulateur plein échelle de conduite de central nucléaire - approche à base de M-Trace  son travail porter sur le aide à le observation de le activité dans le simulateur plein échelle de centrale nucléaire pour assister le formateur pendant le simulation . son approche consister à représenter le activité sous le forme de trace modélisé et à cla transformer afin de extraire et de visualiser un information de haut niveau permettre aux formateur de mieux retracer et analyser le simulation . afin de valider son approche , cln avoir concevoir le prototype D3KODE que cln avoir évaluer avec un expert formateur de EDF . 	Olivier Champalle, Karim Sehaba	2013	@liris.fr	1001828
162	Sélection de variables non supervisée sous contraintes hiérarchiques	sélection de variable non superviser sous contrainte hiérarchique  le sélection des variable avoir un rôle très important dans le fouille de donnée lorsque un grand nombre de variable être disponible . ainsi , certain variable pouvoir être peu significatif , corréler ou non pertinent . un méthode de sélection avoir pour objectif de mesurer le pertinence de un ensemble utiliser principalement un critère de évaluation . cln présenter dans ce article un critère non superviser permettre de mesurer le pertinence de un sous-ensemble de variable . ce dernier reposer sur le utilisation du score Laplacien auquel cln avoir ajouter des contrainte hiérarchique . travailler dans le cadre non superviser être un vrai challenge dans ce domaine devoir à le absence des étiquette de classe . le résultat obtenir sur plusieurs base de test être très encourageant et prometteur . 	Nhat-Quang Doan, Hanane Azzag, Mustapha Lebbah	2013	@univ-paris13.fr	1001823
163	SNOW, un algorithme exploratoire pour le subspace clustering	SNOW , un algorithme exploratoire pour le subspace clustering  ce article proposer un nouveau algorithme pour le problème de subspace clustering dénommer SNOW . contrairement aux approche descendant classique , ilimp ne reposer pas sur le hypothèse de localité et permettre le affectation de un donner à plusieurs cluster dans un sous-espace différent . le expérimentation préliminaire montrer que son approche obtenir de meilleur résultat que le algorithme COPAC sur un base de référence et avoir être appliquer sur un base de donnée réel . 	Sylvain Dormieu, Nicolas Labroche	2013	@gmail.com, @lip6.fr	1001868
164	Technique de factorisation multi-biais pour des recommandations dynamiques	technique de factorisation multi-biais pour un recommandation dynamique  le factorisation de matrice offrir un grand qualité de prédiction pour le système de recommandation . mais son nature statique empêcher de tenir compte des nouveau note que le utilisateur produire en continu . ainsi , le qualité des prédiction décroître entre deux factorisation lorsque un nombreux note ne être pas prendre en compte . le quantité de note écarté être de autant plus grand que le période entre deux factorisation être long , ce qui accentuer le baisse de qualité . son travaux viser à améliorer le qualité des recommandation . cln proposer un factorisation de matrice utiliser un groupe de produit et intégrer en ligne le nouveau note des utilisateur . cln attribuer à chaque utilisateur un biais pour chaque groupe de produit similaire que cln mettre à jour . ainsi , cln améliorer significativement le prédiction entre deux factorisation . son expérimentation sur un jeu de donnée réel montrer le efficacité de son approche . 	Modou Gueye, Talel Abdesssalem, Hubert Naacke	2013	@telecom-paristech.fr, @ucad.sn, @lip6.fr	1001856
165	Text2Geo : des données textuelles aux informations géospatiales	Text2Geo : un donnée textuel aux information géospatial  dans ce article , cln clr intéresser aux méthode de extraction de information spatial dans un document textuel . cln présenter le méthode hybride Text2Geo qui combiner un approche de extraction de information , fonder sur un patron avec un approche de classification superviser permettre de explorer le contexte associer . cln discuter un résultat expérimental obtenir sur le jeu de donnée de le étang de Thau . 	Sabiha Tahrat, Eric Kergosien, Sandra Bringay, Mathieu Roche, Maguelonne Teisseire	2013	@lirmm.fr, @teledetection.fr, @univ-pau.fr	1001861
166	ToTeM: une méthode de détection de communautés adaptées aux réseaux d'information	totem : un méthode de détection de communauté adapté aux réseau de information  alors que le réseau social clr attacher à représenter un entité et le relation qui exister entre lui , le réseau de information intégrer également un attribut décrire ce entité ; ce qui conduire à revisiter le méthode de analyse et de fouille de ce réseau . dans ce article , cln proposer un méthode de classification des sommet de un graphe qui exploiter de un part son relation et de autre part le attribut cla caractériser . ce méthode reprendre le principe de le méthode de Louvain en cla étendre de façon à permettre le manipulation de attribut continu de un manière symétrique à ce qui exister pour le relation . 	David Combe, Christine Largeron, Elod Egyed-Zsigmond, Mathias Géry	2013	@univ-st-etienne.fr, @insa-lyon.fr	1001849
167	Un Critère d'évaluation pour la construction de variables à base d'itemsets pour l'apprentissage supervisé multi-tables	un Critère de évaluation pour le construction de variable à base de itemsets pour le apprentissage superviser multi-table  dans le contexte de le fouille de donnée multi-table , le donnée être représenter sous un format relationnel dans lequel le individu de le table cible être potentiellement lier à plusieurs enregistrement dans un table secondaire en relation un-à-plusieur . dans ce article , cln proposer un Framework baser sur un itemsets pour le construction de variable à partir un table secondaire . le informativité de ce nouveau variable être évaluer dans le cadre de le classification superviser au moyen de un critère régulariser qui viser à éviter le surapprentissage . pour ce faire , cln introduire un espace de modèle baser sur un itemsets dans le table secondaire ainsi que un estimation de le densité conditionnel des variable construite correspondant . un distribution avoir priorir être définir sur ce espace de modèle , pour obtenir ainsi un critère sans paramètre permettre de évaluer le pertinence des variable construite . un expérimentation préliminaire montrer le pertinence de le approche . 	Dhafer Lahbib, Marc Boullé, Dominique Laurent	2013	@orange-ftgroup.com, @orange-ftgroup.com, @u-cergy.fr	1001824
168	Un système hybride de recherche d'information intégrant le raisonnement à partir de cas et la composition d'ontologies	un système hybride de recherche de information intégrer le raisonnement à partir de cas et le composition de ontologie  le croissance des information disponible sur le web nécessiter un outil de recherche de plus en plus performant permettre de répondre efficacement aux besoin des utilisateur . dans ce contexte , le utilisation des ontologie présent des atout important . cependant , le construction manuel de ontologie être très coûteux , ceci avoir pousser à proposer un approche permettre de automatiser ce construction . ce article présenter un système de recherche de information hybride baser sur le raisonnement à Partir de cas ( RàPC ) et le composition de ontologie . ce système viser à combiner le construction automatique de ontologie modulaire et le RàPC , qui avoir pour but de améliorer le résultat de recherche de information ( RI ) . un expérimentation avoir être mener et le résultat obtenir montrer un amélioration de le précision dans le cas de un recherche de information sur le Web . 	Ghada Besbes, Hajer Baazaoui-Zghal, Henda Ben Ghezela	2013	@gmail.com, @riadi.rnu.tn, @cck.rnu.tn	1001845
169	Une approche en programmation par contraintes pour la classification non supervisée	un approche en programmation par contrainte pour le classification non superviser  dans ce article , cln aborder le problème de classification non superviser sous contrainte fonder sur le programmation par contrainte ( PPC ) . cln considérer comme critère de optimisation le minimisation du diamètre maximal des cluster . cln proposer un modèle pour ce tâche en PPC et cln montrer aussi le importance des stratégie de recherche pour améliorer son efficacité . son modèle baser sur le distance entre le objet permettre de traiter un donnée qualitatif et quantitatif . un contrainte supplémentaire sur le cluster et le instance pouvoir directement être ajouter . un expérience sur un ensemble de donnée classique montrer le intérêt de son approche . 	Thi-Bich-Hanh Dao, Khanh-Chuong Duong, Christel Vrain	2013	@univ-orleans.fr	1001822
170	Une nouvelle mesure pour l'évaluation des méthodes d'extraction de thématiques : la Vraisemblance Généralisée	un nouveau mesure pour le évaluation des méthode de extraction de thématique : le vraisemblance généraliser  le méthode dédier à le extraction automatique de thématique être issir de domaine varié : linguistique computationnelle , TAL , algèbre linéaire , statistique , etc. A ce méthode spécifique , pouvoir clr ajouter un méthode adapté de autre domaine , notamment de le apprentissage automatique non superviser . le résultat produire par le ensemble de ce méthode prendre un forme hétérogène : partition de document , distribution de probabilité sur le mots , matrice . cela poser clairement un problème pour cla comparer de manière uniforme . dans ce article , cln proposer un nouveau mesure de qualité , intituler Vraisemblance généraliser , pour permettre un évaluation et ainsi le comparaison de différent méthode de extraction de thématique . le résultat , obtenir sur un corpus de document Web autour un élection présidentiel français de 2012 , ainsi que sur le corpus Associated Press , montrer le pertinence de le mesure proposer . 	Mohamed Dermouche, Julien Velcin, Sabine Loudcher, Leila Khouas	2013	@univ-lyon2.fr, @amisw.com	1001851
171	Validation d'une carte cognitive	validation de un carte cognitif  le carte cognitif être un modèle graphique représenter un influence entre un concept . malgré le fait que un carte cognitif être relativement simple à construire , certain influence pouvoir clr contredire le un le autre . ce article proposer différent critère pour valider un carte cognitif , ce est-àdirer indiquer si le carte contenir ou non des contradiction . cln distinguer deux type de critère : le critère de vérification qui valider un carte cognitif en déterminant son cohérence interne et le critère de test qui valider un carte à partir de un ensemble de contrainte choisir par le concepteur . 	Aymeric Le Dorze, Laurent Garcia, David Genest, Stéphane Loiseau	2013	@univ-angers.fr	1001825
172	Vers un cadre évolutif de classification non supervisée	Vers un cadre évolutif de classification non superviser  le classification non supervisé ( clustering ) évolutif surpasser généralement par celui statique en produire un groupe de donnée ( cluster ) qui refléter le tendance à long terme tout en être robuste aux variation à court terme . dans ce travail , cln présenter un cadre différent pour le clustering évolutif de un manière incrémentale par un suivi précis des variable de proximité temporel entre le objet suivre par un clustering statique ordinaire . 	Mohamed Charouel, Minyar Sassi-Hidri, Mohamed Ali Zoghlami	2013	@enit.rnu.tn, @gmail.com	1001821
173	Vers une architecture multicouche d'ontologies dédiée à la résolution mixte de problèmes	Vers un architecture multicouche de ontologie dédier à le résolution mixte de problème  dans ce article , cln clr intéresser à le gestion de expérience générer au sein des processus de résolution mixte ( individuel et-ou collectif ) de problème afin de assister le capitalisation et le partage des connaissance dans le environnement collaboratif . dans ce contexte , cln proposer un cadre ontologique générique par rapport au domaine dédier à le modélisation formel et consensuel de ce expérience en adopter un architecture multicouche baser sur quatre strate . le premier strate être baser sur le spécialisation de ontologie fondationnel . le deuxième strate être baser sur le conception de trois patron conceptuel ontologique ( PCO ) noyau ( le PCO organisationnel , le PCO téléologique et le PCO argumentatif modéliser respectivement le acteur , le problème et le solution proposer ) . le troisième strate être baser sur le spécialisation des PCO noyau dans un domaine particulier et le dernier strate être baser sur le instanciation du modèle ontologique de domaine pour le représentation de un situation du monde réel . 	Nesrine Ben Yahia, Narjès Bellamine Ben Saoud, Henda Hajjami Ben Ghezala	2013	@ensi.rnu.tn, @ensi.rnu.tn, @ensi.rnu.tn	1001844
174	Vers une Automatisation de la Construction de Variables pour la Classification Supervisée	vers un automatisation de le construction de Variables pour le classification Supervisée  dans ce article , cln proposer un cadre viser à automatiser le construction de variable pour le apprentissage superviser , en particulier dans le cadre multi-table . le connaissance du domaine être spécifier de un part en structurer le donnée en variable , table et lien entre table , de autre part en choisir un règle de construction de variable . le espace de construction de variable ainsi définir être potentiellement infini , ce qui poser un problème de exploration combinatoire et de sur-apprentissage . cln introduire un distribution de probabilité avoir priori sur le espace des variable constructible , ainsi que un algorithme performant de tirage de échantillon dans ce distribution . un expérimentation intensif montrer que le approche être robuste et performant . 	Marc Boullé, Dhafer Lahbib	2013	@orange.com	1001819
175	Vers une mesure de similarité pour les séquences complexes	Vers un mesure de similarité pour le séquence complexe  le calcul de similarité entre le séquence être de un extrême importance dans un nombreux approche de exploration de donnée . ilimp exister un multitude de mesure de similarité de séquence dans le littérature . or , le plupart de ce mesure être concevoir pour un séquence simple , dire séquence de item . dans ce travail , cln étudier de un point de vue purement combinatoire le problème de similarité entre un séquence complexe ( i.eevard , un séquence de ensemble ou itemsets ) . cln présenter un nouveau résultat afin de compter efficacement tout le sous-séquence commun à deux séquence . ce résultat théorique être le base de un mesure de similarité calculer efficacement grâce à un approche de programmation dynamique . 	Elias Egho, Chedy Raïssi, Toon Calders, Thomas Bourquard, Nicolas Jay, Amedeo Napoli	2013	@loria.fr, @ulb.ac.be	1001853
176	Visualisation radiale : approche parallèle entre CPU et GPU	visualisation radiale : approche parallèle entre CPU et GPU  dans ce article , cln proposer un parallélisation sur CPU et GPU de un méthode de visualisation radiale à base de point de intérêt . cln montrer que ce approche pouvoir visualiser avec un temps très court des million de donnée sur un dizaine de dimension , et cln étudier le efficacité de le parallélisation dans différent configuration . 	Tianyang Liu, Fatma Bouali, Gilles Venturini	2013	@univ-tours.fr, @univ-lille2.fr	1001834
177	Apprentissage d'ensemble d'opérateurs de projection orthogonale pour la détection de nouveauté	apprentissage de ensemble de opérateur de projection orthogonal pour le détection de nouveauté  dans ce papier , cln proposer un approche de détection de nouveautéfondé sur le opérateur de projection orthogonal et le idée de doublebootstrap ( doublebootstrap ) . son approche appelé Random Subspace NoveltyDetection Filter ( RS-NDF ) , combiner un technique de rééchantillonnage etl'idé de apprentissage de ensemble . RS-NDF être un ensemble de filtre NDF ( Novelty Detection Filter ) , induire à partir de échantillon bootstrap des donnéesd'apprentissage , en utiliser un sélection aléatoire des variable pour le apprentissagedes filtre . RS-NDF utiliser donc un double doublebootstrap , ce être à dire unrééchantillonnage avec remise sur le observation et un rééchantillonnage sansremis sur le variable . le prédiction être faire par le agrégation des prédictionsd le ensemble des filtre . RS-NDF présenter généralement un important améliorationdes performance par rapport au modèle de base NDF unique . grâce àson algorithme de apprentissage en ligne , le approche RS-NDF être également enmesure de suivre le changement dans le donnée au fil du temps . Plusieursmétriques de performance montrer que le approche proposer être plus efficace , robuste et offrir un meilleur performance pour le détection de nouveauté comparéeaux autre technique existant . 	Fatma Hamdi, Younès Bennani	2012	@univ-paris13.fr	1001156
178	Apprentissage par analyse linéaire discriminante des paramètres de fusion pour la recherche d'information multimédia texte-image	apprentissage par analyse linéaire discriminant des paramètre de fusion pour le recherche de information multimédia texte-image  avec le développement du numérique , un quantité très importantesde document composé de texte et de image être échanger , ce qui nécessiter ledéveloppement demodèle permettre de exploiter efficacement ce informationsmultimédia . dans le contexte de le recherche de information , unmodèle possibleconsiste à représenter séparément le information textuel et visuel et àcombiner linéairement le score issu de chaque représentation . ce approchenécessite le paramétrage de poids afin de équilibrer le contribution de chaquemodalité . le but de ce article être de présenter un nouveau méthode permettantd'apprendre ce poids , baser sur le analyse linéaire discriminant de Fisher ( ALD ) . un expérimentation réaliser sur le collection ImageCLEF montrentquer le apprentissage des poids grâce à le ALD être pertinent et que le combinaisondes score correspondant améliorer significativement le résultat par rapport àl'utilisation de un seul modalité . 	Christophe Moulin, Christine Largeron, Cécile Barat, Mathias Géry, Christophe Ducottet	2012		1001201
179	Caractérisation et extraction de biclusters de valeurs similaires avec l'analyse de concepts triadiques	caractérisation et extraction de bicluster de valeur similaire avec le analyse de concept triadique  le biclustering de donnée numérique être devenir depuis le début desannées 2000 un tâche important de analyse de donnée , particulièrement pourl'étude de donnée biologique de expression de gène . un bicluster représenteune association fort entre un ensemble de objet et un ensemble de attribut dansune table de donnée numérique . le bicluster de valeur similaire peuventêtre voir comme un sous-table maximal de valeur proche . seul quelquesméthode clr être pencher sur un extraction complet ( i.e. non heuristique ) , exact et non redondant de tel motif , qui rester toujours un problème difficile , tandis que aucun cadre théorique fort ne permettre son caractérisation . dans le présentarticle , cln introduire un lien important avec le analyse formel deconcept . plus particulièrement , cln montrer de manière original que le analysede concept triadique ( TCA ) proposer un cadre mathématique intéressant etpuissant pour le biclustering de donnée numérique . de ce manière , le algorithmesexistant de le TCA , qui clr appliquer habituellement à un donnée binaire , pouvoir être utiliser ( directement ou après quelque modification ) aprèsun prétraitement un donnée pour le extraction désirer . 	Mehdi Kaytoue-Uberall, Sergei O. Kuznetsov, Amedeo Napoli, Juraj Macko, Wagner Meira Jr	2012	@dcc.ufmg.br	1001166
180	Classification Conceptuelle avec Généralisation par Intervalles	classification conceptuel avec généralisation par intervalle  cln cln intéresser aux méthode de classification hiérarchique oupyramidal , où chaque classe former correspondre à un concept , i.eès un paire ( extension , intension ) , considérant un donnée décrire par un variable quantitativesà valeur réel ou intervalle , ordinal et-ou prendre le forme de distributionun probabilité ou fréquence sur un ensemble de catégorie . le concept sontobtenir par un correspondance de Galois avec généralisation par intervalle , cequi permettre de traiter le donnée de différent type dans un cadre commun . Unemesure de le généralité de un concept être alors calculer sous un forme communepour le différent type de variable . un exemple illustrer le méthode proposer . 	Géraldine Polaillon, Paula Brito	2012	@fep.up.pt, @supelec.fr	1001141
181	Classification de données EEG par algorithme évolutionnaire pour l'étude d'états de vigilance	classification de donnée EEG par algorithme évolutionnaire pour le étude de états de vigilance  " le objectif de ce travail être de prédire le état de vigilance de un individuà partir de le étude de son activité cérébral ( signal de électro- encéphalographieEEG ) . . le variable à prédire être binaire ( état de vigilance " " normal " " ou " " relaxer " " ) . . Des EEG de 44 participant dans le deu états ( 88 enregistrement ) , avoir étérecueillir via un casque à 58 électrode . . après un étape de prétraitement et devalidation des donnée , un critère nommer " " critère des pente " " avoir être choisir . . Desméthodes de classification supervisé usuel ( k plus proche voisins , arbresbinaire de décision ( CART ) , forêt aléatoire , PLS et sparse PLS discriminant ) avoir être appliquer afin de fournir un prédiction de le état des participant . . Lecritère utiliser avoir ensuite être raffiner grâce à un algorithme génétique , ce qui apermettre de construire un modèle fiable ( taux de bon classement moyen par CARTégal à 86.68 ± 1 .87 \pourcent ) et de sélectionner un électrode parmi le 58 initial . " 	Laurent Vezard, Pierrick Legrand, Marie Chavent, Frédérique Faïta-Aïnseba, Julien Clauzel	2012	@inria.fr, @u-bordeaux2.fr	1001198
182	Classification des données catégorielles via la maximisation spectrale de la modularité	classification des donnée catégoriel via le maximisation spectral de le modularité  ce papier présenter un algorithme spectral pour maximiser le critèred le modularité étendre à le classification des donnée catégoriel . ilimp mettre enevidence le connexion formel entre le maximisation de le modularité et le classificationspectrale , ilimp présenter en particulier le problème de maximisation de lamodularité sous forme de un problème algèbrique de maximisation de le trace . cln développer ensuite un algorithme efficace pour trouver le partition optimalemaximiser le critère de modularité . le résultat expérimental montrentl'efficacité de son approche 	Lazhar Labiod, Younès Bennani	2012	@parisdescartes.fr, @univ-paris13.fr	1001194
183	Classification probabiliste non supervisée et visualisation des données séquentielles	classification probabiliste non supervisé et visualisation des donnée séquentiel  cln proposer dans ce papier un nouveau algorithme de classificationnon superviser à base de modèle de mélange topologique pour un donnéesnon i . i . d ( non independently and identically distributed ) . ce nouveau paradigmeprobabiliste , plonger le carte topologique probabiliste dans un formulationsous forme de chaîne de Markov cacher . dans ce formulation , le générationd'une observation à un instant donner du temps être conditionner par le étatsvoisins au même instant du temps . ainsi , un grand proximité impliquer unegranun probabilité pour le contribution à le génération . le approche proposer estévaluée en utiliser un donnée séquentiel réel issue des base de donnéesde le institut national de le Audiovisuel ( INA ) . le résultat obtenir sonttrès encourageant et prometteur . 	Rakia Jaziri, Mustapha Lebbah, Younès Bennani	2012	@univ-paris13.fr, @ina.fr	1001187
184	Classification topologique probabiliste pour des données catégorielles	classification topologique probabiliste pour un donnée catégoriel  ce article présenter un carte auto- organisatrice probabiliste pour le analyseet le classification topologique des donnée catégoriel . en considérer unmodèle de mélange parcimonieux cln introduire un nouveau carte autoorganisatrice ( SOM ) probabiliste . le estimation des paramètre de son modèleest réaliser à le aide de le algorithme EM classique . contrairement à SOM , le algorithmed'apprentissage proposer optimiser un fonction objectif . ce performancesont être évaluer sur un donnée réel et le résultat obtenir sontencourageant et prometteur à le fois pour le classification et pour le modélisation . 	Nicoleta Rogovschi, Mohamed Nadif	2012	@parisdescartes.fr	1001188
185	Clustering de séquences d'activités pour l'étude de procédures neurochirurgicales	Clustering de séquence de activité pour le étude de procédure neurochirurgical  le utilisation de modèle de procédure chirurgical ( Surgical ProcessModel , SPM ) avoir récemment émerger dans le domaine de le conception de outilsd'intervention chirurgical assisté par ordinateur . ce modèle , qui être utiliséspour analyser et évaluer le intervention , représenter un procédure chirurgical ( Surgical Process , SP ) qui être formaliser comme un structure symboliquesdécrivandre un chirurgie à un niveau de granularité donner . un enjeu importantréside dans le définition de métrique permettre le comparaison et le évaluationd ce procédure . ainsi , le relation entre ce métrique et des donnéespré-opératoire permettre de classer le chirurgie pour mettre en lumière desinformations sur le procédure lui-même , mais également sur le comportementdu chirurgien . dans ce papier , cln étudier le classification automatique de unensemble de procédure chirurgical en utiliser le algorithme Dynamic TimeWarping ( DTW ) pour calculer un mesure de similarité entre procédure chirurgical . le utilisation de DTW permettre de clr concentrer sur le différent typesd'activité effectuer pendant le procédure , ainsi que sur son séquencement touten réduire le différence temporel . un expérience avoir être mener sur 24procéduron chirurgical de hernie discal lombaire dans le but de discriminer leniveau de expertise des chirurgien à partir de un classification connu . A le aided'un algorithme de clustering hiérarchique utiliser DTW cln avoir retrouvédeux groupe de chirurgien présenter un niveau de expertise différent ( junioreant senior ) . 	Germain Forestier, Florent Lalys, Laurent Riffaud, Brivael Trelhu, Pierre Jannin	2012		1001153
186	Clustering hiérarchique non paramétrique de données fonctionnelles	Clustering hiérarchique non paramétrique de donnée fonctionnel  dans ce article , ilimp être question de clustering de courbe . cln proposonsuner méthode non paramétrique qui segmenter le courbe en cluster etdiscrétise en intervalle le variable continu décrire le point de le courbe . le produit cartésien de ce partition former un grille de donnée qui être inféréeen utiliser un approche Bayésienne de sélection de modèle ne faire aucunehypothèse concerner le courbe . enfin , un technique de post-traitement , visantà réduire le nombre de cluster dans le but de améliorer le interprétabilitédes clusters , être proposer . cln consister à fusionner successivement et de façonoptimale le cluster , ce qui revenir à réaliser un classification hiérarchique ascendantedavoir le mesure de dissimilarité correspondre à le variation du critère . de manière intéressant , ce mesure être en fait un somme pondérer de divergencesun Kullback-Leibler entre le distribution des cluster avant et aprèsfusion . le intérêt de le approche dans le cadre de le analyse exploratoire de donnéesfonctionnel être illustrer par un jeu de donnée artificiel et réel . 	Marc Boullé, Romain Guigourès, Fabrice Rossi	2012	@orange.com, @univ-paris1.fr	1001137
187	Combinaison de classificateurs simples pour une sélection rapide de caractéristiques	combinaison de classificateur simple pour un sélection rapide de caractéristique  le sélection de caractéristique être un technique permettre de choisirle caractéristique le plus pertinent , celui adapté à le résolution de unproblème particulier . le méthode classique présenter certain inconvénient . par exemple , cln pouvoir être trop complexe , cln pouvoir faire choisirle caractéristique sélectionner du classificateur utiliser , cln risquer de sélectionnerun caractéristique redondant . dans le but de limiter ce inconvénient , cln proposer dans ce article un nouveau méthode rapide de sélectionun caractéristique baser sur le construction et le sélection de classificateurssimple associer à chacun des caractéristique . un optimisation par unalgorithme génétique être proposer afin de trouver le meilleur combinaison desclassificateurs . différent méthode de combinaison être considérer et adaptéesà son problème . ce méthode avoir être appliquer sur différent ensemblesde caractéristique de taille varié et construire à partir de le base de chiffresmanuscrit MNIST . le résultat obtenir montrer le robustesse de le approcheainsi que le efficacité de le méthode . en moyenne , le nombre de caractéristiquessélectionné avoir diminuer de 69 , 9 \pourcent tout en conserver le taux de reconnaissance . 	Hassan Chouaib, Florence Cloppet, Salvatore-Antoine Tabbone, Nicole Vincent	2012	@parisdescartes.fr, @loria.fr	1001196
188	Combinaison de classification supervisée et non-supervisée par la théorie des fonctions de croyance	combinaison de classification supervisé et non- superviser par le théorie des fonction de croyance  cln proposer dans ce article un nouveau approche de classificationfondé sur le théorie des fonction de croyance . ce méthode reposer surle fusion entre le classification supervisé et le classification non supervisé . Eneffet , cln être face à un problème de manque de donnée de apprentissagepour des application dont le résultat de classification superviser et non superviséesont très variable selon le classificateur employer . le résultat ainsiobtenu être par conséquent considérer comme incertain . son approche clr proposer de combiner le résultat des deu type de classificationan exploiter son complémentarité via le théorie des fonction de croyance . Celle -cus permettre de tenir compte de le aspect de incertitude et de imprécision . Aprèsavoir dresser le différent étape de son nouveau schéma de classification , cln détailler le fusion de classificateur . ce nouveau approche être appliquéesur des donnée générique , issir de un vingtaine de base de donnée . le résultat obtenir avoir montrer le efficacité de le approche proposer . 	Fatma Karem, Mounir Dhibi, Arnaud Martin	2012	@yahoo.fr, @ensta-bretagne.fr, @univ-rennes1.fr	1001143
189	Découverte de règles d'association pour l'aide à la prévision des accidents maritimes	découverte de règle de association pour le aide à le prévision des accident maritime  le système de surveillance maritime permettre le récupération et lafusion des information sur le navire ( position , vitesse , etc. ) à un fin de suividu trafic maritime sur un dispositif de affichage . Aujourd' hui , le identification desrisqurer à partir de ce système être difficilement automatisable compte-tenu del'expertise à formaliser , du nombre important de navire et de le multiplicité desrisque ( collision , échouement , etc ) . de plus , le remplacement périodique desopérateurs de surveillance compliquer le reconnaissance de événement anormauxqui être épars et parcellaire dans le temps et le espace . dans le objectif de faireévoluer ce système de surveillance maritime , cln proposer dans ce article , un approche original fonder sur le data mining pour le extraction de motifsfréquent . ce approche clr focaliser sur un règle de prévision et de ciblagepour le identification automatique des situation induire ou constituer le cadredes accident maritime . 	Bilal Idiri, Aldo Napoli	2012	@mines-paristech.fr	1001192
190	Détection de groupes outliers en classification non supervisée	détection de groupe outliers en classification non superviser  " cln proposer dans ce papier un nouveau méthode de détection degroupes outlier . . son mesure nommer GOF ( Group Outlier Factor ) être estiméepar le apprentissage non- superviser . . cln cla avoir intégrer dans le apprentissage descartes topologique . . son approche être baser sur le densité relative de chaquegroupe de donnée , et fournir simultanément un partitionnement des donnéeset un indicateur quantitatif ( GOF ) sur " " le particularité " " de chaque cluster ougroupe . . le résultat obtenir être très encourageant et prometteur pour continuerdan ce optique . " 	Amine Chaibi, Mustapha Lebbah, Hanane Azzag	2012	@univ-paris13.fr	1001184
191	Détection non supervisée d'une sous-population par méthode d'ensemble et changement de représentation itératif	détection non superviser de un sous-population par méthode de ensemble et changement de représentation itératif  le apprentissage non superviser avoir classiquement pour objectif le détectiond sous-population homogène ( classe ) considérer de manière équivalentesan information avoir priori sur celui -ci . le problème étudier dans ce articleest quelque peu distinct . cln clr focaliser ici uniquement sur un sous-populationd'intérêt que le cln chercher à identifier avec un rappel et un précision optimal . cln proposer , pour cela , un méthode clr appuyer sur le principe suivant : ( 1 ) travailler dans le espace de représentation fournir par un expert faible pourcette tâche , ( 2 ) confronter ce expert pour détecter un seuil de sélection pluspertinent , et ( 3 ) cla combiner itérativement afin de converger vers le expert idéal . ce méthode être éprouver et comparer sur un donnée synthétique . 	Christine Martin, Antoine Cornuéjols	2012	@agroparistech.fr	1001195
192	Evaluation rapide du diamètre d'un graphe	Evaluation rapide du diamètre de un graphe  " Lors de le analyse de graphe , ilimp être important de connaître son propriétésafin de pouvoir par exemple identifier son structure et cla comparer . . un des caractérisation important de ce graphe reposer sur le fait de déterminers'ux clr agir ou non de un " " petit monde " " . . pour ce faire , le valeur du diamètredu graphe être essentiel . . or le mesure du diamètre être pour un très grandgraphe , un opération extrêmement long . . cln proposer un algorithme endeux phase qui permettre de obtenir rapidement un estimation du diamètre de ungraphe avec un proportion de erreur faible . . en réduire ce algorithme à uneseule phase et en accepter un marge de erreur plus élevé , cln obtenir uneestimation très rapide du diamètre . . cln tester ce algorithme sur deux grandsgraphe de terrain ( plus de un million de noeud ) et comparer son performancesavec celui de un algorithme de référence BFS ( Breadth-First Search ) . . le résultatsobtenu être décrire et commenter . " 	Christian Belbeze, Max Chevalier, Chantal Soulé-Dupuy	2012	@belbeze.com, @irit.fr, @irit.fr	1001183
193	Exploitation de l'asymétrie entre termes pour l'extraction automatique de taxonomies à partir de textes	exploitation de le asymétrie entre terme pour le extraction automatique de taxonomie à partir de texte  cln présenter dans ce article un nouveau approche pour le générationautomatique de structure lexical ( ou taxonomie ) à partir de texte . ce tâche être fonder sur le hypothèse fort selon lequel le accumulation defaits statistique simple sur le usages en corpus permettre de approximer des informationsde niveau sémantique sur le lexique . cln utiliser le prétopologiecomme cadre de travail afin de formaliser et de combiner plusieurs hypothèsessur le usages terminologique et enfin de structurer le lexique sous le formed'une taxonomie . cln considérer également le problème de le évaluation destaxonomies résultante et proposer un nouveau indice afin de cla comparer et depositionner son approche par rapport à le littérature . 	Davide Buscaldi, Guillaume Cleuziou, Gaël Dias, Vincent Levorato	2012	@univ-orleans.fr, @unicaen.fr, @cesi.fr	1001200
194	Extraction de co-variations entre des propriétés de sommets et leur position topologique dans un graphe attribué	extraction de co- variation entre un propriété de sommet et son position topologique dans un graphe attribuer  le analyse de grand réseau être très étudier en fouille de donnée . toutefois , le approche existant proposer un analyse être à un niveau macroscopique ( étude des propriété global comme le distribution des degré ) , soit à un niveau microscopique ( extraction de sous-graphe fréquent ou dense ) . cln proposer un nouveau méthode qui effectuer un analyse intermédiairepermettant de découvrir un motif regrouper un propriété microscopique etmacroscopique du réseau . ce motif capturer des co- variation entre un propriétésnumérique relative aux sommet . par exemple , un motif mésoscopiquedans un réseau de co- auteur pouvoir être plus le nombre de publication à EGC estimportant , plus le centralité des sommet correspondant dans le réseau le estégalement . son contribution être multiple . de abord , ce travail être le premierà exploiter conjointement un propriété local et des propriété topologique . de plus , cln produire de nouveau avancer dans le domaine de le extractiond co- variation en revisiter le motif émergent dans ce contexte . enfin , nousrapporter un analyse de un réseau bibliographique réel issir de DBLP . 	Adriana Prado, Marc Plantevit, Celine Robardet, Jean-François Boulicaut	2012		1001171
195	Extraction de Dépendances Fonctionnelles Approximatives	extraction de Dépendances Fonctionnelles Approximatives  le découverte de dépendance fonctionnel ( DF ) à partir de un relationexistant être un technique important pour le analyse de base de Données . le ensemble des DF exact ou approximatif extraire par le algorithme existantsêtre valider tant que le relation ne être pas modifier . ceci être insuffisant pourdes situation réel où le relation être constamment mettre à jour . cln proposer un approche incrémental qui maintenir à jour le ensemble desDF valide , exact ou approximatif selon un erreur donner , quand des tuplessont insérer et supprimer . le résultat expérimental indiquer que lors de le extractiond DF à partir de un relation continuellement modifier , le algorithmesexistant être sensiblement dépasser par son stratégie incrémental . 	Noel Novelli, Ekaterina Simonenko	2012	@lri.fr, @lif.univ-mrs.fr	1001503
196	Extraction de Liens Fréquents dans les Réseaux Sociaux	extraction de lien Fréquents dans le réseau Sociaux  " ce article présent FLMin , un nouveau méthode de extraction de motifsfréquent dans le réseau social . . contrairement aux méthode traditionnellesqui clr intéresser uniquement aux régularité structurel , le originalité denotre approcher résider dans son capacité à exploiter le structure et le attribut desnoeud pour extraire un régularité , que cln appeler " " lien fréquent " " , dansle lien entre un noeud partager un caractéristique commun . " 	Erick Stattner, Martine Collard	2012	@univ-ag.fr	1001174
197	Extraction de séquences fréquentes avec intervalles d'incertitude	extraction de séquence fréquent avec intervalle de incertitude  " Lors de le extraction des séquence , le granularité temporel être plusou moins important selon le besoin des utilisateur et le contrainte du domained'application . . cln proposer un algorithme de extraction de séquencesfréquente par intervalle à partir de séquence à estampille temporel discret . . cln intégrer un relaxation des contrainte temporel en introduisantle définition de " " séquence temporel par intervalle " " ( STI ) . . ce intervalle reflètentune incertitude sur le occurrence précis des évènement . . cln formalisonscer nouveau concept en exhiber certains de son propriété et lui menonsquelque expérience afin de comparer ( qualitativement ) son résultat avec uneautre proposition assez proche de le nôtre " 	Asma Ben Zakour, Sofian Maabout, Mohamed Mosbah, Marc Sistiaga	2012	@labri.fr, @labri.fr, @2moro.fr, @2moro.fr	1001160
198	Extraction de sous-parties ciblées d'une ontologie généraliste pour enrichir une ontologie particulière	extraction de sous-party cibler de un ontologie généraliste pour enrichir un ontologie particulier  différent ressource ontologique généraliste de très grand tailleavoir être développer de façon collectif et être aujourde hui disponible sur leweb . ainsi le ontologie YAGO être un énorme base de connaissance décrivantplus de 2 million de entité . afin de tirer parti de ce gigantesque travail collectif , cln montrer comment en extraire un sous-party thématiquement focaliséespour enrichir un autre ontologie , dire cible , de taille plus limité mais de domainecentré sur un application particulier 1 . 	Fayçal Hamdi, Brigitte Safar, Chantal Reynaud	2012	@lri.fr	1001176
199	Extraction d'opinions appliquée à des critères	extraction de opinion appliqué à un critère  le technologie de le information et le succès des service associé ( e.g. , blog , forum , ... ) avoir ouvrir le voie à un mode de expression massif de opinionssur le sujet le plus varié . récemment , un nouveau technique de détectionautomatique de opinion ( opinion mining ) avoir faire son apparition et viades analyse statistique des avis exprimer , tendre à dégager un tendance viades opinion exprimer par le internaute . néanmoins un analyse plusfine de celui -ci montrer que le argument avancer par le internaute relever decritères de jugement distinct . ici , un film être décrier pour un scénario décousu , là ilimp être encenser pour un bande son époustouflant . dans ce article , cln proposer , après avoir caractériser automatiquement un critère dans un document , de cll extraire le opinion relative . A partir de un ensemble restreindre de mots clésd'opinion , son approche construire automatiquement un base de apprentissageun document issir du web et en déduit un lexique de mots ou de clésd'opinion spécifique au domaine de application . un expérience mener viades jeu de donnée réel illustrer le efficacité de le approche . 	Benjamin Duthil, François Trousset, Gérard Dray, Pascal Poncelet, Jacky Montmain	2012	@mines-ales.fr, @lirmm.fr	1001197
200	Extraction et gestion d'informations pour la construction d'une base vidéo d'apprentissage	extraction et gestion de information pour le construction de un base vidéo de apprentissage  " indexer un vidéo consister à rattacher un ou plusieurs concept à dessegment de ce vidéo , un concept être définir comme un représentation intellectuelled'une idée abstrait . . le indexation automatique clr baser sur le extractionautomatique de caractéristique fournir par un système de traitement de image . . cependant , ilimp être nécessaire de définir le index ou concept . . pour cela ilimp fautdéfinir le lien qui exister entre ce caractéristique et ce concept . . ce qui sépareer caractéristique extraire sur lequel clr baser le indexation automatique etles concept être appeler fossé sémantique qui être le manque de concordance entreles information que le machine pouvoir extraire depuis le document numériquesettre le interprétation que le humain cll faire . . le définition de un conceptpeut être faire automatiquement si le cln disposer de un base de apprentissage liéeau concept . . dans ce cas , ilimp être possible " " de apprendre " " le concept de manièrestatistique . . mais le construction de ce base de apprentissage nécessiter de faireintervenir un utilisateur ou un expert applicatif . . en fait , ilimp clr agir de clr appuyer surson connaissance pour extraire un segment vidéo représentatif du conceptc le cln souhaiter définir . . cln pouvoir cld demander de indexer manuellement le based'apprentissage , mais ce opération être long et fastidieux . . dans ce article , cln proposer un méthode qui permettre de extraire le expertise pour que le implicationd le expert être le plus simple et le plus limité possible . " 	Alain Simac-Lejeune	2012	@litii.com	1001190
201	Human Detection by a Small Autonomous Mobile Robot	cln proposer un méthode utiliser le histogramme de gradientorienté ( HOG ) et le séparateur à vaste marge ( SVM ) pour le détection de personnesà partir de image prendre depuis un petit robot mobile autonome . le travauxantérieurs réaliser dans le domaine de le détection de être humain à partird'image ne pouvoir pas être employer pour ce type de application car cln supposentquer le image être prendre à partir de un position élevé ( au moins lahauteur de un petit enfant ) alors que le taille de son robot ne être que de 15centimètre . cln employer à le fois le HOG et le SVM car ce combinaison de méthodesest reconnaître comme être celui avoir le plus de succès pour le détectiond personne . pour traiter un grand variété de forme humain , principalementen raison de le distance existant entre le personne et le robot , cln avonsdéveloppé un nouvelleméthode de prédiction à deux étape utiliser deux typesd classificateur SVM qui reposer sur un estimation de le distance . le méthodesest baser sur un proportion de pixel de couleur de peau dans le image , cequi cld permettre de clairement séparer son problème de le détection de corpsentier et de celui de corps partiel . le essai réaliser dans un bureau avoir montrédes résultat prometteur de son méthode avec un valeur de F de 0,93 . 	Kouhei Takemoto, Shigeru Takano, Einoshin Suzuki	2012	@sls.kyushu-u.ac.jp, @inf.kyushu-u.ac.jp, @inf.kyushu-u.ac.jp	1001172
202	K-moyennes contraintes par un classifieur Application à la personnalisation de scores de campagnes	K-moyennes contraindre par un classifieur Application à le personnalisation de score de campagne  lorsque cln désirer contacter un client pour cld proposer un produit oncalcule au préalable le probabilité que ilimp acheter ce produit . ce probabilitéest calculer à le aide de un modèle prédictif pour un ensemble de client . le servicemarketing contacter ensuite celui avoir le plus fort probabilité de acheter leproduit . en parallèle , et avant le contact commercial , ilimp pouvoir être intéressant deréaliser un typologie des client qui être contacter . le idée être de proposerde campagne différencier par groupe de client . ce article montrer commentil être possible de contraindre le typologie , réaliser à le aide des k-moyenne , àrespecter le proximité des client vis-à-vis de son score de appétence . 	Vincent Lemaire, Nicolas Creff, Fabrice Clérot	2012		1001155
203	L'extraction de règles de dépendance bien définies entre ensembles de variables multivaluées	le extraction de règle de dépendance bien définir entre ensemble de variable multivalué  ce article étudier le faisabilité et le intérêt de le extraction de règle dedépendance entre ensemble de variable multivalué en comparaison du problèmebien connaître de le extraction des règle de association fréquent . un règlede dépendance correspondre à un dépendance fonctionnel approximatif caractériséeprincipalement par le entropie conditionnel associer . le article montrecomment établir un analogie formel entre le deu famille de règle et commentadapter à le aide de ce analogie le algorithme « Eclat » afin de extraire de unjeu de donnée le règle de dépendance dire bien définir . un étude expérimentaleconclut sur le force et inconvénient des règle de dépendance biendéfini vis-à-vis un règle de association fréquent 	Frédéric Pennerath	2012		1001168
204	Méta-règles pour la génération de règles négatives	Méta-règles pour le génération de règle négatif  le littérature clr être beaucoup intéresser à le extraction de règle classique ( ou positif ) et peu à le extraction des règle négatif en raison essentiellementd'une part , du coût de calcul et de autre part , du nombre prohibitif derègle redondant et inintéressant extraire . le démarche que cln avoir retenueêtre de dégager le règle négatif lors de le extraction des règle positif , et pour cela , cln rechercher le règle négatif que le cln pouvoir inférer ou pas àpartir de le pertinence de un règle positif . ce différent inférence aller êtreformaliser par un ensemble de méta-règle . 	Sylvie Guillaume, Pierre-Antoine Papon	2012	@isima, @isima	1001162
205	Modèle de supervision d'interactions non-intrusif basé sur les ontologies	modèle de supervision de interaction non- intrusif baser sur le ontologie  le automatisation et le supervision des système pervasif être à le heureactuel principalement baser sur le utilisation massif de capteur distribuésdans le environnement . dans ce article , cln proposer un modèle de supervisiond'interaction baser sur le analyse sémantique des log domotique ( commandesémis par le utilisateur ) , viser à limiter le utilisation de ce capteur : le principe être de utiliser un outil de inférence avancer , afin de déduire le informationshabituellement capter . pour cela , un ontologie , automatiquementdérivée de un processus diriger par le modèle , définir le interaction utilisateursystème . le utilisation de un système de règle permettre ensuite de inférer un informationssur le localisation et le intention de le utilisateur , dans le but de réaliserdu monitoring et de proposer un service domotiques adapté . 	Willy Allègre, Thomas Burger, Pascal Berruet, Jean-Yves Antoine	2012	@univ-ubs.fr	1001148
206	Prétraitement Supervisé des Variables Numériques pour la Fouille de Données Multi-Tables	Prétraitement Supervisé des Variables Numériques pour le fouille de Données Multi-Tables  le prétraitement des variable numérique dans le contexte de lafouille de donnée multi-table différer de celui des donnée classique individuvariable . le difficulté venir principalement un relation un-à-plusieur où lesindividus de le table cible être potentiellement associer à plusieurs enregistrementsdans des table secondaire . dans ce article , cln décrire un méthoded discrétisation des variable numérique situer dans un table secondaire . cln proposer un critère qui évaluer le discrétisation candidat pour ce méthoded variable . cln décrire un algorithme de optimisation simple qui permetd'obtenir le meilleur discrétisation en intervalle de fréquence égal pour lecritère proposer . le idée être de projeter dans le table cible le information contenuedans chaque variable secondaire à le aide de un vecteur de attribut ( un attributpar intervalle de discrétisation ) . chaque attribut représenter le nombre de méthoded le variable secondaire appartenir à le intervalle correspondant . ce attributsd'effectif être conjointement partitionner à le aide de modèle en grille de donnéesafin de obtenir un meilleur séparation des valeur de le classe . un expérimentationssur des jeu de donnée réel et artificiel révéler que le méthoded discrétisation permettre de découvrir un variable secondaire pertinent . 	Dhafer Lahbib, Marc Boullé, Dominique Laurent	2012	@orange-ftgroup.com, @orange-ftgroup.com, @u-cergy.fr	1001191
207	Raisonner sur une ontologie cartographique pour concevoir des légendes de cartes	raisonner sur un ontologie cartographique pour concevoir un légende de carte  concevoir un carte géographique , plus particulièrement son légende , exiger un compétence spécifique . le objectif de ce papier être de présenter unebase de connaissance destiner à aider tout utilisateur à concevoir un ou plusieurslégendes adapté à son besoin et conforme aux règle de cartographie . le base de connaissance être former de un ontologie de le cartographie nomméeOntoCarto , de un corpus de règle : OntoCartoRules et de un moteur de raisonnement : Corese . dans ce papier , chaque demande de conception de légende estvuer comme un instanciation particulier de le ontologie , associer à un sélectiond règle pertinent dans le corpus de règle , sur lequel Corese aller raisonnerpour construire un légende adapté à le configuration spécifique traiter . Laconception de le légende clr appuyer sur le définition de deux hiérarchie de objetsgéographique et objetsgéographique . le principe de fonctionnement de Coresesont présenter . un prototype avoir être implémenter et des extrait des résultat sontmontré . 	Catherine Dominguès, Olivier Corby, Fayrouz Soualah-Alila	2012	@ign.fr, @inria.fr, @yahoo.fr	1001178
208	Recherche d'Information Agrégée dans des documents XML basée sur les Réseaux Bayésiens	recherche de information Agrégée dans un document XML baser sur le réseau Bayésiens  dans ce article , cln clr intéresser à le recherche agréger dansdes document XML . pour cela , cln proposer un modèle baser sur le réseauxbayésien . le relation de dépendance entre requête-terme de indexation etterme de indexation-élément être quantifier par un mesure de probabilité . dans ce modèle , le requête de le utilisateur déclencher un processus de propagationpour trouver un élément . ainsi , au lieu de récupérer un liste des élémentsqui être susceptible de répondre à le requête , son objectif être de agréger dansun agrégat des élément pertinent , non- redondant et complémentaire . Nousavons évaluer son approche dans le cadre de le compagne de évaluation INEX2009 et avoir présenter quelque résultat expérimental mettre en évidencel'impact de le agrégation de tel élément . 	Najeh Naffakhi, Mohand Boughanem, Rim Faiz	2012	@irit.fr, @irit.fr, @isg.rnu.tn, @ihec.rnu.tn	1001202
209	Réorganisation hiérarchique de visualisations dans OLAP	réorganisation hiérarchique de visualisation dans OLAP  " dans ce article cln proposer un nouveau algorithme pour le réorganisationhiérarchique des cube OLAP ( On-Line Analytical Processing ) ayantpour objectif de améliorer son visualisation . . ce algorithme clr caractériser par lefait que ilimp pouvoir traiter un dimension organiser hiérarchiquement et optimiserconjointement le dimension du cube , contrairement aux autre approche . . Ilutilise un algorithme génétique qui réorganiser un arbre n-air quelconque . . Ila être intégrer dans un interface OLAP puis tester en comparaison avec un autresapproche de réorganisation , et fournir un résultat très positif . . A ce titre , cln avoir également généraliser le algorithme heuristique classique BEA ( " " bondenergy algorithm " " ) au cas de hiérarchie OLAP . . enfin , son approche avoir être évaluéepar des utilisateur et le résultat souligner le intérêt de le réorganisationdans des exemple de tâche à résoudre pour OLAP . " 	Sébastien Lafon, Fatma Bouali, Christiane Guinot, Gilles Venturini	2012	@univ-tours.fr, @univ-lille2.fr, @ceries-lab.com	1001181
210	RICSH : Recherche d'information contextuelle par segmentation thématique de documents	RICSH : recherche de information contextuel par segmentation thématique de document  le but principal des système de recherche de information ( SRI ) classiquesêtre de retrouver dans un corpus de document le information considéréecomme pertinent pour un requête utilisateur . ce pertinence être souvent liéeà le fréquence de apparition des terme dans le texte par rapport au corpus sanstenir compter du contexte de le recherche . partir de ce constat , cln proposonsdair ce article un approche pour le recherche de information contextuel parsegmentation thématique de document ( RICSH ) . ce approche clr appuyer surle méthode de pondération tf-idfoque que cln avoir adapter dans son cas pourindexer le corpus . ce adaptation clr situer au niveau de le importance du termeet de son pouvoir de discrimination par rapport aux fragment de texte et nonau corpus . ce fragment être obtenir grâce à un processus de identification desunités thématique le plus pertinent pour chaque document . 	Fadila Bentayeb, Omar Boussaid, Rachid Aknouche	2012	@univ-lyon2.fr	1001199
211	Sélection Bayésienne de Modèles avec Prior Dépendant des Données	sélection Bayésienne de Modèles avec Prior Dépendant des Données  ce article analyser le consistance asymptotique des modèle en grilleappliqué à le estimation de densité joint de deux variable catégoriel . Lesmodèles en grille considérer un partitionnement des valeur de chacun des variable , le produit Cartésien des partition former un grille dont le cellulespermettent de résumer le table de contingence des deux variable . le meilleurmodèle de co- partitionnement être rechercher au moyen de un approche MAP ( maximum avoir posteriori ) , présenter le particularité peu orthodoxe de exploiterun famille de modèle et un distribution avoir priorir de ce modèle qui dépendentder donner . ce modèle être par nature des modèle de le échantillon de apprentissage , et non de le distribution sous-jacent . cln démontrer le consistanced le approche , qui clr comporter comme un estimateur universel de densité jointeconvergeant asymptotiquement vers le vrai distribution joint . 	Marc Boullé	2012	@orange.com	1001136
212	Structuration des décisions de jurisprudence basée sur une ontologie juridique en langue arabe	structuration des décision de jurisprudence baser sur un ontologie juridique en langue arabe  le informatique juridique , être un domaine en évolution constant . Lecontexte général de son travail être le élaboration de un système de rechercheun jurisprudence tunisien en langue arabe . le objectif opérationnel de ce systèmeest de fournir un aide aux juriste pour résoudre un situation juridiquedonnée en mettre à son disposition un collection de situation similaire cequi améliorer son raisonnement futur . un ontologie du domaine juridiqueconstruite à partir un document des décision juridique être nécessaire dansnotre contexte . ce ontologie avoir pour but : ( i ) le structuration des décision , ( ie ) le formulation des requête de interrogation de le base des décision , et ( iii ) larecherche des décision . dans ce article , cln présenter le architecture de notresystème de recherche de jurisprudence . cln cln focaliser sur le ontologie dudomain de jurisprudence que cln avoir élaborer , aisni que sur le module destructuration des décision . 	Karima Dhouib, Sylvie Desprès, Faïez Gargouri	2012	@isets.rnu.tn, @univ-paris13.fr, @fsegs.rnu.t	1001175
213	SweetDeki : le wiki sémantique couteau suisse du réseau social ISICIL	SweetDeki : le wiki sémantique couteau suisse du réseau social ISICIL  le projet ANR ISICIL 1 mixer le nouveau application viral duweb avec un représentation formel et des processus de entreprise pour le intégrerdan le pratique de veille en entreprise . le outil développer clr appuientsur le interface avancer des application du web 2.0 ( blog , wiki , social bookmarking , extension de navigateur ) pour le interaction et sur le technologiesdu web sémantique pour le interopérabilité et le traitement de le information . Leprésent article décrire plus précisément le wiki sémantique développer dans lecadre de ce projet et son intégration au coeur du framework ISICIL 	Michel Buffa, Guillaume Husson, Nicolas Delaforge	2012	@unice.fr, @unice.fr, @inria.fr	1001151
214	TMD-MINER : Une nouvelle approche pour la détection des diffuseurs dans un système communautaire	TMD-MINER : un nouveau approche pour le détection des diffuseur dans un système communautaire  plusieurs méthode avoir être développer ce dernier année pour détecter , dans un réseau social , le membre qualifié , selon le auteur , de influenceur , de médiateur , de ambassadeur ou encore de expert . dans ce article , nousproposons un nouveau cadre méthodologique permettre de identifier un diffuseursdans le contexte où seul le information sur le appartenance des membre duréseau à un communauté être disponible . ce cadre , baser sur un représentationdu réseau sous forme de hypergraphe , cln avoir permettre de formaliser le notion dediffuseur et de introduire le algorithme TMD-MINER , dédier à le détection des diffuseurset baser sur le itemsets essentiel . 	Mohamed Nidhal Jelassi, Christine Largeron, Sadok Ben Yahia	2012	@univ-st-etienne.fr, @fst.rnu.tn	1001193
215	Transformation de l'espace de description pour l'apprentissage par transfert	transformation de le espace de description pour le apprentissage par transfert  " dans ce papier , cln proposer un étude sur le utilisation de le apprentissagetopologique pondérer et le méthode de factorisation matriciel pourtransformer le espace de représentation de un jeu de donnée " " sparse " " afin de augmenterle qualité de le apprentissage , et de cla adapter au cas de le apprentissagepar transfert . . le factorisation matriciel cln permettre de trouver un variableslatente et le apprentissage topologique pondérer être utiliser pour détecter le pluspertinent parmi celui -ci . . le représentation de nouveau donnée être baser surleurs projection sur le modèle topologique pondérer . . pour le apprentissage par transfert , cln proposer un nouveau méthode où lareprésentation un donnée être faire de le même manière que dans le premièrephase , mais en utiliser un modèle topologique élaguer . . le expérimentation être présenter dans le cadre de un challenge Internationaloù cln avoir obtenir un résultat prometteur ( 5ieme rang de le compétitioninternationale ) . . 1 Introduction " 	Nistor Grozavu, Younès Bennani, Lazhar Labiod	2012	@univ-paris13.fr, @parisdescartes.fr	1001185
216	Un algorithme de classification automatique pour des données relationnelles multi-vues	un algorithme de classification automatique pour un donnée relationnel multi-vue  classification automatique ( de Carvalho et alection , 2012 ) capable de partitionnerdes objet en prendre en compte de manière simultané plusieur matricesde dissimilarité qui cla décrire . ce matrice pouvoir avoir être généréesen utiliser différent ensemble de variable et de fonction de dissimilarité . ce méthode , baser sur le algorithme de nuée dynamique être concevoir pour fournirun partition et un prototype pour chaque classe tout en découvrir un pondérationpertinante pour chaque matrice de dissimilarité en optimiser un critèred'adéquation entre le classe et son représentant . ce pondération changentà chaque itération de le algorithme et être différent pour chacun des classe . cln présenter aussi plusieurs outil de aide à le interprétation des groupe et dele partition fournir par ce nouveau méthode . Deux exemple illustrer le interêtd le méthode . le premier utiliser un donnée concernant un chiffre manuscrit ( 0 à 9 ) numériser en image binaire provenir de le UCI . le second utiliser unensemble de rapport dont cln connaître un classification expert donner àpriori . 	Francisco de Assis Tenório de Carvalho, Filipe M. de Melo, Yves Lechevallier, Thierry Despeyroux	2012	@cin.ufpe.br, @inria.fr	1001142
217	Un assistant utilisateur pour le choix et le paramétrage des méthodes de fouille visuelle de données	un assistant utilisateur pour le choix et le paramétrage des méthode de fouille visuel de donnée  cln cln intéresser dans ce article au problème de le automatisation du processus de choix et de paramétrage des visualisation en fouille visuel de donnée . pour résoudre ce problème , cln avoir développer un assistant utilisateur qui effectuer deux étape : à partir un objectif annoncer par le utilisateur et des caractéristique de son donnée , le système commencer par proposer à le utilisateur différent appariement entre le base de donnée à visualiser et le visualisation que ilimp gérer . ce appariement être générer par un heuristique utiliser un base de connaissance sur le visualisation et le perception visuel . ensuite , afin de affiner le différent paramétrage suggérer par le système , cln utiliser un algorithme génétique interactif qui permettre aux utilisateur de évaluer et de ajuster visuellement ce paramétrage . cln présenter un évaluation utilisateur qui montrer le intérêt de son système pour deux tâche . 	Abdelheq Et-tahir Guettala, Fatma Bouali, Christiane Guinot, Gilles Venturini	2012	@univ-tours.fr, @ceries-lab.com, @univ-lille2.fr	1001180
218	Un environnement efficace pour la classification d'images à grande échelle	un environnement efficace pour le classification de image à grand échelle  le plupart des processus de classification de image comporter troisprincipale étape : le extraction de descripteur de bas niveau , le création de unvocabulaire visuel par quantification et le apprentissage à le aide de un algorithmede classification ( eg . SVM ) . un nombreux problème clr poser pour le passageà le échelle comme avec le ensemble de donnée ImageNet contenir 14 millionsd'image et 21,841 classe . le complexité concerner le temps de exécution dechaque tâche et le besoin en mémoire et disque ( eg . le stockage des SIFTs nécessite11Tonisé ) . cln présenter un version parallèle de LibSVM pour traiter degrands ensemble de donnée dans un temps raisonnable . de plus , ilimp cll avoir beaucoupun perte de information lors de le phase de quantification et le mots visuelsobtenu ne être pas assez discriminant pour un grand ensemble de image . cln proposer de utiliser plusieurs descripteur simultanément pour améliorerle précision de le classification sur un grand ensemble de image . cln présentonsnos premier résultat sur le 10 plus grand classe ( 24 , 817 image ) de ImageNet . 	Thanh-Nghi Doan, François Poulet	2012	@irisa.fr	1001189
219	Une approche multidimensionnelle basée sur les comportements individuels pour la prédiction de la diffusion de l'information sur Twitter	un approche multidimensionnel baser sur le comportement individuel pour le prédiction de le diffusion de le information sur Twitter  Aujourd' hui , le réseau social en ligne être devenir un outil trèspuissant de propagation de le information . cln favoriser le diffusion rapide àgrande échelle de contenu et le conséquence de un information inexact voirefausse pouvoir alors prendre un ampleur considérable . par conséquent ilimp devientindispensable de proposer un moyens de analyser le phénomène de diffusionde le information dans ce réseau . un nombreux étude récent avoir àgrande le modélisation du processus de diffusion de le information , essentiellementd'un point de vue topologique et dans un perspective théorique , mais le facteursimpliqué être encore méconnaître . cln proposer ici un solution pratiquedont le objectif être de prédire le dynamique temporel de le diffusion au sein deTwitter , baser sur un technique de apprentissage automatique . son approcherepose sur le inférence de probabilité de diffusion tirer de un analyse multidimensionnelledes comportement individuel . le expérimentation menéesmontrer le intérêt de le modélisation proposer . 	Adrien Guille, Hakim Hacid, Cécile Favre	2012	@univ-lyon2.fr, @alcatel-lucent.com	1001173
220	Une distance hiérarchique basée sur la sémantique pour la comparaison d'histogrammes nominaux	un distance hiérarchique baser sur le sémantique pour le comparaison de histogramme nominal  le plupart des distance entre histogramme être définir pour comparerun histogramme ordonner ( dont le entité représenter être totalementordonner ) ou des histogramme nominal ( dont le entité représenter nepeuvent pas être comparer ) . cependant , ilimp ne exister aucun distance qui permetteder comparer un histogramme nominal dans lequel ilimp être possible dequantifier des valeur de proximité sémantique entre le entité considérer . Cetarticle proposer un nouveau distance permettre de pallier ce problème . dans unpremier temps , un hiérarchie de histogramme , obtenir par le biais de un fusionprogressive des entité considérer ( prendre en compte son proximité sémantique ) , être construire . pour chaque étage de ce hiérarchie , un distance standardde comparaison de histogramme nominal être calculer . finalement , pourobteniour le distance proposer , ce différent distance être fusionner en prenanten compter le cohérence sémantique associer aux niveau de chaque étage de lahiérarchie . ce distance avoir être valider dans le cadre de le classification de donnéesgéographique . le résultat obtenir être encourageant et montrer ainsil'intérêt et le utilité de ce dernier pour un processus de fouille de donnée . 	Camille Kurtz	2012	@unistra.fr	1001144
221	Utilisation d'invariants pour une médiation inter-domaines de modèles utilisateurs : ressources invariantes et invariants sémantiques	utilisation de invariant pour un médiation inter-domain de modèle utilisateur : ressource invariant et invariant sémantique  le service de personnalisation du Web 2.0 reposer sur le exploitationd modèle utilisateur . schématiquement , plus le quantité de informationssur le utilisateur être grand , meilleur être le modélisation et le qualité du service . en pratique , nombre de service rencontrer un problème de manque de informationssur le utilisateur . dans ce article , cln cll répondre par médiationinter-domaine de modèle utilisateur , ce est-à-direr le complétion de modèle enexploitant des donnée de un autre domaine . le médiation que cln proposonsreposer sur un transfert de information inter-domain . ce transfert consister enl'utilisation de couple invariant ou très corréler pouvoir être un couple deressourx ou de descripteur sémantique , identifier après enrichissement sémantiquedes modèle . cln montrer que le transfert sous forme de couple deressourx permettre un complétion de qualité et que le exploitation de descripteurssémantique augmenter le couverture à qualité égal . enrichir sémantiquementest donc bénéfique pour le transfert inter-domain . 	Emilien Perrin, Armelle Brun, Anne Boyer	2012	@loria.fr	1001170
222	Validation et optimisation d'une décomposition hiérarchique de graphes	validation et optimisation de un décomposition hiérarchique de graphe  un nombreux algorithme de fragmentation de graphe fonctionnentpar agrégation ou division successif de sous-graphe mener à un décompositionhiérarchique du réseau étudier . un question important dans ce domaineest de savoir si ce hiérarchie refléter le structure du réseau ou si cln ne estqu'un artifice lier au déroulement de le procédure . cln proposer un moyen devalider et , au besoin , de optimiser le décomposition multi-échel produire parce type de méthode . cln appliquer son approche sur le algorithme proposer parBlondel et alection ( 2008 ) baser sur le maximisation de le modularité . dans ce cadre , un généralisation de ce mesure de qualité au cas multi-niveau être introduire . cln tester son méthode sur un graphe aléatoire ainsi que sur un exemplesréel issir de divers domaine . 	Francois Queyroi	2012	@labri.fr	1001182
223	Vers la construction d'un observatoire des pratiques agricoles : gestion et propagation de l'imprécision des données agronomiques	vers le construction de un observatoire des pratique agricole : gestion et propagation de le imprécision des donnée agronomique  le un des objectif de Observox être de traiter et gérer le imprécisiond donner agronomique tant spatialement ( parcelle agricole ) et quantitativement ( quantité de produit disséminer ) et de toujours associer un évaluationd le qualité aux donnée . aussi , cln avoir choisir le cadre théorique desensemble flou . A partir de un modèle conceptuel gérer le imperfection , nousconstruisons un base de donnée gérer un entité spatiotemporel imprécisesappelé « entité agronomique flou » . cependant , ce choix de représentationrend possible le chevauchement des composante spatial entre entité . dans ce cas , cln propager le imprécision du spatial vers le quantitatif àl'aide de un opérateur de caractère additif qui prendre en compte à le fois le informationspatiale et quantitatif , et qui fournir un information quantitatif localeettre flou . le système ainsi construire cln permettre de obtenir un représentationflou des quantité de produit phytosanitaire disséminer à chaque endroit duterritoire étudier . 	Asma Zoghlami, Karima Zayrit, Cyril de Runz, Eric Desjardin, Herman Akdag	2012	@univ-reims.fr, @ai.univ-paris8.fr	1001158
224	Vers une approche efficace d'extraction de motifs spatio-séquentiels	Vers un approche efficace de extraction de motif spatio- séquentiel  ce dernier année , le augmentation de le quantité de informationsspatio- temporel stocker dans le base de donnée avoir faire naître de nouveauxbesoins , notamment en matière de gestion des risque naturel , sanitaire ou anthropique ( page exès compréhension de le dynamique de un épidémie de Dengue ) . dans ce article , cln définir un cadre théorique pour le extraction de motifsspatio- séquentiel , séquence de motif spatial représenter le évolution dansle temps de un localisation et de son voisinage . cln proposer un algorithmed'extraction efficace qui effectuer un parcours en profondeur en clr appuyer surdes projection successif de le base de donnée . cln introduire égalementune mesure de intérêt adapter aux aspect spatio- temporel de ce motif . le expérimentationsréalisé sur un jeu de donnée réel souligner le pertinenced le approche proposer par rapport aux méthode de le littérature . 	Hugo Alatrista Salas, Sandra Bringay, Frédéric Flouvat, Nazha Selmaoui-Folcher, Maguelonne Teisseire	2012	@teledetection.fr, @lirmm.fr, @univ-nc.nc	1001159
225	Vers une méthode automatique de construction de hiérarchies contextuelles	vers un méthode automatique de construction de hiérarchie contextuel  dans un nombreux domaine ( e.gure , fouille de donnée , entrepôt dedonné ) , le existence de hiérarchie sur certain attribut pouvoir être extrêmementutiler dans le processus analytique . toutefois , ce connaissance ne être pas toujoursdisponible ou adapté . ilimp être alors nécessaire de disposer de un processusde découverte automatique pour palier ce problème . dans ce article , cln combinonsettre adapter un technique issu de le théorie de le information et duclustering pour proposer un technique orienter donner de construction automatiquede taxonomie . le deu principal avantage de un tel approchesont son caractère totalement non- superviser et le absence de paramètre utilisateurà spécifier . afin de valider son approche , cln cla avoir appliquer sur desdonné réel et avoir conduire plusieurs type de expérimentation . de abord , le hiérarchie obtenir avoir être expertiser pour cll examiner le pouvoir informatif . ensuite , cln avoir évaluer le apport de ce taxonomie comme support àdes tâche de fouille de donnée nécessiter un définition hiérarchique des valeursd'attribut : le extraction de séquence fréquent multidimensionnel etmulti-niveau ainsi que le construction de résumé de table relationnel . Lesrésultats obtenir permettre de conclure quant à le intérêt de son approche 	Dino Ienco, Yoann Pitarch, Pascal Poncelet, Maguelonne Teisseire	2012	@teledetection.fr, @cs.aau.dk, @lirmm.fr	1001186
226	Webmarks : Le marquage d'intérêt sur le Web de données	Webmarks : le marquage de intérêt sur le Web de donnée  depuis son apparition au sein du W3C , le définition de le ressourceWeb ne avoir cesser de évoluer au delà du simple document . lieu , service , conceptd'ontologie , représentation de un objet réel ou non , le ressource web être complexeet ilimp cld avoir sembler que le outil à disposition des internaute pour son manipulation , comme le bookmark par exemple , ne exploiter pas pleinementx nouveau dimension . dans ce article , cln présenter le modèle Webmarksqui permettre de préciser le objet du marquage , le ressource , mais égalementl'intérêt de le auteur de le marque . le implémentation de ce modèle au sein duprojet ISICIL être également présenter et cln discuter de son apport encomparaison un technologie existant 	Nicolas Delaforge, Fabien Gandon	2012	@inria.fr	1001152
227	@KRex : une méthode de construction des connaissances pour la maîtrise des activités à risques - application au domaine de la sécurité nucléaire	@KRex : un méthode de construction des connaissance pour le maîtrise des activité à risque - application au domaine de le sécurité nucléaire  dans le industrie à risque , comme le nucléaire , le connaissance lier au savoir et à le expérience participer à le maîtrise des activité . cln être explicite , formalisable dans un document , ou tacite , expression du savoir faire moins souvent prendre en compte . AREVA développer le méthode@KRex pour valoriser le retour de expérience existant , créer un dynamique de extraction et de capitalisation des connaissance , faciliter son partage et son enrichissement . ce communication décrire le protocole expérimental de construction des connaissance explicite et tacite du métier sécurité nucléaire . 	Julien Giudici, Hervé Janiaut, Rémy Gautier	2011	@krex, @ensam.eu, @ensam.eu, @areva.com, @krex	1001010
228	Acquisition de structures lexico-sémantiques à partir de textes : un nouveau cadre de travail fondé sur une structuration prétopologique	acquisition de structure lexico- sémantique à partir de texte : un nouveau cadre de travail fonder sur un structuration prétopologique  le structure lexico- sémantique jouer un rôle essentiel dans le processus de fouille de texte . en coder le relation sémantique entre concept du discours cln apporter un connaissance stratégique pour enrichir le capacité de raisonnement . le développement de tel structure être fortement limiter du fait des effort nécessaire à son construction , cln proposer un nouveau formalisme de acquisition automatique de ontologie terminologique à partir de texte . cln utiliser pour cela un formalisation prétopologique de le espace des terme sur lequel clr appuyer un modèle générique de structuration . cln présenter un étude empirique préliminaire rendre compte du potentiel de ce modèle en terme de extraction de connaissance . 	Guillaume Cleuziou, Gaël Dias, Vincent Levorato	2011	@univ-orleans.fr, @di.ubi.pt	1000936
229	Adaptation de l'algorithme CART pour la tarification des risques en assurance non-vie	adaptation de le algorithme CART pour le tarification des risque en assurance non- vie  le développement récent en tarification de le assurance non- vie clr concentrer majoritairement sur le maîtrise et le amélioration des Modèles Linéaires Généralisés . performant , ce modèle imposer cependant à le fois des contrainte sur le structure du risque modélisé et sur le interaction entre variable explicative du risque . ce restriction pouvoir conduire , dans certain sous-population de assuré , à un estimation biaiser de le prime de assurance . le arbre de régression permettre de clr affranchir de ce contrainte et , de plus , augmenter le lisibilité des résultat de le tarification . cln présenter un modification de le algorithme CART pour prendre en compte le spécificité des donnée de assurance non- vie . cln comparer alors son proposition aux modèle linéaire généraliser sur un portefeuille réel de véhicule . son proposition réduire le mesure de erreur entre le risque mesurer et le risque modéliser , et permettre ainsi un meilleur tarification . 	Antoine Paglia, Martial Phélippé-Guinvarc'h, Philippe Lenca	2011	@gmail.com, @sfr.fr, @groupama.com, @telecom-bretagne.eu	1001028
230	Agrégation robuste de données massives à la volée : application aux compteurs électriques communicants	agrégation robuste de donnée massif à le volée : application aux compteur électrique communicant  dans le année à venir , plusieurs million de compteur électrique communicant être déployer sur le ensemble du territoire français . afin de assurer le fiabilité de un réseau de ce envergure cln proposer un topologie de communication multi-chemin qui reposer sur le duplication des donnée transmettre . tout exploitation des donnée collecter devoir alors tenir compte de le présence de élément dupliquer . dans ce article , cln proposer un nouveau méthode permettre de calculer en ligne des consommation électrique agrégé ( agrégation spatial ) . le idée être de adapter le algorithme probabiliste Summation sketch de Considine et alès au contexte des compteur communicant . ce approche avoir le avantage de être insensible à le duplication et permettre de profiter de le structure massivement distribuer du réseau de communication des futur compteur électrique . le expérimentation de ce méthode sur un donnée réel montrer que cln donner un bon précision sur le estimation des consommation agrégé . ce approche être aussi compléter par un méthode baser sur le théorie des sondage : cln obtenir un meilleur réactivité de le estimateur avec rapidement et donc sur un donnée significativement partiel un erreur inférieur à 2 .5 \% 	Yousra Chabchoub, Benoît Grossin	2011	@edf.fr, @isep.fr	1000943
231	Aide à l'Analyse Visuelle de Réseaux Sociaux pour la Détection de Comportements Suspects	aide à le analyse visuel de réseau Sociaux pour le détection de comportement suspect  ce article traiter de le analyse visuel de réseau social pour le détection de comportement suspect à partir de donnée de communication fournir à un enquêteur suivant deux procédure : le interception légal et le rétention de donnée . cln proposer le contribution suivant : ( i ) un modèle de donnée et un ensemble de opérateur pour interroger ce donnée dans le but de extraire un comportement suspect et ( ie ) un représentation visuel convivial pour un navigation simplifier dans le donnée de communication accompagner avec un implémentation . 	Amyn Bennamane, Hakim Hacid, Arnaud Ansiaux, Alain Cagnati	2011	@alcatel-lucent.com, @interieur.gouv.fr	1000948
232	Analyse comparative de méthodologies et d'outils de construction automatique d'ontologies à partir de ressources textuelles	analyse comparatif de méthodologie et de outil de construction automatique de ontologie à partir de ressource textuel  plusieurs méthodologie et outil de construction automatique des ontologie à partir de ressource textuel avoir être proposer ce dernier année . dans ce article cln analyser quatre approche en cla comparer à un approche de référence - Methontology . dans son sélection cln avoir privilégier celui qui couvrir le ensemble des étape du processus de construction de ontologie . puis cln analyser et comparer le portée , le limite et le performance des implémentation logiciel associer aux approche analysé . ce outil avoir être tester sur un corpus de ressource textuel , et cln avoir comparer son résultat à celui obtenir manuellement . 	Toader Gherasim, Mounira Harzallah, Giuseppe Berio, Pascale Kuntz	2011	@univ-nantes.fr, @univ-nantes.fr, @univ-ubs.fr	1000989
233	Analyse du comportement limite d'indices probabilistes pour une sélection discriminante	analyse du comportement limiter de indice probabiliste pour un sélection discriminant  cln étudier ici le comportement de deux type de indice probabiliste discriminant en présence de donnée dont le volume aller en croissant . A ce égard , un modèle spécifique de croissance de le taille des donnée et de liaison entre variable être mettre en oeuvre et celui -ci aller permettre de déterminer le comportement limiter un différent indice quel que être le niveau de liaison entre le prémisse et le conclusion de le règle donner . le clarté des résultat obtenir cln conduire à cll chercher le explication formel . le expérimentation avoir être effectuer avec le base de donnée UCI Wages . 	Sylvie Guillaume, Israël-César Lerman	2011	@isima, @irisa.fr	1001036
234	Analyse factorielle des correspondances hiérarchique pour la fouille d'images	analyse factoriel des correspondance hiérarchique pour le fouille de image  cln proposer un outil graphique interactif qui permettre de visualiser et de extraire un connaissance à partir un résultat de le analyse factorielle des correspondance ( AFC ) sur le image . le AFC être un technique descriptif développer pour analyser un tableau de contingence . le AFC être originellement utiliser dans le Analyse des Données Textuelles ( ADT ) où le corpus être représenter par un tableau de contingence croiser un document et des mots . dans le fouille de image , cln définir de abord le « mots visuel » dans le image ( analogue aux mots textuel ) . ce mots visuel être construire à partir un descripteur local SIFT ( Scale Invariant Feature Transform ) dans le image . ensuite , cln appliquer le AFC sur le tableau de contingence obtenir . son outil ( appeler HCAViz ) analyser ce tableau de contingence de façon récursif et aider le utilisateur à interpréter et interagir avec le résultat de le AFC . de abord , le résultat de le premier AFC sur le image être visualiser . le utilisateur sélectionner ensuite un groupe de image et faire un deuxième AFC sur le nouveau tableau de contingence . ce processus pouvoir continuer jusque à ce que un thème « pur » clr dévoiler . ceci permettre de découvrir un arborescence des thème dans un collection de image . un application sur le base Caltech- 4 illustrer le intérêt de HCAViz dans le fouille de image . 	Nguyen-Khang Pham, Annie Morin, François Poulet, Patrick Gros	2011	@cit.ctu.edu.vn, @irisa.fr, @inria.fr	1000941
235	Analyse spatiotemporelle des vecteurs de mouvement : application au comptage des personnes	analyse spatiotemporel des vecteur de mouvement : application au comptage des personne  ce article présenter un nouveau approche qui permettre de compter le nombre de individu franchir un ligne de comptage . le approche proposer accumuler dans le temps le vecteur de mouvement pour chaque point de le ligne de comptage former un carte spatiotemporel . un procédure de détection en ligne des blob être ensuite utiliser afin de déterminer le région de le carte spatiotemporel qui correspondre à un personne franchir ce ligne . le nombre de individu associer à chaque blob être estimer grâce à un modèle de régression linéaire appliquer aux caractéristique du blob . le approche proposer être valider sur le base de plusieurs ensemble de donnée enregistrer à le aide de un caméra vertical ou de un caméra oblique . 	Yassine Benabbas, Tarek Yahiaoui, Thierry Urruty, Chabane Djeraba	2011	@lifl.fr	1000942
236	Annotation d'entités nommées par extraction de règles de transduction	annotation de entité nommer par extraction de règle de transduction  le reconnaissance de entité nommer être un problématique majoritairement traiter par un modèle spécifier à le aide de règle ou par apprentissage numérique . le premier avoir le désavantage de être coûteux à développer pour obtenir un couverture satisfaisant , le second être souvent difficile à interpréter par un expert ( linguiste ) . dans ce article , cln présenter un approche , dont le objectif être de extraire un règle symbolique discriminant que un humain pouvoir consulter . A partir de un corpus de référence , cln extraire un règle de transduction , dont seul le plus informatif être retenir . cln être ensuite appliquer pour effectuer un annotation : à ce effet , un algorithme rechercher parmi le annotation possible celui de meilleur qualité en terme de couverture et de probabilité . cln présenter le résultat expérimental et discuter de le intérêt et des perspective de son approche . 	Arnaud Soulet, Damien Nouvel	2011	@univ-tours.fr, @univ-tours.fr	1000937
237	Apport des données thématiques dans les systèmes de recommandation : hybridation et démarrage à froid	apport des donnée thématique dans le système de recommandation : hybridation et démarrage à froid  " un travaux récent ( Pilaszy et alection , 2009 ) suggérer que le métadonné être quasiment inutile pour le système de recommandation , cll comprendre en situation de cold-start : le donnée de log de notation être beaucoup plus informatif . . cln étudier , sur un base de référence de log de usages pour le recommandation automatique de DVD ( Netflix ) , le performance de système de recommandation baser sur un source de donnée collaboratif , thématique et hybride en situation de démarrage à froid ( cold-start ) . . cln exhiber un cas expérimental où le métadonné apporter plus que le donnée de log de usage ( collaboratif ) pour le performance prédictif . . pour gérer le cold-start de un système de recommandation , cln montrer que un approche " " en cascade " " , thématique puis hybride , puis collaboratif , être plus approprié . " 	Frank Meyer, Éric Gaussier, Fabrice Clérot, Julien Schluth	2011	@orange-ftgroup.com, @orange-ftgroup.com, @imag.fr, @gmail.com	1000947
238	Apprendre les contraintes topologiques dans les cartes auto-organisatrices	apprendre le contrainte topologique dans le carte auto- organisatrice  le Carte Auto- Organisatrice ( SOM : Self-Organizing Map ) être un méthode populaire pour le analyse de le structure de un ensemble de donnée . cependant , certain contrainte topologique de le SOM être fixer avant le apprentissage et pouvoir ne pas être pertinent pour le représentation de le structure des donnée . dans ce article cln cld proposer de améliorer le performance des SOM avec un nouveau algorithme qui apprendre le contrainte topologique de le carte à partir un donnée . un expérience sur un base de donnée artificiel et réel montrer que le algorithme proposer produire de meilleur résultat que SOM classique . ce ne être pas le cas avec un relaxation trivial des contrainte topologique , qui résulter en un fort augmentation de le erreur topologique de le carte . 	Guénaël Cabanes, Younès Bennani	2011	@univ-paris13.fr	1000939
239	Apprentissage génératif de la structure de réseaux logiques de Markov à partir d'un graphe des prédicats	apprentissage génératif de le structure de réseau logique de Markov à partir de un graphe des prédicat  le réseau logique de Markov ( MLNs ) combiner le apport statistique des réseau de Markov à le logique du premier ordre . dans ce approche , chaque clause logique clr voir affecter de un poids , le instanciation des clause permettre alors de produire un réseau deMarkov . le apprentissage de un MLN consister à apprendre de un part son structure ( le liste de clause logique ) et de autre part le poids de celui -ci . cln proposer ici un méthode de apprentissage génératif de Réseau Logique de Markov . ce méthode reposer sur le utilisation de un graphe des prédicat , produire à partir de un ensemble de prédicat et de un base de apprentissage . un méthode heuristique de variabilisation être mettre en oeuvre afin de produire le jeu de clause candidat . le résultat présenter montrer le intérêt de son approche au regard de le état de le art . 	Quang-Thang Dinh, Matthieu Exbrayat, Christel Vrain	2011	@univ-orleans.fr	1000993
240	Cartes cognitives : une exploitation à base d'échelle, vue et profil	carte cognitif : un exploitation à base de échelle , vue et profil  un carte cognitif être un réseau de influence entre différent concept . le modèle des carte cognitif permettre à un utilisateur de calculer le influence entre deux concept . le carte cognitif contenir un grand nombre de concept et de influence être difficile à comprendre . ce article introduire le notion de carte cognitif ontologique qui associer un ontologie à un carte cognitif classique pour cll organiser le concept . afin de faciliter le compréhension de un carte , le utilisateur pouvoir obtenir un vue de ce carte le simplifier selon un échelle que ilimp avoir choisir . un profil pouvoir être créer pour construire un vue correspondre aux objectif de un type de utilisateur . si un carte être manipuler par différent utilisateur , son profil combiner permettre de construire un vue partager . 	Lionel Chauvin, David Genest, Aymeric Le Dorze, Stéphane Loiseau	2011	@univ-angers.fr	1001008
241	Catégorisation des mesures d'intérêt pour l'extraction des connaissances	catégorisation des mesure de intérêt pour le extraction des connaissance  " le recherche de règle de association intéressant être un domaine de recherche important et actif en fouille de donnée . . le algorithme de le famille Apriori reposer sur deux mesure pour extraire le règle , le support et le confiance . . bien que ce deu mesure posséder un vertu algorithmique accélérateur , cln générer un nombre prohibitif de règle dont le plupart être redondant et sans intérêt . . ilimp être donc nécessaire de disposer un autre mesure filtrer le règle inintéressant . . un travaux avoir être réaliser pour dégager le " " bon " " propriété des mesure de extraction des règle et ce propriété avoir être évaluer sur 61 mesure . . le objectif de ce article être de dégager un catégorie de mesure afin de répondre à un préoccupation des utilisateur : le choix de un ou plusieurs mesure lors de un processus de extraction des connaissance dans le but de éliminer le règle valide non pertinent extraire par le couple ( support , confiance ) . . le évaluation des propriété sur le 61 mesure avoir permettre de dégager 9 classe de mesure , classe obtenir grâce à deux technique : un méthode de le classification ascendant hiérarchique et un version de le méthode de classification non- hiérarchique des k-moyenne . " 	Sylvie Guillaume, Dhouha Grissa, Engelbert Mephu Nguifo	2011	@isima, @isima, @isima	1001014
242	Classificateurs aléatoires Topologiques à base de graphes de voisinage	classificateur aléatoire Topologiques à base de graphe de voisinage  en apprentissage superviser , le méthode ensemble ( ME ) avoir montrer son qualité . le un des méthode de référence dans ce domaine être le forêt Aléatoires ( FA ) . ce dernier reposer sur un partitionnement de le espace de représentation selon un frontière parallèle aux axe ou oblique . le conséquence de ce façon de partitionner le espace de représentation pouvoir affecter le qualité de chaque prédicteur . ilimp cld avoir sembler que ce approche pouvoir être améliorer si cln clr libérer de ce contrainte de manière à mieux coller à le structure topologique de le ensemble de apprentissage . dans ce article , cln proposer un nouveau ME baser sur un graphe de voisinage dont le performance , sur son premier expérimentation , être aussi bon que celui des FA . 	Fabien Rico, Djamel Abdelkader Zighed	2011	@univ-lyon1.fr, @univ-lyon2.fr	1000933
243	Classification des aéronefs par estimation de la pose	classification des aéronef par estimation de le pose  dans le présent travail , cln proposer un outil de aide à le reconnaissance de cible radar baser sur le signature de forme et de le pose de le cible . le tâche principal dans le cadre de ce article consister à établir le fonction de recherche de image ISAR par le exemple en exploiter le information de pose estimer depuis le image ISAR . le objectif être de introduire le information de pose dans le indexation des image , notamment dans le phase de sélection des image candidat . cln proposer un nouveau méthode de estimation de le pose baser sur le axe le plus symétrique de le cible . le méthode proposer être ensuite comparer avec un autre technique connaître tel que le transformer de Hough et le transformer en ondelette . enfin , le tâche de classification être réaliser en utiliser le k-plus proche voisin inclure le information de le pose . 	Mohamed Nabil Saidi, Abdelmalek Toumi, Ali Khenchaf, Driss Aboutajdine	2011	@ensieta.fr, @fsr.ac.ma	1001012
244	Comparaison entre deux indices pour l'évaluation probabiliste discriminante des règles d'association	comparaison entre deux indice pour le évaluation probabiliste discriminant des règle de association  " le élaboration de un échelle de probabilité discriminant pour le comparaison mutuel entre plusieurs attribut observer sur un échantillon de objet de " " gros " " taille , nécessiter un normalisation préalable . . le objet de ce article être le analyse comparé entre deux approche . . le premier dérive de le " " analyse de le vraisemblance des lien Relationnels Normalisée " " . . le seconde être fonder sur le notion de " " Valeur Test " " sur un échantillon virtuel de taille 100 , synthétiser le échantillon initial . " 	Israël-César Lerman, Sylvie Guillaume	2011	@irisa.fr, @isima	1001034
245	Découverte de motifs d'évolution significatifs dans les séries temporelles d'images satellites	découverte de motif de évolution significatif dans le série temporel de image satellite  le série temporel de image satellite ( ou Satellite image Time Series - SITS ) être de important source de information sur le évolution du territoire . étudier ce image permettre de comprendre le changement sur un zone précis mais aussi de découvrir un schéma de évolution à grand échelle . toutefois , découvrir ce phénomène imposer de répondre à plusieurs défi qui être lier aux caractéristique des SITS et à son contrainte . premièrement , chaque pixel de un image satellite être décrire par plusieurs valeur ( le niveau radiométrique sur différent longueur de onde ) . deuxièmement , ce motif de évolution porter sur un période très long et ne être pas forcément synchrone selon le région . troisièmement , le région qui ne être pas concerner par un évolution significatif être majoritaire et son domination rendre difficile le extraction des motif de évolution . dans ce article , cln proposer un méthode qui répondre à ce difficulté et cln le validon sur un série de image satellite acquérir sur un période de 20 an . 	François Petitjean, Florent Masseglia, Pierre Gançarski	2011	@unistra.fr, @inria.fr	1001037
246	Détection de changements de distribution dans un flux de données : une approche supervisée	détection de changement de distribution dans un flux de donnée : un approche superviser  le analyse de flux de donnée traiter un donnée massif grâce à un algorithme en ligne qui éviter le stockage exhaustif des donnée . le détection de changement dans le distribution de un flux être un question important dont le application potentiel être nombreux . dans ce article , le détection de changement être transposer en un problème de apprentissage superviser . cln avoir choisir de utiliser le méthode de discrétisation superviser MODL car celui -ci présent des propriété intéressant . son approche être comparer favorablement à un méthode de le état-d -l'art sur un flux de donnée artificiel . 	Marc Boullé, Alexis Bondu	2011	@edf.fr, @orange-ftgroup.com	1000944
247	Détection de redondances dans les tableaux guidée par une ontologie	détection de redondance dans le tableau guider par un ontologie  cln cln intéresser dans ce article à le réconciliation de annotation flou associer à un tableau de donnée par un méthode de annotation sémantique , qui être guider par un ontologie de domaine . Etant donner deux tableau , le méthode consister à détecter son instance de relation redondant . cln clr appuyer sur le connaissance déclarer dans le ontologie , ainsi que sur un score de similarité entre le annotation flou représenter par un sous-ensemble flou numérique ou par un sous-ensemble flou symbolique 	Rania Khefifi, Patrice Buche, Juliette Dibie-Barthélemy, Fatiha Saïs	2011	@lri.fr, @supagro.inra.fr, @risk, @agroparistech.fr	1001016
248	Détection des profils à long terme et à court terme dans les réseaux sociaux	détection des profil à long terme et à court terme dans le réseau social  le conception des profil et contexte utilisateur clr situer au coeur de le étude et de le mise en oeuvre des mécanisme de personnalisation ou de adaptation de contenu ( recherche de information , système de recommandation , etc. ) . plusieurs modèle et dimension de profil et contexte être décrire dans le littérature . dans le vie réel tout comme dans le système de information , le comportement de le utilisateur être très souvent influencer par son environnement social . cependant , le dimension social des profil et contexte utilisateur rester très peu étudier et évaluer . dans ce article , cln présenter un méthode de visualisation des profil utilisateur permettre de évaluer le pertinence du réseau social de le utilisateur dans le évolution de son profil . le expérimentation de le méthode à partir de Facebook permettre de identifier de un part , le centre de intérêt à court-terme et à court-terme des profil utilisateur , et de autre part , le influence réel à court-terme et à court-terme du réseau social de chaque utilisateur . ce résultat démontrer le intérêt de modéliser et de intégrer un dimension social dans le profil et contexte utilisateur , afin de tenter de améliorer le mécanisme de personnalisation ou de adaptation de contenu . 	Dieudonné Tchuente, Marie-Françoise Canut, Nadine Baptiste-Jessel	2011	@irit.fr, @iut-blagnac.fr, @irit.fr	1000987
249	Equilibrer l'analyse des motifs fréquents	Equilibrer le analyse des motif fréquent  ce article proposer un méthode original de évaluation de le qualité des motif en anticiper le manière qui être utiliser pour cla analyser . cln commencer par introduire le modèle de le analyse aléatoire de un ensemble de motif selon un mesure de intérêt . avec ce modèle , cln constater que le étude des motif fréquent avec le support conduire à un analyse déséquilibré du jeu de donnée . afin que chaque transaction recevoir le même attention , cln définir le support équilibrer qui corriger le support classique en pondérer le transaction . cln proposer alors un algorithme qui calculer ce poids et cln valider expérimentalement son efficacité . 	Arnaud Giacometti, Arnaud Soulet, Patrick Marcel	2011	@univ-tours.fr	1000927
250	Equivalence topologique entre mesures de proximité	Equivalence topologique entre mesure de proximité  le choix de un mesure de proximité entre objet avoir un impact direct sur le résultat de tout opération de classification , de comparaison , de évaluation ou de structuration de un ensemble de objet . pour un problème donné , le utilisateur être amener à choisir un parmi le nombreux mesure de proximité existant . or , selon le notion de équivalence choisir , comme celui baser sur le préordonnance , certains être plus ou moins équivalent . dans ce article , cln proposer un nouveau approche pour comparer le mesure de proximité . Celle -cus être baser sur le équivalence topologique . A ce effet , cln introduire un nouveau concept baptiser équivalence topologique . ce dernier faire appel à le structure de voisinage local . cln proposer alors de définir le équivalence topologique entre deux mesure de proximité à travers le structure topologique induire par chaque mesure . cln établir ensuite un lien formel avec le équivalence en préordonnance . le deu approche être comparer sur le plan théorique et sur le plan empirique . cln illustrer le principe de ce comparaison sur un exemple simple pour un quinzaine de mesure de proximité de le littérature . 	Djamel Abdelkader Zighed, Rafik Abdesselam, Ahmed Bounekkar	2011	@univ-lyon2.fr, @univ-lyon2.fr, @univ-lyon1.fr	1000928
251	Estimation de la densité d'arcs dans les graphes de grande taille: une alternative à la détection de clusters	estimation de le densité de arc dans le graphe de grand taille : un alternative à le détection de cluster  " le recherche de structure dans le graphe être un sujet étudier depuis longtemps , qui avoir bénéficier de un regain de intérêt avec le mise à disposition de graphe de grand taille sur le web , tel le réseau social . . un nombreux méthode de recherche de cluster " " naturel " " dans le graphe avoir être proposer , fonder notamment sur le modularité de Newman . . cln introduire dans ce article un nouveau façon de résumer le structure des graphe de grand taille , en utiliser un estimateur de densité des arc exploiter un modèle en grille , baser sur un co- partitionnent des noeud source et cible des arc . . le structure identifier par ce méthode aller au delà de le " " classique " " détection de cluster dans le graphe , et permettre de estimer asymptotiquement le densité des arc . . le expérimentation confirmer le potentiel de le approche , qui permettre de identifier un structure fortement informatif dans le graphe , sans faire le hypothèse de un décomposition en cluster dense . " 	Marc Boullé	2011	@orange-ftgroup.com	1000986
252	Evaluation des outils d'extraction terminologique Quezao et Acabit	Evaluation des outil de extraction terminologique Quezao et Acabit  le article décrire le évaluation de deux outil de extraction terminologique Acabit et Quezao . si acabit être plus connaître car librement disponible , Quezao être issir un travaux de Orange Labs sur le recherche de information . après un comparaison sur le approche théorique des deu système , un évaluation concret aller porter sur un corpus de actualité ( 2424Actu ) pour le aspect qualitatif et sur un corpus de presse pour le aspect quantitatif 	Edmond Lassalle, Prem Kumar Casimir, Emilie Guimier De Neef	2011	@orange-ftgroup.com	1000938
253	Extraction de motifs séquentiels contextuels	extraction de motif séquentiel contextuel  le motif séquentiel traditionnel ne tenir généralement pas compte des information contextuel fréquemment associer aux donnée séquentiel . dans le cas des séquence de achat de client dans un magasin , le extraction classique de motif clr focaliser sur le achat des client sans considérer son catégorie socio- professionnel , son sexe , son âge . or , en considérer le fait que un motif séquentiel être spécifique à un contexte donner , un expert pouvoir adapter son stratégie au type du client et prendre le décision adéquat . dans ce article , cln proposer de extraire un motif de le forme « le achat des produit A et B suivre de le achat du produit C être spécifique aux jeune client » . en mettre en valeur le propriété formel de tel contexte , cln développer un algorithme efficace de extraction de motif séquentiel contextuel . le expérimentation effectuer sur un jeu de donnée réel montrer le apport et le efficacité de le approche proposer . 	Julien Rabatel, Sandra Bringay	2011	@lirmm.fr	1000924
254	Extraction de motifs temporels à partir de séquences d'événements avec intervalles temporels	extraction de motif temporel à partir de séquence de événement avec intervalle temporel  le fouille de base de donnée séquentiel avoir pour objet le extraction de motif séquentiel représentatif . le plupart des méthode concerner un motif composé de événement lier par un relation temporel baser sur le précédence des instant . pourtant , dans un nombreux situation réel un information quantitatif sur le durée des événement ou le délai inter-événement être nécessaire pour discriminer le phénomène . cln proposer deux algorithme , QTIAPriori et QTIPrefixSpan , pour extraire un motif temporel composé de événement associer à un intervalle décrire son position dans le temps et son durée . chacun de lui ajouter aux algorithme GSP et PrefixSpan un étape de catégorisation de intervalle multi-dimensionnel pour extraire le intervalle temporel représentatif . le expérimentation sur un donnée simuler montrer le capacité des algorithme à extraire un motif précis en présence de bruit et montrer le amélioration des performance en temps de calcul . 	Rene Quiniou, Thomas Guyet	2011	@agrocampus-ouest.fr, @irisa.fr	1000925
255	Extraction et Analyse de réseaux sociaux issus de Bases de Données Relationnelles	extraction et analyse de réseau social issir de base de Données Relationnelles  dans un contexte de entreprise , beaucoup de information important rester stocker dans un base de donnée relationnel , constituer un source riche pour construire un réseau social . le réseau , ainsi extraire , avoir souvent un taille important ce qui rendre son analyse et son visualisation difficile . dans ce travail , cln proposer un étape de extraction suivre de un étape de agrégation des réseau social à partir un base de donnée relationnel . le étape de extraction ou de construction transformer un base de donnée relationnel en base de donnée graphe , puis le réseau social être extraire . le étape de agrégation , qui être baser sur le algorithme k-SNAP , produire un graphe résumer . 	Rania Soussi, Amine Louati, Marie-Aude Aufaure, Hajer Baazaoui Zghal, Yves Lechevallier, Henda Ben Ghezela Hadjami	2011	@ecp.fr, @riadi.rnu.tn, @inria.fr	1000988
256	Extraction sous contraintes d'ensembles de cliques homogènes	extraction sous contrainte de ensemble de clique homogène  cln proposer un méthode de fouille de donnée sur un graphe avoir un ensemble de étiquette associer à chaque sommet . un application être , par exemple , de analyser un réseau social de chercheur co- auteur lorsque un étiquette préciser le conférence dans lequel cln publier . cln définir le extraction sous contrainte de ensemble de clique tel que chaque sommet des clique impliquer partager suffisamment de étiquette . cln proposer un méthode pour calculer tout le ensemble Maximaux de Cliques dire Homogènes qui satisfaire un conjonction de contrainte fixer par le analyste et concerner le nombre de clique séparer , le taille des clique ainsi que le nombre de étiquette partager . le expérimentation montrer que le approche fonctionner sur un grand graphe construire à partir de donnée réel et permettre le mise en évidence de structure intéressant 	Pierre-Nicolas Mougel, Marc Plantevit, Christophe Rigotti, Olivier Gandrillon, Jean-François Boulicaut	2011	@liris.cnrs.fr, @univ-lyon1.fr	1000999
257	Heuristique pour l'extraction de motifs ensemblistes bruités	heuristique pour le extraction de motif ensembliste bruiter  le recherche de motif ensembliste dans un matrice de donnée booléen être un problématique important dans un processus de extraction de connaissance . 	Céline Rouveirol, Lucas Létocart, Karima Mouhoubi	2011	@univ-paris13.fr	1001002
258	Import automatique et interactif de données dans les systèmes de visualisations	import automatique et interactif de donnée dans le système de visualisation  le premier étape du processus de visualisation de information consister à transformer le donnée de un format brut vers un structure de donnée utilisable par le différent composant de visualisation . dans le application réel , ce premier étape représenter un barrière empêcher le accès des utilisateur novice à un riche variété de technique de visualisation . par exemple , ilimp pouvoir être techniquement impossible pour un utilisateur lambda de transformer un donnée arborescent en un modèle de graphe pouvoir utiliser un représentation à base de TreeMap . un autre barrière être aussi le multitude de transformation possible des donnée brut . ilimp falloir pouvoir explorer ce ensemble de combinaison . baser sur son retour de expérience avec un utilisateur final , dans ce article , cln considérer que le format brut être sous forme tabulaire . ce format être le plus couramment utiliser et être facilement accessible par son utilisateur . cln proposer un méthode novateur permettre de générer automatiquement un graphe valuer à partir de ne importer quel table . en analyser le contenu de chaque dimension cln identifier le interconnexion entre celui -ci . puis cln caractériser le entité , le attribut et le relation possible au sein des table . finalement , cln intégrer le utilisateur dans le processus de transformation en cld proposer un ensemble de transformation valide . 	David Auber, Frédéric Gilbert	2011	@labri.fr, @labri.fr	1001006
259	Intégration de données haptiques brutes dans des systèmes experts de diagnostic des connaissances	intégration de donnée haptique brut dans un système expert de diagnostic des connaissance  ce article avoir pour cadre un environnement informatique pour le apprentissage humain ( EIAH ) dédier à le chirurgie orthopédique , et plus précisément sur le diagnostic des connaissance des apprenant . pour ce faire , un réseau bayésien inférer à partir de exercice que le étudiant réaliser sur un simulateur avec bras articuler . ce réseau résulter de un approche centré expert du domaine , comme très souvent dans le EIAH . pourtant , dans un domaine comme le chirurgie où le connaissance être tacite , le geste de le apprenant sembler intéressant à considérer . le but de son travaux être donc de adopter un démarche plus centré sur le donnée en incorporer au réseau bayésien le donnée haptique continu issue du simulateur . divers problème clr poser néanmoins , de un part sur le besoin de étudier le nature des donnée pour conserver le généricité du système , et de autre part pour trouver un méthode de validation pertinent concerner son traitement 	Sébastien Lallé, Vanda Luengo	2011	@imag.fr	1001026
260	Interprétation spectrale de la classification relationnelle	interprétation spectral de le classification relationnel  ce papier présenter un vue spectral sur le approche de le analyse relationnel pour le classification des donnée catégoriel . ilimp établir de abord le lien théorique entre le approche de le analyse relationnel et le problème de classification spectral . en particulier , le problème de classification relationnel être présenter comme un problème de maximisation de trace , ce problème être donc transformer par le relaxation spectral en un problème de optimisation sous contrainte qui pouvoir être résoudre par un multiplicateur de Lagrange , le solution être donner par un problème de valeur propre . 	Lazhar Labiod, Younès Bennani	2011	@univ-paris13.fr	1000997
261	Les moteurs de wikis sémantiques : un état de l'art	le moteur de wiki sémantique : un état de le art  ce article être un état de le art sur le moteur de wiki sémantique , en particulier sur son utilisation des technologie du web sémantique . le principal notion lier aux wiki sémantique être de abord présenter . ensuite , plusieurs projet actif de moteur de wiki être comparé selon différent point de vue . finalement , un recommandation être donner pour le choix de un moteur de wiki . en conclusion , le auteur clr interroger sur le perspective des wiki sémantique tel que le faible interopérabilité de certain moteur . 	Thomas Meilender, Nicolas Jay, Jean Lieber, Fabien Palomares	2011	@a2zi.fr, @loria.fr	1001020
262	Mesure de concordance pour les bases de données évidentielles	mesure de concordance pour le base de donnée évidentiel  dans ce article , cln proposer un mesure de concordance de un source avec le autre source . ce mesure pouvoir servir à réduire le importance de son fonction de masse avant de cla combiner afin de trouver un compromis et donc réduire le conflit . ce mesure être illustrer par un donnée réel . 	Mouna Chebbah, Arnaud Martin, Boutheina Ben Yaghlane	2011	@gnet.tn, @ihec.rnu.tn, @univ-rennes1.fr	1000945
263	Mesures d'hétérogénéité sémantique des systèmes P2P non-structurés	mesure de hétérogénéité sémantique des système P2P non- structurer  le autonomie des participant dans le système P2P pour le partage de donnée pouvoir conduire à un situation de hétérogénéité sémantique dans le cas où le participant utiliser son propre ontologie pour représenter son donnée . dans ce article cln commencer par définir un mesure de disparité entre participant en considérer son contexte sémantique . en considérer le topologie du système et le disparité entre participant , cln proposer un mesure de hétérogénéité sémantique de un système P2P non- structurer . 	Thomas Cerqueus, Sylvie Cazalens, Philippe Lamarre	2011	@univ-nantes.fr	1000984
264	Mixer les moyens pour extraire les gloses	mixer le moyens pour extraire le glose  cln proposer de extraire un connaissance lexical en exploiter le « glose » de mot , ce description spontané de sens , repérable par un marqueur lexical et des configuration morpho- syntaxique spécifique . ainsi dans cla extraire suivre , le mot testing être suivre de un glose en ce est-à dire : « 10 \pourcent de ce embauche aller porter sur un métier qui monter : le « testing » , ce est-à-direr le maîtrise des méthodologie rigoureux de test des logiciel » . ce approche ouvrir un perspective pour le acquisition lexical et terminologique , fondamental pour un nombreux tâche . dans ce article , cln comparer deux façon de extraire le unité en relation de glose : patron et statistique de association de unité sur le web , en cla évaluer sur un donnée réel . 	Augusta Mela, Mathieu Roche, Mohamed el Amine Bekhtaoui	2011	@univ-montp3.fr, @lirmm.fr, @gmail.com	1000935
265	Modélisation de la dynamique de phénomènes spatio-temporels par des séquences de motifs	modélisation de le dynamique de phénomène spatio- temporel par un séquence de motif  dans ce papier , cln proposer un nouveau cadre théorique permettre de modéliser le dynamique de phénomène spatio- temporel . cln définir le concept de séquence spatio- temporel de motif afin de capturer le interaction entre un ensemble de propriété et un phénomène à observer . un algorithme incrémental être proposer pour extraire un séquence spatiotemporel de motif sous contrainte , et un nouveau structure de donnée être mettre en place afin de améliorer son performance . un prototype avoir être développer et tester sur un donnée réel . 	Loïc Mabit, Nazha Selmaoui-Folcher, Frédéric Flouvat	2011	@univ-nc.nc	1001001
266	Modélisation de la propagation de l'information sur le Web : de l'extraction des données à la simulation	modélisation de le propagation de le information sur le Web : de le extraction des donnée à le simulation  cln proposer un modèle de le propagation de le information dans un réseau , en détailler tout le étape de son réalisation et de son utilisation dans un cadre de simulation . A partir de donnée réel extraire du Web , cln identifier parmi le source des catégorie de comportement de publication distinct . cln proposer ensuite un extension de un modèle de diffusion de le information existant , afin de augmenter son pouvoir de expression , en particulier pour reproduire ce comportement de publication , puis cln le validon sur un exemple de simulation . 	François Nel, Marie-Jeanne Lesot, Philippe Capet, Thomas Delavallade	2011	@lip6.fr, @thalesgroup.com	1001023
267	Modélisation d'une ressource termino-ontologique de domaine pour l'annotation sémantique de tableaux	modélisation de un ressource termino- ontologique de domaine pour le annotation sémantique de tableau  cln proposer dans ce article un modélisation de un ressource termino- ontologique ( RTO ) de domaine , guider par le tâche de annotation sémantique de tableau . le annotation de un tableau consister à annoter son cellule , pour pouvoir ensuite identifier le concept représenter par son colonne et enfin identifier le ou le relation n-air que ilimp représenter . le RTO proposer permettre de un part de modéliser dans son composante lexical le terme utiliser pour le annotation des cellule en intégrer le gestion des synonyme et du multilingue , et , de autre part , de modéliser dans son composante conceptuel le concept symbolique , le concept numérique et le relation n-air , qui être propre au domaine étudier . 	Patrice Buche, Juliette Dibie-Barthélemy, Liliana Ibanescu, Abir Saïd	2011	@supagro.inra.fr, @risk, @agroparistech.fr	1001021
268	Moteur de questions-réponses d'une base de connaissances	moteur de questions-réponse de un base de connaissance  ce article présent comment le gestion et le exploitation de connaissance issu du site web Wikipedia avoir permettre de développer un tel fonction qui avoir être intégrer depuis février 2010 dans un moteur de recherche internet français pour le grand public . Aujourd' hui ce fonction être capable de répondre à un question formuler en langage naturel sur environs 170000 lieux ou personne . le formalisation des donnée extraire de wikipedia en connaissance au format OWL ou RDFS avoir permettre de déduire un nouveau information manquant , de typer le entité nommer trouver et de traiter un nouveau forme de question qui être non traiter . 	Michel Plu, Johannes Heinecke	2011	@orange-ftgroup.com	1001024
269	Motifs Séquentiels delta-Libres	motif Séquentiels delta-Libres  bien que largement étudier , le extraction de motif séquentiel rester un tâche très difficile et poser aussi le défi du grand nombre de motif produit . dans ce article , cln proposer un nouveau approche extraire le motif séquentiel le plus général à fréquence similaire . cln montrer en quoi? le extension de ce notion , déjà connaître pour le motif ensembliste , être un problème particulièrement difficile pour le séquence . le motif delta-libre ainsi produire être en nombre réduit et faciliter le usages de un processus de fouille et cln montrer son apport comme descripteur dans un contexte de classification de séquence . 	Marc Plantevit, Chedy Raïssi, Bruno Crémilleux	2011	@liris.cnrs.fr, @loria.fr, @unicaen.fr	1000926
270	MuMIe: Une Approche Automatique pour l'Interopérabilité des Métadonnées	MuMIe : un approche automatique pour le interopérabilité des Métadonnées  avec le explosion du multimedia , le utilisation des métadonné être devenir crucial pour assurer un bon gestion des contenu . cependant , ilimp être nécessaire d assurer un accès uniforme aux métadonné . plusieurs technique avoir ainsi être développer afin de réaliser ce interopérabilité . le plupart de entre cln être spécifique à un seul langage de description . le système de matching existant présenter certain limite , en particulier dans le traitement des information structurel . cln présenter dans ce article un nouveau système de intégration qui supporter un schéma provenir de langage descriptif différent . de plus , le méthode de matching proposer avoir recours à plusieurs type de information de façon à augmenter le précision de matching 	Samir Amir, Ioan Marius Bilasco, Thierry Urruty, Chabane Djeraba	2011	@lifl.fr	1000985
271	Nouvelle approche de fouille de graphes AC-réduits fréquents	nouveau approche de fouille de graphe AC-réduits fréquent  le fouille de graphe être devenir un piste de recherche intéressant et un défi réel en matière de fouille de donnée . parmi le différent famille de motif de graphe , le graphe fréquent permettre un caractérisation intéressant des groupe de graphe , ainsi que un discrimination des différent graphe lors de le classification ou de le segmentation . A cause de le NP-complétude du test de isomorphisme de sous-graphe et de le immensité de le espace de recherche , le algorithme de fouille de graphe être exponentiel en temps de exécution et-ou occupation mémoire . dans ce article , cln étudier un nouveau opérateur de projection polynomial nommer AC-projection baser sur un propriété clé du domaine de le programmation par contrainte , à savoir le arc consistance . ce opérateur être censer remplacer le utilisation de le isomorphisme de sous-graphe en établir un biais sur le projection . ce étude être suivre de un évaluation expérimental du pouvoir discriminer un pattern AC-réduits découvert . 	Brahim Douar, Michel Liquiere, Cherif Chiraz Latiri, Yahya Slimani	2011	@lirmm.fr, @gnet.tn, @fst.rnu.tn	1001004
272	Optimisation de l'extraction de l'alignement des ontologies avec la contrainte de différence	optimisation de le extraction de le alignement des ontologie avec le contrainte de différence  dans ce papier , cln proposer un approche baser sur le programmation par contrainte pour aborder efficacement le problème de le alignement des ontologie , et plus particulièrement le extraction des correspondance à partir un mesure de similarité . le complexité de ce problème être accentuer dans le application à caractère dynamique où le aspect performance être capital . plus précisément , cln exploiter le contrainte global de différence développer dans le domaine de le programmation par contrainte pour extraire un alignement total et injectif . cln montrer que ce approche être efficace et clr prêter à un mise en oeuvre à le fois interactif et automatique . 	Moussa Benaissa, Yahia Lebbah	2011	@yahoo.fr, @yahoo.fr	1000991
273	Optimisation directe des poids de modèles dans un prédicteur Bayésien naïf moyenné	optimisation direct des poids de modèle dans un prédicteur Bayésien naïf moyenner  le classifieur Bayésien naïf être un outil de classification efficace en pratique pour un nombreux problème réel , en dépit de le hypothèse restrictif de indépendance des variable conditionnellement à le classe . récemment , un nouveau méthode permettre de améliorer le performance de ce classifieur avoir voir le jour , sur le base à le fois de sélection de variable et de moyennage de modèle . dans ce article , cln proposer un extension de le sélection de variable pour le classifieur Bayésien naïf , en considérer un modèle de pondération des variable utiliser et des algorithme de optimisation direct de ce poids . le expérimentation confirmer le pertinence de son approche , en permettre un diminution significatif du nombre de variable utiliser , sans perte de performance prédictif . 	Marc Boullé, Romain Guigourès	2011	@orange-ftgroup.com	1000932
274	Pondération et classification simultanée de données binaires et continues	pondération et classification simultané de donnée binaire et continu  dans ce article , cln proposer un nouveau approche de classification topologique et de pondération des variable mixte ( qualitatif et quantitatif coder en binaire ) durant un processus de apprentissage non superviser . ce approche être baser sur le modèle des carte auto- organisatrice . le apprentissage être combiné à un mécanisme de pondération des différent variable sous forme de poids de influence sur le pertinence des variable . le apprentissage des pondération et des prototype être réaliser de un manière simultané en favoriser un classification optimisé des donnée . le approche proposer avoir être valider sur un donnée qualitatif coder en binaire et plusieurs base de donnée mixte . 	Nicoleta Rogovschi, Mustapha Lebbah, Nistor Grozavu	2011	@parisdescartes.fr, @univ-paris13.fr	1000930
275	Prévision de trajectoires de cyclones à l'aide de forêts aléatoires avec arbres de régression	prévision de trajectoire de cyclone à le aide de forêt aléatoire avec arbre de régression  cln présenter un étude pour le prédiction des trajectoire de cyclone dans le océan Atlantique Nord à partir de donnée issu de image satellite . cln cll extraire un mesure de vitesse de vent , de vorticité , de humidité ( base JRA-25 ) et un mesure de latitude , de longitude et de vitesse de vent instantané des cyclone tout le 6 heure ( base IBTrACS ) . le modèle de référence à ce jour ne tenir pas compter un corrélation entre le donnée et le prévision ce qui limiter son intérêt pour certain utilisateur . cln proposer ainsi de prédire le déplacement en latitude et le déplacement en longitude au même instant à un horizon de 120 heure tout le 6 heure à le aide de forêt aléatoire avec arbre de régression . sur le long terme , à partir de 18 heure , le méthode proposer donne de meilleur résultat que le méthode existant . 	Sterenn Liberge, Sileye O. Ba, Philippe Lenca, Ronan Fablet	2011	@telecom-bretagne.eu	1001031
276	Propositionaliser des attributs numériques sans les discrétiser, ni les agréger	Propositionaliser un attribut numérique sans le discrétiser , ni cla agréger  le fouille de donnée relationnel considérer un donnée contenir dans au moins deu table relier par un association un-à-plusieurs , par exemple des client et son achat , ou un molécule et son atome . un façon de fouiller ce donnée consister à transformer le donnée en un seul table attribut-valeur . ce transformation être appelé propositionalisation . le approche existant gérer principalement le attribut catégoriel . un premier solution être donc de discrétiser le attribut numérique pour cla transformer en attribut catégoriel . le approche alternatif , qui gérer le attribut numérique , consister à cla agréger . cln proposer un approche dual de le discrétisation , qui inverser le ordre de traitement du nombre de objet et du seuil , et dont le discrétisation généraliser le quartile . cln pouvoir ainsi construire un attribut que le approche existant de propositionalisation ne pouvoir pas construire , et qui ne pouvoir pas non plus être obtenir par le système complet de fouille de donnée . 	Agnès Braud, Nicolas Lachiche	2011	@unistra.fr	1000998
277	Reconnaissance d'Actions par Modélisation du Mouvement	reconnaissance de action par modélisation du mouvement  ce article proposer un approche utiliser le modèle de direction et de magnitude de mouvement pour détecter le action qui être effectuer par un être humain dans un séquence vidéonisé . un mélange Gaussiens et de loi de von Mises être estimer à partir un orientation et des magnitude des vecteur du flux optique calculer pour chaque bloc de le scène . le paramètre de ce modèle être estimer grâce à un algorithme de apprentissage en ligne . le action être reconnaître grâce à un mesure qui clr baser sur le distance de Bhattacharyya et qui permettre de comparer le modèle de un séquence donner avec le modèle créer à partir de séquence de apprentissage . le approche proposer être évaluer sur deux ensemble de vidéo contenir un action varier exécuter aussi bien dans un environnement intérieur que extérieur . 	Yassine Benabbas, Adel Lablack, Thierry Urruty, Chabane Djeraba	2011	@lifl.fr	1000940
278	Résumés et interrogations de logs de requêtes OLAP	résumé et interrogation de log de requête OLAP  un façon de assister le analyse de entrepôt de donnée reposer sur le exploitation et le fouille de fichier log de requête OLAP . mais , à son connaissance , ilimp ne exister pas un méthode permettre de obtenir un représentation de un tel logarithme qui être à le fois concis et exploitable . dans ce papier , cln proposer un méthode pour résumer et interroger un log de requête OLAP . le idée de base être que un requête résumer un autre requête et que un logarithme , qui être un séquence de requête , résumer un autre logarithme . son cadre formel être composer de un algèbre simple destiner à résumer un requête OLAP , et de un mesure évaluer le qualité du résumé obtenir . cln proposer également plusieurs stratégie pour calculer automatiquement un résumé de log de bon qualité , et cln montrer comment un propriété simple sur le résumé pouvoir être utiliser pour interroger un logarithme efficacement . un test sur un log de requête MDX avoir montrer le intérêt de son approche . 	Julien Aligon, Elsa Negre, Patrick Marcel	2011	@univ-tours.fr	1000951
279	Sélection des variables informatives pour l'apprentissage supervisé multi-tables	sélection des variable informatif pour le apprentissage superviser multi-table  dans le fouille de donnée multi-table , le donnée être représenter sous un format relationnel dans lequel le individu de le table cible être potentiellement associer à plusieurs enregistrement dans un table secondaire en relation un-à-plusieur . le plupart des approche existant opérer en transformer le représentation multi-table , notamment par mise à plat . par conséquent , cln perdre le représentation initial naturellement compact mais également cln risquer de introduire un biais statistique . son approche avoir pour objectif de évaluer le informativité des variable explicative originel par rapport à le variable cible dans le contexte des relation un-à-plusieur . cln consister à résumer le information contenir dans chaque variable par un tuple de attribut représenter le effectif des modalité de celui -ci . un modèle en grille multivarié être alors employer pour qualifier le information apporter conjointement par le nouveau attribut , ce qui revenir à un estimation de densité conditionnel de le variable cible connaître le variable explicatif en relation un-à-plusieur . le premier expérimentation sur un base de donnée artificiel et réel montrer que cln arriver à identifier le variable explicatif potentiellement pertinent sur tout le domaine relationnel . 	Dhafer Lahbib, Marc Boullé, Dominique Laurent	2011	@orange-ftgroup.com, @orange-ftgroup.com, @u-cergy.fr	1000995
280	Système de recherche de musique adaptable à la perception de chaque utilisateur	système de recherche de musique adaptable à le perception de chaque utilisateur  dans le cadre de son travaux sur le portage linguistique des système de gestion de contenu traiter un énoncé spontané en langue naturel , cln présenter ici un évaluation du portage de IMRS ( système de recherche de morceau de musique en langue naturel ) Kumamoto ( 2007 ) du japonais vers le français . ce évaluation pouvoir clr faire au niveau des représentation interne en cla comparer , ou au niveau de le tâche . ici , cln clr intéresser à un évaluation lier à le tâche en proposer un service Web qui permettre de mesurer le performance global de le nouveau version obtenir . cln avoir par le suite chercher à améliorer et ajouter un nouveau fonctionnalité en proposer un service de recherche de musique adaptable à le perception de chaque utilisateur . en effet , un même morceau de musique pouvoir être juger calme pour un premier auditeur , très calme pour un deuxième , et assez calme pour un troisième , etc. cln clr demander le impression final que porter ce dernier morceau de musique . ce être naturel que le utilisateur évaluer différemment un même morceau de musique car cln avoir un perception différent . devant ce situation , cln proposer un service de recherche de musique baser des méthode simple et automatiser et qui être adaptable à le perception de chaque utilisateur . 	Najeh Hajlaoui	2011	@imag.fr	1000962
281	Système pour la catégorisation automatique des offres d'emploi en une typologie de fonctions	système pour le catégorisation automatique des offre de emploi en un typologie de fonction  depuis le deu dernier décennie , le augmentation du nombre de site de emploi sur Internet avoir accentuer le nécessité de proposer un outil de aide à le décision adapter aux besoin des recruteur . ce article présenter un système pour le catégorisation des texte de offre de emploi destiner à être diffuser sur Internet . après un pré-traitement adapté des offre , le terme descripteur être choisi en fonction de son pouvoir discriminer vis-à-vis un différent classe ce qui permettre de réduire son nombre de manière significatif . le offre être ensuite représenter par son coordonnée dans le espace factoriel obtenir par analyse des correspondance et le classification réaliser dans un cadre superviser à le aide de SVM . 	Julie Séguéla	2011	@multiposting.fr	1001009
282	Treillis des concepts SKYLINES : Analyse multidimensionnelle des SKYLINES fondée sur les ensembles en accord	treillis des concept SKYLINES : analyse multidimensionnel des SKYLINES fonder sur le ensemble en accord  le concept de SKYLINE avoir être introduire pour mettre en évidence le objet « le meilleur » selon différent critère . un généralisation multidimensionnel du SKYLINE avoir être proposer à travers le SKYCUBE qui réunir tout le SKYLINES possible selon tout le combinaison de critère et permettre de analyser le lien entre objet SKYLINES . comme cla dater cube , le SKYCUBE clr avérer extrêmement volumineux si bien que un approche de réduction être incontournable . dans ce article , cln définir un approche de matérialisation partiel du SKYCUBE . le idée sous-jacent être de éliminer de le représentation le Skycuboïdes facilement re-calculable . pour atteindre ce objectif de réduction , cln caractériser un cadre formel : le treillis des concept ACCORDS . ce structure combiner le notion de ensemble en accord et le treillis des concept . à partir de ce structure , cln dériver le treillis des concept SKYLINES qui cll être un instance contraindre . le point fort de son approche être de être orienter attribut ce qui permettre de borner le nombre de noeud du treillis et de obtenir un navigation efficace à travers le Skycuboïdes . 	Sébastien Nedjar, Fabien Pesci, Lotfi Lakhal, Rosine Cicchetti	2011		1000949
283	Un critère Bayésien pour évaluer la robustesse des règles de classification	un critère Bayésien pour évaluer le robustesse des règle de classification  le utilisation de règle de classification dans le modèle prédictif avoir être très étudier ce dernier année . le forme simple et interprétable des règle en faire un motif très populaire . le classifieur combinant des règle de classification intéressant ( selon un mesure de intérêt ) offrir de bon performance de prédiction . cependant , le performance de ce classifieur dépendre de le mesure de intérêt ( e.g. , confiance , taux de accroissement , ... ) et du seuillage ( non- trivial ) de ce mesure pour déterminer le règle pertinent . de plus , ilimp être facile de montrer que le règle extraire ne être pas individuellement robuste . dans ce article , cln proposer un nouveau critère pour évaluer le robustesse des règle de classification dans le donnée Booléennes . son critère être issir de un approche Bayésienne : cln proposer un expression analytique de le probabilité de un règle connaître le donnée . ainsi , le règle le plus probable être robuste . le critère Bayésien cld permettre alors de identifier ( sans paramètre ) le règle robuste parmi un ensemble de règle donner . 	Marc Boullé, Dominique Gay	2011	@orange-ftgroup.com	1001013
284	Un cycle de vie complet pour l'enrichissement sémantique des folksonomies	un cycle de vie complet pour le enrichissement sémantique des folksonomie  le tag fournir par le utilisateur des plateforme de tagging social ne être pas explicitement lier sémantiquement , et ceci limiter considérablement le possibilité de exploitation de ce donnée . cln présenter dans ce article son approche pour le enrichissement sémantique des folksonomie qui intégrer un combinaison de traitement automatique ainsi que le capture des contribution de structuration des utilisateur via un interface ergonomique . de plus , son modèle supporter le point de vue qui divergent tout en permettre de cla combiner en respecter son cohérence local . ce approche clr adresser aux communauté de connaissance collaborer en ligne , et en intégrer son usages , cln être en mesure de proposer un cycle de vie complet pour le processus de structuration sémantique des folksonomie . le navigation dans le donnée de tagging être ainsi améliorer , et le folksonomie pouvoir alors être directement intégrer dans le construction de thesauri . 	Freddy Limpens, Fabien Gandon, Michel Buffa	2011	@inria.fr, @unice.fr	1000990
285	Un système cellulaire neuro-symbolique pour l'extraction et la gestion des connaissances	un système cellulaire neuro- symbolique pour le extraction et le gestion des connaissance  le CNSS - Cellular Neuro- Symbolic System - être un système hybride rallier conjointement le neuro- symbolique et le cellulaire . CNSS permettre , à partir de un base de cas pratique , de faire coopérer un réseau de neurone , un graphe de induction et un automate cellulaire pour le construction de un modèle de prédiction . en détecter et en éliminer le individu non applicable et le variable non pertinent , le réseau de neurone optimiser le base de apprentissage . le résultat ainsi obtenir être affiner par un processus de apprentissage symbolique à base de graphe de induction . ce raffinement clr faire par un modélisation booléen qui aller assister le apprentissage symbolique à optimiser le graphe de induction et aller assurer , par le suite , le représentation et le génération des règle de classification sous forme conjonctif avant de entamer le phase de déduction par un moteur de inférence cellulaire . CNSS avoir être tester sur plusieurs application en utiliser un problème académique et réel . le résultat montrer que le système CNSS avoir un performance supérieur et un nombreux avantage . 	Baghdad Atmani, Mohamed Benamina, Bouziane Beldjilali	2011	@gmail.com, @gmail.com, @yahoo.fr	1000934
286	Une mesure de distance dans l'espace des alignements entre parties potentiellement homologues de deux ontologies légères	un mesure de distance dans le espace des alignement entre party potentiellement homologue de deux ontologie léger  cln proposer dans ce article un méthode qui calculer le distance entre ontologie dans un but de aide à le décision sur le pertinence ou non de son fusion . ce méthode calculer le distance entre party homologue de deux ontologie par rapport à son niveau de détail et son structure taxonomique , et ce en exploiter le correspondance produire par un alignement préalablement effectuer entre ce ontologie , et en adapter le méthode de le distance de édition entre arbre ordonner . cln limiter son étude ici aux ontologie léger , ce être à dire un taxonomie représenter en langage OWL , le langage de ontologie pour le Web . son méthode avoir être implémenter et tester sur un ontologie réel , et le résultat obtenir sembler prometteur . 	Ammar Mechouche, Nathalie Abadie, Sébastien Mustière	2011		1001018
287	Une méthodologie de recommandations produits fondée sur l'actionnabilité et l'intérêt économique des clients	un méthodologie de recommandation produire fonder sur le actionnabilité et le intérêt économique des client  dans un contexte économique difficile , le fidélisation des client figurer au premier rang des préoccupation des entreprise . en effet , selon le Gartner , fidéliser un client existant coûter beaucoup moins cher que prospecter un nouveau client . pour cll parvenir , le entreprise optimiser le marge et le cycle de vie des client en développer un relation personnaliser aboutir à un meilleur recommandation . dans ce article , cln proposer un méthodologie pour le système de recommandation fonder sur le analyse des chiffre de affaire des client sur un famille de produit . plus précisément , le méthodologie consister à extraire un comportement de référence sous le forme de règle de association et à cll évaluer le intérêt économique et le actionnabilité . le recommandation être réaliser en cibler le contre-exemple le plus actionnable sur le règle le plus rentable . son méthodologie être appliquer sur 12000 client et 100000 produit de VMMatériaux afin de orienter le commercial sur le possibilité de accroissement de le valeur client . 	Julien Blanchard, Thomas Piton, Henri Briand, Fabrice Guillet	2011	@univ-nantes.fr, @vm-materiaux.fr	1000946
288	Une nouvelle approche pour l'extraction non supervisée de critères	un nouveau approche pour le extraction non supervisé de critère  récemment de nouveau technique regrouper sous le vocable de détection automatique de opinion ( opinion mining ) avoir faire son apparition et proposer un évaluation global de un document . ainsi , cln ne permettre pas de mettre en avant le fait que le personne exprimer un opinion très positif du scénario de un film alors que cln trouver que le acteur être médiocre . dans ce article , cln proposer de caractériser automatiquement le segment de texte relever de un critère donner sur un corpus de critique . 	Benjamin Duthil, François Trousset, Mathieu Roche, Michel Plantié, Gérard Dray, Jacky Montmain	2011	@mines-ales.fr, @lirmm.fr	1000981
289	Une nouvelle approche visuelle pour la classification hiérarchique et topologique	un nouveau approche visuel pour le classification hiérarchique et topologique  " cln proposer dans ce article un nouveau méthode de classification hiérarchique et topologique . . son approche consister à construire de manière auto- organiser un partition de donnée représenter par un ensemble " " forêt " " de arbre répartir sur un grille 2Darles chaque cellule de le grille être modéliser par un arbre dont le noeud représenter le donnée . . le partition global obtenir être visualiser à le aide de un carte de TreeMap dans lequel chaque TreeMap représenter un arbre de donnée . . cln évaluer le capacité et le performance de son approche sur un donnée aux difficulté variable . . un résultat numérique et visuel être présenter et discuter . " 	Mustapha Lebbah, Hanane Azzag	2011	@univ-paris13.fr	1001038
290	Utilisation d'une ontologie du domaine pour la découverte du contenu de bases de données géographiques	utilisation de un ontologie du domaine pour le découverte du contenu de base de donnée géographique  le essor récent des technologie associer à le géomatique avoir permettre le production rapide de nombreux donnée géographique . or , pour tirer profit de ce donnée , ilimp convier de pouvoir évaluer son pertinence et son complexité voir à vis de le application à lequel cln cla destiner . dans ce article , cln présenter un application permettre à un utilisateur de découvrir le contenu de base de donnée géographique , à savoir , quel type de entité géographique être représenter au sein de chaque base et comment . pour accéder à ce information le utilisateur interroger le système via un ontologie global du domaine qui décrire le type de entité topographique du monde réel . un ontologie local ou de application être utiliser pour formaliser le spécification de chaque base de donnée décrire . cln être annoter à le aide de concept issu de le ontologie global . ce système être implémenter sous le forme de un interface Web et inclure un affichage cartographique de échantillon de donnée 	Ammar Mechouche, Nathalie Abadie, Emeric Prouteau, Sébastien Mustière	2011		1000983
291	Utiliser des résultats d'alignement pour enrichir une ontologie	utiliser un résultat de alignement pour enrichir un ontologie  en établir un relation entre un concept issir de deux ontologie distinct , le outil de alignement pouvoir être utiliser pour enrichir un des deu ontologie avec le concept de le autre . A partir de un expérience mener dans le cadre du projet ANR GeOnto 1 dans le domaine de le topographie , ce article identifier un traitement complémentaire à le alignement pour le enrichissement et montrer son mise en oeuvre dans TaxoMap Framework . 	Fayçal Hamdi, Brigitte Safar, Chantal Reynaud	2011	@lri.fr	1000992
292	Visualisation de l'intra et inter structure des groupes en classification non supervisée	visualisation de le intra et inter structure des groupe en classification non superviser  le croissance exponentiel des donnée engendrer un volumétrie de base de donnée très important . un solution couramment envisager être le utilisation de un description condensé des propriété et de le structure des donnée . de ce fait , ilimp devenir crucial de disposer de outil de visualisation capable de représenter le structure des donnée , non pas à partir un donnée cln même , mais à partir de ce description condensé . cln proposer un méthode de description des donnée à partir de prototype enrichir puis segmenter à le aide de un algorithme adapté de classification non supervisé . cln introduire ensuite un procédé de visualisation capable de mettre en valeur le structure intra et inter-groupe des donnée . 	Guénaël Cabanes, Younès Bennani	2011	@univ-paris13.fr	1001005
293	"AbsTop-K &#945;: un algorithme d'extraction de paires abstraites hautement corrélées pour mieux recommander dans la ""longue traine"	" AbsTop-K α : un algorithme de extraction de paire abstrait hautement corréler pour mieux recommander dans le " " long train "  " un nombreux système de recommandation clr focaliser sur le article ( que cln appeler " " item " " ) le plus " " populaire " " et ignorer souventla " " long traîne " " des produit qui cla être moins . . cln proposer le algorithmeAbsTop-kα qui améliorer le recommandation en clr baser sur le combinaison ( pondérer par α ) de paire hautement corréler entre un abstraction de item etentre des paire de item concret classiquement rechercher . " 	Minh Thu Tran Nguyen, François Sempé, Jean-Daniel Zucker	2010		1001439
294	Affichage de publicités sur des portails web	affichage de publicité sur un portail web  cln cln intéresser au problème de le affichage de publicité surle web . de plus en plus de annonceur souhaiter maintenant payer uniquementlorsque quelque un clique sur son publicité . dans ce modèle , le opérateur duportail avoir intérêt à identifier le publicité le plus cliquer , selon son catégoriesde visiteur . comme le probabilité de clic être inconnu avoir priori , ilimp clr agir de undilemme exploration  exploitation . ce problème avoir souvent être traiter en ne tenantpas compte de contrainte provenir du monde réel : le campagne de publicitésont un durée de vie et posséder un nombre de clic à assurer et ne pas dépasser . pour cela , cln introduire un approche hybride ( MAB + LP ) entre le programmationlinéaire et le bandit . son algorithme être tester sur un modèle créésavec un important acteur du web commercial . ce expérience montrer que cesapproche atteindre un performance très proche de le optimum et mettre enévidence des aspect clé du problème . 	Victor Gabillon, Jérémie Mary, Philippe Preux	2010	@inria.fr	1001268
295	Aide à la décision pour la maintenance ferroviaire préventive	aide à le décision pour le maintenance ferroviaire préventif  le maintenance de train être un problème particulièrement délicat liéà de nombreux enjeu à le fois financier , sécuritaire et énergétique . cln nousintéresser à le mise en place de un maintenance préventif baser sur le détectionet le correction de tout comportement anormal susceptible de provoquer unproblème majeur dans un futur proche . cln proposer ainsi un outil de aide à ladécision afin de ( i ) dégager un connaissance utile sur le historique des train , et ( ie ) détecter et étudier le anomalie comportemental , dans le but de prendreun décision optimal en terme de maintenance ferroviaire 	Julien Rabatel, Sandra Bringay, Pascal Poncelet	2010	@lirmm.fr	1001319
296	Allier CSPs et motifs locaux pour la découverte de motifs sous contraintes n-aires	Allier CSPs et motif local pour le découverte de motif sous contrainte n-air  dans ce article , cln étudier le relation entre le découverte de motifssous contrainte et le CSPs ( Constraint Satisfaction Problems ) afin de définirun contrainte de plus haut niveau qui être précieux pour mener à bien destâche de fouille de donnée . pour cela , cln proposer un approche de modélisationet de extraction de motif sous contrainte n-air exploiter le motifslocaux . le utilisateur définir un ensemble de contrainte n-air et un solveur deCSP générer le ensemble des solution . son approche profiter un progrès récentssur le extraction de motif local et permettre de modéliser de manière concis etélégant tout ensemble de contrainte combiner plusieurs motif local , permettantainsi le découverte de motif répondre mieux aux but final de le utilisateur . le expérience mener montrer le faisabilité de son approche . 	Mehdi Khiari, Patrice Boizumault, Bruno Crémilleux	2010	@unicaen.fr	1001292
297	Analyse de documents pédagogiques en vue de leur annotation	analyse de document pédagogique en vue de son annotation  le utilisation des document pédagogique , disponible sur le web , devenir de plus en plus large tant pour le enseignant qui avoir besoin de préparerson support de cours que pour le étudiant qui désirer , par exemple , clr autoformer . le description de un document pédagogique , en cla alimenter par desmétadonné , clr avérer un solution qui conférer un valeur ajouté au documentafin de expliciter un information placer dans ce document . dans cetteoptique , cln proposer un méthode de annotation de documentspédagogique selon différent point de vue , qui être baser sur le analysesémantique des élément discursif du texte 	Boutheina Smine, Rim Faiz, Jean-Pierre Desclés	2010	@yahoo.fr, @ihec.rnu.tn, @paris4.sorbonne.fr	1001502
298	Analyse en ligne d'objets complexes avec l'analyse factorielle	analyse en ligne de objet complexe avec le analyse factoriel  le entrepôt de donnée et le analyse en ligne OLAP ( On-line AnalysisProcessing ) présenter un solution reconnaître et efficace pour le processusd'aide à le décision . notamment le analyse en ligne , grâce aux opérateur OLAP , permettre de naviguer et de visualiser un donnée représenter dans un cube multidimensionnel . mais lorsque le donnée ou le objet à analyser être complexe , ilimp être nécessaire de redéfinir et de enrichir ce opérateur OLAP . dans ce article , cln proposer de combiner le analyse OLAP et le fouille de donnée ( data mining ) afin de créer un nouveau opérateur de visualisation de objet complexe . Cetopérateur utiliser le analyse factoriel des correspondance . 	Loïc Mabit, Sabine Loudcher, Omar Boussaid	2010	@gmail.com, @univ-lyon2.fr	1001321
299	Analyse globale du flux optique pour la détection d'évènements dans une scène de foule	analyse global du flux optique pour le détection de évènement dans un scène de foule  le système de vidéo- surveillance être de plus en plus autonomesdans le détection des événement anormal . ce article présenter un méthode dedétection des flux majeur et des évènement qui survenir dans un scène defoule . ce détection être effectuer en utiliser un modèle directionnel construità partir de un mélange de loi de von Mises appliquer à le orientation des vecteursde mouvement . le flux majeur être alors calculer en récupérer le orientationsle plus important des mélange . divers évènement clr produire dansune foule être aussi détecter en utiliser en plus du modèle de orientation , unmodèle probabiliste de magnitude des vecteur de mouvement . le résultat del'expérimentation sur un échantillon de vidéo de événement être présenter . 	Yassine Benabbas, Nacim Ihaddadene, Thierry Urruty, Chabane Djeraba	2010	@lifl.fr	1001315
300	Apprentissage de patrons lexico-syntaxiques à partir de textes	apprentissage de patron lexico- syntaxique à partir de texte  ce papier présenter un approche de apprentissage de patron lexicosyntaxiquesà partir de texte annoter . le patron lexico- syntaxique être utiliséspour identifier un relation lexical dans le corpus textuel . son constructionmanuelle être un tâche fastidieux et un solution permettre le apprentissagesont souhaitable . cln proposer un approche de apprentissage qui reposesur le utilisation des chemin de dépendance pour représenter le patron et le implémentationd'un algorithme de classification . le approche avoir être appliquer dansle domaine biomédical pour identifier un patron lexico- syntaxique exprimantdes relation fonctionnel . 	Valentina Dragos, Marie-Christine Jaulent	2010	@upmc.fr, @upmc.fr	1001371
301	Approche biomimétique coopérative pour la visualisation de grands graphes multidimensionels	approche biomimétique coopérative pour le visualisation de grand graphe multidimensionel  face à le quantité sans cesse grandissant de donnée stocker , le algorithme de fouille etde visualisation de donnée devoir pouvoir être capable de traiter un grand quantité de donnée . un des solution être de effectuer un prétraitement des donnée permettre le réductiond le dimension des donnée sans perte significatif de information . le idée être donc de réduirel'ensemble de descripteur avant de faire appel à le méthode de visualisation sous forme de ungraphe . 	Lydia Boudjeloud, Hanane Azzag	2010	@univ-metz.fr, @univ-paris13.fr	1001412
302	Approche complexe de l'analyse de documents anciens	approche complexe de le analyse de document ancien  ce article présenter un méthode complexe pour le caractérisation etl'indexation de image graphique de document ancien . A partir de un bref étatd le art , un méthode pour décrire ce image en tenir compte de son complexitéest proposer . Trois étape principal de ce traitement être détailléesdont un méthode novateur de analyse , de segmentation et de description destrait . le résultat être issir de travaux en cours et être encourageant 	Mickaël Coustaty, Giap NGuyen, Vincent Courboulay, Jean-Marc Ogier	2010	@univ-lr.fr	1001368
303	Bien cube, les données textuelles peuvent s'agréger !	bien cube , le donnée textuel pouvoir clr agréger !  le masse des donnée aujourde hui disponible engendrer un besoinscroissant de méthode décisionnel adapté aux donnée traiter . ainsi , récemmentun nouveau approche fonder sur un cube de texte être apparuespour pouvoir analyser et extraire de le connaissance à partir de document . le originalitéd ce cube être de étendre le approche traditionnel des entrepôt etdes technologie OLAP à un contenu textuel . dans ce article , cln clr intéressonsà deux nouveau fonction de agrégation . le premier proposer un nouvellemesure de TF-IDF adaptatif permettre de tenir compte des hiérarchiesassocié aux dimension . le seconde être un agrégation dynamique permettantde faire émerger un groupement correspondre à un situation réel . Lesexpériences mener sur un donnée issu du serveur HAL de un universitéconfirment le intérêt de son proposition . 	Sandra Bringay, Anne Laurent, Pascal Poncelet, Mathieu Roche, Maguelonne Teisseire	2010	@lirmm.fr, @cemagref.fr	1001367
304	Caractériser la terminologie des usagers de santé dans le domaine du cancer du sein	caractériser le terminologie des usager de santé dans le domaine du cancer du sein  " Internet être devenir un source important de information médicalespour le patient et son proche : recherche de information sur son maladieset le dernier recherche clinique , ainsi que pour cll constituer un communauté " " numérique " " de dialogue et de partage . . cependant , accès à Internet nesignifie pas nécessairement accès à le information . . le manque de familiarité avecle langage médical constituer un problème majeur pour le usager de santé dansl'accès à le information et son interprétation . . ce papier clr inscrire dans le problématiqued'étude et de caractérisation de le terminologie des usager de santépour pouvoir proposer un service adapter à son langage et à son niveau deconnaissance . . le travail réaliser être un ontologie dans le domaine du cancerdu sein orienter vers le usager de santé . . ce ontologie être construire à partird'un ensemble de corpus de texte représenter deux catégorie : le médiateurset le usager de santé . . le élément de ce ontologie avoir être analyser en utilisantun méthode quantitatif et qualitatif sur plusieurs niveau : terme , concept et relation . " 	Radja Messai, Michel Simonet, Nathalie Bricon-Souf, Mireille Mousseau	2010	@imag.fr, @univ-lille2.fr, @univ-lille2.fr, @chu-grenoble.fr	1001326
305	CARTOCEL : Un outil de cartographie des connaissances guidée par la machine cellulaire CASI	CARTOCEL : un outil de cartographie des connaissance guider par le machine cellulaire CASI  cln présenter , dans ce papier , le outil CARTOCEL ( CARTOgraphiesCELlulaires ) permettre un visualisation automatique et dynamique desdomaine de connaissance . le fonctionnement de CARTOCEL être baser surune approche original de modélisation booléen de le cartographie des domainesde connaissance métier  stratégique inspirer du principe de le machinecellulaire CASI ( Cellular Automata for Symbolic induction ) . le but , après un modélisation booléen de le cartographie des domaine de connaissance , être double : de un part affiner le cartographie par un fouille de donnéeorchestré par CASI , et de autre part réduire le complexité de stockage , ainsique le temps de calcul 	Menaouer Brahami, Baghdad Atmani, Mostéfa Mokaddem	2010	@gmail.com, @gmail.com, @gmail.com, @univ-oran.dz	1001375
306	Classer, discriminer et visualiser des séquences d'événements	classer , discriminer et visualiser un séquence de événement  ce article 1 présenter un ensemble de outil destiner à analyser un séquencesd'événement en science social et à visualiser le résultat obtenir . cln commencer par formaliser le notion de séquence de événement avant dedéfinir un mesure de dissimilarité entre ce séquence afin de construire destypologion et de tester le lien entre ce séquence et de autre variable de intérêt . initialement définir par Moen ( 2000 ) , ce mesure clr baser sur le notion dedistance de édition entre séquence et permettre de identifier le différence de ordonnancementet de temporalité des événement . cln proposer un extension decelle -cus afin de pouvoir prendre en compte le simultanéité des événement decelle méthode de normalisation qui garantir le respect de le inégalité triangulaire . dans un deuxième temps , cln présenter un ensemble de outil destinésà interpréter le résultat . cln proposer ainsi deux méthode de visualisationd'un ensemble de séquence et cln introduire le notion de sous-séquencediscriminante qui permettre de identifier le différence de ordonnancement des événementsle plus significatif entre groupe . le ensemble des outil présenter estdisponible au sein de le librairie R TraMineR . 	Matthias Studer, Nicolas S. Müller, Gilbert Ritschard, Alexis Gabadinho	2010	@unige.ch	1001264
307	Classification de documents : calcul d'une distance structurelle	classification de document : calcul de un distance structurel  le classification des document numérique garantir un accès rapideet ciblé à le information . si cln considérer que un document être représenter parsa ou son structure , définir un classe de document revenir à définir desclasse de structure . un classe structurel représenter donc un structure « proche » . ainsi , associer le structure de un document à son classe structurellerevenir à calculer un distance dire « structurel » . cln tenir compter à lafois de le organisation des élément ( position des noeud , chemin ) , du coûtd'adaptation des représentant des classe ainsi que de le représentativité dessous-graphe . sur un corpus de document représenter un notice de livresissus de le bibliothèque de le université , cln discuter de le construction decet distance , de le intérêt de chacun des trois paramètre utiliser 	Karim Djemal, Chantal Soulé-Dupuy, Nathalie Vallès-Parlangeau	2010	@irit.fr, @univ-tlse1.fr	1001369
308	Classification et Selection de caracteristique basees sur les concepts semantiques pour la recherche d'information multimedia	classification et Selection de caracteristique basee sur le concept semantique pour le recherche de information multimedia  le besoin récent de nombreux application multimédia baser sur le contenu avoir engendrer un demande croissant de technologie dans le domaine de le recherche de information multimédia . baser sur le état de le art des technique existant , cln proposer dans ce article un approche de recherche de information multimédia qui prendre en compte le information de scène et exploiter un modèle de sélection de caractéristique . le principal avantage de son modèle de recherche par rapport aux modèle existant être : ( i ) un méthode de classification baser sur un catégorie de concept sémantique ; ( ii ) un modèle de recherche par rapport aux modèle existant être : ( i ) un méthode de classification baser sur un catégorie de concept sémantique ; ( ii ) un modèle de sélection de caractéristique ; ( ii ) un index multidimensionnel . son framework proposer un bon compromis entre précision et rapidité de le recherche 	Thierry Urruty, Ismail Elsayad, Adel Lablack, Yue Feng, Jose M. Joemon	2010	@lill.lr	1001271
309	Classification supervisée pour de grands nombres de classes à prédire : une approche par co-partitionnement des variables explicatives et à expliquer	classification superviser pour un grand nombre de classe à prédire : un approche par co- partitionnement des variable explicatif et à expliquer  dans le phase de préparation des donnée du data mining , le méthodesd discrétisation et de groupement de valeur superviser posséder denombreuson application : interprétation , estimation de densité conditionnel , sélection de type filtre des variable , recodage des variable en amont des classifieur . ce méthode supposer habituellement un faible nombre de valeur àexpliquer ( classe ) , typiquement moins de un dizaine , et trouver son limitequand son nombre augmenter . dans ce article , cln introduire un extensiondes méthode de discrétisation et groupement de valeur , consister à partitionnerd'une part le variable explicatif , de autre part le variable à expliquer . le meilleur co- partitionnement être rechercher au moyen de un approche Bayesiennede le sélection de modèle . cln présenter ensuite comment utiliser cetteméthode de prétraitement en préparation pour le classifieur Bayesien naïf . Desexpérimentations intensif démontrer le apport de le méthode dans le cas decentain de classe . 	Marc Boullé	2010	@orange-ftgroup.com	1001352
310	CND-Cube : Nouvelle représentation concise sans perte d'information d'un cube de données	CND-Cube : nouveau représentation concis sans perte de information de un cube de donnée  " le calcul des cube de donnée être excessivement coûteux aussi bienen temps de exécution que en mémoire et son stockage sur disque pouvoir clr avérerprohibitif . . plusieurs effort avoir être consacrer à ce problème à travers le cubesfermé , où le cellule préserver le sémantique de agrégation être réduire à unecellule , sans perte de information . . dans ce article , cln introduire le conceptdu cube de donnée non- dérivable fermé , nommer CND-Cube , qui généraliseler notion des modèle non- dérivable fermer fréquent bidimensionnel à uncontexte multidimensionnel . . cln proposer un nouveau algorithme pour extrairele CND-Cube à partir un base de donnée multidimensionnel en clr basantsur trois contrainte anti- monotone , à savoir " " être fréquent " " , " " être non dérivable " " et " " être un générateur minimal " " . . le expérience montrer que notreproposition fournir le représentation le plus concis de un cube de donnée et elleêtre ainsi le plus efficace pour réduire le espace de stockage " 	Hanen Brahmi, Tarek Hamrouni, Riadh Ben Messaoud, Sadok Ben Yahia	2010	@fst.rnu.tn, @fsegn.rnu.tn	1001303
311	Codage et classification non supervisée d'un corpus maya : extraire des contextes pour situer l'inconnu par rapport au connu	codage et classification non superviser de un corpus maya : extraire un contexte pour situer le inconnu par rapport au connaître  le écriture logosyllabique des ancien Mayas comprendre plus de 500sign et être en bon partie déchiffrer , avec un degré de certitude divers . cln avoir appliquer au codex de Dresde , le un des trois seul manuscrit quinout être parvenir , coder sous LATEXavec le systèmemayaTEX , son méthodede représentation graduer , par apprentissage non superviser hybride entre clusteringe analyse factoriel oblique , sous le métrique de Hellinger , afin de obtenirun image nuancer des thème traiter : le individu statistique être le 212segment de folio du codex , et son attribut être le 1687 bigramme de signesextrait . pour comparaison , cln avoir introduire dans ce approche endogèneun élément exogène , le décomposition en élément des signe composite , pourpréciser plus finement le contenu . le rétro- visualisation dans le texte originaldes résultat et expression dégagé éclaire le signification de certain glyphespeu comprendre , en cla situer dans un contexte clairement interprétable . 	Mohamed Hallab, Bruno Delprat, Alain Lelu	2010	@yahoo.fr, @club-internet.fr, @univ-fcomte.fr	1001366
312	CombinerWeb 2.0 et Web Sémantique pour réduire les disparités d'expertise au sein de blogs d'entreprise	CombinerWeb 2.0 et Web Sémantique pour réduire le disparité de expertise au sein de blog de entreprise  avec le avènement de application social en entreprise ( blog , wiki , etc. ) , ilimp être fréquent que un individu aux niveau de expertise relativement distantsse réunir au sein de communauté en ligne . ce disparité de expertisesion traduire entre autre par un comportement différent dans le manière detagguer le contenu créer , notamment en ce qui concerner le terme utiliser , rendre ainsi complexe le découverte de information pourtant publier . dans cetarticle , cln mettre en avant le possibilité offrir par le technologie du WebSémantique , combiner avec le paradigme du Web Social , de résoudre cetteproblématique . cln proposer ainsi un chaine de traitement combiner ontologie , wiki sémantique et indexation de contenu permettre le production degraphes sémantique interconnecter et faciliter de ce manière le découverted contenir créer au sein de tel système 	Alexandre Passant, Philippe Laublet	2010	@deri.org, @paris-sorbonne.fr	1001270
313	Comparaison de critères de pureté pour l'intégration de connaissances en clustering semi-supervisé	comparaison de critère de pureté pour le intégration de connaissance en clustering semi-supervisé  le utilisation de connaissance pour améliorer le processus de fouilled donner avoir mobiliser un important effort de recherche ce dernier année . Ilest cependant souvent difficile de formaliser ce type de connaissance , commecelles -ci être souvent dépendant du domaine . dans ce article , cln clr intéressonsà le intégration de connaissance sous le forme de objet étiqueter dansles algorithme de clustering . plusieurs critère permettre de évaluer le puretédes clusters être présenter et son comportement être comparer sur un jeu dedonnées artificiel . le avantage et le inconvénient de chaque critère sontanalysé pour aider le utilisateur à faire un choix . 	Germain Forestier, Cédric Wemmert, Pierre Gançarski	2010	@unistra.fr	1001278
314	Comparaisons structurelles de grandes bases de données par apprentissage non-supervisé	comparaison structurel de grand base de donnée par apprentissage non- superviser  dans le domaine de le fouille de donnée , mesurer le similitudesentre différent sous-ensemble être un question important qui avoir être peu étudiéejusqu'à présent . dans ce article , cln proposer un nouveau méthodebasée sur le apprentissage non- superviser . le différent sous-ensemble à comparersont caractériser au moyen de un modèle à base de prototype . ensuite , lesdifférence entre le modèle être détecter en utiliser un mesure de similarité 	Guénaël Cabanes, Younès Bennani	2010		1001276
315	Composition de ServicesWeb Basée sur les Réseau Sociaux	composition de ServicesWeb baser sur le réseau Sociaux  cln proposer dans ce article un premier approche qui consisteà exploiter le réseau social afin de faciliter le composition de service parler utilisateur final . cln introduire un Framework , nommer Social Composer ( SoCo ) , qui implémenter ce approche . SoCo fournir à le utilisateur desrecommandations dynamique de service baser entre autre sur le réseau socialde le utilisateur qui être construire implicitement à partir un interaction entre lesutilisateurs , le service , le différent composition opérer par le membresdu réseau social , ainsi que le réseau social global . 	Abderrahmane Maaradji, Hakim Hacid, Johann Daigremont, Noël Crespi	2010	@alcatel-lucent.com, @it-sudparis.eu	1001290
316	Construction de noyaux pour l'apprentissage supervisé à partir d'arbres aléatoires	construction de noyau pour le apprentissage superviser à partir de arbre aléatoire  cln montrer que un ensemble de arbre de décision avec un composantealéatoire permettre de construire un noyau efficace destiner à le apprentissagesupervisé . cln étudier théoriquement le propriété de un tel noyau et montronsque sous un condition très souvent rencontrer en pratique , ilimp exister uneséparabilité linéaire entre exemple de classe distinct dans le espace induire parcelui -ci . parallèlement , cln observer également que le classique vote à le majoritéd'un ensemble de arbre être un hyperplan ( sans garantie de optimalité ) dansl'espace induire par le noyau . enfin , comme cla montrer son expérimentation , le utilisation conjoint de un ensemble de arbre et de un séparateur à vaste marge ( SVM ) aboutir à un résultat extrêmement encourageant . 	Vincent Pisetta, Pierre-Emmanuel Jouve, Djamel Abdelkader Zighed	2010	@rithme.eu, @fenics.com, @univ-lyon2.fr	1001351
317	Cubes Fermés / Quotients Émergents	cube Fermés  quotient Émergents  " le concept de Cube Émergent avoir être introduire afin de comparer deuxdason cube . . dans ce article , cln introduire deux nouveau représentationsréduite du Cube émerger sans perte des mesure : le Cube Fermé Émergent etle Cube Quotient Émergent . . le premier représentation être baser sur le conceptde fermeture cubique . . ce être le plus petit représentation possible du cube dedonné émerger . . à partir du cube Fermé émerger et donc en stocker le minimumd'information , ilimp être possible de répondre efficacement aux requête quipeuvent être exécuter sur le Cube émerger lui-même . . le seconde représentations'appui sur le structure du Cube Quotient qui avoir être proposer pour résumer uncube de donnée . . le Cube Quotient être revisiter afin de cla doter de un sémantiquebasée sur le fermeture cubique et donc adapter au contexte du cube émergent . . LeCube Quotient Émergent résulter être moins réduire que le Cube Fermé Émergentmais ilimp préserver le propriété de " " spécialisation  généralisation " " du dater cube quipermeant le navigation au sein du cube émergent . . cln établir également lelien entre le deu représentation introduit et celui baser sur le bordure classiquesen fouiller de donnée . . un expérimentation effectuer sur divers jeu dedonné viser à comparer le taille des différent représentation . " 	Sébastien Nedjar, Alain Casali, Rosine Cicchetti, Lotfi Lakhal	2010	@lif.univ-mrs.fr	1001306
318	Découverte des dépendances fonctionnelles conditionnelles fréquentes	découverte des dépendance fonctionnel conditionnel fréquent  le dépendance Fonctionnelles Conditionnelles ( DFC ) avoir être introduitesen 2007 pour le nettoyage des donnée . cln pouvoir être considéréescommer un unification de dépendance Fonctionnelles ( DF ) classique et deRègles de association ( ra ) puisque cln permettre de spécifier un dépendancesmixant des attribut et des couple de le forme attribut  valeur . dans ce article , cln traiter le problème de le découverte des DFC , i.eès déterminerun couverture de le ensemble des DFC satisfaire par un relation r . Nousmontrons comment un technique connaître pour le découverte des DF ( exacteset approximatif ) pouvoir être étendre aux DFC . ce technique avoir être implémentéeedre des expérience avoir être mener pour montrer le faisabilité et le passage àl'échel de son proposition . 	Thierno Diallo, Noel Novelli	2010	@insa-lyon.fr, @lif.univ-mrs.fr	1001311
319	Découverte d'itemsets fréquents fermés sur architectures multicoeurs	découverte de itemsets fréquent fermer sur architecture multicoeurs  dans ce papier cln proposer PLCM , un algorithme parallèle dedécouvert de itemsets fréquent fermer baser sur le algorithme LCM , reconnucomme le algorithme séquentiel le plus efficace pour ce tâche . cln présentonsaussvoir un interface de parallélisme à le fois simple et puissant baser sur lanotion de Tuple Space , qui permettre de avoir un bon répartition dynamique dutravail . grâce à un étude expérimental détaillé , cln montrer que PLCM être le seulalgorithme qui être suffisamment générique pour calculer efficacement un itemsetsfréquent fermé à le fois sur un base creux et sur un base dense , améliorer ainsi le état de le art . 	Benjamin Négrevergne, Alexandre Termier, Jean-François Méhaut, Takeaki Uno	2010	@imag.fr, @nii.jp	1001339
320	Differentes variantes GMM-SMOs pour l'identification du locuteur	Differentes variante GMM-SMOs pour le identification du locuteur  dans ce article , cln présenter différent variante GMM-SMOs pour le identification du locuteur en mode indépendant du texte . pour mettre en oeuvre le différent système , cln avoir opter un représentation multi-gaussien de le espace des caractéristique baser sur le algorithme Expectation Maximisation ( EM ) . ce nouveau représentation constituer le vecteur de entrer pour entraîner le support vecteur machine ( SVMs ) par le algorithme de type optimisation par minimisation Séquentielle ( SMO ) . 	Siwar Zribi Boujelbene, Dorra Ben Ayed Mezghanni, Noureddine Ellouze	2010	@yahoo.fr, @isi.rnu.tn, @enit.rnu.tn	1001421
321	Expansion de requêtes SQL par une ontologie de domaine	Expansion de requête SQL par un ontologie de domaine  ce article traiter un problème dans le domaine de le gestion des basesd donner classique . ilimp clr agir de exploiter un ontologie de domaine pour aiderl'utilisateur de un base de donnée relationnel dans son recherche et de luipermettre un interrogation transparent de le base de donnée . pour cela , nousproposons un approche de expansion automatique de requête SQL lorsquecelles -cus ne avoir pas un réponse . son approche être décrire par un algorithmedéfini de manière générique afin de être utiliser pour un base de donnée quelconque . 	Ines Fayech, Habib Ounalli	2010	@yahoo.fr, @fst.rnu.tn	1001345
322	Explication de décisions de réconciliation : approche fondée sur les réseaux de Petri colorés	explication de décision de réconciliation : approcher fonder sur le réseau de Petri coloré  le objectif des système de intégration de donnée être de faciliter le exploitationet le interprétation de information hétérogène provenir de différentessource . lorsque le cln devoir intégrer un grand volume de donnée , le recours àun expert ne être pas envisageable mais le exploitation de processus de intégrationautomatique pouvoir introduire un approximation ou des erreur . cln cln focalisonssur le résultat fournir par le méthode de réconciliation de donnée . ce dernier comparer le donnée entre lui et détecter celui qui référer àla même entité du monde réel . pour renforcer le confiance des utilisateur dansles résultat retourner par ce méthode , cln proposer dans ce article un approched'explication graphique fonder sur le réseau de Petri coloré qui estparticulièrement adapter aux approche de réconciliation global , numériqueset guider par un ontologie . 	Souhir Gahbiche, Nathalie Pernelle, Fatiha Saïs	2010	@limsi.fr, @lri.fr, @lri.fr	1001313
323	Extraction de motifs graduels clos	extraction de motif graduel clore  " le découverte automatique de règle et motif graduel ( " " plus le âged'une personne être élevé , plus son salaire être élever " " ) trouver de très nombreusesapplications sur un base de donnée réel ( e.gès biologie , flot de donnée decapteurs ) . . si un algorithme de plus en plus efficace être proposer dans desarticle récent , ilimp ne cll rester pas moins que ce méthode générer un nombrede motif tellement important que le expert peiner à cla exploiter . . dans cetarticle , cln proposer donc un représentation condensé des motif graduelsen introduire le concept théorique associer aux opérateur de fermeture surde tel motif . " 	Sarra Ayouni, Sadok Ben Yahia, Anne Laurent, Pascal Poncelet	2010	@fst.rnu.tn, @lirmm.fr	1001293
324	Extraction de règles d'association séquentielle à l'aide de modèles semi-paramétriques à risques proportionnels	extraction de règle de association séquentiel à le aide de modèle semi-paramétrique à risque proportionnel  le recherche de lien entre objet fréquent avoir être populariser par lesméthode de extraction de règle de association . dans le cas de séquence de événement , le méthode de fouille permettre de extraire un sous-séquence quipeuvent ensuite être exprimer sous le forme de règle de association séquentielleentre événement . ce utilisation de le fouille de séquence pour le recherchede lien entre un événement poser deux problème . premièrement , lecritère principal utiliser pour sélectionner le sous-séquence de événement estler fréquence , or le occurrence de certain événement pouvoir être fortementlier entre lui même lorsque cln être peu fréquent . deuxièmement , le mesuresactuelle utiliser pour caractériser le règle de association ne tenir pascompte du caractère temporel des donnée , comme le importance du timing desévénement ou le problème des donnée censurer . dans ce article , cln proposonsuner méthode pour rechercher un lien significatif entre un événementsà le aide de modèle de durée . le règle de association être construire à partirun motif séquentiel observer dans un ensemble de séquence . le influence surle risquer que le événement « conclusion » clr produire après le ou le événement « prémisse » être estimer à le aide de un modèle semi-paramétrique à risque proportionnel . outre le présentation de le méthode , le article proposer un comparaisonavec de autre mesure de association 	Nicolas S. Müller, Matthias Studer, Gilbert Ritschard, Alexis Gabadinho	2010	@unige.ch	1001263
325	Extraction des séquences fermées fréquentes à partir de corpus parallèles : Application à la traduction automatique	extraction des séquence fermé fréquent à partir de corpus parallèle : application à le traduction automatique  dans ce article , cln aborder le problématique de extraction de séquencesfréquente à partir de corpus de texte parallèle en prendre en comptel'ordre de apparition des mots dans un phrase . son finalité être de exploiter cesséquence dans le traduction automatique ( TA ) . cln introduire ainsi le notiond règle associatif inter-langue ( rail ) et cln définir son modèlede traduction à base de ce association . cln décrire également le différentesexpérimentation conduite sur le corpus EUROPARL afin de construire àpartir des rail un table de traduction bilingue qui être intégrer par le suite dansun processus complet de TA . 	Cherif Chiraz Latiri, Cyrine Nasri, Kamel Smaïli, Yahya Slimani	2010	@gnet.tn, @gmail.com, @fst.rnu.tn, @loria.fr	1001266
326	Extraction d'itemsets distinctifs dans les flux de données	extraction de itemsets distinctif dans le flux de donnée  le extraction de itemsets distinctif être un sujet de recherche récent quiconner plusieurs algorithme pour le donnée statique ( Knobbe et Ho , 2006 ; Heikinheimo et alection , 2007 ) . ce solution ne être toutefois pas concevoir pour lecas un flux de donnée , pour lequel le temps de réponse devoir être aussifaibles que possible . cln considérer le problème de le extraction de itemsetsdistinctif dans le flux , qui pouvoir avoir un nombreux application dans le sélectiond variable , le classification ou encore le recherche de information . Nousproposons le heuristique IDkF ( Itemsets Distinctifs dans le flux ) et des résultatsd'expérimentation en comparaison de un technique de le littérature . 	Chongsheng Zhang, Florent Masseglia	2010	@inria.fr	1001291
327	Fouille visuelle de données en 3D et réalité virtuelle : état de l'art	fouille visuel de donnée en 3.D. et réalité virtuel : état de le art  le fouille visuel de donnée ( ou Visual Data Mining , VDM ) avoir pourobjectif de faciliter le interprétation des résultat issir de un fouille de donnée , grâce à le usage de représentation graphique . Au cours de le dernier décennie , un grand nombre de technique de visualisation de information avoir être mettre aupoint , permettre le visualisation de donnée multidimensionnel dans un environnementsvirtuel . lors un travaux antérieur , le chercheur avoir proposédes taxonomie pour classer le technique de VDM ( Chi ( 2000 ) , Herman et alection ( 2000 ) ) . toutefois , ce taxonomie ne prendre en compte que partiellement lestechnique récent relative à le utilisation de le 3D et de le réalité virtuel . Lebut de ce article être de faire un état de le art récent et spécifique à ce technique . Celles -cus être détailler , classer et comparer selon différent critère : le application , le encodage graphique , le technique de interaction , le avantage etles inconvénient de chaque approche . ce technique être présenter dans destableaux accompagner de illustration graphique 	Zohra Ben Said, Fabrice Guillet, Paul Richard	2010	@univ-nantes.fr, @univ-angers.fr	1001282
328	Gestion sémantique des droits d'accès au contenu: l'ontologie AMO	gestion sémantique des droits de accès au contenu : le ontologie AMO  dans ce article cln proposer un approche de le gestion des droitsd'accès pour le système de gestion de contenu qui reposer sur le modèle ettechnique du web sémantique . cln présenter le ontologie AMO qui consister ( 1 ) en un ensemble de classe et propriété permettre de annoter le ressourcesdont ilimp clr agir de contrôler le accès et ( 2 ) en un base de règle de inférence modélisantla stratégie de gestion des droits à mettre en oeuvre . appliquer sur le based'annotation des ressource , ce règle permettre de gérer le ressource selonune stratégie donner . ce modélisation garantir ainsi le adaptabilité de le ontologieà différent stratégie de gestion des droits de accès . cln illustrer le utilisationd le ontologie AMO sur le document du projet ANR ISICIL produitspar le wiki sémantique SweetWiki . cln montrer comment le document sontannoté avec AMO , quel règle être mettre en oeuvre et quel requête permettentle contrôle de le accès aux document . 	Michel Buffa, Catherine Faron-Zucker, Anna Kolomoyskaya	2010	@unice.fr	1001340
329	IncFDs: un nouvel algorithme d'inférence incrémentale des dépendances fonctionnelles	IncFDs : un nouveau algorithme de inférence incrémental des dépendance fonctionnel  le inférence des dépendance fonctionnel être le un des problématiquesle plus étudier en base de donnée . cln avoir faire le objet de plusieurstravail qui avoir proposer un algorithme afin de inférer , efficacement , le dépendancesfonctionnel pour cla utiliser dans différent domaine : administrationde base de donnée , ré-ingénierie , optimisation des requête , etc. toutefois , pour le application réel , le base de donnée être évolutif et le relationssont fréquemment augmenter ou diminuer de tuple . par conséquent , afin des'adapter à ce cadre dynamique , un solution consister à appliquer le un des algorithme , disponible dans le littérature , pour inférer le dépendance fonctionnel , après chaque mise à jour . ce solution être coûteux , cln proposer , dans ce article , de inférer le dépendance fonctionnel de un manière incrémental . à ce effet , cln introduire un nouveau algorithme , appeler INCFDS , etnous évaluer son performance par rapport à le approche classique de inférencedes dépendance fonctionnel à partir de un relation dynamique . 	Ghada Gasmi	2010	@gmail.com	1001310
330	Indexation et recherche d'images à très grande échelle avec une AFC incrémentale et parallèle sur GPU	indexation et recherche de image à très grand échelle avec un AFC incrémental et parallèle sur GPU  cln présenter un nouveau algorithme incrémental et parallèled'analyse factoriel des correspondance ( AFC ) pour le recherche de image àgrande échelle en utiliser le processeur de le carte graphique ( GPU ) . le AFCest adapter à le recherche de image par le contenu en utiliser un descripteurslocaux des image ( SIFT ) . le AFC permettre de réduire le nombre de dimensionset de découvrir un thème qui permettre de diminuer le nombre de image àparcourir et donc le temps de réponse de un requête . pour traiter de trèsgranun base de image , cln présenter un version incrémental et parallèled'AFC , puis cln utiliser son indicateur pour construire un fichier inverséspour retrouver le image contenir le même thème que le image requêter . ce étape être cln aussi parallélisée sur GPU pour obtenir un réponsesrapide . le résultat numérique sur le base de donnée de image Nistér-Stewénius plongée dans 1 million de image de FlickR montrer que notrealgorithme incrémental et parallèle être très significativement plus rapide que saversion standard 	Nguyen-Khang Pham, François Poulet, Annie Morin, Patrick Gros	2010	@irisa.fr	1001281
331	Indice de complexité pour le tri et la comparaison de séquences catégorielles	indice de complexité pour le tri et le comparaison de séquence catégoriel  ce article1 proposer un nouveau indice de le complexité de séquencescatégorielle . bien que concevoir pour un séquence représenter un trajectoiresbiographique tel que celui rencontrer dans le science social , ilimp clr appliqueà tout type de liste ordonner de états . le indice prendre en compte deuxaspects distinct , soit le complexité induire par le ordonnancement des états successifsqui être mesurer par le nombre de transition ( changement de état ) et lacomplexité lier à le distribution des états dont rendre compter le entropie 	Alexis Gabadinho, Gilbert Ritschard, Matthias Studer, Nicolas S. Müller	2010	@unige.ch	1001267
332	Intégration de Connaissances a Priori dans le Principe du Maximum d'Entropie	intégration de Connaissances avoir Priori dans le Principe du Maximum de Entropie  ce article montrer que si le cln disposer de un connaissance avoir priori surle problème en main , le intégration de ce dernier dans le processus de apprentissaged'une machine intelligent pour un tâche de classification pouvoir améliorerle performance de ce machine . cln étudier le effet de le intégration de laconnaissance avoir priori de convexité sur le processus de apprentissage du principedu Maximum de Entropie ( MaxEnt ) en utiliser un exemple virtuel . cln testonsles idée proposer sur un problème benchmark bien connaître dans le littératuredes machine de apprentissage , le problème de forme de onde de Breiman . cln avoir aboutir à un taux de erreur de généralisation de 15 .57 \% qui être trèsproche du taux de erreur théorique estimer par Breiman ( 14 \pourcent ) . 	Fadi Chakik, Fadi Dornaika	2010	@ehu.es, @ul.edu.lb	1001356
333	Intégration interactive de contraintes pour la réduction de dimensions et la visualisation	intégration interactif de contrainte pour le réduction de dimension et le visualisation  " ilimp exister aujourde hui de nombreux méthode de réduction de dimension , que ce être dans un cadre superviser ou non superviser . . le un des intérêt deces méthode être de pouvoir visualiser le donnée , avec pour objectif que lesobjett qui apparaître " " visuellement " " proche être similaire , dans un sensqui correspondre aux connaissance de un expert du domaine ou qui être conformeaux information de supervision . . cln cld placer ici dans un contexte semisuperviséoù des connaissance être ajouter de façon interactif : ce informationsseront apporter sous forme de contrainte exprimer le écart entrela représentation observer et le connaissance de un expert . . cln pouvoir parexemple spécifier que deux objet proche dans le espace de observation être enfait peu similaire , ou inversement . . le méthode utiliser ici dérive de le analyseen composante principal ( ACP ) , à lequel cln proposer de intégrer deuxtyp de contrainte . . cln présenter un méthode de résolution qui avoir être implémentéedanrer un logiciel offrir un représentation 3D des donnée et grâceauquel le utilisateur pouvoir ajouter un contrainte de manière interactif , puis visualiserle modification induire par ce contrainte . . Deux type de expérimentationsont présenter , reposer respectivement sur un jeu de donnée synthétiqueet sur un jeu standard : ce test montrer que un représentation de bonnequalité pouvoir être obtenir avec un nombre limité de contrainte ajouter . " 	Guillaume Cleuziou, Frédéric Moal, Lionel Martin, Matthieu Exbrayat	2010	@univ-orleans.fr	1001320
334	Interrogation des résumés de flux de données	interrogation des résumé de flux de donnée  le système de gestion de flux de donnée ( SGFD ) avoir être conçusafin de traiter un masse important de donnée produire en ligne de façoncontinue . Etant donner que le ressource matériel ne permettre pas de conservertout ce volumétrie , seul le partie récent du flux être mémoriser dans lamémoire du SGFD . ainsi , le requête évaluer par ce système ne pouvoir porterque sur le donnée le plus récent du flux . par conséquent , le SGFD actuelsne pouvoir pas traiter un requête qui porter sur un période très long . cln proposer dans ce article , un approche permettre de évaluer un requêtesqui porter sur un période plus long que le mémoire du SGFD . ce fenêtresfont appel à un donnée récent et des donnée historisé . cln présentonsle niveau logique de ce approche ainsi que son implantation sous le SGFD Esper . un technique de échantillonnage associer à un technique de fenêtre pointde repère être appliquer pour conserver un représentation compact des donnéesdu flux . 	Nesrine Gabsi, Fabrice Clérot, Georges Hébrail	2010	@telecom-paristech.fr, @orange-ftgroup.com	1001300
335	KGRAM: une machine abstraite de graphes de connaissance	KGRAM : un machine abstrait de graphe de connaissance  ce article présenter le machine abstrait de graphe de connaissanceKGRAM qui unifier le notion de homomorphisme de graphe et de calcul de requêtestelle que celui du langage SPARQL sur un donnée RDF . KGRAMimplémente un ensemble extensible de expression qui définir un famille delangage abstrait de interrogation de graphe , GRAAL . cln décrire le sémantiquedynamique de GRAAL en Sémantique Naturelle et cln présenter lamachine abstraire KGRAM concevoir comme le interprète de GRAAL , qui implémenteer règle de sémantique naturel du langage . 	Olivier Corby, Catherine Faron-Zucker	2010	@inria.fr, @unice.fr	1001328
336	Le conflit dans la théorie des fonctions de croyance	le conflit dans le théorie des fonction de croyance  le conflit apparaître naturellement lorsque plusieurs source de informationsimparfaite être en jeu . le théorie des fonction de croyance offrir unformalisme adapter à le fusion de information dans lequel le considération duconflit être central . ce travail proposer de revenir sur le différent définitionsdu conflit dans ce théorie , tenter de cla synthétiser et de montrer commentsupprimer ce conflit , ou bien comment en tenir compte lors de le combinaisonde information . 	Arnaud Martin	2010	@ensieta.fr	1001411
337	Modèle de Langue à base de Concepts pour la Recherche d'Information	modèle de Langue à base de concept pour le recherche de information  le majorité des modèle de langue appliquer à le recherched'information reposer sur le hypothèse de indépendance des mots . plus précisément , ce modèle être estimer à partir un mots simplesapparaissant dans le document sans considérer le éventuel relationssémantique et conceptuel . pour pallier ce problème , deux grandesapproche avoir être explorer : le premier intégrer un dépendance de ordresurfacique entre le mots , et le seconde reposer sur le utilisation des relationssémantique pour capturer le dépendance entre le mots . le modèle delangue que cln présenter dans ce article clr inscrire dans le seconde approche . cln proposer de intégrer le dépendance entre le mots en représenter lesdocuments et le requête par le concept . 	Lynda Said L'Hadj, Mohand Boughanem	2010	@esi.dz, @irit.fr	1001501
338	Modélisation et interrogation de données XML multidimensionnelles	modélisation et interrogation de donnée XML multidimensionnel  xml être devenir omniprésent et son technique de stockage et de interrogationd plus en plus efficace , le nombre de cas de utilisation de ce technologiesaugment tout le jours . un sujet prometteur être le intégration de XML etdes entrepôt de donnée , dans lequel un base de donnée XML natif stockeles donnée multidimensionnel et exécuter un requête OLAP écrire à le aidedu langage de interrogation XML XQuery . ce papier explorer le question quipeuvent survenir lors de le implémentation de un tel entrepôt de donnée XML . 	Boris Verhaegen, Esteban Zimányi, Serge Boucher	2010	@ulb.ac.be	1001327
339	Objective Novelty of Association Rules: Measuring the Confidence Boost1	" cln savoir bien que le confiance des régle de association ne être pas vraimentsatisfaisant comme mésure de interêt . . cln proposer , au lieu de le substituerpar des autre mésure ( soit , en cla employer de façon conjoint avoir desautron mésure ) , évaluer le nouveauté de chaque régle par comparaison de saconfiance par rapport á des régle plus fort que cln trouver au même ensemblede donnée . . ce être á dire , cln considérer un seuil " " relative " " de confiance au lieu duseuil absolute habituel . . ce idée clr préciser avec le magnitude du " " confidenceboost " " , mésurandre le increment rélatif de confiance pré des régle plus fort . . cln prouver que nôtre proposte pouvoir remplacer le " " confidence width " " et leblockage de régle employé avoir un publication précedent . " 	José L Balcazar 	2010	@unican.es	1001308
340	OSOM : un algorithme de construction de cartes topologiques recouvrantes	OSOM : un algorithme de construction de carte topologique recouvrant  le modèle de classification recouvrant avoir montrer son capacité àgénérer un organisation plus fidèle aux donnée tout en conserver le simplificationattendue par un structuration en classe strict . par ailleurs le modèlesneuronaux non- supervisé être plébisciter lorsque ilimp clr agir de visualiser le structurede classe . cln proposer dans ce étude de étendre le carte auto- organisatrice traditionnellesaux carte auto- organisatrice recouvrant . cln montrer que cettenouvel structure apporter un solution à certain problématique spécifiquesen classification recouvrant ( nombre de classe , complexité , cohérence des recouvrement ) . le algorithme OSOM clr inspirer de le version recouvrant des nuée dynamiqueset de le approche de Kohonen pour générer de tel carte recouvrant . Nousdiscutons du modèle proposer de un point de vue théorique ( fonction de énergieassocié , complexité , ... ) . enfin cln présenter un cadre de évaluation généraleque cln utiliser pour valider le résultat obtenir sur un donnée réel . 	Guillaume Cleuziou	2010	@univ-orleans.fr	1001272
341	PCAR : Nouvelle Approche de Génération de Règles d'Association Cycliques	PCAR : nouveau approche de génération de règle de association Cycliques  le règle de association cyclique viser le découverte de nouveau relationsentre des produit qui varier de un façon régulièrement cyclique dans letemps . dans ce cadre , cln introduire , un nouveau algorithme nommer PCARcaractérisé par son performance et son aspect incrémental . le étude empirique quenous avoir mener montre le robustesse et le efficacité de son algorithme proposévoque . celui de le littérature 	Mohamed Salah Gouider, Eya Ben Ahmed	2010	@gmail.com, @isg.rnu.tn	1001415
342	PGP-mc : extraction parallèle efficace de motifs graduels	PGP-mc : extraction parallèle efficace de motif graduel  " initialement utiliser pour le système de commande , le règle et motifsgraduel ( de le forme " " plus un personne être âgé , plus son salaire être élever " " ) trouver de très nombreux application , par exemple dans le domainesd le biologie , un donnée en flot ( e.gès issue de réseau de capteur ) , etc. Trèsrécemment , un algorithme avoir être proposer pour extraire automatiquementde tel motif . . cependant , même si certains de entre lui avoir permettre des gainsde performance important , le algorithme rester coûteux et ne permettentpas de traiter efficacement le base de donnée réel souvent très volumineux ( en nombre de ligne et-ou nombre de attribut ) . . cln proposer doncdans ce article un méthode original de recherche de ce motif utiliser lemulti-threading pour exploiter au mieux le multiple coeur présent dans laplupart un ordinateur et serveur actuel . . le efficacité de ce approche être validéepar un étude expérimental . " 	Anne Laurent, Benjamin Négrevergne, Nicolas Sicard, Alexandre Termier	2010	@lirmm.fr, @efrei.fr, @imag.fr, @imag.fr	1001336
343	PretopoLib: la librairie JAVA de la Prétopologie	PretopoLib : le librairie JAVA de le Prétopologie  PretopoLib être un librairie JAVA implémenter le concept de laprétopologie . son intérêt résider dans le représentation de structure de donnéespermettant le manipulation des donnée par un opération ensembliste . Celle -ci offrir un cadre de développement de algorithme efficace pour le fouilled donner , le apprentissage topologique et le modélisation des système complexe . 	Sofiane Ben Amor, Vincent Levorato	2010	@ephe.sorbonne.fr	1001405
344	Proposition d'une méthode de classification associative adaptative	proposition de un méthode de classification associatif adaptatif  le classification associatif être un méthode de prédiction à base derègles issue de le fouille de règle de association . ce méthode être particulièrementintéressante car cln rechercher de façon exhaustif le règle de associationpertinent que cln filtrer pour ne garder que le règle de association de classe ( celui admettre pour conséquent un modalité de classe ) , qui être utiliséescomme classifieur . le connaissance produire être ainsi directement interprétable . un étude antérieur montrer le inconvénient de ce approche , que ilimp clr agir de le génération massif de règle non utiliser ou de le mauvaiseprédiction de le classe minoritaire lorsque le classe être déséquilibrer . cln proposer un approche original du type boosting de règle de associationun classe qui utiliser comme classifieur faible un base de règle significativesconstruites par un algorithme de génération de itemsets fréquent qui clr limiteà le extraction des seul règle de classe significatif et qui prendre en comptele déséquilibre des donnée . un comparaison avec un autre méthode de classificationassociative montrer que son approche améliorer le précision et lerappel . 	Emna Bahri, Stéphane Lallich	2010	@univ-lyon2.fr	1001346
345	Protein Graph Repository	Protein Graph Repository ( PGR ) être i , outil bioinformatique sur le web permettre de obtenir un nouveau representation de protéine sous le forme de graphe de acide aminer , un représentation plus simple et plus facile à étudier par le moyens informatique et statistique dédier aux graphe . le génération des graphe être faire à partir de un parseur appliquer sur un fichier des protéine PDB extrait de le base Protein Data Bank et en precire le parametres et le methode avoir utiliser . le graphe gener être ensuite enregistrer dans un entrepot doter de moyens de recherche , de filtrage et de telechargement . PGR pouvoir etre provisoirement consulter à le adresse  , ilimp être spécialement dédier aux recherche intéresser à le étude de donnée protéique sous le forme de graphe et permettre donc de fournir un échantillon pour un travaux expérimental . 	Wajdi Dhifli, Rabie Saidi	2010	@gmail.com, @isima	1001403
346	Recherche sémantique sur le Web basée sur l'ontologie Modulaire et le raisonnement à base de cas	recherche sémantique sur le Web baser sur le ontologie Modulaire et le raisonnement à base de cas  dans ce papier , cln présenter un approche de recherche sémantiquebasé sur le ontologie modulaire et le raisonnement à base de cas ( RaPC ) . un cas représenter le ensemble des requête similaire associer à leursrésultat pertinent . le ontologie modulaire être utiliser pour représenteret indexer le cas qui être construire sur le base des requête antérieur et leursrésultat pertinent sélectionner par le utilisateur . le similarité à based'ontologie être utiliser pour retrouver le cas similaire à le requête utilisateuret pour fournir à celui -ci des proposition de reformulation de requête correspondantsà son besoin . le principal contribution de ce travail résider dans le utilisationd'un mécanisme de RaPC et un représentation ontologique à deuxfins : le amélioration de le recherche sémantique et le enrichissement de ontologiesà partir de cas . le expérimentation de le approche proposer montre que le précisionet le rappel des résultat clr être nettement améliorer . 	Nesrine Ben Mustapha, Hajer Baazaoui Zghal, Marie-Aude Aufaure, Henda Ben Ghézala	2010	@riadi.rnu.tn, @ecp.fr	1001457
347	Réduction bi-directionnelle d'images - Vers une méthode d'extraction de caractéristiques multi-niveaux	réduction bi-directionnelle de image - Vers un méthode de extraction de caractéristique multi-niveau  inspirer des performance du cerveau humain à identifier le élémentspar le vue , le problème de le réduction de le dimension dans le domaine de laperception visuel consister à extraire un quantité réduit des caractéristiquesd'un ensemble de image afin de cla identifier . ce papier présenter un approche innovant bi-directionnelle de extraction de caractéristiquesd'image fonder sur le utilisation partiel de un méthode spatiotemporel . le expérience numérique appliquer sur 70000 image représentantdes chiffre écrit à le main ainsi que sur 698 image illustrer un visagesous différent posture démontrer le efficacité de son approche à fortementréduire le dimension tout en conserver le relation intelligible entre le objetsdes donner , permettre même de obtenir un meilleur classification à partir desversions réduire des image que à partir un version original 	Marc Joliveau	2010	@cirrelt.ca	1001279
348	REGLO : une nouvelle stratégie pour résumer un flux de séries temporelles	REGLO : un nouveau stratégie pour résumer un flux de série temporel  le flux de série temporel être aujourde hui produire dans de nombreuxdomaine comme le finance ( Zhu et Shasha ( 2002 ) ) , le surveillance deréseaux ( borgne et alection ( 2007 ) ; Airoldi et Faloutsos ( 2004 ) ) , le gestion de le historiquedes usages fréquent ( Giannella et alection ( 2003 ) ; Teng et alection ( 2003 ) ) , etc. Résumer de tel flux être devenir un domaine important qui permettre de surveilleret de enregistrer un information fiable sur le série observer . à ce jour , lamajorité des algorithme de ce domaine clr être concentrer sur un résumé surveilleret indépendant ( Giannella et alection ( 2003 ) ; Zhu et Shasha ( 2002 ) ; Chen et alection ( 2002 ) ) , en accorder à chaque série le même espace en mémoire . toutefois , lagestion de ce espace mémoire être un sujet important pour le flux de donnéeset un stratégie accorder le même quantité de mémoire à chaque série ne être pasforcément approprié . dans ce article , cln considérer que le série doiventêtre en compétition vis à vis de le espace mémoire , selon son besoin de précision . ainsi , cln proposer : ( 1 ) un stratégie de gestion de le espace mémoireoptimisé et ( 2 ) un nouveau méthode de résumé des série temporel par approximation . dans ce but , cln observer à le fois le erreur global et le erreurslocale . le répartition de le mémoire suivre le étape suivant : ( 1 ) recherchede le séquence le mieux représenter et ( 2 ) recherche de le partie à compresseren minimiser le erreur . son expérimentation sur un donnée réel montrentl'efficacité et le pertinence de son approche . 	Florent Masseglia, Alice Marascu, Yves Lechevallier	2010	@inria.fr	1001294
349	Regrouper les données textuelles et nommer les groupes à l'aide de classes recouvrantes	regrouper le donnée textuel et nommer le groupe à le aide de classe recouvrant  organiser le donnée textuel et en tirer du sens être un défi majeuraujourd'hui . ainsi , lorsque le cln souhaiter analyser un débat en ligne ou unforum de discussion , cln vouloir pouvoir rapidement voir quels être le principauxthème aborder et le manière dont le discussion clr structure autour de lui . pour cela , et parce que un même texte pouvoir être associer à plusieurs thème , nousproposons un méthode original pour regrouper le donnée textuel en autorisantle chevauchement et pour nommer chaque groupe de manière lisible . le contribution principal de ce article être un méthode global qui permettre deréaliser tout le chaîne , partir un donnée textuel brut jusque à le caractérisationd groupe à un niveau sémantique qui dépasser le simple ensemble demot . 	Marian-Andrei Rizoiu, Julien Velcin, Jean-Hugues Chauchat	2010	@univ-lyon2.fr, @univ-lyon2.fr, @univ-lyon2.fr	1001361
350	Requêtes skyline avec prise en compte des préférences utilisateurs pour des données volumineuses	requête skylin avec prise en compte des préférence utilisateur pour un donnée volumineux  " Appréhender , parcourir un donnée ou des connaissance rester unetâche difficile en particulier lorsque le utilisateur être confronter à un gros volumesd donner . . un nombreux travaux clr être intéresser à extraire un point " " skylines " " comme outil de restitution . . le prise en compte des préférence avoir retenul'attention des travaux le plus récent mais le solution existant restenttrès consommateur en terme de stockage de information additionnel afind'obtenir des délai raisonnable de réponse aux requête . . son proposition , EC2Sky ( Efficient computation of compromettre ) , clr focaliser sur deux point : ( 1 ) comment répondre efficacement à un requête de type skyline en présencede préférence utilisateur malgré un gros volume de donnée ( aussi bien enterme de dimension que de préférence ) ; ; ( 2 ) comment restituer le connaissancesle plus pertinent en souligner le compromis associer aux préférencesspécifié . " 	Tassadit Bouadi, Sandra Bringay, Pascal Poncelet, Maguelonne Teisseire	2010	@lirmm.fr, @cemagref.fr	1001325
351	Résumé généraliste de flux de données	résumé généraliste de flux de donnée  lorsque le volume des donnée être trop important pour que cln être stockéesdans un base de donnée , ou lorsque son fréquence de production être élever , le Systèmesde Gestion de Flux de Données ( SGFD ) permettre de capturer un flux de enregistrementsstructuré et de cla interroger à le volée par un requête permanent ( exécuter de façoncontinue ) . mais le SGFD ne conserver pas le historique des flux qui être perdre à jamais . ce communication proposer un définition formel de ce que devoir être un résumé généralistede flux de donnée . le notion de résumé généraliste être lier à le capacité de répondreà des requête varié et de réaliser un tâche varier de fouille de donnée , en utiliser lerésumé à le place du flux de origine . un revue de plusieurs approche de résumé être ensuiteréaliser dans le cadre de ce définition . 	Christine Potier, Georges Hébrail	2010	@telecom-paristech.fr	1001301
352	SALINES : un automate au service de l'extraction de motifs séquentiels multidimensionnels	saline : un automate au service de le extraction de motif séquentiel multidimensionnel  le entrepôt de donnée occuper aujourde hui un place central dans le processus décisionnel . outre son consultation , un des finalité des entrepôt être de servir de socle aux techniquesde fouille de donnée . malheureusement , le approche existant exploiter peu le particularitésdes entrepôt ( multidimensionnalité , hiérarchie et donnée historique ) . parmi ce méthode , le extractiond motif séquentiel multidimensionnel avoir récemment être étudier . cln montrer dans cetarticui que ce dernier ne tirer pas pleinement profit des hiérarchie et ne découvrir par conséquentqu'un partie seulement des motif qualitativement intéressant . cln proposer alors uneméthode de extraction de motif séquentiel multidimensionnel baser sur un automate et extrayantun nouveau motif . le différent expérimentation mener sur un jeu de donnée synthétiquesattestent des bon performance de son proposition . 	Yoann Pitarch, Lionel Vinceslas, Anne Laurent, Pascal Poncelet, Jean-Emile Symphor	2010	@lirmm.fr, @univ-ag.fr	1001265
353	Self-Clustering for Identification of Customer Purchase Behaviours	le segmentation de un base client pouvoir avoir différent objectif etplusieur segmentation pouvoir être utile pour décrire le client ou pour clr adapteravecre le stratégie commercial de un entreprise . dans ce papier , cln présentonsun schéma expérimental viser à proposer un ensemble de segmentationsalternative . ce segmentation être produire sur un donnée réel par latransformation des donnée initial , le génération et le sélection de différentessegmentation . 	Guillem Lefait, Gilles Goncalves, M. Tahar Kechadi	2010	@ucd.ie, @ucd.ie, @univ-artois.fr	1001273
354	SequencesViewer : comment rendre accessible des motifs séquentiels de gènes trop nombreux	SequencesViewer : comment rendre accessible des motif séquentiel de gène trop nombreux  le technique de extraction de connaissance appliquer aux gros volumesd donner , issir de le analyse de puce ADN , permettre de découvrirun connaissance jusque alors inconnu . or , ce technique produire de trèsnombreux résultat , difficilement exploitable par le expert . cln proposonsun outil dédier à le accompagnement de ce expert dans le appropriation et le exploitationd ce résultat . ce outil être baser sur trois technique de visualisation ( nuage , système solaire et treemap ) qui permettre aux biologiste de appréhenderun grand quantité de motif séquentiel ( séquence ordonner de gène ) . 	Arnaud Sallaberry, Nicolas Pecheur, Sandra Bringay, Mathieu Roche, Maguelonne Teisseire	2010	@labri.fr, @lirmm.fr, @lirmm.fr, @cemagref.fr	1001322
355	Simplification de données de vol pour un stockage optimal et une visualisation accélérée	simplification de donnée de vol pour un stockage optimal et un visualisation accélérer  le projet RECORDS ( collaboration entre industriel et université ) apour objectif de développer un infrastructure de service sécuriser pour assurerle suivre et le analyse des condition de utilisation de aéronef . chaque aéronefest munir de capteur . Au cours de chaque mission ( vol ) le donnée mesuréesêtre enregistrer localement . ce dernier être par le suite transférer dansune base de donnée centraliser à un fin de analyse . le problème rencontrer estle grand quantité de donnée ainsi enregistrer , ce qui cll rendre le exploitationdifficile . dans ce article , cln proposer un technique de compression et desimplification de donnée avec un taux de perte contrôler . son expérimentationsmontrent des gains drastique en volumétrie avec un très faible perte de information . ceci représenter un premier étape avant de appliquer un techniquesd'extraction de connaissance . 	Ibrahim Chahid, Loic Martin, Sofian Maabout, Mohamed Mosbah	2010	@2moro.fr, @labri.fr	1001324
356	SimTole	le plateforme SimTOLE être dédiee avoir le evaluation de algorithme de alignement de ontologie heterogene et repartie avoir travers un reseau pair avoir pair ( P2P ) . ce plateforme permettre de simuler un réseau P2P dans lequel chaque pair disposer de son propre ontologie ainsi que un outil permettre le alignement entre le ontologie local et un ontologie stocker sur un pair distant . le developpement de ce plateforme clr inscrire dans le cadre de travaux de recherche étudier le impact de le topologie du réseau P2P dans le processus de inférence de correspondance sémantique . durant ce démonstration , le plateforme simTole être présenter puis tester pour illustrer un scénario montrer comment affiner le processus de alignement de ontologie dans un réseau P2P . 	Nicolas Lumineau, Lionel Médini	2010	@liris.cnrs.fr	1001390
357	SoTree : Auto-organisation topologique et hiérarchique des données	SoTree : auto- organisation topologique et hiérarchique des donnée  " cln proposer dans ce article de introduire un nouveau approche pour le classification non superviser hiérarchique . . son méthode nommer So- Tree consister à construire , de un manière autonome et simultané , un partition topologique et hiérarchique des donnée . . chaque " " cluster " " de le partition être associer à un cellule de un grille 2D et être modéliser par un arbre , dont chaque noeud représenter un donner . . cln évaluer le capacité et le performance de son approche sur un donnée aux difficulté variable . . le résultat préliminaire obtenir être encourageant et prometteur pour continuer dans ce direction . " 	Mustapha Lebbah, Hanane Azzag	2010	@univ-paris13.fr	1001358
358	Sous-échantillonnage topographique par apprentissage semi-supervisé	Sous-échantillonnage topographique par apprentissage semi-supervisé  plusieurs aspect pouvoir influencer le système de apprentissage existant . un de ce aspect être lier au déséquilibre des classe dans lequel le nombre de observationsappartenant à un classe , dépasser fortement celui des observation dans le autresclasse . dans ce type de cas assez fréquent , le système de apprentissage avoir un difficultésaurant cours de le phase de entraînement lier au déséquilibre inter-classe . cln proposonsune méthode de sous-échantillonnage adaptatif pour traiter ce type de base déséquilibré . le processus procéder par le sous-échantillonnage des donnée majoritaire , guidépar le donnée minoritaire tout au long de le phase de un apprentissage semi-supervisé . cln utiliser comme modèle de apprentissage le carte auto- organisatrice . le approcheproposé avoir être valider sur plusieurs base de donnée en utiliser le arbre de décisioncomme classificateur avec un validation croisé . le résultat expérimental avoir montrédes performance très prometteur . 	Younès Bennani, Mustapha Lebbah	2010	@univ-paris13.fr	1001277
359	Système d'extraction des connaissances à partir des données temporelles basé sur les Réseaux Bayésiens Dynamiques	système de extraction des connaissance à partir un donnée temporel baser sur le réseau Bayésiens Dynamiques  un grand nombre de information qui avoir un structure complexeproviennent de divers source . ce information contenir des connaissancestrès utile pour le aide à le décision . le extraction des connaissance àpartir des Données ( ECD ) , permettre de acquérir un information pertinent pourles système interactif de aide à le décision ( SIAD ) . mais , dans plusieurs domaine , le donnée évoluer de un manière dynamique et finir par dépendred plusieur dimension . le réseau Bayésiens dynamique ( RBD ) être un modèle représenter un connaissance incertain sur un phénomènescomplexe de processus dynamique . son objectif revenir à fixer lesmeilleuron modèle de connaissance extraire par le RBD et à le utiliserpour le prise de décision dynamique . ainsi , cln proposer dans ce articleune démarche pour le mise en place de un processus de extraction des connaissancesà partir un donnée multidimensionnel et temporel . 	Ghada Trabelsi, Mounir Ben Ayed, Adel M. Alimi	2010	@yahoo.fr, @ieee.org, @ieee.org	1001299
360	Un modèle d'extraction de masses de croyance à partir de probabilités a posteriori pour une amélioration des performances en classification supervisée	un modèle de extraction de masse de croyance à partir de probabilité avoir posteriori pour un amélioration des performance en classification superviser  le objectif de ce article être de montrer que le utilisation de le règle dedécision du maximum de masse de croyance en lieu et place de celui du maximumde probabilité avoir posteriori pouvoir permettre de réduire le taux de erreur en classificationsupervisée . cln proposer un technique efficace pour extraire , à partird'un vecteur de probabilité avoir posteriori , un vecteur de masse de croyance surlequel baser le décision par le maximum de masse de croyance . le applicationd son méthode dans le domaine de le classification automatique en stade desommeil montre un amélioration des performance pouvoir atteindre 80 \pourcent dedécision du taux de erreur de classification . 	Teh Amouh, Monique Noirhomme-Fraiture, Benoît Macq	2010	@fundp.ac.be, @uclouvain.be	1001349
361	Un système d'aide à l'extraction de relations sémantiques pour la construction d'ontologies à partir de textes	un système de aide à le extraction de relation sémantique pour le construction de ontologie à partir de texte  ce article présenter un méthode de extraction de relation sémantiquespour le construction de ontologie à partir de corpus de texte . son objectif estder proposer un méthode générique , qui être indépendant du domaine et de lalangue . cln reposer sur un analyse distributionnel des unité sémantique ducorpus pour faire émerger un relation sémantique candidat . ce méthodene faire aucun hypothèse sur le type de relation rechercher ni sur son formelinguistique . ilimp clr agir de regrouper le association de terme dans un classesqui représenter un relation sémantique candidat . le hypothèse sous-jacenteêtre que le occurrence de ce association réunir sur le base des élément decontexte que cln partager avoir un chance de relever de un même relation sémantiqueettre que le relation candidat ainsi proposer pouvoir aider le travailde conceptualisation de le ontologue 	Rim Bentebibel, Adeline Nazarenko, Sylvie Szulman	2010	@univ-paris13.fr	1001343
362	Une approche fondée sur la corrélation entre prédicats pour le traitement des réponses pléthoriques	un approche fonder sur le corrélation entre prédicat pour le traitement des réponse pléthorique  le interrogation de base de donnée , dont le dimension ne cessentde croître , clr heurter fréquemment au problème de le gestion des réponse pléthorique . un des approche envisageable pour réduire le ensemble des résultatsretourné et cla rendre exploitable être de contraindre le requête initial parl'ajout de nouveau condition . le approche présenter dans ce article clr appuiesur le identification de lien de corrélation entre prédicat associer aux attributsd le relation concerner . le requête initial pouvoir ainsi être intensifier automatiquementou par validation de le utilisateur à travers le ajout de prédicat prochessémantiquement de celui spécifier . 	Patrick Bosc, Allel HadjAli, Olivier Pivert, Grégory Smits	2010	@enssat.fr, @univ-rennes1.fr	1001305
363	Une approche probabiliste pour l'identification de structures de communautés	un approche probabiliste pour le identification de structure de communauté  dans ce article , cln valoriser et défendre le idée que le modèle génératif être un approche prometteur pour le identification de structure de communauté ( ISC ) . cln proposer un nouveau modèle probabiliste pour le idenditification de structure de communauté qui utiliser le lissage afin de pallier le petit nombre de lien entre le noeud . son modèle être très sensible aux paramètre de lissage , cln proposer également un méthode baser sur le modularité pour son estimation . le résultat expérimental obtenir sur 3 jeu de donnée montrer que son modèle SPCE être largement meilleur que le modèle PHITS 	Nacim Fateh Chikhi, Bernard Rothenburger, Nathalie Aussenac-Gilles	2010	@irit.fr	1001289
364	Une nouvelle approche de découverte des correspondances complexes entre ontologies	un nouveau approche de découverte des correspondance complexe entre ontologie  le correspondance complexe avoir être étudier à plusieurs reprisesdans le domaine de alignement de schéma de base de donnée . par contre , dans le domaine de alignement des ontologie , cln avoir être peu étudier . Nousproposons , dans ce papier , un nouveau approche de découverte de correspondancescomplexe entre deux ontologie . le approche proposer être extensionnelle , terminologique et implicatif . dans ce approche , cln utiliser le modèledes règle de association afin de découvrir un correspondance de typex ⇒ y1 ∧ ... ∧ yn entre deux ontologie . 	Fatma Kaâbi, Faïez Gargouri	2010	@yahoo.fr, @fsegs.rnu.t	1001414
365	Une nouvelle stratégie d'Apprentissage Bayésienne	un nouveau stratégie de Apprentissage Bayésienne  dans ce article , un nouveau stratégie de apprentissage actif être proposer . ce stratégie être fonder sur un méthode de discrétisation Bayésienne semi-supervisée . un expérience comparatif être mener sur un donnée unidimensionnel , le objectif être de estimer le position de un échelon à partir de donnée bruiter . 	Alexis Bondu, Vincent Lemaire, Marc Boullé	2010	@edf.fr, @orange-ftgroup.com	1001463
366	Une Ontologie pour l'Acquisition et l'Exploitation des Connaissances en Conception Inventive	un ontologie pour le acquisition et le Exploitation des connaissance en conception inventif  le acquisition des connaissance en vue de résoudre un problèmesconcernant le évolution des artefact , comme cln clr devoir de être pratiquer enconception inventif , avoir un caractéristique spécifique . cln nécessiter lasélection de certains des connaissance qui pouvoir induire un évolution , cln amener à reformuler le problème initial afin de construire un modèleabstrait de le artefact concerner . le méthode de conception inventif induire parler théorie de le résolution des problème inventif ( aussi connaître sousl'acronyme TRIZ ) ne avoir pas encore faire le objet de un véritable formalisation . cln proposer ici un ontologie des notion principal des concept lier àl'acquisition des connaissance dans ce cadre . ce ontologie , outre laclarification des notion en jeu , être utiliser comme support de un environnementinformatique de aide à le mise en oeuvre de un méthode pour acquérir lesconnaissance et formuler le problème . 	François Rousselot, Cecilia Zanni, Denis Cavallucci	2010	@insa-strasbourg.fr	1001470
367	Une structure basée sur les hiérarchies pour synthétiser les itemsets fréquents extraits dans des fenêtres temporelles	un structure baser sur le hiérarchie pour synthétiser le itemsets fréquent extrait dans un fenêtre temporel  le paradigme des flot de donnée rendre impossible le conservation de le intégralitéd le historique de un flot que ilimp falloir alors résumer . le extraction de itemsets fréquentssur des fenêtre temporel sembler tout à fait adapté mais le amoncellement des résultatsindépendant rendre impossible le exploitation de ce résultat . cln proposer un structurebasée sur le hiérarchie des donnée afin de unifier ce résultat . de plus , puisque laplupart un donnée de un flot présenter un caractère multidimensionnel , cln intégronsler prendre en compte de itemsets multidimensionnel . enfin , cln pallier un faiblesse majeuredes Tilted TimeWindows ( TTW ) en prendre en compte le distribution des donnée . 	Yoann Pitarch, Anne Laurent, Pascal Poncelet	2010	@lirmm.fr	1001467
368	Vers une extraction et une visualisation des co-localisations adaptées aux experts	vers un extraction et un visualisation des co- localisation adapté aux expert  un des tâche classique en fouille de donnée spatial être le extractiond co- localisation intéressant dans un donnée géo- référencer . le objectifest de trouver un sous-ensemble de caractéristique booléen apparaissantfréquemment dans un objet spatial voisin . toutefois , le relation découvertespeuvent ne pas être pertinent pour le expert , et son interprétation sousforme textuel pouvoir être difficile . cln proposer , dans ce contexte , un nouvelleapproche pour intégrer le connaissance des expert dans le découverte desco- localisation , ainsi que un nouveau représentation visuel de ce motif . Unprototype avoir être développer et intégrer dans un SIG . un expérimentation cln étémener sur un donnée géologique réel , et le résultat valider par un expertdu domaine . 	Frédéric Flouvat, Nazha Selmaoui-Folcher, Dominique Gay	2010	@univ-nc.nc	1001335
369	Visualisation de mesures agrégées pour l'estimation de la qualité des articlesWikipedia	visualisation de mesure agrégé pour le estimation de le qualité des articlesWikipedia  Wikipedia , devenir le un des base de connaissance le plus populaire , poser le problème de le fiabilité de le information que cln disséminer . Nousproposons WikipediaViz , un ensemble de visualisation baser sur un mecanismede collecte et de agrégation de donnée de édition Wikipedia pour aider le lecteurà appréhender le maturité de un article . cln lister cinuelque métrique important , déterminer lors de session de conception participatif avec un expert Wikipediapour juger de le qualité , que cln présenter au lecteur sous forme devisualisations compact et expressif , dépeindre le profil de évolution de un article . son étude utilisateur avoir montrer queWikipediaViz réduire significativementle temps requérir pour évaluer le qualité en maintenir un bon précision 	Fanny Chevalier, Stéphane Huot, Jean-Daniel Fekete	2010	@inria.fr, @lri.fr, @inria.fr	1001316
370	WCUM pour l'analyse d'un site web	WCUM pour le analyse de un site web  dans ce papier , cln proposer un approche WCUM ( Web Contentand Usage based Approach ) permettre de relier le analyse du contenu de un siteWeb à le analyse de le usage afin de mieux comprendre le comportement de navigationsur le site . le apport de ce travail résider de un part dans le propositiond'une approcher relier le analyse du contenu à le analyse de le usage et de autre partdans le extension de le application des méthode de block clustering , appliquéesgénéralement en bioinformatique , au contexte Web mining afin de profiter deleur pouvoir classificatoire dans le découverte de biclasse homogène à partird'une partition des instance et un partition des attribut rechercher simultanément . 	Malika Charrad, Yves Lechevallier, Mohamed Ben Ahmed, Gilbert Saporta	2010	@riadi.rnu.tn, @inria.fr, @cnam.fr	1001413
371	Accompagner au début du 21ème siècle les organisations dans la mise en place d'une gestion des connaissances : retour d'expérience	accompagner au début du 21ème siècle le organisation dans le mise en place de un gestion des connaissance : retour de expérience  ce article présenter succinctement le retour de expérience de Ardansdans le implantation de système de gestion de connaissance dans un organisationstrès varier au début de ce 21ème siècle . 	Alain Berger, Jean-Pierre Cotton, Pierre Mariot	2009	@ardans.fr	1000811
372	Acquisition de la théorie ontologique d'un système d'extraction d'information	acquisition de le théorie ontologique de un système de extraction de information  le conception de système de extraction de Information ( EI ) destinésà extraire le réseau de interaction génique décrire dans le littérature scientifiqueest un enjeu important . de tel système nécessiter un représentationssophistiqué , clr appuyer sur un ontologie , afin de définir différent relationsbiologique , ainsi que le dépendance récursif que cln présenter entre lui . cependant , le acquisition de ce dépendance ne être pas possible avec le techniquesd'apprentissage automatique actuellement employer en EI , car ce dernièresne gérer pas le récursivité . afin de palier ce limitation , cln présentonsuner application à le EI de le programmation Logique Inductive , en mode multipredicat . son expérimentation , effectuer sur un corpus bactérien , conduisentà un rappel global de 67 .7 \% pour un précision de 75 .5 \% . 	Alain-Pierre Manine	2009	@univ-paris13.fr	1000788
373	Acquisition, annotation et exploration interactive d'images stéréoscopiques en réalité virtuelle : application en dermatologie	acquisition , annotation et exploration interactif de image stéréoscopique en réalité virtuel : application en dermatologie  cln présenter dans ce article le système Skin 3.D. qui implémentetoutre le composant matériel et logiciel nécessaire pour extraire desinformations dans un image 3D de peau . ilimp clr agir à le fois du matérield'éclairage et de acquisition à base de appareil photographiquesstéréoscopique , de un méthode de calibration de caméra utiliser lesalgorithson génétique , de matériel de réalité virtuel pour restituer lesimagon en stéréoscopie et interagir avec lui , et enfin de un ensemble defonctionnalités interactif pour annoter le image , partager ce annotation etconstruire un hypermédia 3D. cln présenter un étude comparativeconcernant le calibration et un application réel de Skin 3.D. sur un image devisage . 	Mohammed Haouach, Karim Benzeroual, Christiane Guinot, Gilles Venturini	2009	@univ-tours.fr, @ceries-lab.com	1000774
374	Analyse de dissimilarités par arbre d'induction	analyse de dissimilarité par arbre de induction  dans ce article1 , cln considérer un objet pour lequel cln dis-poser de un matrice des dissimilarité et cln cld intéresser à son liensavec des attribut . cln cln centrer sur le analyse de séquence de états pourlesquelles le dissimilarité être donner par le distance de édition . toutefois , lesméthode développer pouvoir être étendre à tout type de objet et de mesurede dissimilarités . cln présenter dans un premier temps un généralisation del'analyr de variance ( ANOVA ) pour évaluer le lien entre un objet non mesu-rable ( page ex. des séquence ) avec un variable catégoriel . le clef de le approcheest de exprimer le variabilité en terme des seul dissimilarité ce qui cln per-mettre de identifier le facteur qui réduire le plus le variabilité . cln présentonsun test statistique général qui pouvoir en être déduire et introduire un méthodeoriginal de visualisation des résultat pour le séquence de états . cln présen-tir ensuite un généralisation de ce analyse au cas de facteur multiple et endiscutons le apport et le limite , notamment en terme de interprétation . Fina-lement , cln introduire un nouveau méthode de type arbre de induction quiutilis le test précédent comme critère de éclatement . le portée des méthodesprésentée être illustrer à le aide de un analyse des facteur discriminer le plusles trajectoire occupationnel . 	Gilbert Ritschard, Matthias Studer, Nicolas S. Müller, Alexis Gabadinho	2009	@unige.ch	1000733
375	Analyse de données pour la construction de modèles de procédures neurochirurgicales	analyse de donnée pour le construction de modèle de procédure neurochirurgical  dans ce article , cln appliquer un méthode de analyse sur desdescription de procédure de neurochirurgie dans le but de cll améliorer lacompréhension . le base de donnée XML utiliser dans ce étude estconstitué de le description de 157 chirurgie de tumeur . Trois cent vingtdeux variable avoir être identifier et décomposer en variable prédictif ( connaître avant le opération ) et variable à prédire ( décrire des gesteschirurgical ) . un analyse factoriel des correspondance ( AFC ) avoir étéréaliser sur le variable prédictif , ainsi que un arbre de décision baser sur undendrogramme préalablement établir . Six classe principal de variablesprédictive avoir ainsi être identifier . Puis , pour chacun de ce classe , uneanalyse AFC avoir être réaliser sur le variable à prédire , ainsi que un arbre dedécision . bien que le nombre de cas et le choix des variable constituer unelimite à ce étude , cln avoir réussir à prédire certain caractéristique liéesaux procédure en partir de donnée prédictif . 	Brivael Trelhu, Florent Lalys, Laurent Riffaud, Xavier Morandi, Pierre Jannin	2009	@irisa.fr, @irisa.fr, @irisa.fr, @chu-rennes.fr, @chu-rennes.fr	1000789
376	Analyse et application de modèles de régression pour optimiser le retour sur investissement d'opérations commerciales	analyse et application de modèle de régression pour optimiser le retour sur investissement de opération commercial  le activité de négoce de matériaux être un marché extrêmementcompétitif . pour le acteur de ce marché , le méthode de fouille de donnéespeuvent clr avérer intéressant en permettre de dégager un gains de rentabilitéimportant . dans ce article , cln présenter le retour de expérience du projetde fouille de donnée mener chez VM Matériaux pour améliorer le retour surinvestissement de opération commercial . le synergie des informaticien , dumarketing et des expert métier avoir permettre de améliorer le extraction des connais-sance à partir un donnée de manière à aboutir à le connaissance actionnable laplus pertinent possible et ainsi aider le expert métier à prendre un décision . 	Thomas Piton, Julien Blanchard, Henri Briand, Laurent Tessier, Gaëtan Blain	2009	@vm-materiaux.fr, @univ-nantes.fr, @kxen.com	1000735
377	Analyse multigraduelle OLAP	analyse multigraduel OLAP  le système décisionnel reposer sur un base de donnée multidimensionnellesqui offrir un cadre adéquat aux analyse OLAP . le articleprésente un nouveau opérateur OLAP nommer « BLEND » rendre possible desanalyse multigraduel . ilimp clr agir de transformer le structuration multidimensionnellelors des interrogation pour analyser le mesure selon un niveauxde granularité différent recombiner comme un même paramètre . cln menonsune étude des combinaison valide de le opération dans le contexte deshiérarchies strict . enfin , un premier série de expérimentation implantel'opération dans le contexte R-OLAP en montrer le faible coût de le opération . 	Gilles Hubert, Olivier Teste	2009	@irit.fr	1000768
378	Analyse sémantique spatio-temporelle pour les ontologies OWL-DL	analyse sémantique spatio- temporel pour le ontologie OWL-DL  le analyse sémantique être un nouveau paradigmed'interrogation du Web Sémantique qui avoir pour objectif de identifier lesassociation sémantique relier un individu décrire dans desontologion OWL-DL . pour déduire davantage de associationssémantique et augmenter le précision de le analyse , le informationspatio- temporel attacher aux ressource devoir être prendre en compte . ace fin - et pour combler le absence actuel de raisonneur spatiotemporeldéfini pour le ontologie RDF ( S ) et OWL- , lui proposonsle système de représentation et de interrogation de ontologie spatiotemporellesONTOAST , compatible avec le langage OWL-DL . Nousprésentons le principe de base de le algorithme de découverted'association sémantique entre individu intégrer dans ONTOAST . ce algorithme utiliser deux contexte , le un spatial et le autre temporelqui permettre de affiner le recherche . cln décrire enfin le approchemise en oeuvre pour le déduction de connexion spatial entreindividus . 	Alina Dia Miron, Jérôme Gensel, Marlène Villanova-Oliver	2009	@imag.fr	1000784
379	Caractérisation automatique des classes découvertes en classification non supervisée	caractérisation automatique des classe découvrir en classification non superviser  dans ce article , cln proposer un nouveau approche de classifi-cation et de pondération des variable durant un processus de apprentissage non superviser . ce approche être baser sur le modèle des carte auto- organisatrice . le apprentissage de ce carte topologique être combiné à un mécanisme de esti-mation de pertinence des différent variable sous forme de poids de influence sur le qualité de le classification . cln proposer deux type de pondération adaptatif : un pondération des observation et un pondération des distance entre observation . le apprentissage simultané des pondération et des prototype utiliser pour le partition des observation permettre de obtenir un classification op-timisé des donnée . un test statistique être ensuite utiliser sur ce pondération pour élaguer le variable non pertinent . ce processus de sélection de variable permettre enfin , grâce à le localité des pondération , de exhiber un sous ensemble de variable propre à chaque groupe ( cluster ) offrir ainsi son caractérisation . le approche proposer avoir être valider sur plusieurs base de donnée et le résultat expérimental avoir montrer un performance très prometteur . 	Nistor Grozavu, Younès Bennani, Mustapha Lebbah	2009	@univ-paris13.fr	1000737
380	Ciblage des règles d'association intéressantes guidé par les connaissances du décideur	ciblage des règle de association intéressant guider par le connaissance du décideur  le usage du modèle des règle de association en fouille de donnée estlimiter par le quantité prohibitif de règle que ilimp fournir et nécessiter le mise enplace de un phase de post-traitement efficace afin de cibler le règle le plusutile . ce article proposer un nouveau approche intégrer explicitement lesconnaissance du décideur afin de filtrer et cibler le règle intéressant . 	Claudia Marinica, Fabrice Guillet	2009	@univ-nantes.fr	1000805
381	Classification des Images de Télédétection avec ENVI FX	classification des image de télédétection avec ENVI FX  un important volume de image satellite et aérien de tout type ( panchromatique , multispectrale , multispectrale ) être généréesquotidiennement , et son classification par un méthode semi-automatiquesdevient nécessaire . le logiciel ENVI Feature eXtractionTM ( ENVI FXTM ) sebaser sur un approche « objet » -par opposition à un approche pixelsclassique-et sur un algorithme innovant , pour le segmentation et laclassification des image de télédétection avec un haut niveau de précision . 	Franck Le Gall, Damien Barache, Ahmed Belaidi	2009	@ittvis.com, @ittvis.com, @ittvis.com	1000813
382	Comment valider automatiquement des relations syntaxiques induites	Comment valider automatiquement un relation syntaxique induire  cln présenter dans ce article des approche viser à valider desrelations syntaxique induire de type Verbe-Objet . ainsi , cln proposer de u-tiliser dans un premier temps un approche clr appuyer sur un vecteur séman-tique déterminer à le aide de un thésaurus . le seconde approche employer unevalidation Web . cln effectuer un requête sur un moteur de recherche asso- ciée à un mesure statistique afin de déterminer le pertinence de un relationsyntaxique . cln proposer enfin de combiner ce deu méthode . le qualitéde son approche de validation de relation syntaxique avoir être évaluer en utilisantdes courbe ROC . 	Nicolas Béchet, Mathieu Roche, Jacques Chauché	2009	@lirmm.fr	1000749
383	Comparaison de distances et noyaux classiques par degré d'équivalence des ordres induits	comparaison de distance et noyau classique par degré de équivalence des ordre induire  le choix de un mesure pour comparer le donnée être au coeur destâche de recherche de information et de apprentissage automatique . cln considéronsici ce problème dans le cas où seul le ordre induire par le mesure importer , et non le valeur numérique que cln fournir : ce situation être caractéristiquedes moteur de recherche de document par exemple . cln étudier dans cecadre le mesure de comparaison classique pour donnée numérique , tellesque le distance et le noyau le plus courant . cln identifier le mesureséquivalente , qui induire toujours le même ordre ; pour le mesure non équivalent , cln quantifier son désaccord par un degré de équivalence baser surle coefficient de Kendall généraliser . cln étudier le équivalence et quasiéquivalencesà le fois sur le plans théorique et expérimental . 	Maria Rifqi, Marcin Detyniecki, Marie-Jeanne Lesot	2009	@lip6.fr	1000738
384	Construction de descripteurs pour classer à partir d'exemples bruités	construction de descripteur pour classer à partir de exemple bruiter  en classification superviser , le présence de bruit sur le valeur desdescripteur pouvoir avoir un effet désastreux sur le performance des classifieurset donc sur le pertinence des décision prendre au moyen de ce modèle . Traiterce problème lorsque le bruit affecter un attribut classe avoir être très étudier . ilimp estplus rare de clr intéresser au bruit sur le autre attribut . ce être son contextede travail et cln proposer le construction de nouveau descripteur robusteslorsque celui des exemple original être bruiter . le résultat expérimentauxmontrer le valeur ajouté de ce construction par le comparaison des qualitésobtenue ( e.gure , précision ) lorsque le cln utiliser le méthode de classification àpartir de différent collection de descripteur . 	Nazha Selmaoui-Folcher, Jean-François Boulicaut, Dominique Gay	2009	@univ-nc.nc, @insa-lyon.fr	1000742
385	Contrôle des observations pour la gestion des systèmes de flux de données.	contrôle des observation pour le gestion des système de flux de donnée .  le système de analyse de flux de donnée prendre de plus en plusd'importance dans un contexte où le donnée circuler sur le réseau être deplus en plus volumineux et où le volonté de réagir au plus vite , en temps réel , devenir un besoin nécessaire . afin de permettre un analyse aussi rapide etefficace que possible , ilimp convier de pouvoir contrôler le flot de donnée et defocaliser le traitement sur le donnée pertinent . le protocole présenter dansce papier donner au module de traitement des capacité de action et de contrôle surles observation remontant en fonction de le état de le analyse . le diminutiondes flux résulter de tel focalisation permettre un traitement beaucoup plusefficace , plus pertinent et moins consommateur de ressource . le premiersrésultat montrer un réel gain de performance sur son application ( facteur100 ) . 	Pierre Le Maigat, Christophe Dousson	2009	@orange-ftgroup.com	1000798
386	Correspondances de Galois pour la manipulation de contextes flous multi-valués	correspondance de Galois pour le manipulation de contexte flou multi-valué  le analyse formel de concept être un méthode fonder sur le correspondanced Galois et qui permettre de construire un hiérarchie de conceptsformel à partir de tableau de donnée binaire . cependant de nombreux problèmesréel aborder en fouille de donnée comporter un donnée plus complexe . afin de traiter de tel problème , cln proposer un conversion de donnéesflou multi-valué en attribut histogramme et un correspondance deGalois adapter à ce format . son propos être illustrer avec un jeu de donnéessimple . enfin , cln évaluer brièvement le résultat et le apport de cettecorrespondance de Galois par rapport à le approche classique 	Aurélie Bertaux, Florence Le Ber, Agnès Braud	2009	@engees.u-strasbg.fr, @urs.u-strasbg.fr	1000763
387	De l'utilisation de l'Analyse de Données Symboliques dans les Systèmes multi-agents	de le utilisation de le analyse de Données Symboliques dans le système multi-agent  le exploitation en temps réel de connaissance complexe être un défidans de nombreux domaine , tel que le web sémantique , le simulation ou lessystèmes multi-agents ( SMA ) . dans le paradigme multi-agent , un travaux ré-cent montrer que le communication multi-parti ( CMP ) offrir un oppor-tunité intéressant en terme de réalisme des communication , diffusion desconnaissance et sémantique des acte de langage . cependant , ce travaux seheurtent à le difficulté de mise en oeuvre des CMP , pour lequel le supportsde communication classique être insuffisant . dans ce article , cln propo- son de utiliser le formalisme de le analyse de Données Symboliques ( ADS ) pourmodéliser le information et le besoin des agent . cln appuyer le routagedes message sur ce modélisation dans le cadre de un environnement de com-munication pour le système multi-agent . afin de illustrer son propos , nousutiliserons le exemple de le gestion des communication dans un poste de appelsd'urgence . cln présenter ensuite son retour de expérience , et discuter lesperspectives ouvrir par le fertilisation croisé de le ADS et des SMA . 	Flavien Balbo, Julien Saunier, Edwin Diday, Suzanne Pinson	2009	@lamsade.dauphine.fr, @ceremade.dauphine.fr	1000746
388	Définition d'une stratégie de résolution de problèmes pour un robot humanoïde	définition de un stratégie de résolution de problème pour un robot humanoïde  " cln avoir développer un système dont le but être de obtenir le logicielde commander de un robot capable de simuler le comportement de un humainplacé en situation de résolution de problème . . cln avoir résoudre ce problèmedan un environnement psychologique particulier où le comportement humainspeuvent être interpréter comme un " observable " de son stratégie derésolution de problème . . son solution contenir de plus celui de un autre problème , celui de construire un boucle complet commencer avec le comportementd'un groupe de humain , son analyse et son interprétation en termesd'observable humain , le définition des stratégie utiliser par le humain ( ycompris celui qui être inefficace ) , le interprétation des observable humainesen terme de mouvement du robot , le définition de ce que être un " " stratégie derobot " " en terme de stratégie humain . . le boucle être boucler avec un langagede programmation capable de programmer ce stratégie robotique , qui deviennentainsvoir à son tour des observable , tout comme cla avoir être le stratégieshumain du début de le boucle . . cln expliquer comment cln avoir être capablesdéfinir de façon objectif ce que cln appeler un stratégie de robot . . son solution assembler deux facteur différent . . le un permettre de éviter lescomportement " inhumain " et clr fonder sur le moyenne des comportementsdes humain que cln avoir observer . . le autre fournir un sorte " de humanité'au robot en cld permettre de dévier de ce moyenne par n fois le écart typeobservé chez le humain que ilimp devoir simuler . ilimp devenir alors possible de programmerde comportement complètement humain . " 	Mary Felkin, Yves Kodratoff	2009	@lri.fr, @lri.fr	1000806
389	DEMON : Découverte de motifs séquentiels pour les puces adn	DEMON : découverte de motif séquentiel pour le puce adn  prometteur en terme de prévention , de dépistage , de diagnostic etd'actions thérapeutique , le puce à ADN mesurer le intensité des expressionsd plusieur millier de gène . dans ce article , cln proposer un nouvelleapproche appelé DEMON , pour extraire un motif séquentiel à partir de don -né issir des puce ADN et qui utiliser un connaissance du domaine . 	Paola Salle, Sandra Bringay, Maguelonne Teisseire	2009	@lirmm.fr	1000803
390	Détection de séquences atypiques basée sur un modèle de Markov d'ordre variable	détection de séquence atypique baser sur un modèle de Markov de ordre variable  récemment , le nombre et le volume des base de donnée séquentiellesbiologique avoir augmenter de manière considérable . dans ce contexte , le identificationd anomalie être essentiel . le plupart des approche pour lesextraire clr fondre sur un base de apprentissage ne contenir pas de outlier . or , dans de très nombreux application , le expert ne disposer pas de un tellebase . de plus , le méthode existant demeurer exigeant en mémoire , cequi cla rendre souvent impossible à utiliser . cln présenter dans ce article unenouveau approche , baser sur un modèle de Markov de ordre variable et sur unemesure de similarité entre objet séquentiel . cln ajouter aux méthode existantesun critère de élagage pour contrôler le taille de le espace de rechercheet son qualité , ainsi que un inégalité de concentration précis pour le mesure desimilarité , conduire à un meilleur détection des outlier . cln démontronsexpérimentalement le validité de son approche . 	Cécile Low-Kam, Anne Laurent, Maguelonne Teisseire	2009	@math.univ-montp2.fr, @lirmm.fr	1000766
391	Détection d'intrusions dans un environnement collaboratif sécurisé	détection de intrusion dans un environnement collaboratif sécuriser  pour pallier le problème des attaque sur le réseau de nouveau ap-proche de détection de anomalie ou de abus avoir être proposer ce dernier an -né et utiliser un signature de attaque pour comparer un nouveau requêteet ainsi déterminer se ilimp clr agir de un attaque ou pas . cependant ce système sontmir à défaut quand le requête ne exister pas dans le base de signature . Généra-lement , ce problème être résoudre via un expertise humain afin de mettre à jourle base de signature . toutefois , ilimp arriver fréquemment que un attaque avoir déjàété détecter dans un autre organisation et ilimp être utile de pouvoir bénéficier dece connaissance pour enrichir le base de signature mais ce information estdifficiler à obtenir car le organisation ne souhaiter pas forcément indiquer lesattaque qui avoir avoir lieu sur le site . dans ce article cln proposer un nouvelleapproche de détection de intrusion dans un environnement collaboratif sécuriser . son approche permettre de considérer tout signature décrire sous le forme de ex- pression régulier et de garantir que aucun information ne être divulguer sur lecontenu des différent site . 	Nischal Verma, François Trousset, Pascal Poncelet, Florent Masseglia	2009	@gmail.com, @ema.fr, @lirmm.fr, @inria.fr	1000775
392	Détermination du nombre des classes dans l'algorithme CROKI2 de classification croisée	détermination du nombre des classe dans le algorithme CROKI2 de classification croisé  un des problème majeur de le classification non supervisé être ladétermination ou le validation du nombre de classe dans le population . ce problèmes'étend aux méthode de bipartitionnement ou block clustering . dans cepapier , cln clr intéresser à le algorithme CROKI2 de classification croiséedes tableau de contingence proposer par Govaert ( 1983 ) . son objectif être dedéterminer le nombre de classe optimal sur le ligne et le colonne à traversun ensemble de technique de validation de classe proposer dans le littératurepour le méthode classique de classification . 	Malika Charrad, Yves Lechevallier, Gilbert Saporta, Mohamed Ben Ahmed	2009	@riadi.rnu.tn, @riadi.rnu.tn, @inria.fr, @cnam.fr	1000797
393	Diagnostic multi-sources adaptatif Application à la détection d'intrusion dans des serveursWeb	diagnostic multi-source adaptatif application à le détection de intrusion dans un serveursinternet  le but de un système adaptatif de diagnostic être de surveiller et diagnostiquerun système tout en clr adapter à son évolution . ceci passer par le adaptationd diagnostiqueur qui préciser ou enrichir son propre modèle poursuivre au mieux le système au fil du temps . pour détecter le besoin de adaptation , cln proposer un cadre de diagnostic multi-sourx clr inspirer de lafusion de information . un connaissance fournir par le concepteur sur un relationsattendue entre le diagnostiqueur mono- source former un méta-modèledu diagnostic . le compatibilité des résultat du diagnostic avec le méta-modèleest vérifier en ligne . lorsque un de ce relation ne être pas vérifier , le diagnostiqueursconcerné être modifier . cln appliquer ce approche à le conception de un système adaptatif de détectiond'intrusion à partir de un flux de connexion à un serveur Web . le évaluationsdu système mettre en évidence son capacité à améliorer le détection desintrusions connaître et à découvrir un nouveau type de attaque . 	Thomas Guyet, Wei Wang    , Rene Quiniou, Marie-Odile Cordier	2009	@irisa.fr, @gmail.fr	1000777
394	Empreintes conceptuelles et spatiales pour la caractérisation des réseaux sociaux	empreinte conceptuel et spatial pour le caractérisation des réseau social  ce article proposer un méthode reposer sur le utilisation del'Analyse Formelle de Concepts et des treillis de Galois pour le analyse desystèmes complexe . un statistique reposer sur ce treillis permettre decalculer le distribution conceptuel des objet classifier par le treillis . le expérimentation sur un échantillon de trois réseau social en ligneillustre le utilisation de ce statistique pour le caractérisation global et pour lefiltrage automatique de ce système . 	Bénédicte Le Grand, Marie-Aude Aufaure, Michel Soto	2009	@lip6.fr, @ecp.fr	1000779
395	Exploration de données de traçabilité issues de la RFID par apprentissage non-supervisé	exploration de donnée de traçabilité issu de le RFID par apprentissage non- superviser  le RFID ( radio Frequency identification ) être un technologie avancer de enregistrementde donner spatio- temporel de traçabilité . le objectif de ce travail être de transformer cesdonnéon spatio- temporel en connaissance exploitable par le utilisateur par le intermé-diaire de un méthode de classification automatique des donnée . le système RFID peuventêtre utiliser pour étudier le société animal , qui être un système dynamique complexescaractériser par beaucoup de interaction entre le individu ( Fresneau et alection , 1989 ) . le cadreapplicatif choisir pour ce travail être le étude de le structure de un groupe de individu en interactionsociale et en particulier le division du travail au sein de un colonie de fourmis1 . le RFID générer un important volume de donnée , ilimp être nécessaire de développer desméthodes approprié afin de cll comprendre le sens . cln proposer pour cela un algorithmede classification topographique non- superviser pour le exploration de ce type de donnée , ca-pable de détecter le groupe de individu exprimer le même comportement . le algorithme DS2L-SOM ( Density-based Simultaneous Two- Level - SOM , Cabanes et Bennani ( 2008 ) ) estcapabler de détecter non seulement le groupe définir par un zone vide de donner , grâce àune estimation de le pertinence des connexion entre référent , mais aussi le groupe défi-nis seulement par un diminution de densité , grâce à un estimation de le densité autour desréférent pendant le apprentissage . 	Guénaël Cabanes, Younès Bennani, Dominique Fresneau	2009	@univ-paris13.fr, @univ-paris13.fr	1000799
396	Exploration des corrélations dans un classifieur Application au placement d'offres commerciales	exploration des corrélation dans un classifieur Application au placement de offre commercial  ce article présenter un nouveau méthode permettre de explorer lesprobabilités délivrer par un modèle prédictif de classification . le augmentationde le probabilité de occurrence de le un des classe du problème étudier être analyséeen fonction des variable explicative prendre isolément . le méthode proposéeêtre poser et illustrer dans un cadre général , puis explicitement dédier au classifieurBayesien naïf . son illustration sur le donnée du challenge PAKDD 2007montre que ce type de exploration permettre de créer un indicateur performantsd'aid à le vente . 	Vincent Lemaire, Carine Hue	2009	@orange-ftgroup.com, @gfi.fr	1000739
397	Extraction de motifs fermés dans des relations n-aires bruitées	extraction de motif fermer dans un relation n-air bruiter  le extraction de motif fermer dans un relation binaire avoir être trèsétudiée . cependant , un nombreux relation intéressant être n-air avec n suivre 2 et bruiter ( nécessiter de un tolérance aux exception ) . récemment , ce deuxproblème avoir être traiter indépendamment . cln introduire son propositionpour combiner de tel fonctionnalité au sein de un même algorithme . 	Loïc Cerf, Jérémy Besson, Jean-François Boulicaut	2009	@liris.cnrs.fr	1000748
398	Extraction de Règles de Corrélation Décisionnelles	extraction de règle de corrélation Décisionnelles  dans ce article , cln introduire deux nouveau concept : le règlesde corrélation décisionnel et le vecteur de contingence . le premier résulted'un couplage entre le règle de corrélation et le règle de décision . ilimp permetder mettre en évidence des lien pertinent entre certain ensemble de motifsd'un relation binaire et le valeur de un attribut cible ( appartenir à ce mêmerelation ) en clr baser à le fois sur le mesure du Khi-carré et sur le support desmotifs extrait . de par le nature du problème , le algorithme par niveau fontque le extraction des résultat avoir lieu avec un temps de réponse élevé et uneoccupation mémoire important . afin de palier à ce deu inconvénient , nousproposons un algorithme baser sur le ordre lectique et le vecteur de contingence . 	Alain Casali, Christian Ernst	2009	@lif.univ-mrs.fr, @emse.fr	1000761
399	Extraction efficace de règles graduelles	extraction efficace de règle graduel  " le règle graduel susciter depuis quelque année un intérêt croissant . . un tel règle , de le forme " " plus ( moins ) A1 et ... ..arles plus ( moins ) an alorsplus ( moins ) B1 et ... ..arles plus ( moins ) Bn " " trouver application dans de nombreuxdomain tel que le bioinformatique , le contrôleur flou , le relever de capteursou encore le flot de donnée . . ce base , souvent composé de un grandnombre de attribut , rester un verrou pour le extraction automatique de connaissance , car cln rendre inefficace le technique de fouille habituel ( règlesd'association , clustering ... ) . . dans ce article , cln proposer un algorithme efficaced'extraction de itemset graduel baser sur le utilisation des treillis . . cln définissonsformellemer le notion de gradualité , ainsi que le algorithme associé . . un expérimentation mener sur jeu de donnée synthétique et réelsmontrer le intérêt de son méthode " 	Lisa Di-Jorio, Anne Laurent, Maguelonne Teisseire	2009	@lirmm.fr	1000764
400	Fouille de données dans les bases relationnelles pour l'acquisition d'ontologies riches en hiérarchies de classes	fouille de donnée dans le base relationnel pour le acquisition de ontologie riche en hiérarchie de classe  de par son caractère structurer , le base de donnée relationnellesêtre des source précieux pour le construction automatisé de ontologie . Ce-pendant , un limite persistant des approche existant être le production de onto- logie de structure calquer sur celui des schéma relationnel source . dans cetarticle , cln décrire le méthode RTAXON dont le particularité être de identifierde motif de catégorisation dans le donnée afin de produire un ontologiesplus structurer , riche en hiérarchie . le méthode formalisé combiner analyseclassique du schéma relationnel et fouiller un donnée pour le identification destructurer hiérarchique . 	Farid Cerbah	2009	@dassault-aviation.fr	1000786
401	Fusion Symbolique pour la Recommandation de Programmes Télévisées	fusion symbolique pour le recommandation de Programmes Télévisées  cln proposer un approche générique pour le fusion de informa-tion qui reposer sur le utilisation du modèle des graphe Conceptuels et le opé-ration de jointure maximal . cln valider son approche par le biais de ex- périmentation . ce expérimentation souligner le importance des heuristiquesmis en place . 	Claire Laudy, Jean-Gabriel Ganascia	2009	@thalesgroup.com, @lip6.fr	1000796
402	Générer des règles de classification par Dopage de Concepts Formels	générer un règle de classification par Dopage de Concepts Formels  le classification superviser être un tâche de fouille de donnée ( DataMining ) , qui consister à construire un classifieur à partir de un ensemble de exemplesétiqueté par un classe ( phase de apprentissage ) et ensuite prédire le classesdes nouveau exemple avec ce classifieur ( phase de classification ) . en classi-fication superviser , plusieurs approche avoir être proposer dont le approche ba-sé sur le analyse de concept Formels . le apprentissage de Concepts Formelsest baser généralement sur le structure mathématique du treillis de Galois ( outreillis de concept ) . cependant , le complexité exponentiel de génération de outreillis de Galois avoir limiter le champs de application de ce système . dans cetarticle , cln présenter plusieurs méthode de classification superviser baséessur le analyse de concept Formels . cln présenter aussi le boosting ( dopage ) de classifieur , un technique de classification innovant . enfin , cln proposonser boosting de concept formel , un nouveau méthode adaptatif qui construitseulement un partie du treillis englober le meilleur concept . ce conceptssont utiliser comme être un règle de classification . le résultat expérimen-taux réaliser avoir prouver le intérêt de le méthode proposer par rapport à cellesexistant . 	Mondher Maddouri, Nida Meddouri	2009	@gmail.com, @fst.rnu.tn	1000760
403	Graphes des liens et anti liens statistiquement valides entre les mots d'un corpus textuel : test de randomisation TourneBool sur le corpus Reuters	graphe des lien et anti lien statistiquement valide entre le mots de un corpus textuel : test de randomisation TourneBool sur le corpus Reuters  " le définition du voisinage être un élément central en fouille de donnée , et de nombreux définition avoir être avancer . . cln cll proposer ici un version statistique issue de son test de randomisation TourneBool , qui permettre , à partir de un tableau de relation binaire objet décrire  descripteur , de établir quel relation entre descripteur être devoir au hasard , et lequel ne cla être pas , sans faire de hypothèse sur le loi de répartition sous-jacent , ce être à dire en tenir compte de loi de tout type sans avoir besoin de cla spécifier . . ce test être baser sur le génération et le exploitation de un ensemble de matrice randomisé avoir le même somme marginal en ligne et colonne que le matrice de origine . . après un premier application encourageant à un corpus textuel réduit , cln avoir opérer le passage à le échelle adéquat pour traiter un corpus textuel de taille réel , comme celui des dépêche Reuters . . cln caractériser le graphe des mots de ce corpus au moyen de indicateur classique comme le coefficient de clustering , le distribution des degré et de le taille des communauté , etc. un autre caractéristique de TourneBool être que ilimp permettre aussi de dégager le " " anti lien " " entre mots , à savoir le mots qui clr éviter plus que attendre du fait du hasard . . le graphe des lien et celui des anti- lien être caractériser de le même façon . " 	Martine Cadot, Alain Lelu	2009	@univ, @loria.fr, @loria.fr	1000783
404	La carte GHSOM comme alternative à la SOM pour l'analyse exploratoire de données	le carte GHSOM comme alternatif à le SOM pour le analyse exploratoire de donnée  le objecif de ce article être de faire de le carte auto- organisatrice hiérarchique ( GHSOM ) un outil utilisable dans le cadre de un démarche de analyseexploratoire de donnée . le visualisation global être un outil indispensable pourrendre le résultat de un segmentation intelligible pour un utilisateur . Nousproposons donc différent outil de visualisation pour le GHSOM équivalent àceux de le SOM . 	Françoise Fessant, Fabrice Clérot, Pascal Gouzien	2009	@orange-ftgroup.com	1000734
405	La « créativité calculatoire » et les heuristiques créatives en synthèse de prédicats multiples	le « créativité calculatoire » et le heuristique créatif en synthèse de prédicat multiple  cln présenter un approche à ce que cln appeler le « créativitécalculatoire » , ce est-à-direr le procédé par lequel un machine pouvoir fairemontre de un certain créativité . dans ce article , cln montronsessentiellemer que le synthèse de prédicat multiple en programmationlogique inductif ( ILP ) et le synthèse de programme à partir de spécificationsformeau ( SPSF ) , deux domaine de le informatique qui clr attaquer à desproblème où le notion de créativité être central , avoir être amener à ajouter àleur formalisme de base ( le ILP pour le un , le tableau de Beth pour le autre ) tout un série de heuristique . ce article présenter un collectiond'heuristique qui être destiner à fournir au programme un forme decréativité créativitécalculatoire . dans ce présentation , le accent être plutôt mettre sur collectiond'heuristique de le ILP mais lorsque cela être possible sans de trop longsdéveloppement , cln avoir aussi présenter quelque heuristique de le SPSF . le outil indispensable de le créativité calculatoire être ce que cln appeler un'générateur de atouts'dont un spécification ( forcément informel commenous cla voir ) être fournir comme premier conclusion aux exemple décritsdans le corps de le article . 	Marta Franová, Yves Kodratoff	2009	@lri.fr, @lri.fr	1000747
406	L'Analyse Formelle de Concepts pour l'Extraction de Connaissances dans les Données d'Expression de Gènes	le analyse formel de concept pour le extraction de connaissance dans le donnée de Expression de Gènes  " le analyse formel de concept ( AFC , Ganter etWille ( 1999 ) ) être uneméthode pertinent de extraction de connaissance à partir de donnée complexesd'expression de gène ( Blachon et alection ( 2007 ) , Motameny et alection ( 2008 ) ) . . dans cepapier , cln proposer de extraire un groupe de gène partager un compor-tement similaire montrer un changement " " significatif " " à travers divers envi-ronnement biologique , servir de hypothèse à le fonction des gène . " 	Mehdi Kaytoue-Uberall, Sébastien Duplessis, Amedeo Napoli	2009	@upc.edu, @udg.edu, @idescat.net	1000793
407	Méthode de regroupement par graphe de voisinage	méthode de regroupement par graphe de voisinage  ce travail clr inscrire dans le problématique de le apprentissage non su-pervisé . dans ce cadre clr retrouver le méthode de classification automatiquenon paramétrique qui reposer sur le hypothèse que plus des individu sontproche dans le espace de représentation , plus cln avoir de chance de faire par-tie de le même classe . ce article proposer un nouveau méthode de ce type quiconsidère le proximité à travers le structure fournir par un graphe de voisinage . 	Fabrice Muhlenbach	2009	@univ-st-etienne.fr	1000782
408	Modèle de préférences contextuelles pour les analyses OLAP	modèle de préférence contextuel pour le analyse OLAP  ce article présenter un environnement pour le personnalisation desanalyses OLAP afin de réduire le charge de navigation de le utilisateur . Nousproposons un modèle de préférence contextuel qui permettre de restituer lesdonner en fonction des préférence de le utilisateur et de son contexted'analyse . 	Houssem Jerbi, Franck Ravat, Olivier Teste, Gilles Zurfluh	2009	@irit.fr	1000769
409	Modélisation des connaissances dans le cadre de bibliothèques numériques spécialisées	modélisation des connaissance dans le cadre de bibliothèque numérique spécialisé  cln présenter un application innovant de le modélisation desconnaissances au domaine des bibliothèque numérique spécialisé . cln utilisonsler spécification expert de le TEI ( Text Encoding Initiative ) pour modéliserle connaissance apporter par le chercheur qui travailler sur un archivesmanuscrit . cln montrer le limite de le TEI dans le cas de un approchediachronique du document , ce dernier impliquer le construction simultanéede structure de donnée concurrent . cln décrire un modèle qui présenteer problème et permettre de envisager un solution . enfin , cln justifier le structuresarborescent sur lequel clr baser ce modèle . 	Sylvie Calabretto, Pierre-Edouard Portier	2009	@insa-lyon.fr	1000785
410	Okmed et Wokm	ce article traiter de le problématique de le classification recouvrant ( overlapping clustering ) et proposer deux variante de le approche OKM : OKMEDet WOKM . OKMED généraliser k-médoïdes au cas recouvrir , ilimp permettre de organiserun ensemble de individu en classe non- disjoindre , à partir de un matriced distance . le méthode WOKM ( Weighted-OKM ) étendre OKM par un pondérationlocale des classe ; ce variante autoriser chaque individu à appartenir àplusieurs classe sur le base de critère différent . un expérimentation être réaliséessur un application cible : le classification de texte . cln montrer alorsque OKMED présenter un comportement similaire à OKM pour le métrique euclidien , et offrir le possibilité de utiliser un métrique plus adapté et de obtenirun meilleur performance . enfin , le résultat obtenir avec WOKM montrentun apport significatif de le pondération local des classe 	Guillaume Cleuziou	2009	@univ-orleans.fr	1000736
411	Partitionnement d'ontologies pour le passage à l'échelle des techniques d'alignement	Partitionnement de ontologie pour le passage à le échelle des technique de alignement  le alignement de ontologie être un tâche important dans le systèmesd'intégration puisque cln autoriser le prise en compte conjoint de ressourcesdécrite par un ontologie différent , en identifier un appariement entreconcept . avec le apparition de très grand ontologie dans un domaine commela médecine ou le agronomie , le technique de alignement , qui mettre souventen oeuvre des calcul complexe , clr trouver face à un défi : passer à le échelle . pour relever ce défi , cln proposer dans ce article deux méthode de partition-nement , concevoir pour prendre en compte , le plus tôt possible , le objectif de ali-gnement . ce méthode permettre de décomposer le deu ontologie à aligneren deux ensemble de bloc de taille limité et tel que le élément susceptiblesd'être apparié clr retrouver concentrer dans un ensemble minimal de bloc quiser effectivement comparé . le résultat des test effectuer avec son deuxméthode sur différent couple de ontologie montrer son efficacité . 	Fayçal Hamdi, Brigitte Safar, Haïfa Zargayouna, Chantal Reynaud	2009	@lri.fr, @univ-paris13.fr	1000787
412	RDBToOnto : un logiciel dédié à l'apprentissage d'ontologies à partir de bases de données relationnelles	RDBToOnto : un logiciel dédier à le apprentissage de ontologie à partir de base de donnée relationnel  RDBToOnto1 être un logiciel extensible qui permettre de élaborer un on-tologie précis à partir de base de donnée relationnel . le processus sup-porté être largement automatiser , de le extraction des donnée à le génération dumodèle de le ontologie et son instanciation . pour affiner le résultat , le processuspeut être orienter par un contrainte local définir interactivement . ce être aussiun cadre faciliter le mise en oeuvre de nouveau méthode de apprentissage . 	Farid Cerbah	2009	@dassault-aviation.fr	1000820
413	Regroupement des Définitions de Sigles Biomédicaux	regroupement des définition de Sigles Biomédicaux  le application présenter permettre de regrouper le définition de siglesissue des science du vivre par un mesure de proximité lexical ( approcheautomatique ) et un intervention de le expert ( approche manuel ) . 	Ousmane Djanga, Hanine Hamzioui, Mickaël Hatchi, Isabelle Mougenot, Mathieu Roche	2009		1000816
414	Résumé hybride de flux de données par échantillonnage et classification automatique	résumer hybride de flux de donnée par échantillonnage et classification automatique  " face à le grand volumétrie des donnée générer par le système informatique , le hypothèse de cla stocker en totalité avant son interrogation ne estplus possible . . un solution consister à conserver un résumé de le historique duflux pour répondre à un requête et pour effectuer de le fouille de donnée . . plusieurs technique de résumé de flux de donnée avoir être développer , tellesque le échantillonnage , le clustering , etc. selon le champagne de requête , ce résuméspeuvent être classer en deux catégorie : résumé spécialisé et résumé généraliste . . dans ce papier , cln clr intéresser aux résumé généraliste . . Notreobjectif être de créer un résumé de bon qualité , sur tout le période temporel , qui cld permettre de traiter un large panoplie de requête . . cln utiliser deuxalgorithmes : : CluStream et StreamSamp . . le idée consister à cla combiner afin detirer profit des avantage de chaque algorithme . . pour tester ce approche , nousutilisons un Benchmark de donnée réel " " KDD  99 " " . . le résultat obtenusêtre comparé à celui obtenir séparément par le deu algorithme . " 	Nesrine Gabsi, Fabrice Clérot, Georges Hébrail	2009	@telecom-paristech.fr, @orange-ftgroup.com	1000767
415	SoftJaccard : une mesure de similarité entre ensembles de chaînes de caractères pour l'unification d'entités nommées	SoftJaccard : un mesure de similarité entre ensemble de chaîne de caractère pour le unification de entité nommer  parmi lesmesure de similarité classique utilisable sur un ensemblesfigure le indice de Jaccard . dans le cadre de ce article , cln cll proposer uneextension pour comparer un ensemble de chaîne de caractère . ce mesurehybride permettre de combiner un distance entre chaîne de caractère , tel que ladistance de Levenstein , et le indice de Jaccard . cln être particulièrement adaptéepourmettre en correspondance des champs composé de plusieurs chaîne de caractère , comme par exemple , lorsque cln clr proposer de unifier un nom de entitésnommé . 	Christine Largeron, Bernard Kaddour, Maria Fernandez	2009	@univ-st-etienne.fr	1000795
416	SPAMS, une nouvelle approche incrémentale pour l'extraction de motifs séquentiels fréquents dans les Data streams	spam , un nouveau approche incrémental pour le extraction de motif séquentiel fréquent dans le Data streams  le extraction de motif séquentiel fréquent dans le datastream être un enjeu important traiter par le communauté des chercheursen fouille de donnée . plus encore que pour le base de donnée , denombreuses contrainte supplémentaire être à considérer de par le na-ture intrinsèque des stream . dans ce article , cln proposer un nouvelalgorithme en un passe : spam , baser sur le construction incrémental , avec un granularité très fin par transaction , de un automate appeler SPA , permettre le extraction des motif séquentiel dans le stream . le infor-mation du stream être apprendre à le volée , au fur et à mesure de le insertiond nouveau transaction , sans pré-traitement avoir priori . le résultat ex- périmental obtenir montrer le pertinence de le structure utiliser ainsique le efficience de son algorithme appliquer à différent jeu de donnée . 	Lionel Vinceslas, Jean-Emile Symphor, Alban Mancheron, Pascal Poncelet	2009	@univ-ag.fr, @mancheron.infos.st, @ema.fr	1000765
417	SVM incrémental et parallèle sur GPU	SVM incrémental et parallèle sur GPU  cln présenter un nouveau algorithme incrémental et parallèle deSéparateur à vaste Marge ( SVM ou Support Vector Machine ) pour laclassification de très grand ensemble de donnée en utiliser le processeur dela carte graphique ( GPUs , Graphics Processing Units ) . le SVMs et lesméthode de noyau permettre de construire un modèle avec un bonneprécision mais cln nécessiter habituellement le résolution de un programmequadratique ce qui requérir un grand quantité de mémoire et un long tempsd'exécution pour le ensemble de donnée de taille important . Nousprésentons un extension de le algorithme de Least Squares SVM ( LS-SVM ) proposer par Suykens et Vandewalle pour obtenir un algorithme incrémental etparallèle . le nouveau algorithme être exécuter sur le processeur graphique pourobteniour un bon performance à faible coût . le résultat numérique sur lesensemble de donnée de le UCI et Delve montrer que son algorithmeincrémental et parallèle être environ 70 fois plus rapide sur GPU que sur CPUet significativement plus rapide ( plus de 1000 fois ) que le algorithmesstandard tel que LibSVM , SVM-perf et CB-SVM . 	François Poulet, Thanh-Nghi Do, Van-Hoa Nguyen	2009	@irisa.fr, @telecom-bretagne.eu, @irisa.fr	1000743
418	Un algorithme stable de décomposition pour l'analyse des réseaux sociaux dynamiques	un algorithme stable de décomposition pour le analyse des réseau social dynamique  le réseau dynamique soulever un nouveau problème de analyse . un outil efficace de analyse devoir non seulement permettre de décomposerce réseau en groupe de élément similaire mais ilimp devoir aussi permettre le détectiond changement dans le réseau . cln présenter dans ce article un nouvelleapproche pour le analyse de tel réseau . ce technique être baser sur unalgorithme de décomposition de graphe en groupe chevauchant ( ou chevauchement ) . le complexité de son algorithme être O ( |E| · deg2max + - V - · log ( - V - ) ) ) . le faible sensibilité de ce algorithme aux changement structural du réseaupermet de cll détecter le modification majeur au cours du temps . 	Romain Bourqui, Paolo Simonetto, Fabien Jourdan	2009	@labri.fr, @toulouse.inra.fr	1000778
419	Un critère d'évaluation Bayésienne pour la construction d'arbres de décision	un critère de évaluation Bayésienne pour le construction de arbre de décision  cln présenter dans ce article un nouveau algorithme automatiquepour le apprentissage de arbre de décision . cln aborder le problème selon uneapproche Bayésienne en proposer , sans aucun paramètre , un expression ana-lytique de le probabilité de un arbre connaître le donnée . cln transformonsle problème de construction de le arbre en un problème de optimisation : nousrecherchons dans le espace des arbre de décision , le arbre optimum au sens ducritère Bayésien ainsi définir , ce être à dire le arbre maximum avoir posteriori ( MAP ) . le optimisation être effectuer en exploiter un heuristique de pré-élagage . Desexpérimentations comparatif sur trent base de le UCI montrer que notreméthode obtenir un performance prédictif proche de celui de le état de le arttout en être beaucoup moins complexe . 	Nicolas Voisine, Marc Boullé, Carine Hue	2009	@orange-ftgroup.com, @orange-ftgroup.com, @gfi.fr	1000740
420	Un nouvel algorithme de forêts aléatoires d'arbres obliques particulièrement adapté à la classification de données en grandes dimensions	un nouveau algorithme de forêt aléatoire de arbre oblique particulièrement adapter à le classification de donnée en grand dimension  le algorithme des forêt aléatoire proposer par Breiman permettre de ob-tenir de bon résultat en fouille de donnée comparativement à de nombreusesapproche . cependant , en ne utiliser que un seul attribut parmi un sous-ensembled'attribut tirer aléatoirement pour séparer le individu à chaque niveau de le arbre , ce algorithme perdre de le information . ceci être particulièrement pénaliser avecle ensemble de donnée en grand dimension où ilimp pouvoir exister de nom-breuson dépendance entre attribut . cln présenter un nouveau algorithme deforêts aléatoire de arbre oblique obtenir par un séparateur à vaste marge ( SVM ) . le comparaison des performance de son algorithme avec celui del'algorithme de forêt aléatoire des arbre de décision C4 . 5 et de le algorithmeSVM montrer un avantage significatif de son proposition . 	Thanh-Nghi Do, Stéphane Lallich, Nguyen-Khang Pham, Philippe Lenca	2009	@telecom-bretagne.eu, @univ-lyon2.fr, @irisa.fr	1000741
421	Un prototype cross-lingue multi-métiers : vers la Gestion Sémantique de Contenu d'Entreprise au service du Collaboratif Opérationnel	un prototype cross-lingue multi-métier : vers le Gestion Sémantique de Contenu de Entreprise au service du Collaboratif Opérationnel  le domaine « Qualité , Hygiène , sécurité et environnement » ( QHSE ) représenter à le heure actuel un vecteur de progrès majeur pourl'industrie européen . le prototype « Semantic Quality Environment » ( SQE ) introduire dans ce article viser à démontrer le validité de un architecturesémantique cross-lingue vouer à le collaboration multi-métier et multilingue , dans le cadre de un système banaliser de gestion de contenu de entreprise dédier pourl'industrie naval européen . 	Christophe Thovex, Francky Trichet	2009	@orange.fr, @univ-nantes.fr	1000809
422	Une méthode de classification supervisée sans paramètre pour l'apprentissage sur les grandes bases de données	un méthode de classification superviser sans paramètre pour le apprentissage sur le grand base de donnée  dans ce papier , cln présenter un méthode de classification super-visé sans paramètre permettre de attaquer le grand volumétrie . le méthodeest baser sur un estimateur de densité univariés optimal au sens de Bayes , sur un classifieur Bayesien naïf améliorer par un sélection de variable et unmoyennage de modèle exploiter un lissage logarithmique de le distribution aposteriori des modèle . cln analyser en particulier le complexité algorith-mique de le méthode et montrer comment cln permettre de analyser un base dedonnées nettement plus volumineux que le mémoire vif disponible . cln pré-sentir enfin le résultat obtenir lors du récent pascal Large Scale LearningChallenge , où son méthode avoir obtenir un performance prédictif de premierplan avec un temps de calcul raisonnable . 	Marc Boullé	2009	@orange-ftgroup.com	1000770
423	Une nouvelle approche pour la classification non supervisée en segmentation d'image	un nouveau approche pour le classification non superviser en segmentation de image  le segmentation des image en région être un problème crucial pourl'analyr et le compréhension des image . parmi le approche existant pourrésoudre ce problème , le classification non supervisé être fréquemment em-ployer lors de un premier étape pour réaliser un partitionnement de le espacedes intensité des pixel ( que ilimp clr agir de niveau de gris , de couleur ou de ré-ponse spectral ) . puisque cln ignorer complètement le notion de voisinageun pixel , un seconde étape de analyse spatial ( étiquetage en composantesconnexe par exemple ) être ensuite nécessaire pour identifier le région issuesde le segmentation . le non prendre en compte de le information spatial être un li-mite majeur de ce type de approche , ce qui avoir motiver un nombreux travaux où laclassification être coupler à un autre technique pour clr affranchir de ce problème . dans ce article , cln proposer un nouveau formulation de le classificationnon supervisé permettre de effectuer le segmentation des image sans faire ap-pel à un technique supplémentaire . plus précisément , cln élaborer un mé-thode itératif de type k-mean où le donnée à partitionner être le pixel lui-même ( et non plus son intensité ) et où le distance des point aux centresdes classe ne être plus euclidien mais topographique . le segmentation estalortir un processus itératif , et à chaque itération , le classe obtenir pouvoir êtreassimiler à un zone de influence dans le contexte de le morphologie mathéma-tique . ce parallèle cld permettre de bénéficier un algorithme efficace proposésdans ce domaine ( tel que celui baser sur le file de attente ) , tout en cll ajoutantle caractère itératif des méthode de classification non superviser considéréesici . cln illustrer finalement le potentiel de le approche proposer par quelquesrésultat préliminaire de segmentation sur un image artificiel . 	Sébastien Lefèvre	2009	@lsiit.u-strasbg.fr	1000745
424	Utilisation de l'analyse factorielle des correspondances pour la recherche d'images à grande échelle	utilisation de le analyse factoriel des correspondance pour le recherche de image à grand échelle  cln cln intéresser à le utilisation de le analyse factorielle des Cor-respondances ( AFC ) pour le recherche de image par le contenu dans un base dedonné de image volumineux . cln adapter le AFC , méthode originellementdéveloppé pour le Analyse des Données Textuelles ( ADT ) , aux image en utili-ser un descripteur local SIFT . en ADT , le AFC permettre de réduire le nombrede dimension et de trouver un thème . ici , le AFC cld permettre de limiter lenombre de image à examiner au cours de le recherche afin de accélérer le nombrede réponse pour un requête . pour traiter un grand base de image , cln pro- poser un version incrémental de le algorithme AFC . ce nouveau algorithmedécoupe un base de image en bloc et le charge dans le mémoire cla un aprèsl'autre . cln présenter aussi le intégration des information contextuel ( e.gès le mesure de Dissimilarité Contextuelle ( Jegou et alection , 2007 ) ) dans son nombrede recherche de image . cela améliorer considérablement le précision . cln ex- ploitons ce intégration dans deux axe : ( i ) hors ligne ( le structure de voisinageest corriger hors ligne ) et ( ie ) à le volée ( le structure de voisinage des image estcorriger au cours de le recherche sur un petit ensemble de image ) . 	Nguyen-Khang Pham, Annie Morin, Patrick Gros, Quyet-Thang Le	2009	@irisa.fr, @cit.ctu.edu.vn	1000773
425	Vers la simulation et la détection des changements des données évolutives d'usage du Web	vers le simulation et le détection des changement des donnée évolutif de usage du Web  dans le domaine des flux des donnée , le prise en compte du tempss'avère nécessaire pour le analyse de ce donnée car son distribution sous-jacentepeut changer au cours du temps . un exemple typique concerner le modèle desprofils de navigation des internaute . son objectif être de analyser le évolutiond ce profil , celui -ci pouvoir être lier au changement de effectif ou aux déplacementd cluster au cours du temps . afin de analyser le validité de son approche , cln mettre en place uneméthodologie pour le simulation des donnée de usageà partir de lequel ilimp être possible de contrôler le occurrence des changement 	Alzennyr Da Silva, Yves Lechevallier, Francisco de Assis Tenório de Carvalho	2009	@inria.fr, @cin.ufpe.br	1000800
426	Vers une utilisation améliorée de relations spatiales pour l'apprentissage de données dans les modèles graphiques	vers un utilisation améliorer de relation spatial pour le apprentissage de donnée dans le modèle graphique  cln cln intéresser dans ce article aux représentation des relationsspatiale pour le extraction de information et le modélisation des donnéesvisuel , en particulier dans le contexte de le catégorisation de image . Nousmontrons comment le prise en compte de un relation spatial entre deux élémentsentraîne le apparition de un information supplémentaire entre ce élémentset le reste de le ensemble à modéliser , ce qui être rarement exploiter explicitement . un représentation flou des relation dans unmodèle graphique être bien adaptéepour le algorithme de apprentissage utiliser actuellement et permettre de intégrerce type de information complémentaire qui concerner le absence de un interactionplutôt que son présence . cln tenter de évaluer le bénéfice de ce approchesur un problème de traitement de image . 	Isabelle Bloch, Emanuel Aldea	2009	@telecom-paristech.fr	1000772
427	Algorithmes rapides de boosting de SVM	algorithme rapide de boosting de SVM  le algorithme de boosting de Newton Support Vector Machine ( NSVM ) , Proximal Support Vector Machine ( PSVM ) et Least-Squares Support Vector Machine ( LS-SVM ) que cln présenter viser à le classification de très grand ensemble de donnée sur un machine standard . cln présenter un extension des algorithme de NSVM , PSVM et LS-SVM , pour construire un algorithme de boosting . A ce fin , cln avoir utiliser un terme de régularisation de Tikhonov et le théorème Sherman-Morrison-Woodbury pour adapter ce algorithme au traitement de ensemble de donnée avoir un grand nombre de dimension . cln cla avoir ensuite étendre par construction de algorithme de boosting de NSVM , PSVM et LS-SVM afin de traiter un donnée avoir simultanément un grand nombre de individu et de dimension . le performance des algorithme être évaluer sur un grand ensemble de donnée de le UCI comme Adult , KDDCup 1999 , Forest Covertype , Reuters- 21578 et RCV1-binary sur un machine standard ( PC-P4 , 2,4 GHz , 1024 méga-octet RAM ) . 	Thanh-Nghi Do, Jean-Daniel Fekete, François Poulet	2008		1000617
428	Analyse exploratoire d'opinions cinématographiques : co-clustering de corpus textuels communautaires	analyse exploratoire de opinion cinématographique : co- clustering de corpus textuel communautaire  le site communautaire être un endroit privilégié pour clr exprimer et publier un opinion . le site www.flixster.com être un exemple de site participatif sur lequel clr rassembler plus de 20 million de cinéphile qui partager un commentaire sur le film que cln avoir ou non aimer . explorer le contenu autoproduire être un challenge pour qui vouloir comprendre le attente des internaute . par un méthode de apprentissage non supervisé , cln montrer que ilimp être possible de mieux comprendre le vocabulaire utiliser pour décrire un opinion . en particulier , grâce à un méthode de co- clustering , cln montrer que un rapprochement pouvoir être faire entre un film particulier sur le base de le usage de un vocabulaire particulier . le analyse des résultat pouvoir conduire à retrouver un certain typologie de film ou encore un rapprochement entre film . ce étude pouvoir être complémentaire avec un analyse linguistique des corpus , ou encore être exploiter dans un contexte applicatif de recommandation de contenu multimédia . 	Damien Poirier, Cécile Bothorel, Marc Boullé	2008		1000654
429	Apport des traitements morpho-syntaxiques pour l'alignement des définitions par une classification SVM	apport des traitement morpho- syntaxique pour le alignement des définition par un classification SVM  ce article proposer un méthode de alignement automatique de définition destiner à améliorer le fusion entre un terminologie spécialisé et un vocabulaire médical généraliste par un classifieur de type SVM ( Support Vecteur Machine ) et un représentation compact et pertinent de un couple de définition par concaténation de un ensemble de mesure de similarité , afin de tenir compte de son complémentarité , auquelle cln ajouter le longueur de chacun des définition . Trois niveau syntaxique avoir être investiguer . le modèle fonder sur un apprentissage à partir un groupe nominal de type Noms-Adjectifs aboutir aux meilleur performance . 	Laura Diosan, Alexandrina Rogozan, Jean-Pierre Pécuchet	2008		1000582
430	Approche d'annotation automatique des événements	approche de annotation automatique des événement  " quotidiennement , plusieurs agence de presse publier un millier de article contenir plusieurs événement de tout sorte ( politiques , économique , culturel , etc. ) . . le preneur de décision , clr trouver face à ce grand nombre de événement dont seulement quelque un cla concerner . . le traitement automatique de tel événement devenir de plus en plus nécessaire . . pour cela , cln proposer un approche , qui clr baser sur le apprentissage automatique , et qui permettre de annoter le article de presse pour générer un résumé automatique contenir le principal événement . . cln avoir valider son approche par le développement du système " " AnnotEv " " . " 	Rim Faiz, Aymen Elkhlifi	2008		1000554
431	Approche hybride de classification à base de treillis de Galois: application à la reconnaissance de visages	approche hybride de classification à base de treillis de Galois : application à le reconnaissance de visage  le recherche dans le domaine de le reconnaissance de visage profiter un solution obtenir dans le domaine de le apprentissage automatique . le problème de classification de visage pouvoir être considérer comme un problème de apprentissage superviser où le exemple de apprentissage être le visage étiqueté . son article introduire dans ce contexte un nouveau approche hybride de classification qui utiliser le paradigme de apprentissage automatique superviser . ainsi , en clr baser sur le fondement mathématique des treillis de Galois et son utilisation pour le classification superviser , cln proposer un nouveau algorithme de classification baptiser CITREC ainsi que son application pour le reconnaissance de visage . le originalité de son approche provenir de le combinaison de le analyse formel de concept avec le approche de classification superviser à inférence bayésien ou à plus proche voisins . un validation expérimental être décrire sur un benchmark du domaine de le reconnaissance de visage . 	Yahya Slimani, Cherif Chiraz Latiri, Brahim Douar	2008		1000618
432	Approches de type n-grammes pour l'analyse de parcours de vie familiaux	approche de type n-gramme pour le analyse de parcours de vie familial  ce article porter sur le analyse de parcours de vie représenter sous forme de séquence de événement . plus spécifiquement , cln examiner le possibilité de exploiter un codage de type n-gramme de ce séquence pour cll extraire un connaissance . en fait , compter tenir de le simultanéité de certain événement , un procédure strict de n-gramme comme cln pouvoir par exemple cla appliquer sur un texte , ne être pas applicable ici . cln discuter divers alternatif qui clr avérer finalement plus proche de le fouille de séquence fréquent . le concept discuter être illustré sur un donnée de le enquête biographique rétrospectif réaliser par le Panel suisse de ménage en 2002 . enfin , cln préciser sur quel aspect le approche proposer pouvoir apporter un éclairage complémentaire utile par rapport à un autre technique plus classique de analyse exploratoire de parcours de vie . 	Matthias Studer, Alexis Gabadinho, Nicolas S. Müller, Gilbert Ritschard	2008		1000639
433	Assignation automatique de solutions à des classes de plaintes liées aux ambiances intérieures polluées	assignation automatique de solution à un classe de plainte lier aux ambiance intérieur polluer  cln présenter dans ce article un système informatique pour le traitement des plainte en lien avec un situation de pollution domestique écrire en français . après le construction automatique de un base de scenario de plainte , un module de recherche apparier le plainte à traiter à le thématique de le plainte le plus similaire . enfin , ilimp clr agir de assigner au problème courir le solution correspondant au scénario de pollution auquel être affecter le plainte pertinent . cln montrer ici le intérêt de le introduction dans le appariement des texte de le aspect sémantique gérer par un dictionnaire généraliste de synonyme et en quoi ilimp ne être pas réalisable pour son problème particulier de construire un ontologie . 	Zoulikha Heddadji, Nicole Vincent, Séverine Kirchner, Georges Stamon	2008		1000656
434	Binary Block GTM : Carte auto-organisatrice probabiliste pour les grands tableaux binaires	Binary Block GTM : carte auto- organisatrice probabiliste pour le grand tableau binaire  ce papier présenter un modèle génératif et son estimation permettre le visualisation de donnée binaire . son approche être baser sur un modèle de mélange de loi de Bernoulli par bloc et le carte de Kohonen probabiliste . le méthode obtenir clr montrer à le fois parcimonieux et pertinent en pratique . 	Rodolphe Priam, Mohamed Nadif, Gérard Govaert	2008		1000614
435	Cas d'utilisation réelle de Nautilus : calculs d'indicateurs chez un opérateur télécom	cas de utilisation réel de Nautilus : calcul de indicateur chez un opérateur télécom  Nautilus être un logiciel de analyse de base de donnée . le but de ce application être de généraliser le utilisation de donnée client au sein des entreprise . cln faciliter le accès aux donnée en permettre de visualiser et manipuler le donnée du SGBD sous forme de concept métier . cln inclure un générateur de requête SQL et un outil de gestion de tâche désigner pour le agrégation de grand volume de donnée . le principe de fonctionnement être baser sur le enchaînement de phase permettre le création des donnée de analyse : importation des métadonné du SGBD ; construction de un dictionnaire de un concept métier ; spécification des champs à calculer . le différent traitement tel que le jointure et le alimentation des table être optimiser afin de rendre le application utilisable sur un SGBD de entreprise 	Adrien Schmidt, Serge Fantino	2008		1000601
436	Classification adaptative de séries temporelles : application à l'identification des gènes exprimés au cours du cycle cellulaire	classification adaptatif de série temporel : application à le identification des gène exprimer au cours du cycle cellulaire  ce travail clr inscrire dans le cadre de le étude de le division cellulaire assurer le prolifération des cellule . un meilleur compréhension de ce phénomène biologique nécessiter le identification des gène caractériser chaque phase du cycle cellulaire . le procédé de identification être généralement baser sur un ensemble de gène dire gène de référence , sélectionner expérimentalement et considérer comme caractériser le phase du cycle cellulaire . le niveau de expression des gène étudier être mesurer durant le cycle de le division cellulaire et permettre de construire un profil de expression . chaque gène étudier être affecter à le phase du cycle cellulaire correspondre au groupe de gène de référence le plus similaire . ce approche classique souffrir de deux limite . de un part le mesure de proximité le plus couramment utiliser entre profil de expression de gène être baser sur le écart en valeur sans tenir compte de le forme des profil . de autre part , dans le littérature , ilimp ne cll avoir pas consensus quant à le ensemble des gène de référence à considérer . dans ce article , son but être de proposer un classification adaptatif , baser sur un indice de dissimilarité inclure le proximité en valeur et en forme des profil de expression de gène , permettre de identifier le phase de expression des gène étudier , et de présenter un nouveau ensemble de gène de référence valider par un connaissance biologique . 	Alpha Diallo, Ahlame Douzal-Chouakria, Françoise Giroud	2008		1000637
437	Clustering en haute dimension par accumulation de clusterings locaux	Clustering en haut dimension par accumulation de clustering local  " le clustering être un tâche fondamental de le fouille de donnée . . ce dernier année , le méthode de type cluster ensemble avoir être le objet de un attention soutenir . . ilimp clr agir de agréger plusieurs clustering de un jeu de donnée afin de obtenir un clustering " " moyen " " . . le clustering individuel pouvoir être le résultat de différent algorithme . . ce méthode être particulièrement utile lorsque le dimensionalité des donnée ne permettre pas aux méthode classique baser sur le distance et-ou le densité de fonctionner correctement . . dans ce article , cln proposer un méthode pour obtenir un clustering individuel à faible coût , à partir de projection partiel du jeu de donnée . . cln évaluer empiriquement son méthode et le comparon à trois méthode de différent type . . cln constater que cln donner un résultat sensiblement supérieur aux autre . " 	Marc-Ismaël Akodjènou-Jeannin, Kavé Salamatian, Patrick Gallinari	2008		1000612
438	Clustering Visuel Semi-Supervisé pour des systèmes en coordonnées en étoiles 3D	Clustering Visuel Semi-Supervisé pour un système en coordonnée en étoile 3D  dans ce article , cln proposer un approche qui combiner le méthode statistique avancer et le flexibilité des approche interactif manuel en clustering visuel . cln présenter le interface Semi-Supervised Visual Clustering ( SSVC ) . son contribution principal être le apprentissage de un métrique de projection optimal pour le visualisation en coordonnée en étoile ainsi que pour le extension 3D que cln avoir développer . le métrique de distance de projection être apprendre à partir un retour de le utilisateur être en terme de similarité  dissimilarité entre le item , soit par le annotation direct . le interface SSVC permettre , de plus , un utilisation hybride dans lequel un ensemble de paramètre être manuellement fixer par le utilisateur tandi que le autre paramètre être déterminer par un algorithme de distance optimal . 	Loïc Lecerf, Boris Chidlovskii	2008		1000559
439	Co-classification sous contraintes par la somme des résidus quadratiques	Co- classification sous contrainte par le somme des résidu quadratique  " dans un nombreux application , un co- classification être plus facile à interpréter que un classification mono- dimensionnel . . ilimp clr agir de calculer un bi-partition ou collection de co- cluster : chaque co- cluster être un groupe de objet associer à un groupe de attribut et le interprétation pouvoir clr appuyer naturellement sur ce association . . pour exploiter le connaissance du domaine et ainsi améliorer le pertinence des partition , plusieurs méthode de classification sous contrainte avoir être proposer pour le cas mono- dimensionnel , e.g. , le exploitation de contrainte " " must-link " " et " " must-link " " . . cln considérer ici le co- classification sous contrainte avec le gestion de tel contrainte étendre aux dimension des objet et des attribut , mais aussi le expression de contrainte de contiguité dans le cas de domaine ordonner . . cln proposer un algorithme itératif qui minimiser le somme des résidu quadratique et permettre le exploitation actif des contrainte spécifier par le analyste . . cln montrer le valeur ajouté de ce type de extraction sur deux application en analyse du transcriptome . " 	Ruggero G. Pensa, Jean-François Boulicaut	2008		1000665
440	Conception de systèmes d'information spatio-temporelle adaptatifs avec ASTIS	conception de système de information spatio- temporel adaptatif avec ASTIS  le avancée technologique récent du Web et du sans fil , conjuguer au succès des application spatialiser grand public , être àl'origine de un accès accroître aux système de information spatio- temporel ( SIST ) par un grand diversité de utilisateur , munir des dispositif de accèset dans un contexte de utilisation varié . adapter ce système à le utilisateurdevient donc un nécessité , un gage de utilisabilité et de pérennité . ce articleprésente un approche générique pour le conception et le génération desystème de information spatio- temporel adapter à le utilisateur , appeléASTIS . asti offrir un modalité général de mise en oeuvre del'adaptation à le utilisateur , viser tant le contenu que le présentation desapplications . cln permettre aux concepteur de intégrer ce modalitésd'adaptation dans un application traitant des donnée spatio- temporel . afin de définir le besoin et type de adaptation propre à son application , ilsuffire aux concepteur de créer un modèle conceptuel , par spécialisation etinstanciation des modèle offrir par son architecture 	Bogdan Moisuc, Jérôme Gensel, Hervé Martin	2008	@imag.fr	1001232
441	Découverte de motifs séquentiels et de règles inattendus	découverte de motif séquentiel et de règle inattendu  le travaux autour de le extraction de motif séquentiel clr être particulièrement focaliser sur le définition de approche efficace pour extraire , en fonction de un fréquence de apparition , un corrélation entre un élément dans un séquence . même si ce critère de fréquence être déterminant , le décideur être également de plus en plus intéresser par un connaissance qui être représentatif de un comportement inattendu dans ce donnée ( erreur dans le donnée , fraude , nouveau niche , ... ) . dans ce article , cln introduire le problème de le détection de motif séquentiel inattendu par rapport aux croyance du domaine . cln proposer le approche USER dont le objectif être de extraire le motif séquentiel et le règle inattendu dans un base de séquence . 	Dong (Haoyuan) Li, Anne Laurent, Pascal Poncelet	2008		1000641
442	Délestage pour l'analyse multidimensionnelle de flux de données	délestage pour le analyse multidimensionnel de flux de donnée  dans le contexte de le gestion de flux de donnée , le donnée entrer dans le système à son rythme . un mécanisme de délestage être à mettre en place pour que un tel système pouvoir faire face aux situation où le débit des donnée dépasser son capacité de traitement . le lien entre réduction de le charge et dégradation de le qualité des résultat devoir alors être quantifier . dans ce article , cln clr placer dans le cas où le système être un cube de donnée , dont le structure être connaître avoir priori , alimenter par un flux de donnée . cln proposer un mécanisme de délestage pour le situation de surcharge et quantifier le dégradation de le qualité des résultat dans le cellule du cube . cln exploiter le inégalité de Hoeffding pour obtenir un borner probabiliste sur le écart entre le valeur attendre et le valeur estimer . 	Sylvain Ferrandiz, Georges Hébrail	2008		1000580
443	Détection de groupes atypiques pour une variable cible quantitative	détection de groupe atypique pour un variable cible quantitatif  " un tâche important en analyse des donnée être le compréhension de comportement inattendu ou atypique de groupe de individu . . Quelles être le catégorie de individu qui gagner de particulièrement fort salaire ou au contraire , quelles être celui qui avoir de très faible salaire ? ? cln présenter le problème de extraction de tel groupe atypique vis-à-vis de un variable cible quantitatif , comme par exemple le variable " " salaire " " , et plus particulièrement pour le faible et fort valeur de un intervalle déterminer par le utilisateur . . ilimp clr agir donc de rechercher un conjonction de variable dont le distribution différer significativement de celui de le ensemble de apprentissage pour le faible et fort valeur de le intervalle de ce variable cible . . un adaptation de un mesure statistique existant , le intensité de inclination , cln permettre de découvrir de tel groupe atypique . . ce mesure cld libérer de le étape de transformation des variable quantitatif , à savoir le étape de discrétisation suivre de un codage disjonctif complet . . cln proposer donc un algorithme de extraction de tel groupe avec un règle de élagage pour réduire le complexité du problème . . ce algorithme avoir être développer et intégrer au logiciel de extraction de connaissance WEKA . . cln terminer par un exemple de extraction sur le base de donnée IPUMS du bureau de recensement américain . " 	Sylvie Guillaume, Florian Guillochon, Michel Schneider	2008		1000627
444	Discretization of Continuous Features by Resampling	le arbre de décision être largement utiliser pour générer un classificateur à partir de un ensemble de donnée . le processus de construction être un partitionnement récursif de le ensemble de apprentissage . dans ce contexte , le attribut continu être discrétiser . ilimp clr agir alors , pour chaque variable à discrétiser de trouver le ensemble des point de coupure . dans ce papier cln montrer que le recherche des ce point de coupure par un méthode de ré-échantillonnage , comme le BOOTSTRAP conduire à un meilleur résultat . cln avoir tester ce approche avec le méthode principal de discrétisation comme MDLPC , FUSBIN , FUSINTER , CONTRAST , Chi-Merge et le résultat être systématiquement meilleur en utiliser le bootstrap . cln exposer ce principal résultat et ouvron de nouveau piste pour le construction de arbre de décision . 	Taimur Qureshi, Djamel Abdelkader Zighed	2008		1000622
445	Echantillonnage adaptatif de jeux de données déséquilibrés pour les forêts aléatoires	Echantillonnage adaptatif de jeu de donnée déséquilibré pour le forêt aléatoire  dans nombre de application , le donnée présenter un déséquilibre entre le classe . le prédiction être alors souvent détériorer pour le classe minoritaire . pour contourner cela , cln proposer un échantillonnage guider , lors un itération successif de un forêt aléatoire , par le besoin de le utilisateur . 	Elie Prudhomme, Julien Thomas, Pierre-Emmanuel Jouve	2008		1000588
446	Echantillonnage pour l'extraction de motifs séquentiels : des bases de données statiques aux flots de données	Echantillonnage pour le extraction de motif séquentiel : un base de donnée statique aux flot de donnée  " depuis quelque année , le communauté fouiller de donnée clr être intéresser à le problématique de le extraction de motif séquentiel à partir un grand base de donnée en considérer comme hypothèse que le donnée pouvoir être charger en mémoire central . . cependant , ce hypothèse être mettre en défaut lorsque le base manipuler être trop volumineux . . dans ce article , cln étudier un technique de échantillonnage baser sur un réservoir et montrer comment ce dernier être particulièrement bien adapter pour résumer un gros volume de donnée . . cln cld intéresser ensuite à le problématique plus récent de le fouille sur un donnée disponible sous le forme de un flot continu et éventuellement infini ( " " dater stream " " ) . . cln étendre le approche de échantillonnage à ce nouveau contexte et montrer que cln être à même de extraire un motif séquentiel de flot tout en garantir le taux de erreur sur le résultat . . le différent expérimentation mener confirmer son résultat théorique . " 	Chedy Raïssi, Pascal Poncelet	2008		1000567
447	Echantillonnage spatio-temporel de flux de données distribués	Echantillonnage spatio- temporel de flux de donnée distribuer  ce dernier année , être apparaître de nombreux application , utiliser un donnée potentiellement infini , provenir de façon continuer de capteur distribuer . cln retrouver ce capteur dans un domaine aussi divers que le météorologie ( établir un prévision ) , le domaine militaire ( surveiller un zone sensible ) , le analyse des consommation électrique ( transmettre un alerte en cas de consommation anormal ) , ... pour faire face à le volumétrie et au taux de arrivée des flux de donnée , un traitement être effectuer " à le volée " sur le flux . en particulier , si le système ne être pas assez rapide pour traiter tout le donnée de un flux , ilimp être possible de construire un résumé de le information . ce communication avoir pour objectif de faire un premier point sur son travaux de échantillonnage dans un environnement de flux de donnée fortement distribuer . son approche être baser sur le théorie des sondage , le analyse des donnée fonctionnel et le gestion de flux de donnée . ce approche être illustrer par un cas réel : celui des mesure de consommation électrique 	Raja Chiky, Jérôme Cubillé, Alain Dessertaine, Georges Hébrail, Marie-Luce Picard	2008		1000569
448	Étude comparative de deux approches de classification recouvrante : MOC vs. OKM	étude comparatif de deux approche de classification recouvrant : MOC vs OKM  le classification recouvrant désigner le technique de regroupement de donnée en classe pouvoir clr intersecter . particulièrement adapter à un domaine de application actuel ( e.gès recherche de information , Bioinformatique ) quelque modèle théorique de classification recouvrant avoir être proposer très récemment parmi lequel le modèle MOC ( Banerjee et alection ( 2005ma ) ) utiliser le modèle de mélange et le approche OKM ( Cleuziou ( 2007 ) ) consister à généraliser le algorithme des k-moyenne . le présent étude viser de un part à étudier le limite théorique et pratique de ce deu modèle , et de autre part à proposer un formulation de le approche OKM en terme de modèle de mélange gaussiens , laisser ainsi entrevoir un perspective intéressant quer à le variabilité des schéma de recouvrement envisageable . 	Guillaume Cleuziou, Jacques-Henri Sublemontier	2008		1000666
449	Étude de l'interaction entre variables pour l'extraction des règles d'influence	étude de le interaction entre variable pour le extraction des règle de influence  ce article présenter un méthode efficace pour le extraction de règle de influence quantitatif positif et négatif . ce règle de influence introduire un nouveau sémantique qui viser à faciliter le analyse de un volume important de donnée . ce sémantique fixer le direction de le règle entre deux variable en positionner , au préalable , le un comme être le influent et le autre comme être le influer . cln permettre , de ce fait , de exprimer le nature de le influence : positif , en maximiser le nombre de élément en commun ou négatif , en maximiser le nombre de élément qui violent le influer . son approche clr appuyer sur un stratégie qui comporter cinuelque étape dont dlui exécuter en parallèle . ce deu étape constituer le étape clé de son approche . le premier combiner un méthode de élagage et de regroupement tabulaire baser sur le tableau de contingence . ce dernier construire et classe le zone potentiellement intéressant . le seconde , injecter le sémantique et évaluer le degré de influence que produire le introduction de un nouveau variable sur un ensemble de variable en utiliser un nouveau mesure de intérêt , le Influence . ce étape venir affiner le résultat de le premier étape , et permettre de clr focaliser sur un zone valide par rapport aux contrainte spécifier . enfin , un système de règle de influence juger intéressant être construire baser sur le juxtaposition des résultat des deu étape clé de son approche . 	Leila Nemmiche Alachaher, Sylvie Guillaume	2008		1000629
450	Évaluation des critères asymétriques pour les arbres de décision	évaluation des critère asymétrique pour le arbre de décision  pour construire un arbre de décision sur un donnée déséquilibré , un auteur avoir proposer un mesure de entropie asymétrique . le problème de le évaluation de ce arbre clr poser ensuite . ce article proposer de évaluer le qualité de arbre de décision baser sur un mesure de entropie asymétrique . 	Gilbert Ritschard, Simon Marcellin, Djamel Abdelkader Zighed	2008		1000587
451	ExpLSA : utilisation d'informations syntaxico-sémantiques associées à LSA pour améliorer les méthodes de classification conceptuelle	ExpLSA : utilisation de information syntaxico- sémantique associer à LSA pour améliorer le méthode de classification conceptuel  le analyse sémantique latent ( LSA - Latent Semantic Analysis ) être aujourde hui utiliser dans un nombreux domaine comme le modélisation cognitif , le application éducatif mais aussi pour le classification . le approche présenter dans ce article consister à ajouter un information grammatical à LSA . différent méthode pour exploiter ce information grammatical être étudier dans le cadre de un tâche de classification conceptuel . 	Nicolas Béchet, Mathieu Roche, Jacques Chauché	2008		1000658
452	Extraction d'itemsets compacts	extraction de itemsets compact  le extraction de itemsets fréquent être un sujet majeur de le ECD et son but être de découvrir un corrélation entre le enregistrement de un ensemble de donnée . cependant , le support être calculer en fonction de le taille de le base dans son intégralité . dans ce article , cln montrer que ilimp être possible de prendre en compte des période difficile à déceler dans le organisation des donnée et qui contenir un itemsets fréquent sur ce période . cln proposer ainsi le définition des itemsets compact , qui représenter un comportement cohérent sur un période spécifique et cln présenter le algorithme DEICO qui permettre son découverte . 	Bashar Saleh, Florent Masseglia	2008		1000628
453	Extraction de Motifs Séquentiels Multidimensionnels Clos sans Gestion d'Ensemble de Candidats	extraction de motif Séquentiels Multidimensionnels Clos sans Gestion de ensemble de Candidats  le extraction de motif séquentiel permettre de découvrir un corrélation entre événement au cours du temps . introduire plusieurs dimension de analyse , le motif séquentiel multidimensionnel permettre de découvrir un motif plus pertinent . mais le nombre de motif obtenir pouvoir devenir très important . ce être pourquoi cln proposer , dans ce article , de définir un représentation condensé garantir sans perte de information : le motif séquentiel multidimensionnel clos extrait ici sans gestion de ensemble de candidat . 	Marc Plantevit, Anne Laurent, Maguelonne Teisseire	2008		1000642
454	Extraction d'un modèle numérique de terrain à partir de photographies par drone	extraction de un modèle numérique de terrain à partir de photographie par drone  dans le suivi et le modélisation de le érosion en montagne , lareprésentation fin du relief être un composante important . en effet , laconnaissance un zone de concentration des eau , notamment à traversl'apparition de rigole élémentaire , être fondamental pour bien décrire lesconnectiviter entre le zone de mobilisation des sédiment sur le versant et leréseau hydrographique stabiliser . le résolution au sol permettre par lesphotographie aérien classique ne permettre pas de accéder à unereprésentation 3.D. suffisamment fin des ravine élémentaire . cln testonsl'utilisation de photographie stéréoscopique à résolution centimétrique prisesà bas altitude par un drone pour obtenir un MNT précis . le question majeureconcerne le règle à suivre pour un meilleur compromis entre précision etfacilité de élaboration , et le évaluation de le importance relative de chaque étapesur le qualité final de le restitution . le zone de étude être situer dans lesBadlands de Draix ( Alpes de haut Provence ) . 	Andres Jacome, Christian Puech, Damien Raclot, Jean-Stéphane Bailly, Bruno Roux	2008	@teledetection.fr, @supagro.inra.fr, @cemagref.fr	1001233
455	Extraction et exploitation des annotations contextuelles	extraction et exploitation des annotation contextuel  dans le perspective de offrir un web sémantique , un travaux avoir chercher à automatiser le extraction des annotation sémantique à partir de texte pour représenter au mieux le sémantique que viser à transmettre un page web . dans ce article cln proposer un approche de extraction des annotation qui représenter le plus précisément possible le contenu de un document . cln proposer de prendre en compte le notion de contexte modéliser par un relation contextuel émaner , à le fois , de le structure et de le sémantique du texte . 	Noureddine Mokhtari, Rose Dieng-Kuntz	2008		1000551
456	FIASCO : un nouvel algorithme d'extraction d'itemsets fréquents dans les flots de données	fiasco : un nouveau algorithme de extraction de itemsets fréquent dans le flot de donnée  cln présenter dans ce article un nouveau algorithme permettre le construction et le mise à jour incrémental du FIA : fiasco . son algorithme effectuer un seul passage sur le donnée et permettre de prendre en compte le nouveau batche , itemsedre par itemset et pour chaque itemset , item par item . 	Lionel Vinceslas, Jean-Emile Symphor, Alban Mancheron, Pascal Poncelet	2008		1000603
457	Fouille de données audio pour la classification automatique de mots homophones	fouille de donnée audio pour le classification automatique de mots homophone  ce article présenter un contribution à le modélisation acoustique des mots à partir un grand corpus oral , faire appel aux technique de fouille de donnée . en transcription automatique , de nombreux erreur concerner un mots fréquent homophone . Deux paire de mots ( quasi- ) homophone à ou avoir et et ou être être sélectionner dans le corpus , pour lequel être définir et examiner 41 descripteur acoustique permettre potentiellement de cla distinguer . 17 algorithme de classification , mettre à le épreuve pour le discrimination automatique de ce deu paire de mots , donner en moyenne 77 \pourcent de classification correct sur le 5 meilleur algorithme . en réduire le nombre de descripteur à 10 ( sélectionner par le algorithme le plus performant ) , le résultat de classification rester proche du résultat obtenir avec 41 attribut . ce comparaison mettre en évidence le caractère discriminant de certain attribut , qui pouvoir venir enrichir à le fois le modélisation acoustique et son connaissance des prononciation de le oral . 	Rena Nemoto, Martine Adda-Decker, Iona Vasilescu	2008		1000633
458	Génération de séquence résumé par une nouvelle approche basée sur le Soft Computing	génération de séquence résumer par un nouveau approche baser sur le Soft Computing  ce article proposer un approche de abstraction des séquence vidéo baser sur le soft computing . Etant donner un longueur cible du condensé vidéo , cln chercher le segment vidéo qui couvrir le maximum du visuel de le vidéo original en respecter le longueur du condensé . 	Youssef Hadi, Rachid El Meziane, Rachid Oulad Haj Thami	2008		1000586
459	Gradients de prototypicalité conceptuelle et lexicale	gradient de prototypicalité conceptuel et lexical  longtemps le ontologie avoir être limiter à un domaine scientifique et technique , favoriser au passage le essor du concept de « connaissance universel et objectif » . avec le émergence et le engouement actuel pour le science cognitif , coupler à le application des ontologie à un domaine relatif aux science Humaines et Sociales ( SHS ) , le subjectivité des connaissance devenir un dimension incontournable qui clr devoir de être intégrer et prendre en compte dans le processus de ingénierie ontologique ( IO ) . le objectif de son travaux être de développer le notion de ontologie Pragmatisée Vernaculaire de Domaine ( OPVD ) . le principe sous-jacent à un tel ressource consister à considérer que chaque ontologie être non seulement propre à un domaine , mais également à un endogroupe donner , doter de un pragmatique qui être fonction tant de le culture que de le apprentissage et de le état émotionnel du dire endogroupe . ce pragmatique , qui traduire un processus de appropriation et de personnalisation de le ontologie considérer , être qualifier à le aide de deux mesure : un gradient de prototypicalité conceptuel et un gradient de prototypicalité lexical 	Xavier Aimé, Frédéric Fürst, Pascale Kuntz, Francky Trichet	2008		1000564
460	HyperSmooth : calcul et visualisation de cartes de potentiel interactives	HyperSmooth : calcul et visualisation de carte de potentiel interactif  le groupe de recherche Hypercarte proposer HyperSmooth , un nouveau outil cartographique pour le analyse spatial de phénomènessocial économique mettre en oeuvre un méthode de calcul depotentiel . le objectif être de pouvoir représenter de façon continu et enchangeant de échelle de analyse un information statistiqueéchantillonner sur tout sorte de maillage , régulier ou non . le défitechnologique être de fournir un outil accessible sur le Web , interactifet rapide , ceci malgré le coût élevé du calcul , et qui assurer laconfidentialité un donnée . cln présenter son solution baser surune architecture client serveur : le serveur calculer le carte depotentiel en utiliser un technique de optimisation particulier , alorsque le client être en charge de le visualisation et du paramétrage del'analyr , et le deu party communiquer via un protocole Web . 	Christine Plumejeaud, Jean-Marc Vincent, Claude Grasland, Jérôme Gensel, Hélène Mathian, Serge Guelton, Joël Boulier	2008	@imag.fr, @parisgeo.cnrs.fr	1001230
461	Industrialiser le data mining : enjeux et perspectives	industrialiser cla dater mining : enjeu et perspective  le informatique décisionnel être un secteur en fort croissance dans tout le entreprise . le technique classique ( reporting simple & Olap ) , qui clr intéresser essentiellement à présenter le donnée , être aujourde hui très largement déployer . le dater mining commencer à clr répandre , apporter un capacité de prévision à fort valeur ajouté pour le entreprise le plus compétitif . ce développement être rendre possible par le disponibilité croissant de masse de donnée important et le puissance de calcul dorénavant disponible . cependant , le mise en IJuvre industriel des projet de data mining poser un contrainte tant théorique ( quel algorithme utiliser pour produire un modèle de analyse exploiter un millier de variable pour un million de exemple ) que opérationnel ( comment mettre en production et contrôler le bon fonctionnement de centaine de modèle ) . cln présenter ce contrainte issir des besoin des entreprise ; cln montrer comment exploiter un résultat théorique ( provenir un travaux de Vladimir Vapnik ) pour produire un modèle robuste ; cln donner un exemple de application réel en gestion de le relation client et en analyse de qualité . cln conclure en présenter quelque perspective ( utilisation du texte et des réseau social ) . 	Françoise Fogelman-Soulié	2008		1000548
462	Intégration de contraintes dans les cartes auto-organisatrices	intégration de contrainte dans le carte auto- organisatrice  le travail présenter dans ce article décrire un nouveau version des carte topologique que cln appeler CrTM . ce version consister à modifier le algorithme de Kohonen de tel façon à ce que ilimp contrôler le violation des contrainte lors de le construction de le topologie de le carte . cln valider son approche sur un donnée connaître de le littérature en utiliser un contrainte artificiel . un validation supplémentaire être faire sur un donnée réel issir de image médical pour le classification des mélanome chez le humain sous contrainte médical . 	Anouar Benhassena, Khalid Benabdeslem, Fazia Bellal, Alexandre Aussem, Bruno Canitia	2008		1000663
463	Intégration de la structure dans un modèle probabiliste de document	intégration de le structure dans un modèle probabiliste de document  en fouille de texte comme en recherche de information , différent modèle , de type probabiliste , vectoriel ou booléen , clr être révéler bien adapter pour représenter un document textuel mais , ce modèle présenter le inconvénient de ne pas tenir compte de le structure du document . or le plupart des information disponible aujourde hui sur Internet ou dans un base documentaire être fortement structurer . dans ce article , cln proposer de étendre le modèle probabiliste de représentation des document de façon à tenir compte du poids de un certain catégorie de élément structurel : le balise représenter le structure logique et le structure de mise en forme . ce modèle avoir être évaluer à le aide de le collection de le campagne de évaluation INEX 2006 . 	Mathias Géry, Christine Largeron, Franck Thollard	2008		1000660
464	Interprétation automatique d'itinéraires à partir d'un corpus de récits de voyages pilotée par un usage pédagogique.	interprétation automatique de itinéraire à partir de un corpus de récit de voyage piloter par un usage pédagogique .  un large corpus à fort ancrage territorial devenir disponible sousforme numérique dans le médiathèque et plus particulièrement dans le médiathèquesde dimension régional . le défi que offrir ce giga-octet octet de documentsbrut être énorme en terme de traitement automatique des contenu . cln proposer dans ce article deu modèle computationnel et un méthodecomplète permettre de réaliser un traitement automatique afin de extraire un itinérairesdans des texte relater un récit de voyage . le premier modèle être unmodèle des attendu . ilimp clr intéresser au concept de itinéraire et adopter le point devue du pédagogue et faire intervenir très tôt le usages envisager . le deuxièmemodèle être un modèle de extraction , ilimp permettre de modéliser le expression du itinérairesdans des texte du genre récit de voyage . cln proposer alors uneméthoun automatique pour : de un part extraire et interpréter automatiquementle déplacement de un récit et de autre part passer un déplacement à le itinéraire , ce est-à-direr alimenter de manière automatique le modèle des attendu à partir unmodèle de extraction . cln montrer également comment le itinéraire extraitsintervenir soit dans le phase de construction de activité pédagogique soitdirectement comme matériau dans un activité de apprentissage . cln présentonsenfin ¼R , un prototype pour le interprétation de Itinéraires dans un Récitsde voyage , qui implémenter son approche . ilimp prendre en entrée un texte brut etfournir le interprétation de le itinéraire décrire dans le texte . ilimp permettre également devisualiser sur un fond cartographique le itinéraire extraire . 	Pierre Loustau, Mauro Gaio, Thierry Nodenot	2008	@univ-pau.fr, @univ-pau.fr	1001237
465	Interprétation d'images basée sur une approche évolutive guidée par une ontologie	interprétation de image baser sur un approche évolutif guider par un ontologie  le approche de fouille et de interprétation de image consister à considérer le pixel de façon indépendant avoir montrer son limite pour le analyse de image complexe . pour résoudre ce problème , un nouveau méthode clr appuyer sur un segmentation préalable de le image qui consister en un agrégation des pixel connexe afin de former un région homogène au sens de un certain critère . cependant le lien être souvent complexe entre le connaissance de le expert sur le objet que ilimp souhaiter identifier dans le image et le paramètre nécessaire à le étape segmentation permettre de cla identifier . dans ce article le connaissance de le expert être modéliser dans un ontologie qui être ensuite utiliser pour guider un processus de segmentation par un approche évolutif . ce méthode trouver automatiquement un paramètre de segmentation permettre de identifier le objet décrire par le expert dans le ontologie . 	Germain Forestier, Sébastien Derivaux, Cédric Wemmert, Pierre Gançarski	2008		1000635
466	Khiops: outil de préparation et modélisation des données pour la fouille des grandes bases de données	Khiops : outil de préparation et modélisation des donnée pour le fouille des grand base de donnée  Khiops être un outil de préparation des donnée et de modélisation pour le apprentissage superviser et non superviser . le outil permettre de évaluer de façon non paramétrique le corrélation entre tout type de variable dans le cas non superviser et le importance prédictif des variable et paire de variable dans le cas de le classification superviser . ce évaluation être effectuer au moyen de modèle de discrétisation dans le cas numérique et de groupement de valeur dans le cas catégoriel , ce qui permettre de rechercher un représentation des donnée efficace au moyen de un recodage des variable . le outil produire également un modèle de scoring pour le tâche de apprentissage superviser , selon un classifieur Bayesien naif avec sélection de variable et moyennage de modèle . le outil être adapter à le analyse des grand base de donnée , avec un centaine de millier de individu et des dizaine de millier de variable , et avoir permettre de participer avec succès à plusieurs challenge international récent . 	Marc Boullé	2008		1000598
467	La prise en compte de la dimension temporelle dans la classification de données	le prise en compte de le dimension temporel dans le classification de donnée  dans un contexte de ingénierie de le connaissance , le analyse des donnée relationnel évolutif être un question central . le représentation de ce type de donnée sous forme de graphe optimiser en faciliter le analyse et le interprétation par le utilisateur non expert . cependant , ce graphe pouvoir rapidement devenir trop complexe pour être étudier dans son globalité , ilimp falloir alors cla décomposer de manière à cll faciliter le lecture et le analyse . pour cela , un solution être de cla simplifier , dans un premier temps , en un graphe réduit dont le sommet représenter chacun un groupe distinct de sommet : acteur ou terme du domaine étudier . dans un second temps , ilimp falloir cla décomposer en instance ( un graphe par période ) afin de prendre en compte le dimension temporel . le plateforme de veille stratégique Tétralogie , développer dans son laboratoire , permettre de synthétiser le donnée relationnel évolutif sous forme de matrice de cooccurrence 3D et VisuGraph , son module de visualisation , permettre de cla représenter sous forme de graphe évolutif . VisuGraph assimiler le différent période à un repère temporel et chaque sommet être placer en fonction de son degré de appartenance aux différent période . ce prototype être aussi doter de un module de le classification interactif de donnée relationnel baser sur un technique de Markov Clustering , qui conduire à un visualisation sous forme de graphe réduit . cln proposer ici de prendre en compte le dimension temporel dans son processus de classification des donnée . ainsi , par le visualisation successif des différent instance , ilimp devenir plus facile de analyser le évolution des classe au niveau intrer mais aussi au niveau inter classe . 	Eloïse Loubier, Bernard Dousset	2008		1000653
468	Le FIA: un nouvel automate permettant l'extraction efficace d'itemsets fréquents dans les flots de données	le FIA : un nouveau automate permettre le extraction efficace de itemsets fréquent dans le flot de donnée  le FIA ( Frequent Itemset Automaton ) être un nouveau automate qui permettre de traiter de façon efficace le problématique de le extraction des itemsets fréquent dans le flot de donnée . ce structure de donnée être très compact et informatif , et cln présenter également un propriété incrémental intéressant pour le mise à jour avec un granularité très fin . le algorithme développer pour le mise à jour du FIA effectuer un unique passage sur le donnée qui être prendre en compte tout de abord par batch ( i.eevard , itemsedre par itemset ) , puis pour chaque itemset , item par item . cln montrer que dans le cadre de un approche prédictif et par le intermédiaire de le bordure statistique , le FIA permettre de indexer le itemsets véritablement fréquent du flot en maximiser le rappel et en fournir à tout moment un information sur le pertinence statistique des itemsets indexer avec le P-valeur . 	Jean-Emile Symphor, Alban Mancheron, Lionel Vinceslas, Pascal Poncelet	2008		1000568
469	Le forage de réseaux sociaux	le forage de réseau social  le exploitation des réseau social pour le extraction de connaissance ne être pas nouveau . le anthropologue , sociologue et épidémiologie clr être déjà pencher sur le question . ce être probablement le succès du moteur de recherche Google qui avoir vulgariser le utilisation des parcours aléatoire des réseau social pour le ordonnancement par pertinence . plusieurs application avoir depuis voir naissance . le découverte des communauté dans le réseau social être aussi un nouveau tendance de recherche très prisé . durant ce exposé cld parler de le analyse des réseau social , le découverte de communauté , et présenter quelque application dont le ordonnancement dans le base de donnée 	Osmar R. Zaïane	2008		1000549
470	Les cartes cognitives hiérarchiques	le carte cognitif hiérarchique  un carte cognitif fournir un représentation graphique de un réseau de influence entre un concept . le carte cognitif de dimension important avoir le inconvénient de être difficile à appréhender , interpréter et exploiter . ce article présenter un modèle de carte cognitif hiérarchique permettre au concepteur de effectuer un regroupement de concept qui être ensuite utiliser dans un mécanisme permettre à le utilisateur de obtenir un vue partiel et synthétique de un carte . 	Lionel Chauvin, David Genest, Stéphane Loiseau	2008		1000560
471	L'intelligence collective géospatiale au service du diagnostic de territoire : GEOdoc	le intelligence collectif géospatial au service du diagnostic de territoire : GEOdoc  le diagnostic de territoire constituer un étape obligatoire dans toutprojet de aménagement ou dans tout volonté politique de modifier durablementl'espace . le décideur politique devoir avoir un vision objectif des actionsà mener en fondant son réflexion sur un étude et des document ; que cln être à caractère géographique ou non . ilimp être donc fondamentald'améliorer le accès et le consultation , par le décideur stratégique , de ce quel'on pouvoir appeler un document géographique . le but de ce article être deprésenter certain concept et solution technologique qui pouvoir être utilisésafin de mieux organiser , de naviguer ( dans ) et de visualiser ce document . Ilpropose un mise en perspective commun de certains de ce approche , surlaquelle être fonder le conception de un premier maquette de un outil de visualisation ( et de navigation ) de document géographique nommer GEOdoc . 	Stéphane Roche, Benoit Kiene, Claude Caron	2008	@scg.ulaval.ca, @ign.fr, @usherbrooke.ca	1001231
472	Mesures hiérarchiques pondérées pour l'évaluation d'un système semi-automatique d'annotation de génomes utilisant des arbres de décision	mesure hiérarchique pondérer pour le évaluation de un système semi-automatique de annotation de génome utiliser un arbre de décision  le annotation de un protéine consister , entre autre , à cld attribuer un classe dans un hiérarchie fonctionnel . Celle -cus permettre de organiser le connaissance biologique et de utiliser un vocabulaire contrôler . pour estimer le pertinence des annotation , un mesure tel que le précision , le rappel , le spécificité et le Fscore être utiliser . cependant ce mesure ne être pas toujours bien adapté à le évaluation de donnée hiérarchique , car cln ne permettre pas de distinguer le erreur faire aux différent niveau de le hiérarchie . cln proposer ici un représentation formel pour le différent type de erreur adapter à son problème . 	Lucie Gentils, Jérôme Azé, Claire Toffano-Nioche, Valentin Loux, Anne Poupon, Jean-François Gibrat, Christine Froidevaux	2008		1000565
473	Méthodologie de définition de e-services pour la gestion des connaissances à partir d'un plateau de créativité : application au e-learning instrumental	méthodologie de définition de e-service pour le gestion des connaissance à partir de un plateau de créativité : application au e-learning instrumental  en clr appuyer sur le théorie de le activité , cln avoir mettre au point un méthodologie de gestion des connaissance à base de e-service sur un plateau de créativité viser à faire piloter le processus de fabrication métier par celui des usages . cln cla avoir tester avec le réalisation de un e-service de apprentissage instrumental de pièce de musique à le guitare ( E-guitare ) . 	David Grosser, Noël Conruyt, Olivier Sebastien	2008		1000591
474	Méthodologie d'Evaluation Intelligente des Concepts Ontologiques	méthodologie de Evaluation intelligent des concept Ontologiques  " un des problème majeur dans le gestion des ontologie être son évaluation . . ce article traiter le évaluation des concept ontologique qui être extrait de page Web . . pour cela , cln avoir proposer un méthodologie de évaluation des concept baser trois critère révélateur : " " le degré de crédibilité " " ; ; " " le degré de cohésion " " et " " le degré de éligibilité " " . . chaque critère correspondre à un apport de connaissance pour le tâche de évaluation . . son méthode de évaluation assurer un évaluation qualitatif grâce aux association de mots ainsi que un évaluation quantitatif par le biais des trois degré . . son résultat et discussion avec le expert et le utilisateur avoir montrer que son méthode faciliter le tâche de évaluation . " 	Lobna Karoui, Marie-Aude Aufaure	2008		1000566
475	Modélisation conceptuelle des trajectoires	modélisation conceptuel des trajectoire  un perception intelligent du mouvement de objet mobile ( personne , voiture , colis , etc. ) être à le base de nombreux application ( parexemple le suivi de un distribution postal à travers le monde , le optimisation dutrafic routier ou le étude de le migration de animal ) . le système de gestion debase de donnée actuel ne offrir ni le concept ni le fonction nécessaire àune analyse sémantique du mouvement , clr limiter au stockage et àl'interrogation de position spatial individuel , hors contexte temporel . Destravaux de recherche précédent avoir introduire et développer le concept de objetmobile ou spatio- temporel . dans ce article cln aller plus loin en proposantle concept de trajectoire comme unité sémantique de mouvement sur laquellesion construire le vision applicatif . cln proposer de décrire le trajectoire , auniveau conceptuel , avec son aspect géométrique , temporel et sémantiquesettre son composant structurel : point de départ , point de arrivée , arrêt etdéplacements intermédiaire . chaque élément , trajectoire , arrêt , déplacement , voire partie de déplacement , pouvoir recevoir un annotation sémantique sousforme de valeur de attribut ou de lien vers un objet de le base . le approchede modélisation décrire dans ce article être baser sur le patron demodélisation , qui permettre un solution générique pour modéliser lescaractéristique standard des trajectoire tout en être ouvrir auxcaractéristique spécifique à le application envisager . enfin , le implémentationdans un base de donnée relationnel étendre être présenter . 	Christine Parent, Stefano Spaccapietra, Christelle Vangenot, Maria-Luisa Damiani, José de Macedo, Fabio Porto	2008	@unil.ch, @epfl.ch, @dico.unimi.it	1001236
476	Nouvelle approche pour la recherche d'images par le contenu	nouveau approche pour le recherche de image par le contenu  cln utiliser le analyse factoriel des correspondance ( AFC ) pour le recherche de image par le contenu en clr inspirer directement de son utilisation en analyse des donnée textuel ( ADT ) . le AFC permettre ici de réduire le dimension du problème et de sélectionner un indicateur pertinent pour le recherche par le contenu . en ADT , le AFC être appliquer à un tableau de contingence croiser mots et document . le premier étape consister donc à définir un « mots visuel » dans le image ( analogue des mots dans le texte ) . ce mots être construire à partir un descripteur local ( SIFT ) un image . le méthode avoir être tester sur le base Caltech4 ( Sivic et alection , 2005 ) sur lequel cln fournir de meilleur résultat ( qualité des résultat de recherche et temps de exécution ) que un méthode plus classique comme TF  IDF  Rocchio ( Rocchio , 1971 ) ou pLSA ( Hofmann , 1999ma , 1999roblème ) . enfin , pour passer à le échelle et améliorer le qualité de recherche , cln proposer un nouveau prototype de recherche qui utiliser un fichier inverser baser sur le qualité de représentation des image sur le axe après avoir faire un AFC . chaque fichier inverser être associer à un partie de un axe ( positif ou négatif ) et contenir un image avoir un bon qualité de représentation sur ce axe . le test réaliser montrer que ce nouveau prototype réduire le temps de recherche sans perte de qualité de résultat et dans certain cas , améliorer le taux de précision par rapport à le méthode exhaustif . 	Nguyen-Khang Pham, Annie Morin	2008		1000636
477	Ontologies et raisonnement à partir de cas : Application à l'analyse des risques industriels	ontologie et raisonnement à partir de cas : application à le analyse des risque industriel  le analyse de risque être un processus viser à décrire le scénario conduire à un phénomène dangereux et à un accident potentiel sur un installation industriel . pour réaliser un analyse de risque , un expert disposer un nombreux ressource : rapport , étude de danger , base de accident , etc. ce ressource être cependant souvent difficile à exploiter parce que cln ne être pas suffisamment structurer ni formaliser . dans le cadre du projet KMGR ( Knowledge Management pour le gestion des risque ) , mener en partenariat avec le institut national de le environnement industriel et des risque ( INERIS ) , cln proposer de traiter ce problème en développer un système de recherche de information baser sur un ontologie , et de cla compléter par un système de raisonnement à partir de cas ( RàPC ) pour tenir compte des expérience passé . 	Amjad Abou Assali, Dominique Lenne, Bruno Debray	2008		1000595
478	Optimisation du Primal pour les SVM	optimisation du Primal pour le SVM  le apprentissage de SVM par optimisation direct du primal être très étudier depuis quelque temps car ilimp ouvrir un nouveau perspective notamment pour le traitement de donnée structurer . cln proposer un nouveau algorithme de ce type qui combiner de façon original un certain nombre de technique et idée comme le méthode du sous-gradient , le optimisation de fonction continu non partout différentiable , et un heuristique de shrinking . 	Trinh Minh Tri Do, Thierry Artières	2008		1000615
479	Optimisation incrémentale de réseaux de neurones RBF pour la régression via un algorithme évolutionnaire : RBF-Gene	optimisation incrémental de réseau de neurone RBF pour le régression via un algorithme évolutionnaire : RBF-Gene  le réseau de neurone RBF être de excellent régresseur . cln être cependant difficile à utiliser en raison du nombre de paramètre libre : nombre de neurone , poids des connexion , ... un algorithme évolutionnaire permettre de cla optimiser mais cln être peu nombreux et complexe . cln proposer ici un nouveau algorithme , RBF-Gene , qui permettre de optimiser le structure et le poids du réseau , grâce à un inspiration biologique . ilimp être compétitif avec le autre technique de régression mais surtout le évolution pouvoir choisir dynamiquement le nombre de neurone et le précision des différent paramètre . 	Virginie Lefort, Guillaume Beslon	2008		1000620
480	Pondération locale des variables en apprentissage numérique non-supervisé	pondération local des variable en apprentissage numérique non- superviser  dans ce article , cln proposer un nouveau approche de pondération des variable durant un processus de apprentissage non superviser . ce méthode clr baser sur le algorithme « batch » un carte auto- organisatrice . le estimation des coefficient de pondération clr faire en parallèle avec le classification automatique . ce pondération être local et associer à chaque référent de le carte auto- organisatrice . cln refléter le importance local de chaque variable pour le classification . le pondération local être utiliser pour le segmentation de le carte topologique permettre ainsi un découpage plus riche tenir compte des pertinence des variable . le résultat de le évaluation montrer que le approche proposer , comparer à un autre méthode de classification , offrir un segmentation plus fin de le carte et de meilleur qualité . 	Nistor Grozavu, Younès Bennani, Mustapha Lebbah	2008		1000619
481	Prétraitement des bases de données de réactions chimiques pour la fouille de schémas de réactions	Prétraitement un base de donnée de réaction chimique pour le fouille de schéma de réaction  un grand nombre de réaction chimique être aujourde hui répertorier dans un base de donnée . le chimiste aimer pouvoir fouiller le graphe moléculaire contenir dans ce donnée pour cll extraire un schéma de réaction fréquent . Deux obstacle clr opposer à cela : de un part le manière dont le chimiste représenter le réaction par un graphe ne permettre pas aux technique de fouille de graphe de extraire le schéma de réaction fréquent . de autre part le base de donnée contenir un description de réaction souvent incomplet , ambigu ou erroné . le présent article décrire un processus de prétraitement opérationnel qui permettre de filtrer , compléter puis transformer le contenu de un base de réaction en un donnée fiable constituer de graphe abstrait répondre au problème de le fouille de schéma de réaction . le processus placer ainsi le base de réaction à portée des technique de fouille de graphe comme cll attester le résultat expérimental . 	Frédéric Pennerath, Géraldine Polaillon, Amedeo Napoli	2008		1000652
482	Principes d'Analyse des données symboliques et application à la détection d'anomalies sur des ouvrages publics	principe de analyse des donnée symbolique et application à le détection de anomalie sur un ouvrage public  le analyse des donnée Symboliques avoir pour objectif de fournir un résultatscomplémentaire à celui fournir par le fouille de donnée classique encréant des concept issu de donnée simple ou complexe puis en analysantce concept par un description symbolique où le variable exprimer lavariation un instance de ce concept en prendre des valeur intervalle , histogramme , suite , munir de règle et de taxonomie , etc . 	Edwin Diday	2008		1001800
483	Processus d'acquisition d'un dictionnaire de sigles et de leurs définitions à partir d'un corpus	processus de acquisition de un dictionnaire de sigle et de son définition à partir de un corpus  le logiciel présenter dans ce article clr appuyer sur un approche de acquisition de sigle à partir de donnée textuel 	Vladislav Matviico, Nicolas Muret, Mathieu Roche	2008		1000599
484	Proposition d'une nouvelle approche de détection d'intrusions basée sur les règles associatives génériques de classification	proposition de un nouveau approche de détection de intrusion baser sur le règle associatif générique de classification  le système de détection de intrusion ( SDIs ) avoir pour objectif le sécurité des réseau informatique . dans ce papier , cln proposer un nouveau approche de détection de intrusion baser sur un règle associatif générique de classification pour améliorer le qualité de le détection de intrusion . 	Imen Brahmi, Sadok Ben Yahia, Yahya Slimani	2008		1000589
485	Proposition pour l'intégration de l'analyse spatiale et de l'analyse multidimensionnelle	proposition pour le intégration de le analyse spatial et de le analyse multidimensionnel  le introduction de le information spatial dans le modèlesmultidimensionnel avoir donner naissance au concept de Spatial OLAP ( SOLAP ) . dans ce article , cln montrer en quoi? le spécificité de le informationgéographique et de le analyse spatial ne être pas entièrement prendre en comptedan le analyse et le modèle multidimensionnel SOLAP . pour pallier ceslimites , cln proposer le concept de dimension géographique et décrire lesdifférent type de hiérarchie associer . cln proposer le introduction denouveaux opérateur qui permettre de adapter le opérateur de analyse spatialeau paradigme multidimensionnel . enfin , cln présenter son prototype quioffre un interface web de navigation spatial et multidimensionnel , etpermet le intégration de ce nouveau concept . 	Sandro Bimonte,  Anne Tchounikine, Maryvonne Miquel, Robert Laurini	2008	@imag.fr, @insa-lyon.fr	1001235
486	Recherche adaptative de structures de régulation génétique	recherche adaptatif de structure de régulation génétique  cln avoir proposer un algorithme original de fouille de Données , LICORN , afin de inférer un relation de régulation coopératif à partir de donnée de expression . LICORN donne de bon résultat se ilimp être appliquer à un donnée de levure , mais le passage à le échelle sur un donnée plus complexe ( e.g. , humain ) être difficile . dans ce article , cln proposer un extension de LICORN afin que ilimp pouvoir gérer un contrainte de co- régulation adaptatif . un évaluation préliminaire sur un donnée de transcriptome de tumeur de vessie montrer que le réseau significatif être obtenir à le aide de un contrainte de corégulation adaptatif de manière beaucoup plus efficace , et que cln avoir un performance de prédiction équivalent voire meilleur que celui obtenir par LICORN . 	Mohamed Elati, Céline Rouveirol	2008		1000631
487	Recherche de motifs spatio-temporels de cas atypiques pour le trafic routier urbain	recherche de motif spatio- temporel de cas atypique pour le trafic routier urbain  un large panel de domaine de application utiliser un réseau de capteur géoréférencé pour mesurer divers évènement . le série temporel fournir par ce réseau pouvoir être utiliser dans le but de dégager un connaissance sur le relation spatio- temporel de le activité mesuré . dans ce article , cln proposer un méthode permettre de abord de détecter un situation atypique ( au sens de le occurrence ) puis de construire un motif spatio- temporel relater son propagation sur un réseau . le cas étudier être celui du trafic routier urbain . son raisonnement clr fonder sur le application de le méthode Space-Time principal Component Analysis ( STPCA ) et de le combinaison entre le information mutuel et le algorithme Isomap . le résultat expérimental exécuter sur un donnée réel de trafic routier démontrer le efficacité de le méthode introduire à identifier le propagation de cas atypique fournir ainsi un outil performant de prédiction de le circulation intraday à court et moyen terme . 	Marc Joliveau, Florian De Vuyst	2008		1000640
488	Recherche d'images par noyaux sur graphes de régions	recherche de image par noyau sur graphe de région  dans le cadre de le recherche interactif de image dans un base de donnée , cln clr intéresser à un mesure de similarité de image qui permettre de améliorer le apprentissage et utilisable en temps réel lors de le recherche . le image être représenter sous le forme de graphe de adjacence de région flou . pour comparer un graphe valué cln employer un noyau de graphe clr appuyer sur un ensemble de chaîne , extraire des graphe comparé . cln proposer un cadre général permettre le emploi de différent noyau et différent type de chaîne ( sans cycle , avec boucle ) autoriser un appariement inexact . cln avoir effectuer un comparaison sur deux base issu de Columbia et Caltech et montrer que un chaîne de très faible dimension ( longueur inférieur à 3 ) être le plus efficace pour retrouver un classe de objet . 	Philippe-Henri Gosselin, Justine Lebrun, Sylvie Philipp-Foliguet	2008		1000634
489	Recherche d'information personnalisée dans les bibliothèques numériques scientifiques	recherche de information personnaliser dans le bibliothèque numérique scientifique  dans ce article cln présenter son travaux sur le recherche de information personnaliser dans le bibliothèque numérique . cln utiliser un profil utilisateur qui représenter un intérêt et des préférence des utilisateur . le résultat de recherche pouvoir être retrier en tenir compte des besoin de information spécifique de différent personne , ce qui donner un meilleur précision . cln étudier différent méthode baser sur le citation , sur le contenu textuel des document et des approche hybride . le résultat des expérimentation montrer que son approche être efficace et applicable dans le cadre des bibliothèque numérique . 	Thanh-Trung Van, Michel Beigbeder	2008		1000556
490	Requêtes alternatives dans le contexte d'un entrepôt de données génomiques	requête alternatif dans le contexte de un entrepôt de donnée génomique  afin de aider le biologiste à annoter un génome , ce qui nécessiter le analyse , le croisement , et le comparaison de donnée provenir de source divers , cln avoir concevoir un entrepôt de donnée de génomique microbien . cln présenter le structure global flexible de le entrepôt et son architecture multi-niveau et définir un correspondance entre ce niveau . cln introduire ensuite le notion de requête alternatif et montrer comment le système pouvoir construire le ensemble des requête alternatif à un requête initial . pour cela , cln introduire un mécanisme de interrogation qui reposer sur le architecture multi-niveau , et donner un algorithme de calcul des requête alternatif . 	Christine Froidevaux, Frédéric Lemoine	2008		1000557
491	Segmentation hiérarchique des cartes topologiques	segmentation hiérarchique des carte topologique  dans ce papier , cln présenter un nouveau mesure de similarité pour le classification des référent de le carte auto- organisatrice qui être réaliser à le aide de un nouveau approche de classification hiérarchique . ( 1 ) le mesure de similarité être composer de deux terme : le distance de Ward pondérer et le distance euclidien pondérer par le fonction de voisinage sur le carte topologique . ( 2 ) un algorithme à base de fourmi artificiel nommer AntTree être utiliser pour segmenter le carte auto- organisatrice . ce algorithme avoir le avantage de prendre en compte le voisinage entre le référent et de fournir un hiérarchie des référent avec un complexité proche du nlogarithme ( n ) . le segmentation inclure le nouveau mesure être valider sur plusieurs base de donnée public . 	Mustapha Lebbah, Hanane Azzag	2008		1000662
492	Semantics of Spatial Window over Spatio-Temporal Data Stream	dans le système DSMS ( Data Stream Management Systems ) , le donnée en entrée être infini et le requête sur celui -ci être actif tout le temps . dans le but de satisfaire ce caractéristique , le fenêtrage temporel être largement utiliser pour convertir le flux infini de donnée sous forme de relation fini . mais ce technique être inadapté pour un nombreux application émergent , en particulier le service de localisation . un nombreux requête ne pouvoir pas être traiter en utiliser le fenêtrage temporel , ou être traiter plus ecacement à le aide de un fenêtrage baser sur le espace ( fenêtrage spatial ) . dans ce article , cln analyser le nécessité de un fenêtrage spatial sur un flux de donnée spatio- temporel , et proposer , sur le base du langage de requête CQL ( Continuous Query Language ) , un syntaxe et un sémantique associer au fenêtrage spatial . 	Yi Yu, Talel Abdessalem	2008		1000570
493	Sémantique et Réutilisation d'ontologie générique	sémantique et réutilisation de ontologie générique  dans ce papier , cln enrichir le méthode Terminae de construction de ontologie à partir de texte en proposer un semi-automatisation de le construction du modèle conceptuel . cln présenter un algorithme permettre le conceptualisation de un terme en clr appuyer sur le information linguistique contenir dans le ontologie générique de référence . 	Sylvie Desprès, Sylvie Szulman	2008		1000563
494	SOM pour la Classification Automatique Non supervisée de Documents Textuels basés sur Wordnet	SOM pour le classification automatique non superviser de Documents Textuels baser sur Wordnet  dans ce article , cln proposer le méthode des SOM ( carte auto- organisatrice de Kohonen ) pour le classification non supervisé de document textuel baser sur le n-gramme . le même méthode baser sur le synsets de WordNet comme terme pour le représentation des document être étudier par le suite . ce combinaison être évaluer et comparer . 	Mimoun Malki, Abdelmalek Amine, Zakaria Elberrichi, Michel Simonet	2008		1000596
495	Stratégies de classification non supervisée basées sur fenêtres superposées : application aux données d'usage du Web	Stratégies de classification non superviser baser sur fenêtre superposé : application aux donnée de usage du Web  un problème majeur clr poser dans le domaine des flux de donnée : le distribution sous-jacent des donnée pouvoir changer sur le temps . dans ce article , cln proposer trois stratégie de classification non superviser baser sur un fenêtre superposer . son objectif être de pouvoir repérer ce changement dans le temps . son approche être appliquer sur un benchmark de donnée réel et le conclusion obtenir être baser sur deux indice de comparaison de partition . 	Alzennyr Da Silva, Yves Lechevallier	2008		1000592
496	Suppression des Itemsets Clés Non Essentiels en Classification basée sur les Règles d'Association	suppression des Itemsets Clés non Essentiels en Classification baser sur le règle de association  en classification baser sur le règle de association , le itemsets clé être essentiel : le suppression des itemsets non clé ne affecter pas le précision du classifieur en construction . ce travail montrer que parmi ce itemsets clé , cln pouvoir clr intéresser seulement à celui de petit taille . plus loin encore , ilimp étudier un généralisation de un propriété important des itemsets non clé et montrer que parmi le itemsets clé de petit taille , ilimp cll avoir celui qui ne être pas significatif pour le classification . ce itemsets clé être dire non essentiel . cln être définir via un test de 2 . le expérience mener sur le grand jeu de donnée montrer que le optimisation par le suppression de ce itemsets être correct et efficace . 	Viet Phan Luong	2008		1000626
497	Système multi-agent argumentatif pour la classification des connaissances cruciales	système multi-agent argumentatif pour le classification des connaissance crucial  dans ce article , cln proposer un approche multi-agent argumentatif permettre de automatiser le résolution des conflit entre décideur dans un système de aide à le identification des connaissance crucial nommer K-DSS . en effet , un divergence concernant le crucialité des connaissance pouvoir apparaître entre le décideur et aboutir ainsi à un incohérence dans le base commun de connaissance le rendre inexploitable . son objectif à travers ce travail être de proposer un approche argumentatif permettre de résoudre le conflit entre décideur . afin de concevoir ce approche , cln clr appuyer sur le théorie multi-agent pour représenter le acteur humain par un agent logiciel connaître son préférence et son règle de décision et pouvoir ainsi argumenter son choix ou mettre à jour son croyance en fonction des argument que cln recevoir un autre agent décideur . 	Inès Saad, Imène Brigui-Chtioui	2008		1000667
498	Un algorithme de classification topographique non supervisée à deux niveaux simultanés	un algorithme de classification topographique non superviser à deux niveau simultané  un des question le plus important pour le plupart des application réel de le classification être de déterminer un nombre approprié de groupe ( cluster ) . déterminer le nombre optimal de groupe être un problème difficile , puisque ilimp ne cll avoir pas un moyen simple pour connaître ce nombre sans connaissance avoir priori . dans ce article , cln proposer un nouveau algorithme de classification non superviser à deux niveau , appeler S2L-SOM ( Simultaneous Twolevel Clustering - Self Organizing Map ) , qui permettre de déterminer automatiquement le nombre optimal de groupe , pendant le apprentissage de un carte auto- organisatrice . le estimation du nombre correct de groupe être en relation avec le stabilité de le segmentation et le validité des groupe générer . pour mesurer ce stabilité cln utiliser un méthode de sous-échantillonnage . le principal avantage de le algorithme proposer , comparer aux méthode classique de classification , être que ilimp ne être pas limiter à le détection de groupe convexe , mais être capable de détecter un groupe de forme arbitraire . le validation expérimental de ce algorithme sur un ensemble de problème fondamental pour le classification montrer son supériorité sur le méthode standard de classification à deux niveau comme SOM + K-Moyennes et SOM + Hierarchical-Agglomerative-Clustering . 	Guénaël Cabanes, Younès Bennani	2008		1000661
499	Un cyber cartogramme gravitationnel pour l'analyse visuelle de données spatiotemporelles complexes	un cyber cartogramme gravitationnel pour le analyse visuel de donnée spatiotemporel complexe  le cartogramme présenter dans ce article être destiner à faciliterl'analyse visuel de donnée spatiotemporel complexe . pour cela , ilimp offreler possibilité de représenter simultanément le trois dimension nécessaire àtoute forme de analyse géographique que être le dimension spatial ( où ) , thématique ( quoi ) et temporel ( quand ) , à partir de trois composante principal : ( 1 ) un représentation unidimensionnel ( 1.D. ) de le espace géographiquede forme semi-circulaire centrer sur un origine ( exès le Canada ) ; ( 2 ) desentité géographique ( exès pays ) qui venir graviter autour de ce origineen fonction de valeur attributaire ; et ( 3 ) un ligne de temps interactif permettantd'explorer le dimension temporel de le information représenter . Lacombinaison de ce trois composante offrir de multiple potentialité pourl'analyr spatio- temporel de différent forme de proximité que cln soientéconomiquer , culturel , social ou démographique . le fonctionnalité etpotentialités de ce cartogramme développer en source ouvert être illustrer àpartir de exemple issu de le atlas cybercartographique du commerce canadien . ce article reprendre le grand ligne de un communication présenter lors de laconférence SAGEO 2007 . 	Sébastien Caquard, Jean-Pierre Fiset	2008	@connect.carleton.ca	1001229
500	Un modèle d'espace vectoriel de concepts pour noyaux sémantiques	un modèle de espace vectoriel de concept pour noyau sémantique  le noyau avoir être largement utiliser pour le traitement de donnée textuel comme mesure de similarité pour un algorithme tel que le séparateur à VasteMarge ( SVM ) . le modèle de le espace vectoriel ( VSM ) avoir être amplement utiliser pour le représentation spatial des document . cependant , le VSM être un représentation purement statistique . dans ce papier , cln présenter un modèle de espace vectoriel de concept ( CVSM ) qui clr baser sur un connaissance linguistique avoir priori pour capturer le sens des document . cln proposer aussi un noyau linéaire et un noyau latent pour ce espace . le noyau linéaire exploiter le concept linguistique pour le extraction du sens alors que le noyau latent combiner le concept statistique et linguistique . en effet , le noyau latent utiliser un concept latent extrait par le analyse sémantique latent ( LSA ) dans le CVSM . le noyau être évaluer sur un tâche de catégorisation de texte dans le domaine biomédical . le corpus Ohsumed , bien connaître pour son difficulté de catégorisation , avoir être utiliser . le résultat avoir montrer que le performance de catégorisation être améliorer dans le CSVM . 	Sujeevan Aseervatham	2008		1000659
501	Un modèle et une algèbre pour les systèmes de gestion d'ontologies	un modèle et un algèbre pour le système de gestion de ontologie  cln présenter ici un approche pour le gestion de base de ontologie baser sur un modèle comprendre , outre le définition formel des concept ( sous forme de axiome de logique de description ) , un autre élément descriptif ( terme , commentaire et argument ) , ainsi que son lien de alignement avec un concept de autre ontologie . le adaptation ou le combinaison de ontologie clr faire grâce à un algèbre comprendre un opération tel que le sélection , le projection , le union ou le jointure de ontologie . ce opération agir au niveau des axiome , un élément descriptif et des lien de alignement . 	Gilles Falquet, Claire-Lise Mottaz Jiang, Jacques Guyot	2008		1000670
502	Un nouveau système immunitaire artificiel pour l'apprentissage non supervisé	un nouveau système immunitaire artificiel pour le apprentissage non superviser  cln proposer dans ce papier un nouveau système immunitaire artificiel ( SIA ) appeler système NK , pour le détection de comportement du lui non lui avec un approche non supervisé baser sur le mécanisme de cellule NK ( Naturel Killer ) . dans ce papier , le système NK être appliquer à le détection de fraude en téléphonie mobile . 	Rachid Elmeziane, Ilham Berrada, Ismail Kassou	2008		1000585
503	Un processus d'acquisition d'information pour les besoins de l'enrichissement des BDG	un processus de acquisition de information pour le besoin de le enrichissement des BDG  le donnée constituer le élément central de un système de information Géographiques ( SIG ) et son coût être souvent élever en raison de le investissement substantiel qui permettre son production . cependant , ce donnée être souvent restreindre à un service ou pour un catégorie de utilisateur . ce qui avoir faire ressortir le nécessité de proposer un moyens de enrichissement en information pertinent pour un nombre plus important de utilisateur . cln présenter dans ce papier son approche de enrichissement de donnée qui clr dérouler selon trois étape : un identification de segment et de thème associer , un délégation et enfin , un filtrage textuel . un processus de raffinement être également offrir . son approche global avoir être intégrer à un SIG . son évaluation avoir être accomplir montrer ainsi son performance . 	Khaoula Mahmoudi, Sami Faiz	2008		1000668
504	Un système de vote pour la classification de textes d'opinion	un système de vote pour le classification de texte de opinion  le tâche de classification textuel avoir souvent pour objectif de regrouper thématiquement différent texte . dans ce article , cln clr être intéresser à le classification de document en fonction des opinion et jugement de valeur que cln contenir . le approche proposer être fonder sur un système de vote utiliser plusieurs méthode de classification . 	Michel Plantié, Mathieu Roche, Gérard Dray	2008		1000657
505	Une aide à la découverte de mappings dans SomeRDFS	un aide à le découverte de mapping dans SomeRDFS  dans ce article , cln clr intéresser à le découverte de mise en correspondance entre ontologie distribuer modéliser le connaissance de pairs du système de gestion de donnée P2P SomeRDFS . plus précisément , cln montrer comment exploiter le mécanisme de raisonnement mettre en oeuvre dans SomeRDFS pour aider à découvrir un mapping entre ontologie . ce travail être réaliser dans le cadre du projet MediaD en partenariat avec France Telecom R&D . 	François-Élie Calvier, Chantal Reynaud	2008		1000671
506	Une approche ensembliste inspirée du boosting en classification non supervisée	un approche ensembliste inspirer du boosting en classification non superviser  en classification supervisé , de nombreux méthode ensembliste pouvoir combiner plusieurs hypothèse de base afin de créer un règle de décision final plus performant . ainsi , ilimp avoir être montrer que un méthode comme le bagging ou le boosting pouvoir clr révéler intéressant , tant dans le phase de apprentissage que en généralisation . dès lors , ilimp être tentant de vouloir clr inspirer un grand principe de un méthode comme le boosting en classification non supervisé . or , ilimp convier préalablement de clr confronter aux difficulté connaître de le thématique des ensemble de regroupeur ( correspondance des classe , agrégation des résultat , qualité ) puis de introduire le idée du boosting dans un processus itératif . ce article proposer un méthode ensembliste inspirer du boosting , qui , à partir de un partitionnement flou obtenir par le c-moyenne flou ( fuzzy-c-means ) , aller insister itérativement sur le exemple difficile pour former un partition dur final plus pertinent . 	Romain Billot, Henri-Maxime Suchier, Stéphane Lallich	2008		1000624
507	Une approche ontologique pour automatiser le contrôle de conformité dans le domaine du bâtiment	un approche ontologique pour automatiser le contrôle de conformité dans le domaine du bâtiment  ce article présenter le méthode et le système C3R pour vérifier de façon semi-automatique le conformité de un projet de construction par rapport à un norme du bâtiment . le projet de construction être représenter par un graphe RDF et le norme par un requête SPARQL ; le processus de contrôle consister en le appariement des requête et des graphe . son efficacité reposer sur le acquisition de connaissance ontologique et sur un processus de extraction de connaissance guider par ce but spécifique de contrôle de conformité qui prendre en compte le connaissance ontologique acquérir . cln reposer ensuite sur un méta-connaissance acquérir auprès un expert du CSTB qui permettre de guider le contrôle lui-même : le requête représenter le norme être annoter et organiser selon ce annotation . ce annotation être également utiliser dans le interaction avec le utilisateur de C3R pour expliquer le résultat du processus de validation , en particulier en cas de échec . 	Anastasiya Yurchyshyna, Catherine Faron-Zucker, Nhan Le Thanh, Celson Lima	2008		1000562
508	Une mesure de similarité contextuelle pour l'aide à la navigation dans un treillis	un mesure de similarité contextuel pour le aide à le navigation dans un treillis  le recherche de information et le navigation dans le page web clr avérer complexe du fait du volume croissant des donnée et de son manque de structure . le formalisation conceptuel de un contexte associer à un ontologie rendre possible le amélioration de ce processus . cln définir un contexte conceptuel comme être le association de un treillis de concept construire à partir de page web avec un ontologie . le recherche et le navigation pouvoir alors clr effectuer à plusieurs niveau de abstraction : le niveau des donnée , le niveau conceptuel et le niveau sémantique . ce article clr intéresser essentiellement au niveau conceptuel grâce à un représentation par le treillis de concept des document selon le terme que cln avoir en commun . son objectif être de proposer un mesure de similarité permettre à le utilisateur de mieux naviguer dans le treillis . en effet , un bon interprétation du treillis devoir passer par un choix rigoureux des concept , objet , relation et propriété le plus intéressant . pour faciliter le navigation , ilimp falloir pouvoir indiquer à le utilisateur le concept le plus pertinent par rapport au concept correspondre à son requête ou pouvoir cld proposer un point de départ . le originalité de son proposition résider dans le fait de considérer un lien sémantique entre le concept du treillis , baser sur un extension des mesure de similarité utiliser dans le cadre des ontologie , afin de permettre un meilleur exploitation de ce treillis . cln présenter le résultat expérimental de le application de ce mesure sur un treillis construire à partir de page web dans le domaine du tourisme . 	Saoussen Sakji, Marie-Aude Aufaure, Géraldine Polaillon, Bénédicte Le Grand, Michel Soto	2008		1000561
509	Une nouvelle approche du boosting face aux données bruitées	un nouveau approche du boosting face aux donnée bruiter  le réduction de le erreur en généralisation être le un des principal motivation de le recherche en apprentissage automatique . de ce fait , un grand nombre de travaux avoir être mener sur le méthode de agrégation de classifieur afin de améliorer , par un technique de vote , le performance de un classifieur unique . parmi ce méthode de agrégation , le boosting être sans doute le plus performant grâce à le mise à jour adaptatif de le distribution des exemple viser à augmenter de façon exponentiel le poids des exemple mal classer . cependant , en cas de donnée fortement bruiter , ce méthode être sensible au sur-apprentissage et son vitesse de convergence être affecter . dans ce article , cln proposer un nouveau approche baser sur un modification de le mise à jour des exemple et du calcul de le erreur apparent effectuer au sein de le algorithme classique de AdaBoost . un étude expérimental montrer le intérêt de ce nouveau approche , appelé approche Hybride , face à AdaBoost et à BrownBoost , un version de AdaBoost adapter aux donnée bruiter . 	Emna Bahri, Mondher Maddouri	2008		1000623
510	Une nouvelle méthode divisive en classification non supervisée pour des données symboliques intervalles	un nouveau méthode divisive en classification non supervisé pour un donnée symbolique intervalle  dans ce article cln présenter un nouveau méthode de classification non supervisé pour un donnée symbolique intervalle . ilimp clr agir de le extension de un méthode de classification non superviser classique à un donnée interval . le méthode classique supposer que le point observer être le réalisation de un processus de Poisson homogène dans k domaine convexe disjoindre de Rp . le premier partie de le nouveau méthode être un procédure monothétique divisif . le règle de coupure être baser sur un extension à un donnée intervalle du critère de classification des Hypervolumes . le étape de élagage utiliser un test statistique baser sur le processus de Poisson homogène . le résultat être un arbre de décision . le seconde partie de le méthode consister en un étape de recollement , qui permettre , dans certain cas , de améliorer le classification obtenir à le fin de le premier partie de le algorithme . le méthode être évaluer sur un ensemble de donnée réel . 	Nathanaël Kasoro, André Hardy	2008		1000664
511	Une proposition pour l'extraction de relations non prédicatives	un proposition pour le extraction de relation non prédicatif  le relation sémantique généralement reconnaître par le méthode de extraction être porter par un structure de type prédicats-argument . or , le information rechercher être souvent répartir sur plusieurs phrase . pour détecter ce relation dire complexe , cln proposer un modèle de représentation des connaissance baser sur le graphe conceptuel . 	Mouna Kamel	2008		1000590
512	Utilisation du Web Sémantique pour la gestion d'une liste de diffusion d'une CoP	utilisation du Web Sémantique pour le gestion de un liste de diffusion de un CoP  ce article décrire un approche de création semi-automatique de ontologie et de annotation sémantique à partir de message électronique échanger dans un liste de diffusion dédier au support informatique . le ressource sémantique générer permettre de identifier le question fréquemment poser ( FAQ ) à travers un recherche guider par ce ontologie . 	Bassem Makni, Khaled Khelif, Rose Dieng-Kuntz, Hacène Cherfi	2008		1000553
513	"Vers des Machines à Vecteurs de Support ""Actionnables"" : Une Approche Fondée sur le Classement"	" vers des Machines à Vecteurs de Support " " Actionnables " " : : un approche fonder sur le classement "  " un des principal critique que le cln pouvoir faire aux séparateur à vaste Marge ( SVM ) être le manque de intelligibilité des résultat . . en effet , ilimp clr agir de un technique " " boiter noir " " qui ne fournir pas de explication ni de indice quant aux raison de un classification . . le résultat devoir être prendre tel quel en faire confiance au système qui cla avoir produire . . pourtant selon son expérience pratique , le expert du domaine préférer largement un méthode de apprentissage avec explication et recommandation de action plutôt que un boite noir , aussi performant et prédictif être cln . . dans ce thématique , cln proposer un nouveau approche qui consister avoir rendre le SVM plus " " actionnable " " . . ce but être atteindre en coupler un modèle de classement des résultat des SVM à un méthode de apprentissage de concept . . cln présenter un application de son méthode sur divers donnée dont des donnée médical concerner un patient de le athérosclérose . . son résultat empirique sembler très prometteur et montrer le utilité de son approche quant à le intelligibilité et le actionnabilité des résultat produire par SVM . " 	Ansaf Salleb-Aouissi, Bert C. Huang, David L. Waltz	2008		1000616
514	Vers l'exploitation de grandes masses de données	vers le exploitation de grand masse de donnée  un tendance lourd depuis le fin du siècle dernier être le augmentation exponentiel du volume des donnée stocker . ce augmentation ne clr traduire pas nécessairement par un information plus riche puisque le capacité à traiter ce donnée ne progresser pas aussi rapidement . avec le technologie actuel , un difficile compromis devoir être trouver entre le coût de mise en oeuvre et le qualité de le information produire . cln proposer un approche industriel permettre de augmenter considérablement son capacité à transformer un donnée en information grâce à le automatisation des traitement et à le focalisation sur le seul donnée pertinent . 	Raphaël Feraud, Marc Boullé, Fabrice Clérot, Françoise Fessant	2008		1000609
515	Vers une fouille sémantique des brevets : Application au domaine biomédical	Vers un fouille sémantique des brevet : application au domaine biomédical  " le brevet être un source de information très riche puisque ce être un document qui servir à décrire le invention . . le accès aux document de brevet en ligne être possible grâce aux effort des offices national de le propriété intellectuel . . par ailleurs , avoir un objectif différent , le présentation de ce document avoir prendre un forme varier loin de être unifier . . ce papier présenter un méthode et un système permettre le analyse de brevet " " Patent Mining " " pour générer un annotation sémantique . . le idée principal être de pouvoir prendre en considération le structure des brevet pour pouvoir trouver un lien entre le contenu du brevet et le concept des différent ontologie . " 	Nizar Ghoula, Khaled Khelif, Rose Dieng-Kuntz	2008		1000552
516	Visualisation des motifs séquentiels extraits à partir d'un corpus en Ancien Français	visualisation des motif séquentiel extrait à partir de un corpus en ancien français  ce article présenter un interface permettre de visualiser un motif séquentiel extrait à partir de donnée textuel en ancien français . 	Julien Rabatel, Yuan Lin, Yoann Pitarch, Hassan Saneifar, Claire Serp, Mathieu Roche, Anne Laurent	2008		1000605
517	Visualisation et classification des parcours de vie	visualisation et classification des parcours de vie  ce article proposer un méthodologie pour le visualisation et le classification des parcours de vie . plus spécifiquement , cln considérer le parcours de vie de individu suisse naître durant le premier moitié du XXème siècle en utiliser le donnée provenir de le enquête biographique rétrospectif mener en 2002 par le Panel suisse de ménage . cln cln être concentrer sur ce événement du parcours de vie : le départ du foyer parental , le naissance du premier enfant , le premier mariage et le premier divorce . A partir un donnée de base sur ce événement , cln discuter de son transformation en séquence de états . cln présenter ensuite son méthodologie pour extraire de le connaissance des parcours de vie . ce méthodologie reposer sur un distance calculer par un algorithme de optimal matching . ce distance être ensuite utiliser pour le classification des parcours de vie et son visualisation à le aide de technique de « Multi Dimensional Scaling » . ce article clr intéresser en particulier aux problématique entourer le application de ce méthode aux donnée de parcours de vie . 	Nicolas S. Müller, Sylvain Lespinats, Gilbert Ritschard, Matthias Studer, Alexis Gabadinho	2008		1000638
518	Web Content Data Mining : la classification croisée pour l'analyse textuelle d'un site Web	web Content Data Mining : le classification croisé pour le analyse textuel de un site Web  son objectif dans ce article être le analyse textuel de un site Web indépendamment de son usage . son approche clr dérouler en trois étape . le premier étape consister au typage des page afin de distinguer le page de navigation ou page « auxiliaire » un page de contenu . le deuxième étape consister au prétraitement du contenu des page de contenu afin de représenter chaque page par un vecteur de descripteur . le dernier étape consister au block clustering ou le classification simultané des ligne et des colonne de le matrice croiser le page aux descripteur de page afin de découvrir un biclasse de page et de descripteur . le application de ce approche au site de tourisme de Metz prouver son efficacité et son applicabilité . le ensemble de classe de page grouper en thème faciliter le analyse ultérieur de le usage du site . 	Malika Charrad, Yves Lechevallier, Gilbert Saporta, Mohamed Ben Ahmed	2008		1000555
519	Alignement de ressources sémantiques à partir de règles	alignement de ressource sémantique à partir de règle  ce papier présenter un approche automatique pour aligner un ressource sémantique . le alignement clr traduire par le mise en correspondance des entité ( terme , concept , rôle ) appartenir à un ressource de un même domaine qui pouvoir avoir un niveau de formalisation différent . le entité correspondant être de même nature et un coefficient caractériser son degré de ressemblance . le approche proposer être fonder sur un règle de appariement entre le entité des deu ressource . dans un premier phase , ce règle de appariement être identifier empiriquement . un algorithme combiner le différent règle identifié être ensuite définir afin de établir un correspondance entre le entité des ressource considérer . ce papier présenter un ensemble de règle de appariement exploiter un élément situer à différent niveau conceptuel . ce ensemble constituer un cadre pour le alignement automatique des ressource sémantique . le résultat de un premier expérimentation qui avoir porter sur le alignement de deux ressource du domaine de le accidentologie être également présenter . 	Valentina Ceausu, Sylvie Desprès	2007	@univ-paris5.fr, @univ-paris5.fr	1001444
520	Annotation et navigation de données archéologiques	annotation et navigation de donnée archéologique  dans ce article , cln proposer un cadre et un outil pour le annotation et le navigation de donnée archéologique . le objectif principal être de structurer le annotation de façon à permettre un navigation incrémental où le utilisateur pouvoir , à partir de un ensemble de objet initialement retourner par un requête , découvrir un lien approximatif avec un autre objet de le base . le approche avoir être implémenter et être en cours de validation . 	Bernardo Lopez, Samira Hammiche, Samir Sebahi, Mohand-Said Hacid	2007	@univ-lyon1.fr	1001350
521	Annotation sémantique floue de tableaux guidée par une ontologie	annotation sémantique flou de tableau guider par un ontologie  cln présenter dans ce article différent étape de le annotation de tableau de donnée à le aide de un ontologie . tout de abord , cln distinguer le colonne de donnée numérique et symbolique . le donnée symbolique être ensuite annoter de manière flou à le aide des terme de le ontologie . ce annotation cld permettre de déduire le type des colonne de donnée symbolique . pour trouver le type des colonne de donnée numérique , cln utiliser à le fois le titre de le colonne et le valeur numérique et unité présent dans le colonne . chaque étape de son annotation être valider expérimentalement . 	Gaëlle Hignette, Patrice Buche, Juliette Dibie-Barthélemy, Ollivier Haemmerlé	2007	@risk, @inapg.fr, @univ-tlse2.fr	1001441
522	Application des réseaux bayésiens à l'analyse des facteurs impliqués dans le cancer du Nasopharynx	application des réseau bayésien à le analyse des facteur impliquer dans le cancer du Nasopharynx  le apprentissage de le structure des réseau bayésien à partir de donnée être un problème NP-difficile . un nouveau heuristique de complexité polynômial , intituler Polynomial Max-Min Skeleton ( PMMS ) , avoir être proposer en 2005 par Tsamardinos et alection et valider avec succès sur un nombreux banc de essai . PMMS présenter , en outre , le avantage de être performant avec un jeu de donnée réduit . néanmoins , comme tout le algorithme sous contrainte , celui -ci échouer lorsque un dépendance fonctionnel ( déterministe ) exister entre un groupe de variable . ilimp ne clr appliquer , par ailleurs , que aux donnée complet . aussi , dans ce article , cln apporter quelque modification pour remédier à ce deu problème . après validation sur le banc de essai Asia , cln le appliquon aux donnée de un étude épidémiologique cas-témoin du cancer du nasopharynx ( NPC ) de 1289 observation , 61 variable et 5 \pourcent de donnée manquant issir de un questionnaire . le objectif être de dresser un profil statistique type de le population étudier et de apporter un éclairage utile sur le différent facteur impliquer dans le NPC 	Alexandre Aussem, Sergio Rodrigues de Morais, Marilys Corbex	2007	@univ-lyon1.fr, @iarc.fr	1001318
523	Apport du Web sémantique dans la réalisation d'un moteur de recherche géo-localisé à usage des entreprises	apport du Web sémantique dans le réalisation de un moteur de recherche géo- localiser à usage des entreprise  le recherche de un entreprise sur le Web , relative à un savoir-faire particulier , ne être pas un tâche toujours facile à mener . le outil mettre à le disposition de le internaute ne donner pas entièrement satisfaction . de un côté le moteur de recherche éprouver un difficulté à faire ressortir clairement le résultat escompter . de le autre côté , le annuaire spécialisé ( type Pages Jaunes ) être tributaire de un organisation figé , nuire à son efficacité . face à ce constat , cln clr proposer de créer un nouveau moteur spécialiser dans le recherche de entreprise , associer Web sémantique et géo- localisation . ce approche novateur nécessiter le implémentation de un ontologie avoir pour objectif le formalisation des connaissance du domaine . ce tâche avoir mettre en évidence le intérêt des structure économique , maintenir par le INSEE , et son utilisation au sein de le ontologie . le nomenclature économique avoir être retenir pour gérer le classification des activité et produit pouvoir être dispenser par le entreprise . le structure des unité administratif , tel que gérer au sein du fichier SIRENE , clr être avérer judicieux pour répondre à le problématique de géo- localisation des entreprise . un opération de désambiguïsation être réaliser en associer à chaque noeud de activité le mots clé et synonyme cld correspondre . enfin , cln comparer le résultat obtenir par son moteur à celui obtenir par le principal moteur de recherche de activité géo- localiser en France : le page jaune . que ce être au niveau de le précision et du rappel , son moteur obtenir un résultat significativement meilleur . 	Frédéric Triou, Fabien Picarougne, Henri Briand	2007	@univ-nantes.fr	1001307
524	Apprentissage actif d'émotions dans les dialogues Homme-Machine	apprentissage actif de émotion dans le dialogue Homme-Machine  le prise en compte des émotion dans le interaction Homme-machine permettre de concevoir un système intelligent , capable de clr adapter aux utilisateur . le technique de redirection de appel dans le centre téléphonique automatiser clr baser sur le détection des émotion dans le parole . le principal difficulté pour mettre en oeuvre de tel système être le acquisition et le étiquetage des donnée de apprentissage . ce article proposer le application de deux stratégie de apprentissage actif à le détection de émotion dans un dialogue en interaction homme-machine . le étude porter sur un donnée réel issir de le utilisation de un serveur vocal et proposer un outil adapter à le conception de système automatiser de redirection de appel . 	Alexis Bondu, Vincent Lemaire, Barbara Poulain	2007	@orange-ft.com	1001428
525	Apprentissage semi-supervisé de fonctions d'ordonnancement	apprentissage semi-supervisé de fonction de ordonnancement  cln présenter dans ce article un algorithme inductif semi-superviser pour le tâche de ordonnancement bipartite . le algorithme semi-supervisé proposer jusque à maintenir avoir être étudier dans le cadre strict de le classification . récemment un travaux avoir être réaliser dans le cadre transductif pour étendre le modèle existant en classification au cadre de ordonnancement . le originalité de son approche être que cln être capable de inférer un ordre sur un base test non- utiliser pendant le phase de apprentissage , ce qui cla rendre plus générique que un méthode transductive pur . le résultat empirique sur le base CACM contenir le titre et le résumé du journal Communications of the Association for Computer Machinery montrer que le donnée non- étiqueté être bénéfique pour le apprentissage de fonction de ordonnancement . 	Tuong-Vinh Truong, Massih-Reza Amini	2007	@lip6.fr	1001425
526	Apprentissage statistique de la topologie d'un ensemble de données étiquetées	apprentissage statistique de le topologie de un ensemble de donnée étiqueté  découvrir le topologie de un ensemble de donnée étiqueter dans un espace Euclidien pouvoir aider à construire un meilleur système de décision . dans ce papier , cln proposer un modèle génératif baser sur le graphe de Delaunay de plusieurs prototype représenter le donnée étiqueter dans le but de extraire de ce graphe le topologie des classe . 	Pierre Gaillard, Michaël Aupetit, Gérard Govaert	2007	@cea.fr, @cea.fr, @utc.fr	1001419
527	Approche connexionniste pour l'extraction de profils cas-témoins du cancer du Nasopharynx à partir des données issues d'une étude épidémiologique	approche connexionniste pour le extraction de profil cas-témoin du cancer du Nasopharynx à partir un donnée issir de un étude épidémiologique  dans ce article , cln présenter un système de découverte de connaissance à partir de donnée issir de un étude épidémiologique cas-témoin du cancer du Nasopharynx ( NPC ) . ce donnée être obtenir par un collecte de questionnaire , cln avoir de un part , le particularité de être qualitatif et , de autre part , de présenter un valeur manquant . prendre en compte ce deu dernier contrainte , le système que cln proposer suivre un démarche de exploration de donnée qui consister à ( 1 ) définir un procédure de codage des donnée qualitatif en présence de valeur manquant ; ( 2 ) étudier le propriété de le algorithme des carte auto- organisatrice de Kohonen et son adaptation à ce type de donnée dans un cadre de découverte et de visualisation de groupe homogène des cas cancer  non- cancer ; ( 3 ) post-traiter le resultat de ce algorithme par un classification automatique pour optimiser le nombre de groupe ainsi trouvé , et ( 4 ) donner un interprétation sémantique des profil extrait de chaque groupe . le objectif général de ce étude être de éclater le profil statistique global de le population étudier en un ensemble de profil type ( cancer ou non- cancer ) et de extraire pour chaque profil le ensemble de variable explicatif du NPC à partir de un cartographie bidimensionnelle . 	Khalid Benabdeslem, Mustapha Lebbah, Alexandre Aussem, Marilys Corbex	2007	@univ-lyon1.fr, @limbio-paris13.org, @iarc.fr	1001418
528	Approche logique pour la réconciliation de références	approche logique pour le réconciliation de référence  le problème de réconciliation de référence consister à décider si deux description provenir de source distinct référer ou non à le même entité du monde réel . dans ce article , cln étudier ce problème quand le schéma des donnée être décrire en RDFS étendre par certain primitif de OWL-DL . cln décrire et montrer le intérêt de un approche logique baser sur un règle de réconciliation qui pouvoir être générer automatiquement à partir un axiome du schéma . ce règle traduire de façon déclaratif le dépendance entre réconciliation qui découler de le sémantique du schéma . le premier résultat avoir être obtenir sur un donnée réel dans le cadre du projet PICSEL 3 en collaboration avec France Telecom R&D . 	Fatiha Saïs, Nathalie Pernelle, Marie-Christine Rousset	2007	@lri.fr, @imag.fr	1001449
529	Calcul et représentation efficace de cubes de données pour une visualisation orientée pixel	calcul et représentation efficace de cube de donnée pour un visualisation orienter pixel  le cube de donnée fournir un aide non négligeable lorsque ilimp clr agir de interroger un entrepôt de donnée . un cube de donnée représenter un pré-calcul de tout le requête OLAP et ainsi améliorer son temps de réponse . le approche proposer jusque à présent réduire le temps de calcul et de entrée sortir mais son utilisation rester très coûteux . un autre travaux de recherche clr être intéresser à le visualisation de donnée pour cla exploiter de façon interactif . cln proposer un adaptation de le représentation condensé des cube de donnée baser sur le modèle partitionnel . ce technique cld permettre de calculer efficacement un cube de donnée et de représenter le lien entre le donnée pour le visualisation . le visualisation proposer dans ce article être baser sur un technique de visualisation orienter pixel et sur un technique de diagramme de lien entre noeud pour offrir à le fois un vision global et local pour le exploitation . ce nouveau approche utiliser de un part le calcul efficace de cube de donnée et de autre part le technique avancée de visualisation . 	Noel Novelli, David Auber	2007	@lif.univ-mrs.fr, @labri.fr	1001362
530	Caractérisation des transitions temporisées dans les logs de conversation de services Web	caractérisation des transition temporiser dans le log de conversation de service Web  le connaissance du protocole de conversation de un service Web être important pour le utilisateur et le fournisseur , car ilimp cll modéliser le comportement externe ; mais , ilimp ne être souvent pas spécifier lors de le conception . son travail clr inscrire dans un thématique de extraction du protocole de conversation de un service existant à partir de son donnée de exécution . cln cll étudier un sous-problème important qui être le découverte des transition temporiser ( i.eès le changement de état lier à un contrainte temporel ) . cln proposer un cadre formel aboutir à le définition des expiration propre , qui représenter un équivalent dans le log des transition temporiser . A son connaissance , ceci représenter le premier contribution à le résolution de ce problème . 	Didier Devaurs, Fabien De Marchi, Mohand-Said Hacid	2007	@irisa.fr, @liris.cnrs.fr	1001302
531	Cartographie de l'organisation : une approche topologique des connaissances	cartographie de le organisation : un approche topologique des connaissance  le gestion des connaissance être devenir aujourde hui un enjeu majeur pour tout organisation . Celle -cus avoir pour but de capitaliser et de rendre accessible à son acteur le connaissance détenir par le organisation . ce article clr intéresser particulièrement à le visualisation à deux niveau de ce connaissance ( macroscopique - relatif aux connaissance global détenir par le organisation - et microscopique - relatif aux connaissance local détenir par chaque membre organisationnel ) . le caractérisation des connaissance détenir par le acteur reposer sur quatre dimension complémentaire ( formel , conatif , cognitif , et socio- cognitif ) . le deu type de visualisation proposer clr appuyer sur le carte auto- organisatrice et permettre un navigation dans différent représentation des connaissance de le organisation . 	Marc Boyer, Marie-Françoise Canut, Max Chevalier, André Péninou, Florence Sedes	2007	@iut-tlse3.fr, @iut-blagnac.fr, @iut-blagnac.fr, @irit.fr, @irit.fr	1001437
532	Choix des conclusions et validation des règles issues d'arbres de classification	choix des conclusion et validation des règle issu de arbre de classification  ce article traiter de le validation de règle dans un contexte de ciblage où ilimp clr agir de déterminer le profil type des différent valeur de le variable à prédire . le concept de le analyse statistique implicative fonder sur le différence entre nombre observer de contre-exemple et nombre moyen que produire le hasard , clr avérer particulièrement bien adapter à ce contexte . le papier montrer comment le notion de indice et de intensité de implication de Gras clr appliquer aux règle produire par le arbre de décision et présenter un alternative inspirer de résidu utiliser en modélisation de table de contingence . cln discuter ensuite sur un jeu de donnée réel deu usages de ce indicateur de force de implication pour le règle issu de arbre . ilimp clr agir de un part de le évaluation individuel des règle , et de autre part de son utilisation comme critère pour le choix de le conclusion de le règle . 	Vincent Pisetta, Gilbert Ritschard, Djamel Abdelkader Zighed	2007	@univ-lyon2.fr, @univ-lyon2.fr, @unige.ch	1001424
533	Classement des fragments de documents XML par une méthode d'aide à la décision	classement des fragment de document XML par un méthode de aide à le décision  vu le accroissement constant du volume de information accessible en ligne sous format XML , ilimp devenir primordial de proposer un modèle adapté à le recherche de information dans le document XML . Tandis que le recherche de information classique reposer sur le indexation du contenu des document , le recherche de information dans le document XML tenter de améliorer le qualité des résultat en tirer profit de le sémantique véhiculer par le structure des document . dans ce article , cln présenter un méthode de classement des item ( élément XML ) retourner lors de un recherche dans un collection de document XML . le classement reposer sur le prise en compte de un ensemble de critère discriminant . le particularité de son approche résider dans le façon dont cln le utilisons : cln employer un méthode décisionnel pour classer le item en cla comparer deux-à-deux là où en général un fonction de scoring global être utiliser . 	Faiza Abbaci, Pascal Francq	2007	@ulb.ac.be, @ulb.ac.be	1001393
534	Classification de fonctions continues à l'aide d'une distribution et d'une densité définies dans un espace de dimension infinie	classification de fonction continu à le aide de un distribution et de un densité définir dans un espace de dimension infini  ilimp ne être pas rare que un donnée individu être caractériser par un distribution continu et non un seul valeur . ce donnée fonctionnel pouvoir être utiliser pour classer le individu . un solution élémentaire être de réduire le distribution à son moyen et variance . un solution plus riche avoir être proposer par Diday ( 2002 ) et mettre en oeuvre par Vrac et al. ( 2001 ) et Cuvelier et Noirhomme-Fraiture ( 2005 ) . cln utiliser un point de coupure dans le distribution et modéliser ce valeur conjoindre par un distribution multidimensionnel construire à le aide de un copule . cln avoir montrer dans un précédent travail que , si ce technique apporter un bon résultat , le qualité de le classification dépendre néanmoins du nombre et de le emplacement des coupure . le question du choix du nombre et de le emplacement des coupure rester un question ouvert . cln proposer un solution à ce question , lorsque le nombre de coupure tendre vers le infini , en proposer un nouveau distribution de probabilité adapter à le espace de dimension infini que former le donnée fonctionnel . cln proposer aussi un densité de probabilité adapter à le nature de ce distribution en utiliser le dérivée directionnel de Gâteaux . le direction choisir pour ce dérivée être celui de le dispersion des fonction à classer . le résultat être encourageant et offrir un perspective multiple dans tout le domaine où un distribution de donnée fonctionnel être nécessaire . 	Etienne Cuvelier, Monique Noirhomme-Fraiture	2007	@fundp.ac.be	1001456
535	Classification de grands ensembles de données avec un nouvel algorithme de SVM	classification de grand ensemble de donnée avec un nouveau algorithme de SVM  le nouveau algorithme de boosting de Least-Squares Support Vector Machine ( LS-SVM ) que cln présenter viser à le classification de très grand ensemble de donnée sur un machine standard . le méthode de SVM et de noyau permettre de obtenir un bon résultat en ce qui concerner le précision mais le tâche de apprentissage pour un grand ensemble de donnée demander un grand capacité mémoire et un temps relativement long . cln présenter un extension de le algorithme de LS-SVM proposer par Suykens et Vandewalle pour le boosting de LS-SVM . A ce fin , cln avoir ajouter un terme de régularisation de Tikhonov et utiliser le formule de Sherman-Morrison-Woodbury pour traiter un ensemble de donnée avoir un grand nombre de dimension . cln cla avoir ensuite étendre par application du boosting de LS-SVM afin de traiter un donnée avoir simultanément un grand nombre de individu et de dimension . le performance de le algorithme être évaluer sur le ensemble de donnée de le UCI , Twonorm , Ringnorm , Reuters- 21578 et NDC sur un machine standard ( PC-P4 , 3GHz , 512 méga-octet RAM ) . 	Thanh-Nghi Do, François Poulet	2007	@lri.fr, @esiea-ouest.fr	1001466
536	Classification supervisée de séquences biologiques basée sur les motifs et les matrices de substitution	classification superviser de séquence biologique baser sur le motif et le matrice de substitution  le classification des séquence biologique être le un des important défi ouvrir dans le bioinformatique , tant pour le séquence protéique que pour le séquence nucléique . cependant , le présence de ce donnée sous le forme de chaîne de caractère ne permettre pas de cla traiter par le outil standard de classification supervisé , qui utiliser souvent le format relationnel . pour remédier à ce problème de codage , plusieurs travaux clr être baser sur le extraction des motif pour construire un nouveau représentation des séquence biologique sous le forme de un tableau binaire . cln décrire un nouveau approche qui étendre le méthode précédent par le utilisation de matrice de substitution dans le cas des séquence protéique . cln présenter ensuite un étude comparatif qui prendre en compte le effet de chaque méthode sur le précision de le classification mais aussi le nombre de attribut générer et le temps de calcul . 	Rabie Saidi, Mondher Maddouri, Engelbert Mephu Nguifo	2007	@univ-artois.fr, @fsegt.mu.tn, @univ-artois.fr	1001409
537	Clustering : from model-based approaches to heuristic algorithms	le méthode du " clustering " avoir pour but de diviser un ensemble ( large ) de objet dans un petit nombre de groupe homogène ( cluster ) , baser sur un donnée relever ou observer qui décrire le ( dis- ) similarité qui exister entre le objet - en espérer que ce cluster être utile pour le application concerner . ilimp exister un multitude de approche , et ce contribution présent quelques-uns qui être le plus important ou actuel . 	Hans-Hermann Bock	2007	@stochastik.rwth-aachen.de	1001287
538	Combinaison des cartes topologiques mixtes et des machines à vecteurs de support : une application pour la prédiction de perte de poids chez les obèses	combinaison des carte topologique mixte et un machine à vecteur de support : un application pour le prédiction de perte de poids chez le obèse  ce article présenter un modèle pour aborder le problème de classement difficile , en particulier dans le domaine médical . ce problème avoir souvent le particularité de avoir un taux de erreur en généralisation très élevé et ce quel que être le méthode utiliser . pour ce genre de problème , cln proposer de utiliser un modèle de classement combiner le modèle de partitionnement un carte topologique mixte et le machine à vecteur de support ( SVM ) . le modèle non superviser être dédier à le visualisation et au partitionnement un donnée composé de variable quantitatif et-ou qualitatif . le deuxième modèle superviser , être dédier au classement . le combinaison de ce deu modèle permettre non seulement de améliorer le visualisation des donnée mais aussi en le performance en généralisation . ce modèle ( CT-SVM ) consister à entraîner un carte auto- organisatrice pour construire un partition organisé des donnée , constituer de plusieurs sous-ensemble qui aller servir à reformuler le problème de classement initial en sous-problème de classement . pour chaque sous-ensemble , cln entraîner un classeur SVM spécifique . pour le validation expérimental de son modèle ( CT-SVM ) , cln avoir utiliser quatre jeu de donnée . le premier base être un extraire de un grand base médical sur le étude de le obésité réaliser à le Hôpital Hôtel-Dieu de Paris , et le trois dernier base être issir de le littérature . 	Mohamed Ramzi Temanni, Mustapha Lebbah, Christine Poitou-Bernert, Karine Clément, Jean-Daniel Zucker	2007	@limbio-paris13.org, @htp.aphp.fr	1001298
539	Construction coopérative de carte de thèmes : vers une modélisation de l'activité socio-sémantique	construction coopératif de carte de thème : vers un modélisation de le activité socio- sémantique  cln présenter dans ce contribution un cadre de modélisation recourir conjointement au modèle Hypertopic ( Cahier et alection , 2004 ) pour le représentation des connaissance de domaine et au modèle SeeMe ( Herrmann et alection , 1999 ) pour le représentation de le activité . ce deu approche apparaître complémentaire , et cln montrer comment cln pouvoir être combiner , pour mieux ancrer , sur le plans formel et méthodologique , le approche de cartographie collectif des connaissance . 	L'Hédi Zaher, Jean-Pierre Cahier, Christophe Lejeune, Manuel Zacklad	2007	@utt.fr	1001304
540	Construction d'ontologie à partir de corpus de textes	construction de ontologie à partir de corpus de texte  " ce article présenter un méthode semi-automatique de construction de ontologie à partir de corpus de texte sur un domaine spécifique . . ce méthode reposer en premier lieu sur un analyseur syntaxique partiel et robuste des texte , et en second lieu , sur le utilisation de le analyse formel de concept " " FCA " " pour le construction de classe de objet en un treillis de Galois . . le construction de le ontologie , ce être à dire de un hiérarchie de concept et de instance , être réaliser par un transformation formel de le structure du treillis . . ce méthode clr appliquer dans le domaine de le astronomie . " 	Amedeo Napoli, Yannick Toussaint, Rokia Bendaoud	2007	@loria.fr	1001364
541	Construction et analyse de résumés de données évolutives : application aux données d'usage du Web	construction et analyse de résumé de donnée évolutif : application aux donnée de usage du Web  le manière dont un visite être réaliser sur un site Web pouvoir changer en raison de modification lier à le structure et au contenu du site lui-même , ou bien en raison du changement de comportement de certain groupe de utilisateur ou de le émergence de nouveau comportement . ainsi , le modèle associer à ce comportement dans le fouille de usage du Web devoir être mettre à jour continuellement afin de mieux refléter le comportement actuel des internaute . un solution , proposer dans ce article , être de mettre à jour ce modèle à le aide des résumé obtenir par un approche évolutif des méthode de classification . 	Alzennyr Da Silva, Yves Lechevallier, Fabrice Rossi, Francisco de Assis Tenório de Carvalho	2007	@inria.fr, @cin.ufpe.br	1001434
542	Construction incrémentale et visualisation de graphes de voisinage par des fourmis artificielles	construction incrémental et visualisation de graphe de voisinage par un fourmi artificiel  ce article décrire un nouveau algorithme incrémental nommer AntGraph pour le construction de graphe de voisinage . ilimp clr inspirer du comportement de autoassemblage observer chez un fourmi réel où ce dernier clr fixer progressivement à un support fixe puis successivement aux fourmi déjà fixer afin de créer un structure vivant . cln utiliser ainsi un approche à base de fourmi artificiel où chaque fourmi représenter un donner . cln indiquer comment ce comportement pouvoir être utiliser pour construire de manière incrémental un graphe à partir de un mesure de similarité entre le donnée . cln montrer finalement que son algorithme obtenir un meilleur résultat en comparaison avec le graphe de Voisins Relatifs , notamment en terme de temps de calcul . 	Julien Lavergne, Hanane Azzag, Christiane Guinot, Gilles Venturini	2007	@univ-tours.fr, @univ-paris13.fr, @ceries-lab.com	1001323
543	Découverte de chroniques à partir de séquences d'événements pour la supervision de processus dynamiques	découverte de chronique à partir de séquence de événement pour le supervision de processus dynamique  ce papier adresser le problème de le découverte de connaissance temporel à partir un donnée dater , générer par le système de supervision de un processus de fabrication . par rapport aux approche existant qui clr appliquer directement aux donnée , son méthode de extraction des connaissance clr baser sur un modèle global construire à partir un donnée . le approche de modélisation adopter , dire stochastique , considérer le donnée dater comme un séquence de occurrence de classe de événement discret . ce séquence être représenter sous le forme dual de un chaîne de Markov homogène et de un superposition de processus de Poisson . le algorithme proposer , appeler BJT4R , permettre de identifier le motif séquentiel , le plus probable entre deux classe de événement discret et cla représenter sous le forme de modèle de chronique . ce papier présenter le premier résultat de le application de ce algorithme sur un donnée générer par un processus de fabrication de semi-conducteur de un site de production du groupe STMicroelectronics . 	Nabil Benayadi, Marc Le Goc, Philippe Bouché	2007	@lsis.org	1001389
544	Des fonctions d'oubli intelligentes dans les entrepôts de données	un fonction de oubli intelligent dans le entrepôt de donnée  " le entrepôt de donnée stocker un quantité de donnée de plus en plus massif et arriver vite à saturation . . un langage de spécification de fonction de oubli être définir pour résoudre ce problème . . dans le but de offrir le possibilité de effectuer un analyse sur le historique des donnée , le spécification définir un résumé par agrégation et par échantillonnage à conserver parmi le donnée à " " oublier " " . . ce communication présenter le langage de spécification ainsi que le principe et le algorithme pour assurer de façon mécanique le gestion des fonction de oubli . " 	Aliou Boly, Sabine Goutier, Georges Hébrail	2007	@enst.fr, @enst.fr, @edf.fr, @edf.fr	1001380
545	Détermination du niveau de consommation des abonnés en téléphonie mobile par la théorie des ensembles flous	détermination du niveau de consommation des abonné en téléphonie mobile par le théorie des ensemble flou  le détermination du niveau de consommation chez le client être essentiel pour tout objectif de segmentation stratégique et de churn . cln présenter sur un cas réel le utilisation de le théorie des ensemble flou pour le définition de un fonction de appartenance permettre de évaluer , de manière précis , le niveau de consommation , un abonné en téléphonie mobile . 	Rachid El Meziane, Ilham Berrada, Ismail Kassou, Karim Baïna	2007	@ensias.ma	1001378
546	Ensemble prédicteur fondé sur les cartes auto-organisatrices adapté aux données volumineuses	ensemble prédicteur fonder sur le carte auto- organisatrice adapter aux donnée volumineux  le stockage massif des donnée noyer le information pertinent et engendrer un problème théorique lier à le volumétrie des donnée disponible . ce problème dégrader le capacité prédictif des algorithme de extraction des connaissance à partir un donnée . dans ce article , cln proposer un méthodologie adapter à le représentation et à le prédiction des donnée volumineux . A ce fin , suite à un partitionnement des attribut , un groupe de attribut non- corréler être créer qui permettre de contourner le problème lier aux espace de grand dimension . un ensemble être alors mettre en place , apprendre chaque groupe par un carte auto- organisatrice . outre le prédiction , ce carte avoir pour objectif un représentation pertinent des donnée . enfin , le prédiction être réaliser par un vote des différent carte . un expérimentation être mener qui confirmer le bien-fondé de ce approche . 	Elie Prudhomme, Stéphane Lallich	2007	@univ-lyon2.fr, @univ-lyon2.fr	1001422
547	Evaluation d'une approche de classification conceptuelle	Evaluation de un approche de classification conceptuel  le objectif de ce travail être de évaluer le perte de information au sens de le inertie entre un méthode de partitionnement ou de classification hiérarchique et un approche de classification conceptuel . cln vouloir répondre à le question suivant : le aspect simpliste du processus monothétique de un méthode conceptuel impliquer ilimp un partition de moins bon qualité au sens du critère de le inertie ? cln proposer de réaliser ce expérience sur 6 base de le UCI , troit de ce base être un tableau de donnée quantitatif , le trois autre être un tableau de donnée qualitatif . 	Marie Chavent, Yves Lechevallier	2007	@math.u-bordeaux1.fr, @inria.fr	1001455
548	Evaluation supervisée de métrique : application à la préparation de données séquentielles	Evaluation superviser de métrique : application à le préparation de donnée séquentiel  de son jours , le statisticien ne avoir plus nécessairement le contrôle sur le récolte des donnée . le besoin de un analyse statistique venir dans un second temps , un fois le donnée récolter . par conséquent , un travail être à fournir lors de le phase de préparation des donnée afin de passer de un représentation informatique à un représentation statistique adapter au problème considérer . dans ce article , cln étudier un procédé de sélection de un bon représentation en cld baser sur un travaux antérieur . cln proposer un protocole de évaluation de le pertinence de un représentation par le intermédiaire de un métrique , dans le cas de le classification superviser . ce protocole exploiter un méthode de classification non paramétrique régulariser , garantir le automaticité et le fiabilité de le évaluation . cln illustrer le fonctionnement et le apport de ce protocole par un problème réel de préparation de donnée de consommation téléphonique . cln montrer également le fiabilité et le interprétabilité des décision qui cll résulter . 	Sylvain Ferrandiz, Marc Boullé	2007	@francetelecom.com, @francetelecom.com	1001392
549	Evolution de l'ontologie et gestion des annotations sémantiques inconsistantes	Evolution de le ontologie et gestion des annotation sémantique inconsistant  le ontologie et le annotation sémantique être deux composant important dans un système de gestion des connaissance baser sur le web sémantique . dans le environement dynamique et distribuer du Web sémantique , le ontologie et le annotation pouvoir être changer pour clr adapter à le évolution de le organisation concerner . ce changement pouvoir donc entraîner un inconsistance à détecter et traiter . dans ce article , cln clr focaliser principalement sur le évolution des annotation sémantique en souligner le contexte où le modification de le ontologie entraîner un inconsistance sur ce annotation . cln présenter un approche baser sur un règle permettre de détecter le inconsistance dans le annotation sémantique devenir obsolète par rapport à le ontologie modifier . cln décrire aussi le stratégie de évolution nécessaire pour guider le processus de résolution de ce inconsistance grâce à un règle correctif . 	Phuc-Hiep Luong, Rose Dieng-Kuntz, Alain Boucher	2007	@inria.fr, @auf.org	1001450
550	Extension sémantique du modèle de similarité basé sur la proximité floue des termes	extension sémantique du modèle de similarité baser sur le proximité flou des terme  le modèle flou de proximité reposer sur le hypothèse que plus le occurrence des terme de un requête clr trouver proche dans un document , plus ce dernier être pertinent . ce mesure flou être très avantageux dans le traitement des document à texte court , toutefois cln ne tenir pas compte de le sémantique des terme . cln présenter dans ce article le intégration de un métrique conceptuel au modèle de proximité flou des terme pour le formalisation de son propre modèle . 	Zoulikha Heddadji, Nicole Vincent, Séverine Kirchner, Georges Stamon	2007	@cstb.fr, @math-info.univ	1001399
551	Extraction d'entités dans des collections évolutives	extraction de entité dans un collection évolutif  cln cln intéresser à le extraction de entité nommer avec comme but de exploiter un ensemble de rapport pour cll extraire un liste de partenaire . à partir de un liste initial , cln utiliser un premier ensemble de document pour identifier un schéma de phrase qui être ensuite valider par apprentissage superviser sur un document annoter pour cll mesurer le efficacité avant de être utiliser sur le ensemble des document à explorer . ce approche être inspirer de celui utiliser pour le extraction de donnée dans le document semi-structuré ( wrapper ) et ne nécessiter pas un ressource linguistique particulier ni de large collection de test . son collection de document évoluer annuellement , cln espérer de plus un amélioration de son extraction dans le temps . 	Thierry Despeyroux, Eduardo Fraschini, Anne-Marie Vercoustre	2007	@inria.fr	1001433
552	Extraction de connaissances d'adaptation par analyse de la base de cas	extraction de connaissance de adaptation par analyse de le base de cas  en raisonnement à partir de cas , le adaptation de un cas source pour résoudre un problème cible être un étape à le fois crucial et difficile à réaliser . un des raison de ce difficulté tenir au fait que le connaissance de adaptation être généralement dépendant du domaine de application . ce être ce qui motiver le recherche sur le acquisition de connaissance de adaptation ( ACA ) . ce article proposer un approche original de le ACA fonder sur un technique de extraction de connaissance dans un base de donnée ( ECBD ) . cln présenter CABAMAKA , un application qui réaliser le ACA par analyse de le base de cas , en utiliser comme technique de apprentissage le extraction de motif fermé fréquent . le ensemble du processus de extraction des connaissance être détailler , puis cln examiner comment organiser le résultat obtenir de façon à faciliter le validation des connaissance extraire par le analyste . 	Amedeo Napoli, Jean Lieber, Fadi Badra	2007	@loria.fr	1001464
553	Extraction de données sur Internet avec Retroweb	extraction de donnée sur Internet avec Retroweb  ce document décrire Retroweb , un boite à outil qui permettre le extraction de donnée structurer à partir de page Web . son solution être semi-automatique car le donnée à extraire être préalablement dénir par le utilisateur . le intérêt de ce approche être que cln permettre le extraction de donnée ciblé et conforme aux besoin de le application utilisateur ( migrateur , moteur de recherche , outil de veille ) . Retroweb clr caractériser aussi par un grand facilité de utilisation car ilimp ne nécessiter aucun connaissance de langage particulier , le définition des règle de extraction clr faire directement de manière interactif dans le navigateur Internet . ce document décrire le trois principal processus de son méthode . 	Fabrice Estievenart, Jean-Roch Meurisse	2007	@cetic.be, @fundp.ac.be	1001338
554	Extraction de séquences multidimensionnelles convergentes et divergentes	extraction de séquence multidimensionnel convergent et divergent  " le motif séquentiel être un domaine de le fouille de donnée très étudier depuis son introduction par Agrawal et Srikant . . même clr ilimp exister un nombreux travaux ( algorithme , domaine de application ) , peu de entre lui clr situer dans un contexte multidimensionnel avec le prise en compte de son spécificité : plusieurs dimension , relation hiérarchique entre le élément de chaque dimension , etc. dans ce article , cln proposer un méthode original pour extraire un connaissance multidimensionnel définir sur plusieurs niveau de hiérarchie mais selon un certain point de vue : du général au particulier ou vice et verser . . cln définir ainsi le concept de séquence multidimensionnel convergent ou divergent ainsi que le algorithme associer , M2S  CD , baser sur le paradigme " " pattern growth " " . . un expérimentation , sur un jeu de donnée synthétique et réel , montrer le intérêt de son approche aussi bien en terme de robustesse des algorithme que de pertinence des motif extrait . " 	Marc Plantevit, Anne Laurent, Maguelonne Teisseire	2007	@lirmm.fr	1001388
555	Extraction des Top-k Motifs par Approximer-et-Pousser	extraction des Top-k motif par Approximer-et-Pousser  ce article porter sur le extraction de motif sous contrainte global . contrairement aux contrainte usuel comme celui de fréquence minimal , son vérification être problématique car cln entraine de multiple comparaison entre le motif . typiquement , le localisation des k motif maximiser un mesure de intérêt , i.e. satisfaire le contrainte top-k'n'roll , être difficile . pourtant , ce contrainte global clr révéler très utile pour trouver le motif le plus significatif au regard de un critère choisir par le utilisateur . dans ce article , cln proposer un méthode général de extraction de motif sous contrainte global , appelé Approximer-et-Pousser . ce méthode pouvoir être voir comme un méthode de relaxation de un contrainte global en un contrainte local évolutif . cln appliquer alors ce approche à le extraction des top-k'n'roll motif selon un mesure de intérêt . le expérimentation montrer le efficacité de le approche Approximer-et-Pousser . 	Arnaud Soulet, Bruno Crémilleux	2007	@unicaen.fr	1001387
556	Filtrage des sites Web à caractère violent par analyse du contenu textuel et structurel	filtrage des site Web à caractère violent par analyse du contenu textuel et structurel  " dans ce article , cln proposer un solution pour le classification et le filtrage des site Web à caractère violent . . A le différence de le majorité de système commercial baser essentiellement sur le détection de mots indicatif ou le utilisation de un liste noir manuellement collecter , son solution baptiser , " " WebAngels Filter " " , clr appuyer sur un apprentissage automatique par un technique de data mining et un analyse conjoint du contenu textuel et structurel de le page Web . . le résultat expérimental obtenir lors de le évaluation de son approche sur un base de test être assez bon . . Comparé avec un logiciel , parmi le plus populaire , " " WebAngels Filter " " montrer son performance en terme de classification . " 	Abdelmajid Ben Hamadou, Mohamed Hammami, Radhouane Guermazi	2007	@laposte.net, @isimsf.rnu.tn, @ec-lyon.fr	1001395
557	Finding interesting queries in relational databases	le découverte de motif dans un base de donnée relationnel quelconque être un problème intéressant pour lequel ilimp exister très peu de méthode efficace . cln présenter un cadre dans lequel un paire de requête sur le donnée être utiliser comme un motif et cln discuter du problème de le découverte de association utile entre lui . plus spécifiquement , cln considérer un petit sous-classe de requête conjonctif qui cld permettre de découvrir un motif intéressant de manière efficace . 	Bart Goethals	2007		1001285
558	Fusion des approches visuelles et contextuelles pour l'annotation des images médicales	fusion des approche visuel et contextuel pour le annotation des image médical  dans le contexte de le recherche de information sur Internet , cln proposer un architecture de annotation automatique des image médical , extraire à partir un document de santé en ligne . son système être concevoir pour extraire un information médical spécifique ( i.e. modalité médical , région anatomique ) à partir du contenu et du contexte des image . cln proposer un architecture de fusion des approche contenir  contexte adapter aux image médical . le approche orienter sur le contenu des image , consister à annoter un image inconnu par le catégorisation des représentation visuel compact . cln utiliser en même temps le contexte des image ( le région textuel ) ainsi que un ontologie médical spécialement adapté aux information rechercher . finalement , cln démontrer que en fusionner le décision des deu approche , cln améliorer le performance global du système de annotation . 	Filip Florea, Valeriu Cornea, Alexandrina Rogozan, Abdelaziz Bensrhair, Stéfan Jacques Darmoni	2007	@insa-rouen.fr, @chu-rouen.fr	1001416
559	Génération et enrichissement automatique de listes de patrons de phrases pour les moteurs de questions-réponses	génération et enrichissement automatique de liste de patron de phrase pour le moteur de questions-réponse  cln utiliser un algorithme de amorce mutuel ( Riloff et Jones 99 ) , entre un couple de terme de un relation et des patron de phrase . à partir de couple de amorce , le système générer un liste de patron qui être ensuite enrichir de façon semi-supervisé , puis utiliser pour trouver un nouveau couple . ce couple être à son tour réutiliser pour générer , par itération successif , un nouveau patron . le originalité de le étude résider dans le interprétation du rappel , estimer comme le couverture de un patron sur le ensemble des exemple auxquels ilimp clr appliquer 	Cédric Vidrequin, Juan-Manuel Torres-Moreno, Jean-Jacques Schneider, Marc El-Bèze	2007	@univ-avignon.fr, @semantia.com	1001363
560	Intégration des connaissances utilisateurs pour des analyses personnalisées dans les entrepôts de données évolutifs	intégration des connaissance utilisateur pour un analyse personnaliser dans le entrepôt de donnée évolutif  " dans ce article , cln proposer un approche de évolution de schéma dans le entrepôt de donnée qui permettre aux utilisateur de intégrer son propre connaissance du domaine afin de enrichir le possibilité de analyse de le entrepôt . . cln représenter ce connaissance sous le forme de règle de type " " si-alors " " . . ce règle être utiliser pour créer un nouveau axe de analyse en générer un nouveau niveau de granularité dans le hiérarchie de dimension . . son approche être fonder sur un modèle formel de entrepôt de donnée évolutif qui permettre de gérer le mise à jour des hiérarchie de dimension . " 	Cécile Favre, Fadila Bentayeb, Omar Boussaid	2007	@univ-lyon2.fr, @univ-lyon2.fr	1001379
561	L'émergence de connaissances dans les communautés de pratique	le émergence de connaissance dans le communauté de pratique  ce article être le résultat de un recherche sur le processus , peu expliciter dans le littérature , de création de connaissance dans le communauté de pratique . cln commencer par établir un définition de travail pour ce concept de communauté de pratique qui permettre le échange et le partage de connaissance au sein de groupe de plus en plus virtuel . cln analyser ensuite le communauté de pratique sous le angle de le théorie de le émergence . cln proposer , alors , le modélisation de un outil de support pour ce communauté qui améliorer le échange entre le membre et favoriser le émergence de nouveau connaissance . ce outil manipuler le connaissance implicite ainsi que explicite et proposer un possibilité pour le publication et le recherche de information . de plus , ilimp clr adapter à chaque membre de le communauté par un processus de personnalisation . 	Caroline Wintergerst, Thomas Ludwig, Danielle Boulanger	2007	@univ-lyon3.fr, @univ-lyon3.fr, @web.de	1001442
562	L'outil SDET pour le complètement des données descriptives liées aux bases de données géographiques	le outil SDET pour le complètement des donnée descriptif lier aux base de donnée géographique  le enrichissement des base de donnée être un moyen viser à offrir un supplément informationnel aux utilisateur . dans le cas des donnée géographique , ce activité représenter de son jours un problème crucial . son résolution permettre de meilleur prise de décision ne reposer pas uniquement sur le information limité . son outil SDET ( Semantic Data Enrichment Tool ) venir proposer un solution de enrichissement faire du système de information Géographiques ( SIG ) initial un source riche de information . 	Khaoula Mahmoudi, Sami Faiz	2007	@insat.rnu.tn, @insat.rnu.tn	1001337
563	Les itemsets essentiels fermés : une nouvelle représentation concise	le itemsets essentiel fermer : un nouveau représentation concis  devant le accroissement constant des grand base de donnée , plusieurs travaux de recherche en fouille de donnée clr orienter vers le développement de technique de représentation compact . ce recherche clr développer suivant deux axe complémentaire : le extraction de base générique de règle de association et le extraction de représentation concis de itemsets fréquent . dans ce papier , cln introduire un nouveau représentation concis exact des itemsets fréquent . cln clr situer au croisement de chemin de deux autre représentation concis , à savoir le itemsets fermé et celui dire essentiel . le idée intuitif être de profiter du fait que tout opérateur de fermeture induire un fonction surjectif . dans ce contexte , cln introduire un nouveau opérateur de fermeture permettre de calculer le fermeture des itemsets essentiel . ceci avoir pour but de avoir un représentation concis de taille réduire tout en permettre le extraction des support négatif et disjonctif de un itemset en plus de son support conjonctif . un nouveau algorithme appeler D-CLOSURE permettre de extraire le itemsets essentiel fermer être aussi présenter . le étude expérimental que cln avoir mener avoir permettre de confirmer que le nouveau approche présent un bon taux de compacité comparativement aux autre représentation concis exact . 	Tarek Hamrouni, Islem Denden, Sadok Ben Yahia, Engelbert Mephu Nguifo, Yahya Slimani	2007	@fst.rnu.tn, @univ-artois.fr	1001384
564	Logiciel d'aide à l'évaluation des catégorisations	logiciel de aide à le évaluation des catégorisation  " le méthode de classification automatique être employer dans un domaine varié et de nombreux algorithme avoir être proposer dans le littérature . . Au milieu de ce " " jungle " " , ilimp sembler parfois difficile à un simple utilisateur de choisir quel algorithme être le plus adapté à son besoin . . depuis le milieu des année 90 , un nouveau thématique de recherche , appelé clustering validity , tenter de répondre à ce genre de interrogation en proposer un indice pour juger de le qualité des catégorisation obtenir . . mais le choix être parfois difficile entre ce indice et ilimp pouvoir clr avérer délicat de prendre le bon décision . . ce être pourquoi cln proposer un logiciel adapter à ce problématique de évaluation . " 	Julien Velcin, William Vacher, Jean-Gabriel Ganascia	2007	@lip6.fr, @free.fr	1001333
565	Mesure d'entropie asymétrique et consistante	mesure de entropie asymétrique et consistant  le mesure de entropie , dont le plus connu être celui de Shannon , avoir être proposer dans un contexte de codage et de transmission de information . néanmoins , dès le milieu des année soixant , cln avoir être utiliser dans un autre domaine comme le apprentissage et plus particulièrement pour construire un graphe de induction et des arbre de décision . le usage brut de ce mesure ne être cependant pas toujours bien approprier pour engendrer un modèle de prédiction ou de explication pertinent . ce faiblesse résulter un propriété des entropie , en particulier le maximum nécessairement atteindre pour le distribution uniforme et le insensibilité à le taille de le échantillon . cln commencer par rappeler ce propriété classique . cln définir ensuite un nouveau axiomatique mieux adapter à son besoin et proposer un mesure empirique de entropie plus flexible vérifier ce axiome . 	Djamel Abdelkader Zighed, Simon Marcellin, Gilbert Ritschard	2007	@univ-lyon2.fr, @unige.ch	1001309
566	Mesure non symétrique pour l'évaluation de modèles, utilisation pour les jeux de données déséquilibrés	mesure non symétrique pour le évaluation de modèle , utilisation pour le jeu de donnée déséquilibré  le critère servir à le évaluation de modèle de apprentissage superviser ainsi que celui utiliser pour bâtir un arbre de décision être , pour le plupart , symétrique . de manière pragmatique , cela signifier que chacun des modalité de le variable endogène clr voir assigner un importance identique . or , dans nombre de cas pratique cela ne être pas le cas . ainsi , cln pouvoir notamment prendre le exemple de jeu de donnée fortement déséquilibré pour lequel le objectif principal être le identification des objet représentatif de le modalité minoritaire ( aide au diagnostic , identification de phénomène inhabituel : fraude , panne ... ) . dans ce type de situation ilimp apparaître clairement que assigner un importance identique aux erreur de prédiction ne constituer pas le meilleur des solution . cln proposer dans ce article un critère ( pouvoir servir à le fois pour le évaluation de modèle de apprentissage superviser ou encore de critère utiliser pour bâtir un arbre de décision ) prendre en compte ce aspect non symétrique de le importance associer à chacun des modalité de le variable endogène . cln proposer ensuite un évolution des modèle de type forêt aléatoire utiliser ce critère pour le jeu de donnée fortement déséquilibré . 	Julien Thomas, Pierre-Emmanuel Jouve, Nicolas Nicoloyannis	2007		1001426
567	Méthodes statistiques et modèles thermiques compacts	méthode statistique et modèle thermique compact  dans le domaine thermique , le plupart des étude reposer sur un modèle à élément fini . cependant , le coût en calcul et donc en temps de ce méthode avoir renforcer le besoin de modèle plus compact . le réseau RC équivalent être le solution le plus souvent utiliser . toutefois , son paramètre devoir souvent être ajuster à le aide de mesure ou de simulation . dans ce contexte de identification de système , le méthode statistique être comparer aux méthode classiquement utiliser pour le prédiction thermique . 	Hubert Polaert, Philippe Leray, Grégory Mallet	2007	@insa-rouen.fr	1001377
568	Navigation et appariement d'objets géographiques dans une ontologie	navigation et appariement de objet géographique dans un ontologie  le ACI FoDoMuSt clr proposer de élaborer un processus de fouille de donnée multi-stratégi pour le reconnaissance automatique de objet géographique sur un image satellitaire ou aérien . ce dernier être segmenter afin de isoler un polygone définir par un ensemble de descripteur de bas niveau . afin de cld affecter un sémantique , cln appliquer dans un premier temps un classification . si aucun objet géographique ne être identifié , cln tenter alors un appariement du polygone avec le concept de un ontologie de objet géographique . un algorithme de navigation dans le ontologie et un mesure de comparaison sémantique avoir ainsi être développer , paramétrables selon le contexte de appariement . ce mesure évaluer le pertinence de un appariement et comprendre un composante local ( comparaison au niveau du concept ) et un composante global ( combinaison linéaire de mesure local ) . le méthode proposer avoir être développer en JAVA et intégrer à le plate-forme FoDoMuSt . le premier expérimentation et évaluation humain être très encourageant . 	Rémy Brisson, Omar Boussaid, Pierre Gançarski, Anne Puissant, Nicolas Durand	2007	@yahoo.fr, @univ-lyon2.fr, @lsiit.u-strasbg.fr, @lsiit.u-strasbg.fr, @unicaen.fr	1001402
569	Notion de conversation dans les communications interpersonnelles instantanées sur IP	notion de conversation dans le communication interpersonnel instantané sur IP  dans ce article cln étudier le contribution des technique de fouille de donnée à le amélioration des service de communication instantané sur IP tel que le messagerie instantané ( IM ) et le téléphonie sur IP ( ToIP ) . 	Alexandre Bouchacourt, Luigi Lancieri	2007	@orange-ftgroup.com, @orange-ftgroup.com	1001359
570	OKM : une extension des k-moyennes pour la recherche de classes recouvrantes	OKM : un extension des k-moyenne pour le recherche de classe recouvrant  dans ce article cln aborder le problème de le classification ( ou clustering ) dans le but de découvrir un classe avec recouvrement . malgré quelque avancée récent dans ce domaine , motiver par un besoin applicatif important ( traitement des donnée multimédia par exemple ) , cln constater le absence de solution théorique à ce problème . son étude consister alors à proposer un nouveau formulation du problème de classification par partitionnement , adapter à le recherche de un recouvrement des donnée en classe de objet similaire . ce approche clr fonder sur le dénition de un critère objectif de qualité de un recouvrement et de un solution algorithmique viser à optimiser ce critère . cln proposer deux évaluation de ce travail permettre de un part de appréhender le fonctionnement global de le algorithme sur un donnée simple ( vitesse de convergence , visualisation des résultat ) et de autre part de évaluer quantitativement le bénéfice de un tel approche sur un application de classification de document textuel . 	Guillaume Cleuziou	2007	@univ-orleans.fr	1001458
571	Partitionnement d'un réseau de sociabilité à fort coefficient de clustering	Partitionnement de un réseau de sociabilité à fort coefficient de clustering  afin de comparer le organisation social de un paysannerie médiéval avant et après le guerre de Cent Ans cln étudier le structure de réseau social construire à partir de un corpus de contrat agraire . faible diamètre et fort clustering révéler un graphe en petit monde . comme beaucoup de grand réseau de interaction étudier ce dernier année ce graphe être sans échelle typique . le distribution des degré de son sommet être bien ajuster par un loi de puissance tronquer par un coupure exponentiel . cln posséder en outre un club-huppé , ce être à dire un noyau dense et de faible diamètre regrouper le individu à fort degré . le forme particulier des élément propre du laplacien permettre de extraire un communauté qui clr répartir en étoile autour du club huppé . 	Romain Boulet, Bertrand Jouve	2007	@univ-tlse2.fr	1001438
572	Peut-on capturer la sémantique à travers la syntaxe ? - découverte des règles d'exception simultanée	pouvoir cln capturer le sémantique à travers le syntaxe ? - découverte des règle de exception simultané  le objectif de le fouille de donnée être le découverte sophistiquer de connaissance lisible , surprenant et possiblement utile . le aspect surprenant et utile faire partie de le sémantique et nécessiter le utilisation des connaissance du domaine , ce qui cause souvent le problème de acquisition de le connaissance . son découverte des règle de exception simultané pouvoir être un réponse à ce problème . cln envisager de trouver le connaissance surprenant et possiblement utile à travers son forme de paire de règle de exception . le autre méthode inventer concerner le index de évaluation et le recherche exhaustif . plusieurs application médical être présenter sur lequel son proposition avoir être appliquer . 	Einoshin Suzuki	2007		1001280
573	Préservation de l'Intimité dans les Protocoles de Conversations	préservation de le intimité dans le protocole de conversation  le travail présenter dans ce article , rentrer dans le cadre de le gestion des donnée privé en vue de le substitution , appelé remplaçabilité , dynamique des service Web . Trois contribution être apporter , ( 1 ) modélisation des politiques privé spécifier le règle de utilisation des donnée privé , prendre en compte des aspect clr rapporter aux service Web , ( 2 ) étendre le protocole de conversation des service Web par le modèle proposer , afin de apporter le primitif nécessaire pour le analyse des protocole en présence de ce règle , ( 3 ) définition de un mécanisme de analyse de le remplaçabilité de un service par un autre en vue de son politiques privé . 	Nawal Guermouche, Salima Benbernou, Emmanuel Coquery, Mohand-Said Hacid	2007	@loria.fr, @liris.cnrs.fr	1001360
574	RAS : Un outil pour l'annotation de documents basée sur les liens de citation	ras : un outil pour le annotation de document baser sur le lien de citation  ras ( Reference Annotation System ) être un outil de annotation de document . ce outil être le résultat de le implémentation de son approche de annotation baser sur le contexte de citation . le approche être indépendant du contenu et utiliser un regroupement thématique des référence construire à partir de un classification flou non- supervisé . le outil présenter dans ce article avoir être expérimenter et évaluer avec le base de document scientifique Citeseer . 	Lylia Abrouk, Danièle Hérin	2007	@lirmm.fr	1001341
575	Ré-ordonnancement pour l'apprentissage de transformations de documents HTML	Ré-ordonnancement pour le apprentissage de transformation de document HTML  son objectif être de transformer le document Web vers un schéma médiateur XML définir avoir priorir . ce être un étape nécessaire pour un nombreux tâche de recherche de information concerner le Web Sémantique , le document semi-structuré , le traitement de source hétérogène , etc. cln permettre de associer un structure sémantiquement riche à un document dont le format ne contenir que un information de présentation . cln proposer de traiter ce problème comme un problème de apprentissage structurer en le formaliser comme un transformation de arbre en arbre . son méthode de transformation comporter deux étape . dans un premier étape , un grammaire hors-contexte probabiliste permettre de générer un ensemble de solution candidat . dans un deuxième étape , ce solution candidat être ordonner grâce à un algorithme de ré-ordonnancement à base de perceptron à noyau . ce étape de ordonnancement cld permettre de utiliser de manière efficace des caractéristique complexe définir à partir du document de entrée et de le solution candidat . 	Guillaume Wisniewski, Patrick Gallinari	2007	@lip6.fr	1001461
576	Réduction de dimension pour l'analyse de données vidéo	réduction de dimension pour le analyse de donnée vidéo  le donnée vidéo avoir le particularité de être très volumineux alors que cln contenir peu de information sémantique . pour cla analyser , ilimp falloir réduire le quantité de information dans le espace de recherche . le donnée vidéo être souvent considérer comme le ensemble des pixel de un succession de image analysé séquentiellement . dans ce article , cln proposer de utiliser un analyse en composante principal ( ACP ) pour réduire le dimensionnalité des information sans perdre le nature tridimensionnel des donnée initial . cln commencer par considérer un sous-séquence , dont le nombre de trame être le nombre de dimension dans le espace de représentation . cln appliquer un ACP pour obtenir un espace de faible dimension où le point similaire sémantiquement être proche . le sous-séquence être ensuite diviser en bloc tridimensionnel dont cln projeter le ellipsoïde de inertie dans le premier plan factoriel . cln déduire enfin le mouvement présent dans le bloc à partir un ellipse ainsi obtenir . cln présenter le résultat obtenir pour un problème de vidéosurveillance . 	Nicolas Verbeke, Nicole Vincent	2007	@univ-paris5.fr	1001404
577	Régression floue et crédibiliste par SVM pour la classification des images sonar	régression flou et crédibiliste par SVM pour le classification des image sonar  le classification des image sonar être de un grand importance par exemple pour le navigation sous-marin ou pour le cartographie des fonds marin . en effet , le sonar offrir un capacité de imagerie plus performant que le capteur optique en milieu sous-marin . le classification de ce type de donnée rencontrer plusieurs difficulté en raison des imprécision et incertitude lier au capteur et au milieu . un nombreux approche avoir être proposer sans donner un bon résultat , celui -ci ne tenir pas compte des imperfection des donnée . pour modéliser ce type de donnée , ilimp être judicieux de utiliser le théorie de le incertain comme le théorie des sous-ensemble flou ou le théorie des fonction de croyance . le machine à vecteur de support être de plus en plus utiliser pour le classification automatique aux vue son simplicité et son capacité de généralisation . ilimp être ainsi possible de proposer un approche qui tenir compte de ce imprécision et de ce incertitude au coeur même de le algorithme de classification . le approche de le régression par SVM que cln avoir introduire permettre ce modélisation des imperfection . cln proposer ici un application de ce nouveau approche sur un donnée réel particulièrement complexe , dans le cadre de le classification des image sonar . 	Hicham Laanaya, Arnaud Martin, Driss Aboutajdine, Ali Khenchaf	2007	@fsr.ac.ma, @ensieta.fr	1001295
578	Segmentation thématique par calcul de distance thématique	segmentation thématique par calcul de distance thématique  dans ce article , cln présenter un approche de le segmentation thématique fonder sur un représentation en vecteur sémantique des phrase et des calcul de distance entre ce vecteur . le vecteur sémantique être générer par le système SYGFRAN , un analyseur morpho- syntaxique et conceptuel de le langue français . le segmentation thématique clr effectuer cln en rechercher un zone de transition au sein du texte grâce aux vecteur sémantique . le évaluation de ce méthode clr être faire sur le donnée du défi DEFT'06 . 	Jacques Chauché, Alexandre Labadié	2007	@lirmm.fr, @lirmm.fr	1001398
579	Sémantique et contextes conceptuels pour la recherche d'information	sémantique et contexte conceptuel pour le recherche de information  ce article proposer un méthodologie de recherche de information qui utiliser le analyse conceptuel conjointement avec le sémantique dans le but de fournir un réponse contextuel à un requête sur le web . le contexte conceptuel définir dans ce article pouvoir être global - ce est-à-direr stable - ou instantané - ce est-à-direr borner par le contexte global . son méthodologie consister en un premier phase de pré traitement permettre de construire le contexte global , et un seconde phase de traitement en ligne des requête des utilisateur , associer au contexte instantané . son processus de recherche de information être illustrer à travers un expérimentation dans le domaine du tourisme . 	Michel Soto, Bénédicte Le Grand, Marie-Aude Aufaure	2007	@supelec.fr, @inria.fr, @lip6.fr	1001440
580	Sous-bases k-faibles pour des règles d'association valides au sens de la confiance	Sous-bases k-faible pour un règle de association valide au sens de le confiance  cln introduire le notion de sous-base k-faible pour le règle de association valide au sens de le confiance . ce sous-base k-faible être caractériser en terme de opérateur de fermeture correspondre à un famille de Moore k-faiblement hiérarchique . 	Jean Diatta, Régis Girard	2007	@univ-reunion.fr	1001383
581	SPoID : Extraction de motifs séquentiels pour les bases de données incomplètes	SPoID : extraction de motif séquentiel pour le base de donnée incomplet  le base de donnée issu du monde réel contenir souvent un nombreux information non renseigner . durant le processus de extraction de connaissance dans le base de donnée , un phase de traitement spécifique de ce donnée être souvent nécessaire , permettre de cla supprimer ou de cla compléter . lors de le extraction de séquence fréquent , ce donnée incomplet être le plupart du temps occulter . ceci conduire parfois à le élimination de plus de le moitié de le base et le information extraire ne être plus représentatif . cln proposer donc de ne plus éliminer le enregistrement incomplet , mais de utiliser le information partiel que cln contenir . le méthode proposer ignorer en fait temporairement certain donnée incomplet pour le séquence rechercher . le expérimentation sur jeu de donnée synthétique montrer le validité de son proposition aussi bien en terme de qualité des motif extrait que de robustesse aux valeur manquant . 	Céline Fiot, Anne Laurent, Maguelonne Teisseire	2007	@lirmm.fr	1001460
582	SyRQuS - Recherche par combinaison de graphes RDF	SyRQuS - recherche par combinaison de graphe RDF  cln cln intéresser à un mécanisme permettre le construction de réponse combiner à partir de plusieurs graphe RDF . cln imposer , par souci de cohérence , que ce combinaison être réaliser uniquement si le graphe RDF ne clr contredire pas . pour déterminer le non- contradiction entre deux graphe RDF cln utiliser un mesure de similarité , calculer au moment de le ajout de document RDF dans le base de document . 	Adrian Tanasescu	2007	@liris.cnrs.fr	1001347
583	Traitement de données de consommation électrique par un Système de Gestion de Flux de Données	traitement de donnée de consommation électrique par un système de gestion de Flux de Données  avec le développement de compteur communicant , le consommation de énergie électrique pouvoir à terme être télérelever par le fournisseur de électricité à un pas de temps pouvoir aller jusque à le seconde . ceci générer un information en continu , à un rythme rapide et en quantité important . le système de gestion de Flux de Données ( SGFD ) , aujourde hui disponible sous forme de prototype , avoir vocation à faciliter le gestion de tel flux . ce communication décrire un étude expérimental pour analyser le avantage et limite de le utilisation de deux prototype de SGFD ( STREAM et TelegraphCQ ) pour le gestion de donnée de consommation électrique . 	Talel Abdessalem, Raja Chiky, Georges Hébrail, Jean Louis Vitti	2007	@enst.fr, @edf.fr	1001432
584	Traitement et exploration du fichier Log du Serveur Web pour l'extraction des connaissances : Web Usage Mining	traitement et exploration du fichier Log du Serveur Web pour le extraction des connaissance : web Usage Mining  le but dans ce travail consister à concevoir et réaliser un outil Logiciel , en utiliser le concept du Web Usage Mining pour offrir aux web masters le ensemble des connaissance , cll inclure le statistique sur son site , afin de prendre le décision adéquat . ilimp clr agir en fait , de extraire de le information à partir du fichier logarithme du serveur Web , héberger le site Web , et de prendre le décision pour découvrir le habitude des internaute , et de répondre à son besoin en adapter le contenu , le forme et le agencement des page web . 	Mostafa Hanoune, Faouzia Benabbou	2007	@yahoo.fr, @menara.ma	1001344
585	Un algorithme multi-agent de classification pour la construction d'ontologies dynamiques	un algorithme multi-agent de classification pour le construction de ontologie dynamique  le construction de ontologie à partir de texte rester un tâche coûteux en temps qui justifier le émergence de le Ontology Learning . son système , Dynamo , clr inscrire dans ce mouvance , en apporter un approche original baser sur un architecture multi-agent adaptatif . en particulier , le article présent le coeur de son approche , un algorithme distribuer de classification hiérarchique qui clr appliquer sur le résultat de un analyseur syntaxique . ce algorithme être évaluer et comparer à un algorithme centraliser plus conventionnel . fort de ce résultat , cln discuter son limite et dresser en perspective le aménagement à effectuer pour aller vers un solution complet de construction de ontologie . 	Kévin Ottens, Nathalie Aussenac-Gilles	2007	@irit.fr	1001452
586	Un cadre théorique pour la gestion de grandes bases de motifs	un cadre théorique pour le gestion de grand base de motif  le algorithme de fouille de donnée être maintenant capable de traiter un grand volume de donnée mais le utilisateur être souvent submerger par le quantité de motif générer . en outre , dans certain cas , que ce être pour un raison de confidentialité ou de coût , le utilisateur pouvoir ne pas avoir accès directement aux donnée et ne disposer que un motif . le utilisateur ne avoir plus alors le possibilité de approfondir à partir un donnée initial le processus de fouille de façon à extraire un motif plus spécifique . pour remédier à ce situation , un solution consister à gérer le motif . ainsi , dans ce article , cln présenter un cadre théorique permettre à un utilisateur de manipuler , en post-traitement , un collection de motif préalablement extraire . cln proposer de représenter le collection sous le forme de un graphe que un utilisateur pouvoir ensuite exploiter à le aide de opérateur algébrique pour cll retrouver un motif ou en chercher un nouveau . 	François Jacquenet, Baptiste Jeudy, Christine Largeron	2007	@univ-st-etienne.fr	1001385
587	Un outil pour la visualisation de relations entre gènes	un outil pour le visualisation de relation entre gène  le reconstruction de réseau de gène être un des défi majeur de le post-génomique . A partir de donnée de expression issu de puce à ADN , différent technique exister pour inférer un réseau de gène . cln proposer dans ce papier un approche pour le visualisation de réseau de interaction entre gène à partir de donnée de expression . le originalité de son approche être de superposer un règle avec un sémantique différent au sein de un même support visuel et de ne générer que le règle qui impliquer un gène dire central . celui -ci être spécifier en amont par le expert et permettre de limiter le génération des règle aux seul gène qui intéresser le spécialiste . un implémentation avoir être réaliser dans le logiciel libre MeV de le institut TIGR . 	Jean-Marc Petit, Marie Agier	2007	@isima, @insa-lyon.fr	1001342
588	Un segmenteur de texte en phrases guidé par l'utilisateur	un segmenteur de texte en phrase guider par le utilisateur  ce programme effectuer un segmentation en phrase de un texte . contrairement aux procédure classique , cln ne utiliser pas un annotation préliminaire et tirer partir de un apprentissage guider par le utilisateur . 	Thomas Heitz	2007	@lri.fr	1001334
589	Une approche de classification non supervisée basée sur la détection de singularités et la corrélation de séries temporelles pour la recherche d'états : application à un bioprocédé fed-batch	un approche de classification non superviser baser sur le détection de singularité et le corrélation de série temporel pour le recherche de états : application à un bioprocédé fed-batch  cln proposer dans ce article un méthode de clustering qui combiner le analyse dynamique et le analyse statistique pour caractériser un états . ilimp clr agir de un méthode de fouille de donnée qui travailler sur un ensemble de série temporel pour détecter un états ; ce états représenter le information le plus significatif du système . le objectif de ce méthode non superviser être de extraire de le connaissance à partir de le analyse des série temporel multiple . cln clr appuyer sur le détection de singularité dans le série temporel et sur le analyse des corrélation des série entre le intervalle définir par ce singularité . pour le application présenter , le série temporel être un signal biochimique mesurer durant un bioprocédé . ce approche être donc utiliser pour confirmer et enrichir le connaissance des expert du domaine des bioprocédé sans utiliser le connaissance avoir priorir de ce expert . cln être appliquer à le recherche de états physiologique dans un bioprocédé de type fed-batch . 	Sébastien Régis	2007	@univ-ag.fr	1001453
590	Une approche non paramétrique Bayésienne pour l'estimation de densité conditionnelle sur les rangs	un approche non paramétrique Bayésienne pour le estimation de densité conditionnel sur le rang  cln cln intéresser à le estimation de le distribution des rang de un variable cible numérique conditionnellement à un ensemble de prédicteur numérique . pour cela , cln proposer un nouveau approche non paramétrique Bayesienne pour effectuer un partition rectangulaire optimal de chaque couple ( cible , prédicteur ) uniquement à partir un rang des individu . cln montrer ensuite comment le effectif de ce grille cld permettre de construire un estimateur univarié de le densité conditionnel sur le rang et un estimateur univarié utiliser le hypothèse Bayesienne naïf . ce estimateur être comparé aux meilleur méthode évaluer lors de un récent challenge sur le estimation de un densité prédictif . si le estimateur Bayésien naïf utiliser le ensemble des prédicteur clr révéler peu performant , le estimateur univarié et le estimateur combiner deux prédicteur donne de très bon résultat malgré son simplicité . 	Marc Boullé, Carine Hue	2007	@orange-ftgroup.com, @orange-ftgroup.com	1001317
591	Une approche sociotechnique pour le Knowledge Management (KM)	un approche sociotechnique pour le Knowledge Management ( KM )  ce article présenter un cadre sociotechnique pour le KM . ce vision sociotechnique du KM permettre : ( 1 ) de écarter le KM de un souci commercial ; ( 2 ) faire le clivage des différent technologie du KM ; et ( 3 ) de clr interroger sur le paradigme associer aux composant social et technique du KM . ce être précisément ce dernier point que ce article développer afin de identifier le mécanisme générique du KM . plus précisément , le aspect social être décrire à travers le approche organisationnel du KM , le approche managérial du KM , et le approche biologique du KM , alors que le aspect technique être décrire à travers le approche ingénierie des connaissance et compétence du KM . ce approche cld conduire aussi à donner un tableau comparatif entre ce vision organisationnel , managérial et biologique du KM . 	Leoncio Jiménez	2007	@spock.ucm.cl	1001436
592	Une étude des algorithmes de construction d'architecture des réseaux de neurones multicouches	un étude des algorithme de construction de architecture des réseau de neurone multicouche  le problème de choix de architecture de un réseau de neurone multicouche rester toujours très difficile à résoudre dans un processus de fouille de donnée . ce papier recenser quelque algorithme de recherche de architecture de un réseau de neurone pour le tâche de classification . ilimp présenter également un analyse théorique et expérimental de ce algorithme . ce travail confirmer le difficulté de choix des paramètre de apprentissage ( modèle , nombre de couche , nombre de neurone par couche , taux de apprentissage , algorithme de apprentissage , ... ) commun à tout processus de construction de réseau de neurone et le difficulté de choix de paramètre propre à certain algorithme . 	Norbert Tsopzé, Engelbert Mephu Nguifo, Gilbert Tindo	2007	@univ-artois.fr, @gmail.com, @uycdc.uninet.cm	1001288
593	Une extension de XQuery pour la recherche textuelle d'information dans des documents XML	un extension de XQuery pour le recherche textuel de information dans un document XML  cln présenter dans ce article un extension de XQuery que cln avoir développer pour interroger le contenu et le structure de document XML . ce extension consister à intégrer dans XQuery le langage NEXI , un sous-ensemble de XPath , définir dans le cadre de le initiative INEX . son proposition être double : ( i ) équiper NEXI de un sémantique flou , ( ie ) intégrer NEXI dans XQuery au moyen de un métafonction appelé nexi , avoir un requête NEXI comme paramètre , et de un extension de le clause for de le opérateur FLWOR de XQuery . de plus , cln décrire le prototype paramétrable que cln avoir développer au dessus de deux moteur XQuery classique : Galax et Saxon . 	Jacques Le Maitre, Nicolas Faessel	2007	@lsis.org, @univ-tln.fr	1001401
594	Une méthode d'interprétation de scores	un méthode de interprétation de score  ce article présenter un méthode permettre de interpréter le sortie de un modèle de classification ou de régression . le interprétation clr baser sur le importance de le variable et le importance de le valeur de le variable . ce approche permettre de interpréter le sortie du modèle pour chaque instance . 	Raphaël Feraud, Vincent Lemaire	2007	@orange-ft.com	1001348
595	Une méthode optimale d'évaluation bivariée pour la classification supervisée	un méthode optimal de évaluation bivarié pour le classification superviser  en préparation des donnée pour le classification superviser , le méthode filtre usuellement utiliser pour le sélection de variable être efficace en temps de calcul . néanmoins , son nature univarié ne permettre pas de détecter le redondance ou le interaction constructif entre variable . ce article présenter un nouveau méthode permettre de évaluer le importance prédictif joindre de un paire de variable de façon automatique , rapide et fiable . cln être baser sur un partitionnement de chaque variable exogène , en intervalle dans le cas numérique et groupe de valeur dans le cas catégoriel . le grille de donnée exogène résultante permettre alors de évaluer le corrélation entre le paire de variable exogène et le variable endogène . le meilleur partitionnement bivarié être rechercher au moyen de un approche Bayésienne de le sélection de modèle . le expérimentation démontrer le apport de le méthode , notamment un amélioration significatif des performance en classification . 	Marc Boullé	2007	@orange-ft.com	1001420
596	Une nouvelle approche de la programmation DC et DCA pour la classification floue	un nouveau approche de le programmation DC et DCA pour le classification flou  dans ce article , cln clr intéresser à Fuzzy C-Means ( FCM ) , un technique très connaître pour le classification flou . cln proposer un algorithme efficace baser sur le programmation DC ( Difference of Convexe functions ) et DCA ( DC Algorithm ) pour résoudre ce problème . le expérience numérique comparatif avec le algorithme standard FCM sur le donnée réel montrer le robustesse , le performance de ce nouveau algorithme DCA et son supériorité par rapport à FCM . 	Le Thi Hoai An, Le Hoai Minh, Pham Dinh Tao	2007	@univ-metz.fr, @univ-metz.fr, @insa-rouen.fr	1001459
597	Une nouvelle méthode d'alignement et de visualisation d'ontologies OWL-Lite	un nouveau méthode de alignement et de visualisation de ontologie OWL-Lite  dans ce papier , un nouveau plate-forme de alignement et de visualisation des ontologie , appelé POVA ( Prototype OWL-Lite Visual Alignment ) , être décrire . le module de alignement implémenter un nouveau approche de alignement de ontologie remédier au problème de le circularité et de le intervention de le utilisateur . 	Sami Zghal, Karim Kamoun, Sadok Ben Yahia, Engelbert Mephu Nguifo	2007	@fst.rnu.tn, @univ-artois.fr	1001355
598	Une règle d'exception en Analyse Statistique Implicative	un règle de exception en analyse statistique Implicative  en fouille de règle , certain situation exceptionnel défier le bon sens . ce être le cas de le règle R : avoir -- c et b -- c et ( avoir et b ) -- non c . un tel règle , que cln étudier dans le article , être appelé règle de exception . A le suite des travaux précurseur de E. Suzuki et Y. Kodratoff ( 1999 ) , qui avoir étudier un autre type de règle de exception , cln chercher ici à caractériser le condition de apparition de le règle R dans le cadre de le analyse statistique Implicative . 	Régis Gras, Pascale Kuntz, Einoshin Suzuki	2007	@club-internet.fr, @univ-nantes.fr, @i.kyushu-u.ac.jp	1001312
599	Utilisation de WordNet dans la catégorisation de textes multilingues	utilisation de WordNet dans le catégorisation de texte multilingue  ce article être consacrer au problème de le catégorisation multilingue qui consister à catégoriser un document de différent langue en utiliser le même classifieur . le approche que cln proposer être baser sur le idée de étendre le utilisation de WordNet dans le catégorisation monolingue vers le catégorisation multilingue . 	Mohamed Amine Bentaallah, Mimoun Malki	2007	@univ-sba.dz, @yahoo.com	1001353
600	Validation des visualisations par axes principaux de données numériques et textuelles	validation des visualisation par axe principal de donnée numérique et textuel  parmi le outil de visualisation de donnée multidimensionnel figurer de un part le méthode fonder sur le décomposition aux valeur singulier , et de autre part le méthode de classification , inclure le carte auto- organiser de Kohonen . Comment valider ce visualisation ? cln présenter sept procédure de validation par bootstrap qui dépendre un donnée , un hypothèse , un outil : avoir ) le bootstrap partiel , qui considérer le réplication comme un variable supplémentaire ; b ) le bootstrap total de type 1 , qui réanalyser le réplication avec changement éventuel de signe des axe ; c ) le bootstrap total de type 2 qui corriger aussi le interversion de axe ; d ) le bootstrap total de type 3 , sur lequel cln insister , qui corriger le réplication par rotation procrustéen ; e ) le bootstrap spécifique ( cas des hiérarchie de individu statistique et des donnée textuel ) . f ) le bootstrap sur variable . gramme ) le extension des procédure précédent à certain carte auto- organiser . 	Ludovic Lebart	2007	@enst.fr	1001332
601	Vers un algorithme multi-agents de clustering dynamique	vers un algorithme multi-agent de clustering dynamique  dans ce article , cln présenter un algorithme multi-agent de clustering dynamique . ce type de clustering devoir permettre de gérer un donnée évolutif et donc être capable de adapter en permanence le cluster construire . 	Bruno Mermet, Gaële Simon, Dominique Fournier	2007	@univ-lehavre.fr, @univ-lehavre.fr	1001357
602	Vers un système hybride pour l'annotation sémantique d'images IRM du cerveau	vers un système hybride pour le annotation sémantique de image IRM du cerveau  ce article montrer le intérêt de combiner un méthode numérique et symbolique pour obtenir un annotation sémantique des image IRM du cerveau humain . ilimp clr agir de identifier un structure anatomique du cortex cérébral humain , en utiliser conjointement un connaissance avoir priorir de nature numérique et un ontologie des structure cortical du cerveau représenter en OWL DL , étendre par un règle SWRL . ce connaissance symbolique avoir priori représenter dans un langage standard du Web devenir non seulement partageable mais permettre aussi un raisonnement automatique qui aider le utilisateur à le labellisation des structure anatomique mettre en évidence dans un image IRM du cerveau de un individu donné . 	Ammar Mechouche, Christine Golbreich, Bernard Gibaud	2007	@irisa.fr, @univ-rennes1.fr	1001417
603	Vers une base de connaissances biographique : extraction d'information et ontologie	Vers un base de connaissance biographique : extraction de information et ontologie  le projet B-Ontology avoir pour but le extraction , le organisation et le exploitation de connaissance biographique à partir de dépêche de presse . son réalisation requérir le intégration de divers technologie , principalement le extraction de information , le ontologie et base de connaissance , le technique de data mining . ce article proposer un aperçu des choix réaliser dans le cadre du projet . ce démarche permettre également de définir un environnement de outil utile pour le application de extraction et de gestion de connaissance . 	Laurent Kevers, Cédrick Fairon	2007	@uclouvain.be, @uclouvain.be	1001400
604	Vers une nouvelle approche d'extraction des motifs séquentiels non-dérivables	vers un nouveau approche de extraction des motif séquentiel non- dérivable  le extraction de motif séquentiel être un défi important pour le communauté fouiller de donnée . même si le représentation condensé avoir montrer son intérêt dans le domaine des itemsets , à le heure actuel peu de travaux considérer ce type de représentation pour extraire un motif . ce article proposer de établir le premier base formel pour obtenir le borne inférieur et supérieur du support de un séquence S. cln démontrer que ce borne pouvoir être dériver à partir un sous-séquence de S et prouver que ce règle de dérivation permettre le construction de un nouveau représentation condensé de le ensemble des motif fréquent . le différent expérimentation mener montrer que son approche offrir un meilleur représentation condensé que celui des motif clos et cela sans perte de information . 	Pascal Poncelet, Chedy Raïssi	2007	@lirmm.fr, @ema.fr	1001391
605	Vers une plate-forme interactive pour la visualisation de grands ensembles de règles d'association	vers un plate-forme interactif pour le visualisation de grand ensemble de règle de association  " le recherche de règle de association être un question central en extraction de connaissance dans le Données ( ECD ) . . dans ce article , cln clr intéresser plus particulièrement à le restitution visuel de règle pertinent dans un corpus très important . . cln proposer ainsi un prototype baser sur un approche de type " " wrapper " " par intégration des phase de extraction et de visualisation de le ECD . . tout de abord , le processus de extraction générer un base générique de règle et dans un second temps , le tâche de visualisation clr appuyer sur un processus de regroupement ( " " clustering " " ) permettre de grouper et de visualiser un sous-ensemble de règle de association générique . . le rendre visuel à le écran exploiter un représentation de type " " Fisheye view " " de manière à obtenir simultanément un représentation global des différent groupe de règle et un vue détailler du groupe sélectionner . " 	Olivier Couturier, Tarek Hamrouni, Sadok Ben Yahia, Engelbert Mephu Nguifo	2007	@univ-artois.fr, @fst.rnu.tn	1001381
606	Visualisation de graphes avec Tulip : exploration interactive de grandes masses de données en appui à la fouille de données et à l'extraction de connaissances	visualisation de graphe avec Tulip : exploration interactif de grand masse de donnée en appui à le fouille de donnée et à le extraction de connaissance  ce article décrire un étude de cas exhiber le qualité de le plateforme de visualisation de graphe Tulip , démontrer le apport de le visualisation à le fouille de donnée interactif et à le extraction de connaissance . le calcul de un graphe à partir de indice de similarité être un exemple typique où le exploration visuel et interactif de graphe venir en appui au travail de fouille de donnée . cln pencher sur le cas où le cln souhaiter étudier un collection de document afin de avoir un idée des thématique aborder dans le collection . 	David Auber, Yves Chiricota, Maylis Delest, Jean-Philippe Domenger, Patrick Mary, Guy Melançon	2007	@labri.fr, @uqac.ca, @lirmm.fr	1001330
607	Visualisation exploratoire des résultats d'algorithmes d'arbre de décision	visualisation exploratoire des résultat de algorithme de arbre de décision  cln présenter un méthode de exploration des résultat des algorithme de apprentissage par arbre de décision ( comme C4.5 ) . le méthode présenter utiliser simultanément un visualisation radiale , focus + contextation , fisheye et hiérarchique pour le représentation et le exploration des résultat des algorithme de arbre de décision . le utilisateur pouvoir ainsi extraire facilement un règle de induction et élaguer le arbre obtenir dans un phase de post-traitement . cela cld permettre de avoir un meilleur compréhension des résultat obtenir . le résultat des test numérique avec un ensemble de donnée réel montrer que le méthode proposer permettre un bien meilleur compréhension des résultat des arbre de décision . 	Thanh-Nghi Do, Nguyen-Khang Pham, François Poulet	2007	@lri.fr, @irisa.fr, @esiea-ouest.fr	1001331
608	WebDocEnrich : enrichissement sémantique flexible de documents semi-structurés	WebDocEnrich : enrichissement sémantique flexible de document semi-structuré  WebdocEnrich être un approche de enrichissement sémantique automatique de document HTML hétérogène qui exploiter un description du domaine pour enrichir le contenu des document et cla représenter en XML . 	Mouhamadou Thiam, Nacéra Bennacer, Nathalie Pernelle	2007	@lri.fr, @supelec.fr	1001365
609	Accès aux connaissances orales par le résumé automatique	accès aux connaissance oral par le résumé automatique  le temps nécessaire pour écouter un flux audio être un facteur réduire le accès efficace àde grand archive de parole . un premier approche , le structuration automatique des donnée , permettre de utiliser un moteur de recherche pour cibler plus rapidement le information . Leslistes de résultat générer être long dans un souci de exhaustivité . alors que pour un documentstextuel , un coup de oeil discriminer un résultat interessant de un résultat non pertinant , ilimp falloir écouter le audio dans son intégralité pour cll capturer le contenu . cln proposer doncd'utiliser le résumé automatique afin de structurer le résultat des recherche et de en réduirele redondance . 	Benoît Favre, Jean-François Bonastre, Patrice Bellot, François Capman	2006	@thalesgroup.com, @univ-avignon.fr, @univ-avignon.fr, @univ-avignon.fr	1000358
610	Affectation pondérée sur des données de type intervalle	affectation pondérer sur un donnée de type intervalle  cln clr intéresser à le construction de arbre de décision sur un donnée symbolique de type intervalle en utiliser le critère de découpage binaire de Kolmogorov-Smirnov . cln proposer un approche permettre de affecter un individu à le fois aux deu noeud fils générer par le partitionnement de un noeud non terminal . le but de ce méthode être de prendre en compte le positionnement de le donner à classer par rapport à le donner seuil de coupure . 	Edwin Diday, Chérif Mballo	2006	@esiea-ouest.fr, @ceremade.dauphine.fr	1000373
611	Algorithme semi-interactif pour la sélection de dimensions	algorithme semi-interactif pour le sélection de dimension  " cln présenter un algorithme génétique semi-interactif de sélectionun dimension dans le grand ensemble de donnée pour le détectiond'individu atypique ( outlier ) . . le ensemble de donnée posséder unnombre élevé de dimension poser un nombreux problème aux algorithmesd fouiller de donnée , un solution être de effectuer un pré-traitement afin de neretenir que le dimension " " intéressant " " . . cln utiliser un algorithmegénétique pour le choix du sous-ensemble de dimension à retenir . . par ailleursnous souhaiter donner un rôle plus important à le utilisateur dans le processusde fouille , cln avoir donc développer un algorithme génétique semi-interactifoù le évaluation des solution ne éliminer pas complètement le fonctiond'évaluation mais le couple avec un évaluation de le utilisateur . . enfin , le important réduction du nombre de dimension cld permettre de visualiser lesrésultat de le algorithme de détection de outlier . . ce visualisation permettre àl'expert un donnée de étiqueter le élément atypique ( erreur ou simplementdes individu différent de le masse ) . " 	Lydia Boudjeloud, François Poulet	2006	@esiea-ouest.fr	1000366
612	Alignement extensionnel et asymétrique de hiérarchies conceptuelles par découverte d'implications entre concepts	alignement extensionnel et asymétrique de hiérarchie conceptuel par découverte de implication entre concept  dans le littérature , de nombreux travaux traiter de méthode de alignementd'ontologie . cln utiliser , pour le plupart , un relation baser sur desmesure de similarité qui avoir le particularité de être symétrique . cependant , peude travaux évaluer le intérêt de utiliser un mesure de appariement asymétriquesdans le but de enrichir le alignement produire . ainsi , cln proposer dans ce papierun méthode de alignement extensionnel et asymétrique baser sur le découvertedes implication significatif entre deux ontologie . son approche , baser sur le modèle probabiliste de écart à le indépendance appeler intensité de implication , être diviser en deux party consécutif : ( 1 ) le extraction , à partir ducorpus textuel associer à le ontologie , et le association des terme aux concept ; ( 2 ) le découverte et sélection des implication générateur le plus significativesentre le concept . le méthode proposer être évaluer sur deux jeu de donnéesréel porter respectivement sur un profil de entreprise et sur un cataloguesd cours de université . le résultat obtenir montrer que le cln pouvoir trouver desrelations pertinent qui être ignorer par un alignement baser seulement sur desmesure de similarité . 	Jérôme David, Fabrice Guillet, Régis Gras, Henri Briand	2006	@univ-nantes.fr	1000337
613	Amélioration des indicateurs techniques pour l'analyse du marché financier	amélioration des indicateur technique pour le analyse du marché financier  le technique des motif fréquent avoir être utiliser pour améliorer lepouvoir prédictif des stratégie quantitatif . innover dans le contexte desmarchés financier , son méthode associer un signature aux configuration demarché fréquent . un système de « trading » automatique sélectionner lesmeilleuron signature par un procédure de « back testing » itératif et le utiliseen combinaison avec le indicateur technique pour améliorer son performance . le application des motif fréquent à ce problématique des indicateurstechnique être un contribution original . Au sens du test t de Student , son méthode améliorer nettement le approche sans signature . le techniquea être tester sur un donnée journalier type taux de intérêt et action . Notreanalyse des indicateur ( Williams \% R , BN et croisement des moment ) avoir montréqurer que un approche par signature être particulièrement bien adapter auxstratégies à mémoire court . 	Hunor Albert-Lorincz, Jean-François Boulicaut	2006	@sdm.cic.fr, @insa-lyon.fr	1000428
614	Analyse du Comportement des utilisateurs exploitant une base de données vidéo	analyse du comportement des utilisateur exploiter un base de donnée vidéo  dans ce article , cln présenter un modèle de fouille des usages dela vidéo pour améliorer le qualité de le indexation . cln proposer un approchebasée sur un modèle à deux niveau représenter le comportement des utilisateursexploitant un moteur de recherche vidéo . le premier niveau consister àmodéliser le comportement lors de le lecture de un vidéo unique ( comportementintron vidéo ) , le second à modéliser le comportement sur le ensemble de un session ( comportement inter videonisé ) . A partir de ce représentation , cln avonsdéveloppé un algorithme de regroupement , adapter à le nature particulier de cesdonné . le analyse des usages de le vidéo cln permettre de affiner le indexationvidéo sur le base de le intérêt des utilisateur . 	Sylvain Mongy	2006	@lifl.fr	1000376
615	Annotation sémantique de pages web	annotation sémantique de page web  ce article présenter un système automatique de annotation sémantiquede page web . le système de annotation automatique existant être essentiellementsyntaxique , même lorsque le travaux viser à produire un annotationsémantique . le prise en compte de information sémantique sur le domaine pourl'annotation de un élément dans un page web à partir de un ontologie supposed'aborder conjointement deux problème : ( 1 ) le identification de le structuresyntaxique caractériser ce élément dans le page web et ( 2 ) le identification duconcept le plus spécifique ( en terme de subsumption ) dans le ontologie dontl'instance être utiliser pour annoter ce élément . son démarche reposer sur lamis en oeuvre de un technique de apprentissage issue initialement des wrappersque cln avoir articuler avec un raisonnement exploiter le structure formellede le ontologie . 	Sylvain Tenier, Amedeo Napoli, Xavier Polanco, Yannick Toussaint	2006	@inist.fr, @loria.fr	1001499
616	Apprentissage de la structure des réseaux bayésiens à partir des motifs fréquents corrélés : application à l'identification des facteurs environnementaux du cancer du Nasopharynx	apprentissage de le structure des réseau bayésien à partir un motif fréquent corréler : application à le identification des facteur environnemental du cancer du Nasopharynx  le apprentissage de structure des réseau bayésien à partir de donnéesest un problème NP-difficile pour lequel de nombreux heuristique avoir être proposer . dans ce article , cln proposer un nouveau méthode inspirer des travauxsur le recherche de motif fréquent corréler pour identifier le causalitésentre le variable . le algorithme opérer en quatre temps : ( 1 ) le découvertepar niveau des motif fréquent corréler minimal ; ( 2 ) le construction de ungraphe non orienter à partir de ce motif ; ( 3 ) le détection des V  structure etl'orientation partiel du graphe ; ( 4 ) le élimination des arête superflu par destest de indépendance conditionnel . le méthode , appliquer au réseau Asia , permetde retrouver le structure du graphe initial . cln cla appliquer ensuite auxdonner de un étude épidémiologique cas-témoin du cancer du nasopharynx ( NPC ) . le objectif être de dresser un profil statistique type de le population étudiéeettre de apporter un éclairage utile sur le différent facteur impliquer dans leNPC . 	Alexandre Aussem, Zahra Kebaili, Marilys Corbex, Fabien De Marchi	2006	@univ-lyon1.fr, @iarc.fr, @liris.cnrs.fr	1000420
617	Approche entropique pour l'analyse de modèle de chroniques	approche entropique pour le analyse de modèle de chronique  ce article proposer de utiliser le entropie informationnel pouranalyser des modèle de chronique découvert selon un approchestochastique ( Bouché et le Goc , 2005 ) . ilimp décrire un adaptation de le algorithmeTemporalID3 ( console et Picardi , 2003 ) permettre de découvrir un modèlesd chronique à partir de un ensemble de apprentissage contenir un séquencesd'occurrence de événement discret . ce séquence représenter un suitesd'alarme générer par un système à base de connaissance de monitoring et dediagnostic de système dynamique . cln montrer sur un exemple que le approcheentropique compléter le approche stochastique en identifier le classesd'événement qui contribuer le plus significativement à le prédiction de uneoccurrence de un classe particulier . 	Nabil Benayadi, Marc Le Goc, Philippe Bouché	2006	@lsis.org	1000397
618	Arbres de décision multi modes et multi cibles.	arbre de décision multi mode et multi cible .  cln présenter un nouveau méthode de induction de arbre de décision appelé MuMTree ( pour Multi Models Tree ) utilisable pour le mode de apprentissage superviser , non superviser , superviser à plusieurs variable cible . cln présenter le différent principe nécessaire pour réaliser un tel arbre de décision . cln illustrer ensuite , sur un cas de modélisation multi-cible , le avantage de ce méthode par rapport à un arbre de décision classique . 	Frank Meyer, Fabrice Clérot	2006	@francetelecom.com, @francetelecom.com	1000401
619	Bordures statistiques pour la fouille incrémentale de données dans les Data Streams	bordure statistique pour le fouille incrémental de donnée dans le Data Streams  récemment le communauté Extraction de Connaissances clr être intéresser à un nouveau modèle où le donnée arriver séquentiellement sous le forme de un flot rapide et continu , i.e. cla dater stream . le un des particularité important de ce flot être que seul un quantité de information partiel être disponible au cours du temps . ainsi après différent mise à jour successif , ilimp devenir indispensable de considérer le incertitude inhérent à le information retenir . dans ce article , cln introduire un nouveau approche statistique en biaiser le valeur support pour le motif fréquent . ce dernier avoir le avantage de maximiser le un des deu paramètre ( précision ou rappel ) déterminer par le utilisateur tout en limiter le dégradation sur le paramètre non choisir . pour cela , cln définir le notion de bordure statistique . Celles -ci constituer le ensemble de motif candidat qui clr avérer très pertinent à utiliser dans le cas de le mise à jour incrémental des stream . le différent expérimentation effectuer dans le cadre de recherche de motif séquentiel avoir montrer le intérêt de le approche et le potentiel des technique utiliser . 	Jean-Emile Symphor, Pierre-Alain Laur	2006	@univ-ag.fr	1000417
620	Carte auto-organisatrice probabiliste sur données binaires	carte auto- organisatrice probabiliste sur donnée binaire  Lesméthodes factorielle de analyse exploratoire statistique définissentdes direction orthogonal informatif à partir de un ensemble de donnée . cln conduire par exemple à expliquer le proximité entre individu à le aided'un groupe de variable caractéristique . dans le contexte du datamining lorsqueles tableau de donnée être de grand taille , un méthode de cartographie synthétiques'avère intéressant . ainsi un carte auto- organisatrice ( SOM ) être uneméthode de partitionnement munir de un structure de graphe de voisinage-surle classe cla plus souvent planaire . un travaux récent être développer pourétendre le SOM probabiliste Generative Topographic Mapping ( GTM ) aux modèlesde mélange classique pour donnée discret . dans ce papier cln présentonsettre étudier un modèle génératif symétrique de carte auto- organisatricepour donner binaire que cln appeler Bernoulli Aspect Topological Model ( BATM ) . cln introduire un nouveau lissage et accélérer le convergence del'estimation par un initialisation original des probabilité en jeu . 	Mohamed Nadif, Rodolphe Priam	2006		1000386
621	Champs de Markov conditionnels pour le traitement de séquences	Champs de Markov conditionnel pour le traitement de séquence  le modèle conditionnel du type modèle de Markov de entropiemaximale et champs de Markov conditionnel apporter un réponse auxlacunes des modèle de Markov cacher traditionnellement employer pour laclassification et le segmentation de séquence . ce modèle conditionnel ontété essentiellement utiliser jusque à présent dans un tâche de extractiond'information ou de étiquetage morphosyntaxique . ce contribution explorel'emplovoir de ce modèle pour un donnée de nature différent , de type « signal » , tel que le parole ou le écriture en ligne . cln proposer desarchitecture de modèle adapté à ce tâche pour lequel cln avonsdérivé le algorithme de inférence et de apprentissage correspondant . Nousfournissons un résultat expérimental pour deux tâche de classification etd'étiquetage de séquence . 	Thierry Artières, Trinh Minh Tri Do	2006	@lip6.fr, @lip6.fr	1000419
622	Choix du taux d'élagage pour l'extraction de la terminologie. Une approche fondée sur les courbes ROC	choix du taux de élagage pour le extraction de le terminologie . un approche fonder sur le courbe ROC  le choix du taux de élagage être crucial dans le but de acquérir un terminologiede qualité à partir de corpus de spécialité . ce article présent uneétude expérimental consister à déterminer le taux de élagage le plus adapté . plusieurs mesure de évaluation pouvoir être utiliser pour déterminer ce tauxtel que le précision , le rappel et le Fscore . ce étude clr appuyer sur un autremesure de évaluation qui sembler particulièrement bien adapter pour le extractiond le terminologie : le courbe ROC ( Receiver Operating Characteristics ) . 	Mathieu Roche, Yves Kodratoff	2006	@lirmm.fr, @lri.fr	1000347
623	Classification de documents XML à partir d'une représentation linéaire des arbres de ces documents	classification de document XML à partir de un représentation linéaire des arbre de ce document  ce article présenter un nouveau modèle de représentation pour le classificationd document XML . son approche permettre de prendre en compte soitle structure seul , soit le structure et le contenu de ce document . le idée estder représenter un document par le ensemble des sous-chemin de le arbre XMLde longueur comprendre entre n et m , deux valeur fixé avoir priori . ce cheminssont ensuite considérer comme un simple mots sur lequel cln pouvoir appliquerdes méthode standard de classification , par exemple K-means . cln évaluonsson méthode sur deux collection : le collection INEX et le rapport de activitéd le INRIA . cln utiliser un ensemble de mesure bien connaître dans le activitéd le recherche de information lorsque le classe être connaître avoir priorir . lorsque cln ne être pas connaître , cln proposer un analyse qualitatif desrésultat qui clr appuyer sur le mots ( chemin ) le plus caractéristique des classesgénéré . 	Anne-Marie Vercoustre, Mounir Fegas, Yves Lechevallier, Thierry Despeyroux	2006	@inria.fr	1000384
624	Classification des comptes-rendus mammographiques à partir d'une ontologie radiologique en OWL	classification des comptes-rendu mammographique à partir de un ontologie radiologique en OWL  dans ce article , cln proposer un système de classification descomptes-rendus mammographique , reposer sur un ontologie radiologiquedécrivant le signe radiologique et le différent classe de le classificationACR des système BIRADS dans le langage OWL . le système être concevoir pour , extraire le fait issir des texte libre de comptes-rendu en être diriger parl'ontologie , puis inférer le classe correspondant et cll déduire le attitude à tenirà partir de le classification ACR . ce travail présenter le construction de un ontologieradiologique mammaire dans le langage OWL et son intérêt pour classerautomatiquement le comptes-rendu de mammographie . 	Amel Boustil, Zaïdi Sahnoun, Ziad Mansouri, Christine Golbreich	2006	@yahoo.fr, @yahoo.fr, @univ-rennes1.fr	1000346
625	Classification d'un tableau de contingence et modèle probabiliste	classification de un tableau de contingence et modèle probabiliste  ce dernier année , le classification croisé ou classification parblocs , ce est-à-direr le recherche simultané de un partition des ligne et de unepartition des colonne de un tableau de donnée , être devenir un outil très utiliséen fouille de donnée . dans ce domaine , le information clr présenter souvent sousforme de tableau de contingence ou tableau de co- occurrence croiser le modalitésde deux variable qualitatif . dans ce article , cln étudier le problèmed le classification croisé de ce type de donnée en cld appuyer sur un modalitésde mélange probabiliste . en utiliser le approche vraisemblance classifiant , cln proposer un algorithme de classification croisé baser sur le maximisationalterné de le vraisemblance associer à deux mélange multinomiaux classiqueset cln montrer alors que sous certain contrainte restrictif , cln retrouveles critère du Chi2 et de le information mutuel . un résultat sur un donnéessimulé et des donnée réel illustrer et confirmer le efficacité et le intérêt decette approche . 	Gérard Govaert, Mohamed Nadif	2006	@utc.fr, @univ-metz.fr	1000387
626	Classifications hiérarchiques factorielles de variables	classification hiérarchique factoriel de variable  cln présenter deux méthode de classification hiérarchique ascendantede variable quantitatif et de fréquence . chaque noeud de ce hiérarchiesregroupe deu classe de variable à partir de un analyse factoriel particulièrebasée sur le variable représentatif de ce deu classe . par ce méthode , cln disposer , à chaque pas , de un plan factoriel permettre de représenter àle fois le variable des deu classe fusionner et le ensemble des individu . ce dernier clr positionner dans ce plan suivant son valeur pour le variablesconsidéré . ainsi , le interprétation des noeud obtenir clr effectuer facilementà partir de le examen de ce représentation factoriel . le répartition desindividus observer dans chacun de ce plans factoriel permettre également dedéfinir un segmentation des individu en total accord avec le hiérarchie desvariable obtenir . cln montrer le fonctionnement des méthode sur un exemplesréel . 	Sergio Camiz, Jean-Jacques Denimal 	2006	@uniroma1.it, @univ-lille1.fr	1000374
627	Clustering dynamique d'un flot de données : un algorithme incrémental et optimal de détection des maxima de densité	Clustering dynamique de un flot de donnée : un algorithme incrémental et optimal de détection des maximum de densité  le extraction non supervisé et incrémental de classe sur un flot dedonné ( dater stream clustering ) être un domaine en plein expansion . le plupartdes approche viser le efficacité informatique . le nôtre , bien que clr prêtantà un passage à le échelle en mode distribuer , relever de un problématiquequalitative , applicable en particulier au domaine de le veille informationnel : faire apparaître le évolution fin , le « signal faible » , à partir un thématiquesextrait de un flot de document . son méthode GERMEN localiser defaçon exhaustif le maximum du paysage de densité des donnée à le instant t , en identifier le perturbation local du paysage à t- 1 et modification defrontier induire par le document présenter . son caractère optimal provenir deson exhaustivité ( à un valeur du paramètre de localité correspondre un ensembleunique de maximum , et un découpage unique des classe qui cla rendre indépendanteder tout paramètre de initialisation et de le ordre des donnée . 	Alain Lelu	2006	@univ-fcomte.fr	1000320
628	Combinaison de l'approche inductive (progressive) et linguistique pour l'étiquetage morphosyntaxique des corpus de spécialité	combinaison de le approche inductif ( progressif ) et linguistique pour le étiquetage morphosyntaxique des corpus de spécialité  le étiqueteur morphosyntaxique être de plus en plus performantset cependant , un véritable problème apparaître lorsque cln vouloir étiqueterdes corpus de spécialité pour lequel cln ne avoir pas un corpus annoter . Lacorrection des ambiguïté difficile être un étape important pour obtenir uncorpus de spécialité parfaitement étiqueter . pour corriger ce ambiguïté et diminuerle nombre de faute , cln utiliser un approche itératif appelé InductionProgressive . ce approche être un combinaison de apprentissage automatique , de règle rédiger par le expert et de correction manuel qui secombiner itérativement afin de obtenir un amélioration de le étiquetage tout enrestreignant le action de le expert à le résolution de problème de plus en plusdélicat . le approche proposer cln avoir permettre de obtenir un corpus de biologiemoléculaire « correctement » étiqueter . en utiliser ce corpus , cln avoir effectuéun étude comparatif de quatre étiqueteur supervisé . 	Ahmed Amrani, Yves Kodratoff	2006	@esiea.fr, @lri.fr	1000354
629	Comparaison de deux modes de représentation de données faiblement structurées en sciences du vivant	comparaison de deux mode de représentation de donnée faiblement structurer en science du vivre  ce article présenter deux mode de représentation de le informationdans le cadre de un problématique en science du vivre . le premier , appliquer àla microbiologie prévisionnel , clr appuyer sur deux formalisme , le modèle relationnelettre le graphe conceptuel , interroger uniformément via un même interface . le second , appliquer aux technologie des céréale , utiliser le seul modèlerelationnel . ce article décrire le caractéristique des donnée et comparer le solutionsde représentation adopter dans le deu système . 	Rallou Thomopoulos, Patrice Buche, Ollivier Haemmerlé, Frédéric Mabille, Nongyao Mueangdee	2006	@ensam.inra.fr, @risk, @inapg.fr, @univ-tlse2.fr	1000332
630	Comparaison de dissimilarités pour l'analyse de l'usage d'un site web	comparaison de dissimilarité pour le analyse de le usage de un site web  " le obtention de un classification des page de un site web en fonctionun navigation extraire des fichier " " logs " " du serveur pouvoir clr avérer très utilepour évaluer le adéquation entre le structure du site et le attente des utilisateur . . Onconstruit un tel typologie en clr appuyer un mesure de dissimilarité entre lespage , définir à partir un navigation . . le choix de le mesure le plus appropriéeà le analyse du site être donc fondamental . . dans ce article , cln présenter unsite de petit taille dont le page être classer en catégorie sémantique parun expert . . cln confronter ce classement aux partition obtenir à partir dediverson dissimilarité afin de cll étudier le avantage et inconvénient . " 	Fabrice Rossi, Francisco de Assis Tenório de Carvalho, Yves Lechevallier, Alzennyr Da Silva	2006		1000378
631	Comparaison des mesures d'intérêt de règles d'association : une approche basée sur des graphes de corrélation	comparaison des mesure de intérêt de règle de association : un approche baser sur un graphe de corrélation  le choix des mesure de intérêt ( MI ) afin de évaluer le règle de associationest devenir un question important pour le post-traitement des connaissanceen ECD . dans le littérature , de nombreux auteur avoir discuter et comparéles propriété des mi afin de améliorer le choix des meilleur mesure . cependant , ilimp clr avérer que le qualité de un règle être contextuel : cln dépendre à le fois dela structure de donnée et des but du décideur . ainsi , certain mesure peuventêtre approprié dans un certain contexte , mais pas dans un autre . dans ce article , cln présenter un nouveau approche contextuel mettre en applicationpar un nouveau outil , ARQAT , permettre à un décideur de évaluer et de comparerle comportement des mi sur son jeu de donnée spécifique . ce approche estbaséer sur le analyse visuel de un graphe de corrélation entre un mi objectif . cln employer ensuite ce approche afin de comparer et de discuter le comportementd trente-six mesure de intérêt sur deux ensemble de donnée avoir prioritrèrer opposer : un premier dont le donnée être fortement corréler et un secondal donner faiblement corréler . alors que cln attendre un différence importantesentre le graphe de corrélation de ce deu jeu de essai , cln avonspu observer un stabilité de corrélation entre certain MI qui être révélatricesun propriété indépendant de le nature des donnée observer . ce stabilitéssont récapitulé et analysé . 	Xuan-Hiep Huynh, Fabrice Guillet, Henri Briand	2006	@univ-nantes.fr	1000404
632	Critère VT100 de sélection des règles d'association	critère VT100 de sélection des règle de association  le extraction de règle de association générer souvent un grand nombreun règle . pour cla classer et cla valider , un nombreux mesure statistiqueêtre être proposer ; cln permettre de mettre en avant tel ou tel caractéristiquesdes règle extraire . cln avoir pour point commun de être fonctioncroissant du nombre de transaction et aboutir bien souvent àl'acceptation de tout le règle lorsque le base de donnée être de grandetaille . dans ce article , cln proposer un mesure inspirer de le notion de valeur-test . cln présenter comme principal caractéristique de être insensible à lataille de le base , éviter ainsi le écueil des règle fallacieusement significatif . cln permettre également de mettre sur un même pied , et donc de cla comparer , un règle qui avoir être extraire de base de donnée différent . cln permetenfin de gérer différent seuil de signification des règle . le comportement deler mesure être détailler sur un exemple . 	Alain Morineau, Ricco Rakotomalala	2006	@modulad.fr, @univ-lyon2.fr	1000409
633	De l'analyse didactique à la modélisation informatique pour la conception d'un EIAH en chirurgie orthopédique	de le analyse didactique à le modélisation informatique pour le conception de un EIAH en chirurgie orthopédique  le objet de le recherche présenter être de concevoir un environnementinformatique de apprentissage qui permettre de réduire le écart entre le formationthéorique des chirurgien et son formation pratique , qui clr dérouleprincipalement sur le mode du compagnonnage . le article exposer laméthodologie et quelque illustration du travail didactique de analyse desconnaissance et du système de enseignement  apprentissage en milieuhospitalier ( chirurgie orthopédique ) ainsi que partie de le environnementinformatique de ce connaissance . ce modélisation permettre le prise encompte dans le environnement informatique de connaissance pragmatiquespour le diagnostic des connaissance de le utilisateur en fonction des actionsqu'ux effectuer à le interface pendant le résolution de un problème ( pose de visdans le bassin ) , et le prise de décision didactique qui suivre : quel rétroactionfournir pour affiner le diagnostic , et-ou permettre le apprentissage souhaiter . 	Vanda Luengo, Lucile Vadcard, Dima Mufti-Alchawafa	2006	@imag.fr, @imag.fr, @imag.fr	1000422
634	Définition et diffusion de signatures sémantiques dans les systèmes pair-à-pair	définition et diffusion de signature sémantique dans le système pair-à-pair  le système pair-à-pair ( peer-to- peer , P2P , égal-à-égal ) clr être popularisésx dernier année avec le système de partage de fichier sur Internet . un nombreux recherche concernant le optimisation de le localisationd donner avoir émerger et constituer un axe de recherche très actif . le priseen compte de le sémantique du contenu des pairs dans le routage des requêtespermet de améliorer considérablement le localisation des donnée . cln nousconcentrons sur le approche PlanetP , faire usage de le notion de filtre de Bloom , qui consister à propager un signature sémantique des pairs ( filtre de Bloom ) àtravers le réseau . cln présenter ce approche et cll proposer un amélioration : le création de filtre de Bloom dynamique , dans le sens où son tailledépend de le charge des pairs ( nombre de document partager ) . 	Raja Chiky, Bruno Defude, Georges Hébrail	2006	@enst.fr, @enst.fr, @int-evry.fr	1000388
635	Des motifs séquentiels généralisés aux contraintes de temps étendues	un motif séquentiel généraliser aux contrainte de temps étendre  dans un nombreux domaine , le recherche de connaissance temporellesêtre très apprécier . un technique avoir être proposer aussi bien en fouille dedonné que en apprentissage , afin de extraire et de gérer de tel connaissance , en cla associer également à le spécification de contrainte temporel ( e.gure : fenêtretemporelle maximal ) , notamment dans le contexte de le recherche de motifsséquentiel . cependant , ce contrainte être souvent trop rigide ou nécessitentune bon connaissance du domaine pour ne pas extraire un informationserronée . ce être pourquoi cln proposer un approche baser sur le constructiond graphe de séquence afin de prendre en compte des contrainte de tempsplus souple . ce contrainte être relâcher par rapport aux contrainte de tempsprécédemment proposer . cln permettre donc de extraire plus de motif pertinent . afin de guider le analyse des motif obtenir , cln proposer égalementun niveau de précision des contrainte temporel pour le motif extrait . 	Maguelonne Teisseire, Céline Fiot, Anne Laurent	2006	@lirmm.fr	1000415
636	Exploration des paramètres discriminants pour les représentations vectorielles de la sémantique des mots	exploration des paramètre discriminant pour le représentation vectoriel de le sémantique des mots  le méthode de représentation sémantique des mots à partir de un analyse statistique être baser sur un comptes de co- occurence entre mots et unité textuel . ce méthode avoir des paramétrage complexe , notamment le type de unité textuel utiliser comme contexte . ce paramètre déterminer fortement le qualité des résultat obtenir . dans ce article , cln clr intéresser au paramètrage de le technique dire Hyperspace Analogue to Language ( HAL ) . cln proposer un nouveau méthode pour explorer son paramètre discriminant . ce méthode être baser sur le analyse de un graphe de voisinage de un liste de mots de référence pré-classé . cln expérimenter ce méthode et en donner le premier résultat qui renforcer et compléter un résultat issu de travaux précédent . 	Frank Meyer, Vincent Dubois	2006	@francetelecom.com, @francetelecom.com	1000360
637	Exploration interactive de bases de connaissances : un retour d'expérience	exploration interactif de base de connaissance : un retour de expérience  le navigation au sein de base de connaissance rester un problèmeouvert . S' ilimp exister plusieurs paradigme de visualisation , peu de travaux sur lesretour de expérience être disponible . dans le cadre de ce article cln noussommer intéresser aux différent paradigme de navigation interactif au seinde base documentaire annoter sémantiquement ; le accès à le base deconnaissances clr effectuer à travers le ontologie du domaine de application . Cesparadigmes avoir être évaluer dans le cadre de un application industriel ( mécanique des fluide et échangeur thermique ) en fonction de critèresdéfini par le utilisateur . le analyse des retour de expérience1 cld avoir permisde spécifier et de réaliser un nouveau navigateur dédier à le gestion deconnaissances technique annoter par un ontologie de domaine : le « eye Tree » , navigateur de type « polar fisheye view » . 	Christophe Tricot, Christophe Roche	2006	@univ-savoi	1000362
638	Extraction automatique de champs numériques dans des documents manuscrits	extraction automatique de champs numérique dans un document manuscrit  cln décrire dans ce article un chaine de traitement complet etgénérique permettre de extraire automatiquement le champs numérique ( numérosun téléphone , codes client , codes postal ) dans un document manuscritslibre . son chaïne de traitement être constituer des trois étape suivant : localisation des champs numérique potentiel selon un approche markoviennesans reconnaissance chiffre ni segmentation , reconnaissance des séquence extraire , et vérification des hypothèse de localisation  reconnaissance en vue delimiter le fausser alarme géneré lors de le étape de localisation . le évaluation denotre système sur un base de 300 courrier manuscrit montrer des performancesen rappel-précision intéressant . 	Clément Chatelain, Laurent Heutte, Thierry Paquet	2006	@univ-rouen.fr	1000319
639	Extraction d'objets vidéo : Une approche combinant les contours actifs et le flot optique	extraction de objet vidéo : un approche combiner le contour actif et le flot optique  dans ce article , cln présenter un méthode mixte de segmentationd'objet visuel dans un séquence de image de un vidéo combiner à le foisune segmentation baser région et le estimation de mouvement par flot optique . le approche développé être baser sur un minimisation de un fonctionnelled'énergie ( E ) qui faire intervenir le probabilité de appartenance ( densité ) avecune gaussienne , en tenir compte des information perceptuel de couleur etde texture des région de intérêt . pour améliorer le méthode de détection et desuioui , cln avoir étendre le formulation énergétique de son modèle decontour actif en inclure un force supplémentaire issue du calcul du flot optique . cln montrer le intérêt de ce approche mixte en terme de temps de calculet de extraction de objet vidéo complexe , et cln présenter le résultatsobtenu sur un séquence de corpus vidéo couleur . 	Youssef Zinbi, Youssef Chahir, Abder Elmoatz	2006	@unicaen.fr, @greyc.ismra.fr	1000321
640	Extraction de motifs séquentiels dans les flots de données d'usage du Web	extraction de motif séquentiel dans le flot de donnée de usage du Web  " ce dernier année , de nouveau contrainte être apparaître pour lestechnique de fouille de donnée . . ce contrainte être typique de un nouveaugenre de donnée : le " " dater stream " " . . dans un processus de fouille appliquésur un dater stream , le utilisation de le mémoire être limiter , de nouveau élémentssont générer en permanence et devoir être traiter le plus rapidement possible , aucun opérateur bloquer ne pouvoir être appliquer sur le donnée et celui -ci nepeuvent être observer que un seul fois . . A le heure actuel , le majorité des travauxrelatif à le extraction de motif dans le data stream ne concerner pas lesmotifs temporel . . cln montrer dans ce article que cela être principalement dûau phénomène combinatoire qui être lier à le extraction de motif séquentiel . . Nousproposons alors un algorithme baser sur le alignement de séquence pour extrairele motif séquentiel dans le data stream . . Afin de respecter le contrainte de unepasse unique sur le donnée , un heuristique glouton être proposer pour extrairele séquence . . cln montrer enfin que son proposition être capabled'extraire un motif pertinent avec un support très faible . " 	Florent Masseglia, Alice Marascu	2006	@inria.fr	1000418
641	Extraction de relations dans les documents Web	extraction de relation dans le document Web  cln présenter un système pour le inférence de programme de extraction de relation dans le document Web . ilimp utiliser le vue textuel et structurel sur le document . le extraction des relation être incrémental et utiliser un méthode de composition et de enrichissement . cln montrer que son système être capable de extraire un relation pour le organisation existant dans le document Web ( liste , table , table tourner , table croisé ) . 	Rémi Gilleron, Patrick Marty, Marc Tommasi, Fabien Torre	2006	@univ-lille3.fr	1000380
642	Extraction et identification d'entités complexes à partir de textes biomédicaux	extraction et identification de entité complexe à partir de texte biomédical  cln présenter ici un système de extraction et de identification de entitésnommé complexe à le intention des corpus de spécialité biomédical . Nousavons développer un méthode qui reposer sur un approche mixte à base de ensembled règle avoir priori et de dictionnaire contrôler . ce article exposer lestechnique que cln avoir mettre en place pour éviter ou minimiser le problèmesde synonymie , de variabilité des terme et pour limiter le présence denoms ambigu . cln décrire le intégration de ce méthode au sein du problèmesde reconnaissance des entité nommer . le intérêt de ce outil résider dans lacomplexité et le hétérogénéité des entité extraire . ce méthode ne clr limitepas à le détection des nom des gène ou un protéine , mais clr adapter à un autresdescripteur biomédical . cln avoir expérimenter ce approche en mesurantle performance obtenir sur le corpus de référence GENIA . 	Julien Lorec, Gérard Ramstein, Yannick Jacques	2006	@nantes.inserm.fr, @univ-nantes.fr	1000350
643	FaBR-CL : méthode de classification croisée de protéines	FaBR-CL : méthode de classification croisé de protéine  dans ce article , cln proposer un méthode de classification croiséepermettant de classer un protéine , de un part , et de classer un descripteur ( 3- gramme ) selon son pertinence par rapport aux groupe de protéine obtenir , un autre part . 	Walid Erray, Faouzi Mhamdi	2006	@univ-lyon2.fr, @ensi.rnu.tn	1000446
644	Faire vivre un référentiel métier dans l'industrie : le système de gestion de connaissances ICARE	faire vivre un référentiel métier dans le industrie : le système de gestion de connaissance ICARE  le gestion des connaissance , enjeu majeur pour le industrie , être entréedans un phase concret de déploiement . le conjonction de un maturitédes organisation dans le maîtrise de son métier , le consolidation de méthodeset le outil évolutif pour faire vivre un patrimoine de connaissance favorisentl'émergence de projet significatif et son diffusion opérationnel au seinde grand groupe industriel . ICARE chez PSA Peugeot Citroën réaliser avecl'environnement Ardans Knowledge Maker cll être ici le exemple . 	Alain Berger, Pierre Mariot, Christophe Coppens, Julien Laroque Malbert	2006	@ardans.com, @ardans.com, @mpsa.com, @mpsa.com	1000450
645	Fast-MGB : Nouvelle Base Générique Minimale de Règles Associatives	Fast-MGB : nouveau Base Générique Minimale de Règles Associatives  le problème de le exploitation des règle associatif être devenir primordial , puisque le nombre des règle associatif extraire des jeu de donnéesréel devenir très élevé . un solution possible consister à ne dériver que unebase générique de règle associatif . ce ensemble de taille réduit permettre degénérer tout le règle associatif via un système axiomatique adéquat . Danscet article , cln proposer un nouveau approche FAST-MGB qui permettre dedériver , directement à partir du contexte de extraction formel , un base génériqueminimal de règle associatif . 	Cherif Chiraz Latiri, Lamia Ben Ghezaiel, Mohamed Ben Ahmed	2006	@gnet.tn, @riadi.rnu.tn, @riadi.rnu.tn	1000349
646	Fouille de données dans les systèmes Pair-à-Pair pour améliorer la recherche de ressources	fouille de donnée dans le système Pair-à-Pair pour améliorer le recherche de ressource  le quantité de source de information disponible sur Internet faire dessystèmes de échange pair-à-pair ( P2P ) un genre nouveau de architecture qui offreà un large communauté des application pour partager un fichier , un calcul , dialoguer ou communiquer en temps réel . dans ce article , cln proposonsuner nouveau approche pour améliorer le localisation de un ressource sur un réseauP 2P non structurer . en utiliser un nouveau heuristique , cln proposonsd'extrairer un motif qui apparaître dans un grand nombre de noeud du réseau . ce connaissance être très utile pour proposer aux utilisateur des fichierssouvent demander ( en requête ou en téléchargement ) et éviter un trop grandeconsommation de le bande passant . 	Florent Masseglia, Pascal Poncelet, Maguelonne Teisseire	2006	@inria.fr, @ema.fr, @lirmm.fr	1000390
647	Fouille de données spatiales, Approche basée sur la programmation logique inductive	fouille de donnée spatial , Approche baser sur le programmation logique inductif  ce qui caractériser le fouille de donnée spatial être le nécessité de prendre en compte le interaction des objet dans le espace . le méthode classique de fouille de donnée être mal adapté pour ce type de analyse . cln proposer dans ce article un approche baser sur le programmation logique inductif . cln clr baser sur deux idée . le premier consister à matérialiser ce interaction spatial dans un table de distance , ramener ainsi le fouille de donnée spatial à le fouille de fonnée multi-table . le seconde transformer le donnée en logique du premier ordre et appliquer ensuite le programmation logique inductif . ce article présenter ce approche . ilimp décrire son application à le classification superviser par arbre de décision spatial . ilimp présenter aussi le expérimentation réaliser et le résultat obtenir sur le analyse de le contamination des coquillage dans le lagune de Thau . 	Nadjim Chelghoum, Karine Zeitouni, Thierry Laugier, Annie Fiandrino, Lionel Loubersac	2006	@ifremer.fr, @prism.uvsq.fr	1000400
648	Graphes de voisinage pour l'indexation et l'interrogation d'images par le contenu	graphe de voisinage pour le indexation et le interrogation de image par le contenu  le découverte de information cacher dans le base de donnée multimédiasest un tâche difficile à cause de son structure complexe et à le subjectivitélié à son interprétation . face à ce situation , le utilisation de un indexest primordial . un index multimédia permettre de regrouper le donnée selondes critère de similarité . cln proposer dans ce article de apporter un améliorationà un approche déjà existant de interrogation de image par le contenu . cln proposer un méthode efficace pour mettre à jour , localement , le graphesde voisinage qui constituer son structure de index multimédia . ce indexest baser sur un manière intelligent de localisation de point dans un espacemultidimensionnel . un résultat prometteur être obtenir après un expérimentationssur divers base de donnée . 	Hakim Hacid, Djamel Abdelkader Zighed	2006	@univ-lyon2.fr, @univ-lyon2.fr	1000318
649	Indexation de vues virtuelles dans un médiateur XML pour le traitement de XQuery Text	indexation de vue virtuel dans un médiateur XML pour le traitement de XQuery Text  intégrer le traitement de requête de recherche de information dans unmédiateur XML être un problème difficile . ceci être notamment devoir au faire quecertain source de donnée ne permettre pas de recherche sur mot -clef etdistance ni de classer le résultat suivre son pertinence . dans ce article nousabordons le intégration des fonctionnalité principal du standard XQuery Textdans XLive , un médiateur XML  XQuery . pour cela cln avoir choisid'indexer des vue virtuel de document . le document virtuelssélectionné être transformer en objet des source . le opérateur de sélectiondu médiateur être étendre pour supporter un recherche de information sur lesdocuments de le vue . le recherche sur mots -clef et le classement de résultatsont ainsi supporter . son formule de classement de résultat être adapter auformat de donnée semi-structuré , baser sur le nombre de mots -clef dans lesdifférent élément et le distance entre le élément de un résultat . 	Clément Jamard, Georges Gardarin	2006	@prism.uvsq.fr	1000325
650	Interrogation et Vérification de documents OWL dans le modèle des Graphes Conceptuels	interrogation et vérification de document OWL dans le modèle des graphe Conceptuels  OWL être un langage pour le description de ontologie sur le Web . cependant , en tant que langage , OWL ne fournir aucun moyen pour interpréter lesontologie que ilimp décrire , et être orienter machine , ilimp rester difficilement compréhensiblepar le humain . cln proposer un approche de visualisation , de interrogationet de vérification de document OWL , regrouper dans un unique environnementgraphique : le modèle des graphe conceptuel . 	Thomas Raimbault, Henri Briand, Rémi Lehn, Stéphane Loiseau	2006	@univ-angers.fr, @univ-nantes.fr	1000342
651	La fouille de graphes dans les bases de données réactionnelles au service de la synthèse en chimie organique	le fouille de graphe dans le base de donnée réactionnel au service de le synthèse en chimie organique  le synthèse en chimie organique consister à concevoir de nouvellesmolécule à partir de réactif et de réaction . le expert de le synthèse clr appuientsur de très grand base de donnée de réaction que cln consulter à traversun procédure de interrogation standard . un processus de découverte denouveau réaction cld permettre de mettre au point de nouveau procédé desynthèse . ce article présenter un modélisation des réaction par un graphe etintroduire un méthode de fouille de ce graphe de réaction qui permettre de faireémerger des motif générique utile à le prédiction de nouveau réaction . Enfinl'article faire le point sur le état actuel de ce travail de recherche en présentantle modèle général dans lequel clr intégrer un nouveau algorithme de fouille deréactions chimique . 	Frédéric Pennerath, Amedeo Napoli	2006	@supelec.fr, @loria.fr	1000398
652	Le forage distribué des données : une méthode simple, rapide et efficace	le forage distribuer des donnée : un méthode simple , rapide et efficace  dans ce article cln cld attaquer au problème du forage de trèsgranun base de donnée distribuer . le résultat viser être un modèle qui être etprédictif et descriptif , appeler méta-classificateur . pour ce faire , cln proposonsder miner à distance chaque base de donnée indépendamment . Puis , ilimp clr agitder regrouper le modèle produire ( appelé classificateur de base ) , savoir quechaque forage produire un modèle prédictif et descriptif , représenter pour son besoinspar un ensemble de règle de classification . afin de guider le assemblage del'ensemble final de règle , qui être le union des ensemble individuel de règle , un coefficient de confiance être attribuer à chaque règle de chaque ensemble . Cecoefficient , calculer par un moyens statistique , représenter le confiance que nouspouvons avoir dans chaque règle en fonction de son couverture et de son taux de erreurface à son capacité de être appliquer correctement sur un nouveau donnée . cln démontrer dans ce article que , grâce à ce coefficient de confiance , le agrégationpur et simple de tout le classificateur de base pour obtenir un agrégatd règle produire un méta-classificateur rapide et efficace par rapport aux techniquesexistant . 	Mohamed Aounallah, Guy Mineau	2006	@ift.ulaval.ca	1000328
653	Modèle conceptuel pour bases de données multidimensionnelles annotées	modèle conceptuel pour base de donnée multidimensionnel annoter  son travaux viser à proposer un mémoire de expertise décisionnellespermettant de conserver et de manipuler non seulement le donnée décisionnellesmais aussi le expertise analytique des décideur . le donnée décisionnellessont représenter au travers de concept multidimensionnel etl'expertise associer être matérialiser grâce au concept de annotation 	Guillaume Cabanac, Max Chevalier, Franck Ravat, Olivier Teste	2006	@irit.fr	1000330
654	Modèle décisionnel basé sur la qualité des données pour sélectionner les règles d'associations légitimement intéressantes	modèle décisionnel baser sur le qualité des donnée pour sélectionner le règle de association légitimement intéressant  dans ce article cln proposer de exploiter un mesure décrire laqualité un donnée pour définir le qualité des règle de association résultantd'un processus de fouille . cln proposer un modèle décisionnel probabilistebaser sur le coût de le sélection de règle légitimement , potentiellement intéressantesou inintéressant si le qualité des donnée à le origine de son calcul estbon , moyen ou douteux . le expérience sur le donnée de KDD-CUP- 98 montrer que le 10 meilleur règle sélectionner de après son mesuresde support et confiance ne être intéressant que dans le cas où le qualité deleurs donner être correct voire améliorer . 	Laure Berti-Equille	2006	@irisa.fr	1000410
655	Modélisation informationnelle : un cadre méthodologique pour représenter des connaissances évolutives spatialisables	modélisation informationnel : un cadre méthodologique pour représenter un connaissance évolutif spatialisable  pour comprendre et représenter le évolution du bâti , question renouveler avec le développement des NTIC , le analyste clr appuyer sur un connaissance évolutif avoir dans son champagne de application - le patrimoine architectural - un caractère spatialisable ( par le attachement à un lieu lambda ) mais aussi des caractéristique handicapant ( hétérogénéité , incertitude et contradiction , etc. ) . en réponse , cln utiliser ce caractère spatialisable pour intégrer le ressource constituer le jeu de connaissance propre à chaque édifice : théorie , source documentaire , observation . ce démarche que cln nommer modélisation informationnel avoir pour objectif un gain de compréhension du lieu architectural et des information qui cld être associer . son contribution introduire le filiation de ce démarche , le cadre méthodologique qui cla matérialiser , et discuter de son application au cas concret de le place central de Cracovie ( Rynek Glowny ) pour cll évaluer le apport potentiel en matière de gestion et de visualisation de connaissance . 	Jean-Yves Blaise, Iwona Dudek	2006	@gamsau.map.archi.fr	1000368
656	Multi-catégorisation de textes juridiques et retour de pertinence	Multi-catégorisation de texte juridique et retour de pertinence  le fouille de donnée textuel constituer un champagne majeur dutraitement automatique des donnée . un large variété de conférence , commeTREC , cld être consacrer . dans ce étude , cln clr intéresser à le fouillede texte juridique , dans le objectif être le classement automatique de ce texte . cln utiliser un outil de analyse linguistique ( extraction de terminologie ) dans le but de repérer le concept présent dans le corpus . ce conceptspermettent de construire un espace de représentation de faible dimensionnalité , ce qui cld permettre de utiliser un algorithme de apprentissage baser sur desmesure de similarité entre individu , comme le graphe de voisinage . Nouscomparons le résultat issu du graphe et de C4 . 5 avec le SVM qui lui sontutilisévoir sans réduction de le dimensionnalité . 	Vincent Pisetta, Hakim Hacid, Djamel Abdelkader Zighed	2006	@univ-lyon2.fr, @eric-univ.lyon2.fr, @univ-lyon2.fr	1000353
657	Prédiction de solubilité de molécules à partir des seules données relationnelles	prédiction de solubilité de molécule à partir un seul donnée relationnel  le recherche de médicament passer par le synthèse de molécule candidatesdavoir le efficacité être ensuite tester . ce processus pouvoir être accélérer enidentifiant le molécule non soluble , car celui -ci ne pouvoir entrer dans lacomposition de un médicament et ne devoir donc pas être étudier . un techniquesont être développer pour induire un modèle de prédiction de le indice desolubilité , utiliser principalement un réseau de neurone ou des régressionslinéaire multiple . le plupart des travaux actuel viser à enrichir le donnéesd caractéristique supplémentaire sur le molécule . dans ce article , cln étudionsl'intérêtir de le construction automatique de attribut baser sur le structureintrinsèquement multi-relationnel des donnée . le attribut obtenir être utilisésdans un algorithme de arbre de modèle , auquel cln associer un donnéesd bagging . le test réaliser montrer que ce méthode donner des résultatscomparable aux meilleur méthode du domaine qui travailler sur un attributsconstruits par le expert . 	Sébastien Derivaux, Agnès Braud, Nicolas Lachiche	2006	@lsiit.u-strasbg.fr	1000424
658	Préparation des données Radar pour la reconnaissance/identification de cibles aériennes	préparation des donnée Radar pour le reconnaissance  identification de cible aérien  le problématique général présenter dans ce papier concerner lessystèson intelligent , dédier pour le aide à le prise de décision dans le domaineradar . le premier travaux avoir donc consister après avoir adapter le processusd'extraction de connaissance à partir de donnée ( ECD ) au domaine radar , àmettre en oeuvre le étape en amont de le phase de fouille de donnée . Nousnous limiter dans ce papier à le phase de préparation des donnée ( imagesISAR : Inverse Synthetic Aperture Radar ) . cln introduire ainsi le notion dequalité comme moyen de évaluer le imperfection dans le donnée radarsexpérimental . 	Abdelmalek Toumi, Brigitte Hoeltzener, Ali Khenchaf	2006	@ensieta.fr	1000426
659	Prétraitement de grands ensembles de données pour la fouille visuelle	Prétraitement de grand ensemble de donnée pour le fouille visuel  cln présenter un nouveau approche pour le traitement des ensemblesd donner de très grand taille en fouille visuel de donnée . le ensemblesd le approche visuel concerner le nombre de individu et le nombre dedimension être connaître de tout . pour pouvoir traiter un ensemble de donnéesun grand taille , un solution possible être de effectuer un prétraitement del'ensemble de donnée avant de appliquer le algorithme interactif de fouille visuel . pour ce faire , cln utiliser le théorie du consensus ( avec un affectationvisuel des poids ) . cln évaluer le performance de son nouveau approchesur des ensemble de donnée de le UCI et du Kent Ridge Bio MedicalDataset Repository . 	François Poulet, Edwige Fangseu Badjio	2006	@esiea-ouest.fr, @esiea-ouest.fr	1000324
660	Recherche de sous-structures fréquentes pour l'intégration de schémas XML	recherche de sous-structure fréquent pour le intégration de schéma XML  le recherche de un schéma médiateur à partir de un ensemble de schémasXML être un problématique actuel où le résultat de recherche issusde le fouille de donnée arborescent pouvoir être adopter . dans ce contexte , plusieurs proposition avoir être réaliser mais le méthode de représentation desarborescence être souvent trop coûteux pour permettre un véritable passageà le échelle . dans ce article , cln proposer un algorithme de recherche desous-schémas fréquent baser sur un méthode original de représentation deschémas xml . cln décrire brièvement le structure adopter pour ensuitedétailler le algorithme de recherche de sous-arbre fréquent clr appuyer surune tel structure . le représentation proposer et le algorithme associer ontété évaluer sur différent base synthétique de schéma XML montrer ainsil'intérêt de le approche proposer 	Federico Del Razo López, Anne Laurent, Pascal Poncelet, Maguelonne Teisseire	2006	@lirmm.fr, @ema.fr	1000393
661	Recherche en temps réel de préfixes massifs hiérarchiques dans un réseau IP à l'aide de techniques de stream mining	recherche en temps réel de préfixe massif hiérarchique dans un réseau IP à le aide de technique de stream mining  Au cours de ce dernier année , de nombreux technique de streammining avoir être proposer afin de analyser un flux de donnée en temps réel . dans ce article , cln montrer comment cln avoir utiliser un technique destream mining permettre le recherche de objet massif hiérarchique ( hierarchicalheavy hitters ) dans un flux de donnée pour identifier en temps réel dans unréseau IP le préfixe dont le contribution au trafic dépasser un certain proportiond ce trafic pendant un intervalle de temps donner . 	Pascal Cheung-Mon-Chan, Fabrice Clérot	2006	@francetelecom.com	1000323
662	Reconnaissance automatique de concepts à partir d'une ontologie	reconnaissance automatique de concept à partir de un ontologie  ce papier présenter un approche qui clr appuyer sur un ontologie pourreconnaître automatiquement un concept spécifique à un domaine dans uncorpus en langue naturel . le solution proposer être non- superviser et peuts'appliquer à tout domaine pour lequel un ontologie avoir être déjà construire . Uncorpus du domaine être utiliser dans lequel le concept être reconnaître . Dansune premier phase , un connaissance être extraire de ce corpus en faisantappel à un fouille de texte . un ontologie du domaine être utiliser pour étiqueterce connaissance . le papier donner un aperçu des technique de fouillesemployé et décrire le processus d " étiquetage . . le résultat de un premièreexpérimentation dans le domaine de le accidentologie être aussi présenter 	Valentina Ceausu, Sylvie Desprès	2006	@univ-paris5.fr, @univ-paris5.fr	1000351
663	Reconnaissance automatique d'évènements survenant sur patients en réanimation à l'aide d'une méthode adaptative d'extraction en ligne d'épisodes temporels	reconnaissance automatique de évènement survenir sur patient en réanimation à le aide de un méthode adaptatif de extraction en ligne de épisode temporel  ce papier présenter le version adaptatif de un algorithmed'extraction de épisode temporel développer précédemment . le trois paramè-tres de réglage de le algorithme ne être plus fixe . cln être modifier en ligne enfonction de le variance estimer du signal que le cln vouloir décomposer en épiso- des temporel . le version adaptatif de le algorithme avoir être utiliser pour recon-naître automatiquement un aspiration trachéal à partir de plusieur varia-bles physiologique enregistrer sur un patient hospitaliser en réanimation . un résultat préliminaire être présenter dans ce papier . 	Sylvie Charbonnier	2006	@inpg.fr	1000333
664	Règles d'association avec une prémisse composée : Mesure du gain d'information.	règle de association avec un prémisse composer : mesure du gain de information .  le communauté de fouille de donnée avoir développer un grand nombre de indice permettantde mesurer le qualité des règle de association ( RA ) selon divers sémantique ( Guillet , 2004 ) . cependant ce sémantique , qui permettre de interpréter le règle simple , clr avèrentd'utilisation trop complexe pour un expert dans le cas de règle à prémisse composer . Notreobjectif être donc de sélectionner le règle à prémisse composer de type AB→C quiapporter un information supplémentaire à celui des règle simple A→C et B→C. Pourcela cln définir un indice de gain de un règle composer par rapport aux règle simple . dans le application présenter , cln extraire des ra de résultat de classification pouren faciliter le analyse . le gain avoir permettre de filtrer un règle de interprétation simple 	Martine Cadot, Pascal Cuxac, Claire François	2006	@loria.fr, @inist.fr, @inist.fr	1000412
665	Sélection supervisée d'instances : une approche descriptive	sélection superviser de instance : un approche descriptif  le classification suivre le plus proche voisin être un règle simple etperformant . son mise en oeuvre pratique nécessiter , tant pour un raison de coûtun calcul que de robustesse , de sélectionner le instance à conserver . le partitionde Voronoi induire par le prototype constituer le structure sous-jacent àcet règle . dans ce article , cln introduire un critère descriptif de évaluation de unetel partition , quantifier le compromis entre nombre de cellule et partitionde le variable cible entre le cellule . un heuristique de optimisation estproposé , tirer partie des propriété des partition de Voronoi et du critère . Laméthode obtenir être comparer avec le standard sur un vingtaine de jeu dedonné de le UCI . son technique ne souffrir de aucun défaut de performanceprédictive , tout en sélectionner un minimum de instance . de plus , cln ne surapprendpas . 	Sylvain Ferrandiz, Marc Boullé	2006	@francetelecom.com, @francetelecom.com	1000382
666	SVM incrémental, parallèle et distribué pour le traitement de grandes quantités de données	SVM incrémental , parallèle et distribuer pour le traitement de grand quantité de donnée  cln présenter un nouveau algorithme de SVM ( Support VectorMachine ou Séparateur à vaste Marge ) linéaire et non- linéaire , parallèle etdistribué permettre le traitement de grand ensemble de donnée dans untemps restreindre sur du matériel standard . A partir de le algorithme de Newton-GSVM proposer par Mangasarian , cln avoir construire un algorithmeincrémental , parallèle et distribuer permettre de améliorer le performance untemps de exécution et mémoire en clr exécuter sur un groupe de ordinateur . Cenouvel algorithme avoir le capacité de classifier un million de individu en 20dimension et deux classe en quelque seconde sur un ensemble de dix PC 	Thanh-Nghi Do, François Poulet	2006	@cit.ctu.edu.vn, @esiea-ouest.fr	1000322
667	Techniques de fouille de données pour la réécriture de requêtes en présence de contraintes de valeurs	technique de fouille de donnée pour le réécriture de requête en présence de contrainte de valeur  dans ce article , cln montrer comment le technique de fouille de donnée pouvoir résoudre efficacement le problème de le réécriture de requête en terme de vue en présence de contrainte de valeur . A partir de un formalisation du problème de le réécriture dans le cadre de le logique de description ALN ( Ov ) , cln montrer comment ce problème clr rattacher à un cadre de découverte de connaissance dans le base de donnée . le exploitation de ce cadre cld permettre de bénéficier de solution algorithmique existant pour le résolution du problème de réécriture . cln proposer un implémentation de ce approche , puis cln le expérimenton . le premier résultat démontrer le intérêt de un tel approche en terme de capacité à traiter un grand nombre de source de donnée . 	Hélène Jaudoin, Frédéric Flouvat	2006	@isima	1000326
668	Teximus Expertise : un logiciel de gestion de connaissances	Teximus Expertise : un logiciel de gestion de connaissance  le logiciel Teximus Expertise être un outil évoluer de gestion dynamiquede connaissance baser sur le notion de référentiel sémantique . ce suiteintégrée faciliter le partage de connaissance et de information dans le entreprise . 	Olivier Gerbé	2006	@teximus.com	1000453
669	Typicalité et contribution des sujets et des variables supplémentaires en Analyse Statistique Implicative	Typicalité et contribution des sujet et des variable supplémentaire en analyse statistique Implicative  le analyse statistique implicatif traite des tableau sujet xvariable afin de extraire règle et métarègle statistique entre le variable . le article interroger le structure obtenir représenter par graphe et hiérarchieorienté afin de dégager le responsabilité des sujet ou un groupe de sujet ( variable supplémentaire ) dans le constitution des chemin du graphe ou desclasse de le hiérarchie . cln distinguer le concept de typicalité pour signifier laproximité un sujet avec le comportement moyen de le population envers lesrègle statistique extraire , puis de contribution pour quantifier le rôlequ'auraient le sujet par rapport aux règle strict associer . un exemple dedonnées réel , traiter à le aide du logiciel CHIC , illustrer et montrer le intérêt deces deux concept . 	Régis Gras, Jérôme David, Jean-Claude Régnier, Fabrice Guillet	2006	@club-internet.fr, @univ-nantes.fr, @univ-lyon2.fr	1000370
670	Un automate pour évaluer la nature des textes	un automate pour évaluer le nature des texte  cln ne pouvoir clr intéresser aux texte sans clr intéresser à son nature . le nature des texte permettre de distinguer le texte de un point de vue primaire . cln être utiliser pour identifier le texte artificiel , pour le reconnaissance de le langue , afin de identifier le spam ... en ce sens , le méthode le plus connu rester encore le méthode de Zipf . ce article proposer un nouveau méthode baser sur un automate . le automate construire un signal pour chaque texte . le automate être présenter en détail et des expérimentation montrer son utilité dans le domaine aussi divers que celui cité précédemment  	Hubert Marteau, Nicole Vincent	2006	@univ-tours.fr, @univ-paris5.fr	1000355
671	Un modèle de qualité de l'information	un modèle de qualité de le information  ce travail clr intégrer dans le problématique général de le recherched'information ; et plus particulièrement dans le personnalisation et le recherched'information . dans ce article cln proposer un modèle multidimensionnelde le qualité de le information décrire le différent facteur de qualité influantsur le personnalisation de le information . ce modèle permettre de structurerle différent facteur de qualité de le information dans un hiérarchie afind'assister le utilisateur dans le construction de son propre profil selon son besoinset son exigence en terme de qualité . 	Rami Harrathi, Sylvie Calabretto	2006	@yahoo.fr, @insa-lyon.fr	1000363
672	Une approche distribuée pour l'extraction de connaissances : Application à l'enrichissement de l'aspect factuel des BDG	un approche distribuer pour le extraction de connaissance : application à le enrichissement de le aspect factuel des BDG  le système de information géographique ( SIG ) être utiliser pouraméliorer le efficacité des entreprise et des service public , en associantméthode de optimisation et prise en compte de le dimension géographique . cependant , le base de donnée géographique ( BDG ) stocker dans le SIGsont restreindre à le application pour lequel cln avoir être concevoir . souvent , lesutilisateurs demeurer contraindre de le existant et clr trouver dans le besoin dedonné complémentaire pour un prise de décision adéquat . de où , le idée del'enrichissement de le aspect descriptif des BDG existant . pour atteindre cetobjectif , cln proposer un approche qui consister à intégrer un module defouille de donnée textuel au SIG cld même . ilimp clr agir de proposer uneméthode distribuer de résumé de document multiple à partir de corpus enligne . le idée être de faire coopérer un ensemble de agent clr entraider afind'aboutir à un résumé optimal . 	Khaoula Mahmoudi, Sami Faiz	2006	@insat.rnu.tn, @insat.rnu.tn	1000329
673	Une approche multi-agent adaptative pour la simulation de schémas tactiques	un approche multi-agent adaptatif pour le simulation de schéma tactique  ce papier être consacrer à le simulation ou à le réalisation automatiquede schéma tactique par un groupe de agent footballeur autonome . son objectifest de montrer ce que pouvoir apporter un technique de apprentissagepar renforcement à un agent réactif concevoir pour ce tâche . dans un premiertemps , cln proposer un plateforme et un architecture de agent capabled'effectuer des schéma tactique dans un cas relativement simple . ensuite , cln mettre en oeuvre un algorithme de apprentissage par apprentissagepar permettre aux agent de faire face à un situation plus complexe . enfin , un série de expérimentation montrer le gain apporter aux agent réactif parl'utilisation de algorithme de apprentissage . 	Aydano Machado, Yann Chevaleyre, Jean-Daniel Zucker	2006	@lip6.fr, @lamsade.dauphine.fr	1000334
674	Une approche simple inspirée des réseaux sociaux pour la hiérarchisation des systèmes autonomes de l'Internet	un approche simple inspirer des réseau social pour le hiérarchisation des système autonome de le Internet  " le transit des flux de information dans le réseau Internet à le échellemondiale être régir par un accord commercial entre système autonome , accordsqui être mettre en oeuvre via le protocole de routage BGP . . le négociationd ce accord commercial reposer implicitement sur un hiérarchie des systèmesautonome et le position relative de deux système déboucher sur un accordd type client  fournisseur ( un des système , le client , être nettement mieuxclasser que le autre , le fournisseur , et le client payer le fournisseur pour le transitdes flux de information ) ou sur un accord de type " " peering " " ( transit gratuit dutrafic entre le deu système ) . . en dépit de son importance , ilimp ne exister pas dehiérarchie officiel de le Internet ( le clause commercial des accord entresystèmes autonome ne être pas nécessairement public ) ni de consensus surla façon de établir un tel hiérarchie . . cln proposer un heuristique simpleinspirée de le notion de " " centralité spectral " " issue de le analyse des réseau sociauxpour analyser le position relative des système autonome de le Internet àpartir des information des seul information de connectivité entre systèmesautonome . " 	Fabrice Clérot, Quang Nguyen	2006	@francetelecom.com, @francetelecom.com	1000391
675	Une comparaison de certains indices de pertinence des règles d'association	un comparaison de certain indice de pertinence des règle de association  ce article proposer un comparaison graphique de certain indice depertinence pour évaluer le intérêt des règle de association . cln cln sommesappuyévoir sur un étude existant pour sélectionner quelque indice auxquelsnous avoir ajouter le indice de Jaccard et le indice de accord désaccord ( IAD ) . ce deu dernier cld sembler plus adapté pour discriminer le règle intéressantesdan le cas où le item être un événement peu fréquent . un applicationest réaliser sur un donnée réel issir du secteur automobile 	Marie Plasse, Ndeye Niang, Gilbert Saporta, Laurent Leblond	2006	@cnam.fr, @cnam.fr, @mpsa.com, @mpsa.com	1000405
676	Une mesure de proximité et une méthode de regroupement pour l'aide à l'acquisition d'ontologies spécialisées	un mesure de proximité et un méthode de regroupement pour le aide à le acquisition de ontologie spécialisé  ce article traiter du regroupement de unité textuel dans un perspectived'aide à le élaboration de ontologie spécialisé . le travail présenter clr inscritdair le cadre du projet BIOTIM . cln cld concentrer ici sur le un desétape de construction semi-automatique de un ontologie qui consister à structurerun ensemble de unité textuel caractéristique en classe susceptible dereprésenter le concept du domaine . le approche que cln proposer clr appuiesur le dénition de un nouveau mesure non- symétrique permettre de évaluer laproximité entre lemme , en utiliser son contexte de apparition dans le document . en complément de ce mesure , cln présenter un algorithme declassication non- superviser adapter à le problématique et aux donnée traiter . le premier expérimentation présenter sur le donnée botanique laissentpercevoir des résultat pertinent pouvoir être utiliser pour assister le expert dansla détermination et le structuration des concept du domaine . 	Guillaume Cleuziou, Sylvie Billot, Stanislas Lew, Lionel Martin, Christel Vrain	2006	@univ-orleans.fr	1000339
677	Une nouvelle mesure sémantique pour le calcul de la similarité entre deux concepts d'une même ontologie	un nouveau mesure sémantique pour le calcul de le similarité entre deux concept de un même ontologie  le ontologie être au coeur du processus de gestion des connaissance . différent mesure sémantique avoir être proposer dans le littératurepour évaluer quantitativement le importance de le liaison sémantique entre pairesde concept . ce article proposer un synthèse analytique des principal mesuressémantique baser sur un ontologie modéliser par un graphe et restreint iciaux lien hiérarchique is-a . après avoir mettre en évidence différent limite desmesures actuel , cln cll proposer un nouveau , le PSS ( proportion of SharedSpecificity ) , qui sans corpus externe , tenir compte de le densité des lien dans legraphe relier deux concept 	Emmanuel Blanchard, Mounira Harzallah, Pascale Kuntz, Henri Briand	2006	@univ-nantes.fr	1000344
678	Utilisation de métadonnées pour l'aide à l'interprétation de classes et de partitions	utilisation de métadonné pour le aide à le interprétation de classe et de partition  le résultat des méthode de fouille de donnée être difficilementinterprétablrer par un utilisateur ne avoir pas le expertise requérir . dans ce papiernous proposer un outil permettre aux utilisateur de interpréter le résultatsissus des méthode de classification non supervisé . ce outil être baser sur desmétadonné utiliser pour formaliser le processus de interprétationautomatique . ce desmétadonné aller servir à le utilisateur pour comprendre dansquel circonstance le donnée original avoir être collecter et de quellemanière cln avoir être agréger puis classifier . le intérêt de ce travail porter surle souplesse que avoir le utilisateur à pouvoir interpréter facilement lesclasses obtenir . cln développer son approche baser sur le utilisation desmétadonné . cln traduire son méthodologie par un exemple concret . 	Abdourahamane Baldé, Yves Lechevallier, Brigitte Trousse, Marie-Aude Aufaure	2006	@inria.fr, @inria.fr, @supelec.fr	1000371
679	Utilisation des réseaux bayésiens dans le cadre de l'extraction de règles d'association	utilisation des réseau bayésien dans le cadre de le extraction de règle de association  ce article aborder le problème de le utilisation de un modèle de connaissancedan un contexte de fouille de donnée . le approche méthodologique proposéemontre le intérêt de le mise en oeuvre de réseau bayésien coupler à le extractiond règle de association dire delta-forte ( membre gauche minimal , fréquenceminimal et niveau de confiance contrôler ) . le découverte de règle potentiellementutile être alors faciliter par le exploitation des connaissance décritespar le expert et représenter dans le réseau bayésien . ce approche estvalidéer sur un cas de application concernant le fouille de donnée de interruptionsopérationnel dans le industrie aéronautique . 	Clément Fauré, Sylvie Delprat, Alain Mille, Jean-François Boulicaut	2006	@eads.net, @liris.cnrs.fr	1000407
680	Vers l'extraction de motifs rares	vers le extraction de motif rare  un certain nombre de travaux en fouille de donnée clr être intéresser à le extraction de motif et à le génération de règle de association à partir de ce motif . cependant , ce travaux clr être jusque à présent , centrer sur le notion de motif fréquent . le premier algorithme à avoir permettre le extraction de tout le motif fréquent être Apriori mais un autre avoir être mettre au point par le suite , certains ne extraire que un sous-ensemble de ce motif ( motif fermé fréquent , motif fréquent maximal , générateur minimal ) . dans ce article , cln clr intéresser aux motif rare qui pouvoir également véhiculer un information important . le motif rare correspondre au complémentaire des motif fréquent . A son connaissance , ce motif ne avoir pas encore être étudier , malgré le intérêt que certain domaine pouvoir tirer de ce genre de modèle . ce être en particulier le cas de le médecine , où par exemple , ilimp être important pour un praticien de repérer le symptôme non usuel ou le effet indésirable exceptionnel qui pouvoir clr déclarer chez un patient pour un pathologie ou un traitement donné . 	Laszlo Szathmary, Sandy Maumus, Pierre Petronin, Yannick Toussaint, Amedeo Napoli	2006	@loria.fr, @nancy.inserm.fr, @gmail.com	1000396
681	Visualisation en Gestion des Connaissances Développement d'un nouveau modèle graphique Graph'Atanor	visualisation en gestion des connaissance Développement de un nouveau modèle graphique Graph'Atanor  le système de gestion des connaissance servir de support pour lacréation et le diffusion de mémoires de entreprise qui permettre de capitaliser , conserver et enrichir le connaissance des expert . dans ce système , le interactionavec le expert être effectuer avec un outil adapter dans lequel uneformalisation graphique des connaissance être utiliser . ce formalisation estsouvent baser au niveau théorique sur un modèle de graphe mais de façonpratique , le représentation visuel être souvent un arbre et des limitationsapparaissent par rapport aux représentation baser sur un graphe . dans cetarticle cln présenter le modèle utiliser par le serveur de connaissance Atanorqui utiliser un arbre pour visualiser le connaissance , et cln développer unenouvel approche qui permettre de représenter le même connaissance sous laforme de graphe en niveau . un analyse comparatif des deu méthode dansun contexte industriel de maintenance permettre de mettre en valeur le apport desgraphrer dans le processus de visualisation graphique des connaissance . 	Bruno Pinaud, Pascale Kuntz, Fabrice Guillet, Vincent Philippé	2006	@knowesia.fr, @univ-nantes.fr	1000364
682	Visualisation interactive de données avec des méthodes à base de points d'intérêt	visualisation interactif de donnée avec un méthode à base de point de intérêt  cln présenter dans ce article un méthode de visualisation interactivede donnée numérique ou symbolique permettre à un utilisateur expertdu domaine de obtenir un information et des connaissance pertinent . Nousproposons un approche nouveau en adapter le utilisation des point de intérêtsdans un contexte de fouille visuel de donnée . A partir de un ensemble de pointsd'intérêt disposer sur un cercle , le donnée être visualiser à le intérieur de cecercle en fonction de son similarité à ce point de intérêt . un opération interactivesêtre alors définir : sélectionner , zoomer , changer dynamiquement lespoint de intérêt . cln évaluer le propriété de un tel visualisation sur desdonnéon aux caractéristique connaître . cln décrire un application réel encours dans le domaine de le exploration de donnée issu de enquête de satisfaction . 	David Da Costa, Gilles Venturini	2006	@univ-tours.fr, @univ-tours.fr, @agicom.fr	1000367
683	Web sémantique pour la mémoire d'expériences d'une communauté scientifique : le projet MEAT	web sémantique pour le mémoire de expérience de un communauté scientifique : le projet MEAT  ce article décrire le projet MEAT ( mémoire de Expériences pourl'Analyse du Transcriptome ) dont le but être de assister le biologiste travaillantdans le domaine des puce à ADN , pour le interprétation et le validation de leursrésultat . cln proposer un aide méthodologique et logiciel pour construireun mémoire de expérience pour ce domaine . son approche , baser surles technologie du web sémantique , reposer sur le utilisation des ontologie surles annotation sémantique sur un article scientifique et de autre sourcesde connaissance du domaine . son approche pouvoir être généraliser à un autresdomaine requérir un expérimentation et traiter un grand flux de donnée ( protéomique , chimie , etc. ) . 	Khaled Khelif, Rose Dieng-Kuntz, Pascal Barbry	2006	@inria.fr, @ipmc.fr	1000340
684	Web Usage Mining : extraction de périodes denses à partir des logs	web Usage Mining : extraction de période dense à partir un log  " le technique de Web Usage Mining existant être actuellementbaser sur un découpage des donnée arbitraire ( e.g. " " un logarithme par mois " " ) ou guidépar un résultat supposé ( e.gure " " quels être le comportement des client pourla période des achat de Noël ? " " ) . . ce approche souffrir un deux problèmessuivant . . de un part , cln dépendre de ce organisation arbitraire des donnéesaurant cours du temps . . de autre part cln ne pouvoir pas extraire automatiquementdes " " pic saisonnier " " dans le donnée stocker . . cln proposer de exploiterle donner pour découvrir de manière automatique des période " " dense " " decomportement . . un période être considérer comme " " dense " " si cln contenir aumoins un motif séquentiel fréquent pour le ensemble des utilisateur qui étaientconnectévoir sur le site à ce période . " 	Florent Masseglia, Pascal Poncelet, Maguelonne Teisseire, Alice Marascu	2006	@inria.fr, @ema.fr, @lirmm.fr	1000377
685	ACKA : Une approche d'acquisition coopérative de connaissances pour la construction d'un modèle de simulation multi-agents	ACKA : un approche de acquisition coopératif de connaissance pour le construction de un modèle de simulation multi-agent  ce article présenter un approche ( ACKA an Approach for Cooperative Knowledge Acquisition ) participatif et coopératif de acquisition de connaissance nécessaire pour le construction de un modèle de simulation baser sur un agent . cln être baser sur le principe de jeu de rôle dans un réunion de entreprise . cln proposer de construire un modèle multi-acteur , représenter un modèle initial du système multi-agent . dans ce étude , cln appliquer ACKA pour construire un modèle multi-acteur pour le compréhension des processus de décision dans le ? ronsieur de le ? liere avicole . en particulier , cln chercher à comprendre le impact des comportement individuel sur le gestion de le utilisation des matière premier agricole . 	Athmane Hamel, Suzanne Pinson	2005	@tours.inra.fr, @lamsade.dauphine.fr	1000403
686	Acquisition et exploitation de connaissances dans un contexte multi-experts pour un système d'aide à la décision	acquisition et exploitation de connaissance dans un contexte multi-expert pour un système de aide à le décision  cln présenter un méthodologie de extraction , de gestion et de exploitation de connaissance dans un contexte multi-expert . cln reposer sur trois étape : extraction des connaissance de chaque expert , gestion des connaissance individuel afin de constituer un base de connaissance commun et exploitation de ce base afin de fournir un aide à le décision aux expert . le méthodologie proposer avoir être mettre en oeuvre au Cameroun avec cinuelque expert en micro- finance . cln avoir donner un résultat en adéquation avec le pratique des expert . au-delà , cln envisager de mettre en oeuvre un système de capitalisation des connaissance . ilimp devoir permettre de analyser rapidement un plus grand nombre de situation , le expert rester en nombre limité , et contribuer à un transfert de compétence pour former le décideur local . en effet , le expert être en général membre de ONG et rester rarement plus de deux an sur place . 	Jean-Pierre Barthélemy, Jean-Robert Kala Kamdjoug, Philippe Lenca	2005	@enst-bretagne.fr	1000220
687	AID : Un framework intégré de conception d'un schéma objet-relationnel	AID : un framework intégrer de conception de un schéma objet-relationnel  devant le prolifération des donnée complexe qui ne cesser de croître , et le diversité des structure qui clr multiplier , le conception des schéma de base de donnée en général et des schéma objet-relationnel en particulier , être devenir un activité difficile et complexe , qui faire appel à un connaissance varié . lors de le conception de un schéma , le utilisateur ( non averti ) devoir connaître le théorie sous-jacent au modèle de donnée , de façon à énoncer son modèle , syntaxiquement correct cld permettre de construire un schéma de base de donnée objet-relationnel répondre à son besoin . plusieurs outil spécialiser dans le conception de schéma de base de donnée provenir aussi bien de le communauté académique que du monde industriel , tel Super , Totem , Rational  Rose , etc. avoir être développer dans un contexte et avec un but souvent très différent . affin de répondre à ce besoin pressant , cln avoir proposer un solution consister en le élaboration de environnement intégré faciliter le cohabitation de plusieurs modèle et technique utiliser lors de le conception de un schéma de base de donnée . ilimp clr agir de offrir un plate-forme logiciel appelé AID ( Aided Interface for Database design ) offrir un mécanisme opératoire uniforme représenter un soutien graphique et interactif pour un conception incrémental baser sur un manipulation direct et systémique des graphe au travers de un palette graphique de opérateur . le innovation de AID être son approche systémique qui faciliter le expression des besoin par le concepteur averti ou non , en cld automatiser son tâche . 	Etienne Pichat, Hassan Badir	2005	@liris.cnrs.fr	1000292
688	Analyse comparative de classifications : apport des règles d'association floues	analyse comparatif de classification : apport des règle de association flou  son travail clr appuyer sur le analyse de un corpus bibliographique dans le domaine de le géotechnique à le aide de carte réaliser avec le plateforme Stanalyst®. celui -ci intégrer un algorithme de classification automatique non hiérarchique ( le K-means axial ) donner un résultat dépendant du nombre de classe demander . ce instabilité rendre difficile tout comparaison entre classification , et laisser un doute quant au choix du nombre de classe nécessaire pour représenter correctement un domaine . cln comparer le résultat de classification selon 3 protocole : ( 1 ) analyse des intitulé des classe ; ( 2 ) relation entre le classe à partir un membre commun ; ( 3 ) règle de association flou . le graphe obtenir présenter un similitude remarquable , cln privilégier le règle de association flou : cln être extraire automatiquement et clr baser sur le description des classe et non des membre . ceci cld permettre donc de analyser un classification issu de corpus différent . 	Pascal Cuxac, Martine Cadot, Claire François	2005	@inist.fr, @inist.fr, @loria.fr	1000359
689	Analyse de données symboliques et graphe de connaissances d'un agent	analyse de donnée symbolique et graphe de connaissance de un agent  dans ce article cln appliquer le analyse de donnée symbolique au graphe de connaissance de un agent . cln présenter un mesure de similarité entre un donnée symbolique adapter à son graphe de connaissance . cln utiliser le pyramide symbolique pour extraire un nouveau objet symbolique . le nouveau objet être ensuite réinsérer dans le graphe où ilimp pouvoir être utiliser par le agent , faire ainsi évoluer son sémantique . ilimp pouvoir alors servir de individu lors des analyse ultérieur , permettre de découvrir un nouveau concept prendre en compte le évolution de le sémantique . 	Philippe Caillou, Edwin Diday	2005	@lamsade.dauphine.fr, @ceremade.dauphine.fr	1000408
690	Analyse stochastique de séquences d'événements discrets pour la découverte de signatures	analyse stochastique de séquence de événement discret pour le découverte de signature  " ce article concerner le découverte de signature ( ou modèle de chronique ) à partir de un séquence de événement discret ( alarme ) générer par un agent cognitif de surveillance ( Monitoring Cognitive Agent ou MCA ) . . Considérant un couple ( Processus , MCA ) comme un générateur stochastique de événement discret , deux représentation complémentaire permettre de caractériser le propriété stochastique et temporel de un tel générateur : un chaîne de Markov à temps continu et un superposition de processus de Poisson . . le étude de ce deu représentation dual permettre de découvrir un " " signature " " décrire le relation stochastique et temporel entre événement dans un séquence . . ce signature pouvoir alors être utiliser pour reconnaître un comportement spécifique , comme le montre le application de le approche à un outil de production industriel piloter par un système Sachem , le MCA développer et utiliser par le groupe Arcelor pour aider au pilotage de son outil de production . " 	Philippe Bouché, Marc Le Goc	2005	@lsis.org, @lsis.org	1000219
691	Annotation de textes par extraction d'informations lexicosyntaxiques  et acquisition de schémas conceptuels de causalité	annotation de texte par extraction de information lexicosyntaxique et acquisition de schéma conceptuel de causalité  cln présenter le méthode INSYSE ( INterface SYntaxe SEmantique ) pour le annotation de document textuel . son objectif être de construire un annotation sémantique de ce résumé pour interroger le corpus sur le fonction des gène et son relation de causalité avec certain maladie . son approche être semi-automatique , centrer sur ( 1 ) le extraction de information lexico- syntaxique à partir de certain phrase du corpus comporter un lexème de causation , et ( 2 ) le élaboration de règle baser sur un grammaire de unification permettre de acquérir à partir de ce information des schéma conceptuel instancier . celui -ci être traduire en annotation RDF ( S ) sur le base desquelles le corpus de texte pouvoir être interroger avec le moteur de recherche sémantique Corese . 	Laurent Alamarguy, Rose Dieng-Kuntz, Catherine Faron-Zucker	2005	@inria.fr, @essi.fr	1000258
692	Apprentissage automatique des modèles structurels d'objets cartographiques	apprentissage automatique des modèle structurel de objet cartographique  pour reconnaitre le objet cartographique dans le image satellital cln avoir besoin de un modèle de objet que cln rechercher . cln avoir développer un système de apprentissage qui construire le modèle structurel de objet cartographique automatiquement avoir partir un image satellital segmenter . le image contenant le objet être décomposer en forme primitif et être transformer en Graphes Relationnels Attribués ( ARGs ) . cln avoir générer le modèle de objet avoir partir de ce graphe , en utiliser un algorithme de appariement de graphe . le qualité de un modèle être évaluer par le distance de édition des exemple avoir ce modèle . cln être parvenir avoir obtenir un modèle de pont et de rond-point qui être compatible avec le modèle construire manuellement . 	Güray Erus, Nicolas Loménie	2005	@univ-paris5.fr	1000336
693	Apprentissage de signatures de facteurs de transcription à partir de données d'expression	apprentissage de signature de facteur de transcription à partir de donnée de expression  le inférence de signature de facteur de transcription à partir un donnée puce à ADN avoir déjà être étudier dans le communauté bioinformatique . le principal difficulté à résoudre être de trouver un ensemble de heuristique pertinent , afin de contrôler le complexité de résolution de ce problème NP-difficile . cln proposer dans ce article un solution heuristique alternatif à celui utiliser dans le approche bayésien , fonder sur le recherche de motif fréquent maximal dans un matrice discrétisé issue des donnée numérique de puce ADN . son méthode être appliquer sur un donnée de cancer de vessie de le Institut Curie et de le hôpital Henri Mondor de Créteil . 	Mohamed Elati, Céline Rouveirol, François Radvanyi	2005	@lri.fr, @curie.fr	1000416
694	Apprentissage de structures de réseaux Bayésiens et données incomplètes	apprentissage de structure de réseau Bayésiens et donnée incomplet  " le formalisme des modèle graphique conner actuellement un essor dans le domaine du " " machine learning " " . . en particulier , le réseau bayésien être capable de effectuer un raisonnement probabiliste à partir de donnée incomplet alors que peu de méthode être actuellement capable de utiliser le base de exemple incomplet pour son apprentissage . . en clr inspirer du principe de AMS-EM proposer par ( Friedman , 1997 ) et des travaux de ( Chow et Liu , 1968 ) , cln proposer un méthode permettre de faire le apprentissage de réseau bayésien particulier , de structure arborescent , à partir de donnée incomplet . . un étude expérimental exposer ensuite un résultat préliminaire que ilimp être possible de attendre de un tel méthode , puis montrer le gain potentiel apporter lorsque cln utiliser le arbre obtenir comme initialisation de un méthode de recherche glouton comme AMS-EM. " 	Olivier François, Philippe Leray	2005	@insa-rouen.fr	1000222
695	Apprentissage non supervisé de séries temporelles à l'aide des k-Means et d'une nouvelle méthode d'agrégation de séries	apprentissage non superviser de série temporel à le aide des k-Means et de un nouveau méthode de agrégation de série  " le utilisation de un algorithme de apprentissage non superviser de type k-Means sur un jeu de série temporel amener à clr poser deux question : : Celle du choix de un mesure de similarité et celui du choix de un méthode effectuer le agrégation de plusieurs série afin de cll estimer le centre ( i.e. calculer le k moyen ) . . Afin de répondre à le premier question , cln présenter dans ce article le principal mesure de similarité existant puis cln expliquer pourquoi le un de entre lui ( appelé Dynamic Time Warping ) cln paraître le plus adapté à le apprentissage non superviser . . le deuxième question poser alors problème car cln avoir besoin de un méthode de agrégation respecter le caractéristique bien particulier du Dynamic Time Warping . . cln penser que le association de ce mesure de similarité avec le agrégation Euclidienne pouvoir générer un perte de information important dans le cadre de un apprentissage sur le " " forme " " des série . . cln proposer donc un méthode original de agrégation de série temporel , compatible avec le Dynamic Time Warping , qui améliorer ainsi le résultat obtenir à le aide de le algorithme des k-Means . " 	Nicolas Nicoloyannis, Rémi Gaudin	2005	@univ-lyon2.fr, @univ-lyon2.fr	1000250
696	Apprentissage supervisé pour la classification des images basé sur la structure P-tree	apprentissage superviser pour le classification des image baser sur le structure P-tree  un problème important de le production automatique de règle de classification concerner le durée de génération de ce règle ; en effet , le algorithme mettre en oeuvre produire souvent un règle pendant un certain temps assez long . cln proposer un nouveau méthode de classification à partir de un base de donnée image . ce méthode clr situer à le jonction de deux technique : le algèbre de P-tree et le arbre de décision en vue de accélérer le processus de classification et de recherche dans un grand base de image . le modélisation que cln proposer clr baser , de un part , sur le descripteur visuel tel que le couleur , le forme et le texture dans le but de indexer le image et , de autre part , sur le génération automatique des règle de classification à le aide de un nouveau algorithme C4.5 ( P-tree ) . pour valider son méthode , cln avoir développer un système baptiser C.I.A.D.P-tree qui avoir être implémenter et confronter à un application réel dans le domaine du traitement de image . le résultat expérimental montrer que ce méthode réduire efficacement le temps de classification . 	Rim Faiz, Najeh Naffakhi, Khaled Mellouli	2005	@ihec.rnu.tn, @ihec.rnu.tn, @isg.rnu.tn	1000343
697	Arbre de décision sur des données de type intervalle : évaluation et comparaison	arbre de décision sur un donnée de type intervalle : évaluation et comparaison  le critère de découpage binaire de Kolmogorov-Smirnov nécessiter un ordre total des valeur prendre par le variable explicative . cln pouvoir ordonner un intervalle fermé borner de nombre réel de différent façon . son contribution dans ce article consister à évaluer et à comparer un arbre de décision obtenir sur un donnée de type intervalle à le aide du critère de découpage binaire de Kolmogorov-Smirnov étendre à ce type de donnée ( Mballo et alès 2004 ) . pour ce faire , cln axer son attention sur le taux de erreur mesurer sur le échantillon de test . pour estimer ce paramètre , cln diviser aléatoirement chaque base de donnée en deux party égal en terme de effectif ( à un objet près ) pour construire deux arbre . ce deu arbre être de abord tester par un même échantillon puis par deux échantillon différent . 	Chérif Mballo, Edwin Diday	2005	@esiea-ouest.fr, @ceremade.dauphine.fr	1000215
698	Caractérisation d'une région d'intérêt dans les images	caractérisation de un région de intérêt dans le image  un image être un support de information qui avoir montrer son efficacité . néanmoins un image comporter souvent plusieurs zone , le arrière plan et un zone de intérêt privilégié . le vision humain permettre le segmentation de manière naturel et intégrer tout le connaissance que le sujet pouvoir avoir de le objectif viser par le image . cln proposer ici un méthode de détermination des région de intérêt de un image numérique comme zone saillant . le loi de Zipf et Zipf inverse être adapté au traitement des image et permettre de évaluer le complexité structurel de un image . un comparaison des modèle local évaluer sur un imagette permettre de mettre en évidence un région de le image . Deux méthode de classification avoir être utiliser pour le détermination de le région de intérêt : le partition de un nuage de point représenter le caractéristique associer aux imagette , et le réseau de neurone . ce méthode de détection permettre de obtenir un zone de intérêt conforme à le perception humain . cln opérer un hiérarchisation sur le zone en fonction de le structuration de le information élémentaire , le pixel . 	Yves Caron, Pascal Makris, Nicole Vincent	2005	@univ-tours.fr, @univ-tours.fr, @univ-paris5.fr	1000338
699	CHIC : traitement de données avec l'analyse implicative	chic : traitement de donnée avec le analyse implicatif  ce article avoir pour but de montrer le possibilité offrir par le logiciel CHIC ( Classification Hiérarchique Implicative et Cohésitive ) pour effectuer certain analyse de donnée . ilimp être baser sur le théorie de le analyse Statistique Implicative ou A.S.I. développer par Régis Gras et son collaborateur . le principe premier de le A.S.I. reposer sur le problématique de un mesure des règle de association du type : « si avoir alors b » dans un population instanciant le variable avoir et b . chic enrichir son réponse , établir sur un base statistique , en évaluer le responsabilité des sujet dans le élection de le règle . le article présent expliquer le démarche à suivre pour utiliser le logiciel ainsi que le possibilité offrir par celui -ci . 	Raphaël Couturier, Régis Gras	2005	@univ-fcomte.fr, @club-internet.fr	1000423
700	Classification d'un tableau de contingence et modèle probabiliste	classification de un tableau de contingence et modèle probabiliste  le modèle de mélange , qui supposer que le échantillon être former de sous-population caractériser par un distribution de probabilité , constituer un support théorique intéressant pour étudier le classification automatique . cln pouvoir ainsi montrer que le algorithme des k-means pouvoir être voir comme un version classifiant de le algorithme de estimation EM dans un cas particulièrement simple de mélange de loi normal . lorsque le cln chercher à classifier le ligne ( ou le colonne ) de un tableau de contingence , ilimp être possible de utiliser un variante de le algorithme des k-means , appeler Mndki2 , en clr appuyer sur le notion de profil et sur le distance du khi- 2 . cln obtenir ainsi un méthode simple et efficace pouvoir clr utiliser conjointement à le analyse factoriel des correspondance qui clr appuyer sur le même représentation des donnée . malheureusement et contrairement à le algorithme des k-means classique , le lien qui exister entre le modèle de mélange et le classification ne clr appliquer pas directement à ce situation . dans ce travail , cln montrer que le algorithme Mndki2 pouvoir être associer , à un approximation près , à un modèle de mélange de loi multinomial . 	Gérard Govaert, Mohamed Nadif	2005	@utc.fr, @univ-metz.fr	1000251
701	Classification non supervisée et visualisation 3D de documents	classification non superviser et visualisation 3D de document  le nombre de document issir de un requête sur le Web devenir de plus en plus important . cela cln amener à chercher un solution pour aider le utilisateur qui être confronter à ce masse de donnée . un alternative possible à un affichage linéaire non trier selon un critère , consister à effectuer un classification des résultat . ce être dans ce but que le cln clr intéresser aux carte auto- organisatrice de Kohonen qui être issir de un de algorithme de classification non supervisé . cependant , ilimp falloir ajouter un contrainte à ce algorithme afin que ilimp être adapter à le classification des résultat de un requête . par exemple , ilimp devoir être déterministe . de plus le classification obtenir dépendre fortement de le distance utiliser pour comparer deux document . cln évaluer alors le impact de différent distance ou dissimilarité , afin de trouver le plus adapté à son problème . un compromis devoir également être trouver entre le temps de exécution de le algorithme et le qualité de le classification obtenir . pour cela , le utilisation de un échantillonnage être envisager . enfin , ce travaux être intégrer dans un prototype qui permettre de visualiser le résultat en trois dimension et de interagir avec lui . 	Nicolas Bonnel, Annie Morin, Alexandre Cotarmanac'h	2005		1000379
702	Classifying XML Materialized Views for their maintenance on distributed Web sources	ce dernier année avoir mettre en évidence le croissance et le diversité des information électronique accessible sur le web . ce être ainsi que le système de intégration de donnée tel que un médiateur avoir être concevoir pour intégrer ce donnée distribuer et hétérogène dans un vue uniforme . pour faciliter le intégration des donnée à travers différent système , XML avoir être adopter comme format standard pour échanger un information . XQuery être un langage de intégration des donnée à travers différent système , XML avoir être adopter comme format standard pour échanger un information . XQuery être un langage de interrogation pour XML qui clr être imposer pour le système baser sur XML . ainsi XQuery être employer sur un système de médiation pour concevoir un vue définir sur plusieurs source . pour optimiser le évaluation de requête , le vue être matérialiser lors de le mise à jour des source , car dans le contexte de source web , très peu de information être fournir par le source . le méthode habituellement proposer ne pouvoir pas être appliquer . ce article étudier comment mettre à jour des vue matérialiser XML sur un source web , au sein de un architecture de médiation . 	Tuyet-Tram Dang-Ngoc, Virginie Sans, Dominique Laurent	2005	@dept-info.u	1000331
703	Combinaison de fonctions de préférence par Boosting pour la recherche de passages dans les systèmes de question/réponse	combinaison de fonction de préférence par Boosting pour le recherche de passage dans le système de question  réponse  cln proposer un méthode de apprentissage automatique pour le sélection de passage susceptible de contenir le réponse à un question dans le système de Question-Réponse ( QR ) . le système de RI ad hoc ne être pas adapter à ce tâche car le passage rechercher ne devoir pas uniquement traiter du même sujet que le question mais en plus contenir son réponse . pour traiter ce problème le système actuel ré-ordonner le passage renvoyer par un moteur de recherche en considérer un critère sous forme de un somme pondérer de fonction de score . cln proposer de apprendre automatiquement le poids de ce combinaison , grâce à un algorithme de réordonnancement définir dans le cadre du Boosting , qui être habituellement déterminer manuellement . en plus du cadre de apprentissage proposer , le originalité de son approche résider dans le définition des fonction allouer un score de pertinence aux passage . cln valider son travail sur le base de question et de réponse de le évaluation TREC- 11 des système de QR . le résultat obtenir montrer un amélioration significatif des performance en terme de rappel et de précision par rapport à un moteur de recherche standard et à un méthode de apprentissage issue du cadre de le classification . 	Nicolas Usunier, Massih-Reza Amini, Patrick Gallinari	2005	@lip6.fr	1000169
704	Élagage et aide à l'interprétation symbolique et graphique d'une pyramide	élagage et aide à le interprétation symbolique et graphique de un pyramide  " le but de ce travail être de faciliter le interprétation de un classification pyramidal construire sur un tableau de donnée symbolique . . alors que dans un hiérarchie binaire le nombre de palier être égal à n-1 si n être le nombre de individu à classer , dans le cas de un pyramide ce dernier pouvoir atteindre n ( n-1 ) ou 2 . . Afin de réduire ce nombre , cln élaguer le pyramide et cln utiliser un critère de sélection de palier baser sur le hauteur . . de plus cln décrire tout le palier retenir par un variable que le cln sélectionner également en utiliser " " le degré de généralité " " ainsi que un mesure de dissimilarité de type symbolique-numérique . . le aide à le interprétation clr servir de outil graphique et interactif grâce à le bibliothèque OpenGL . . enfin un simulation montrer comment évoluer ce sélection quand le nombre de classe et de variable croire . " 	Kutluhan Kemal Pak, Mohamed Cherif Rahal, Edwin Diday	2005	@ceremade.dauphine.fr	1000226
705	Enrichissement sémantique de documents XML représentant des tableaux	enrichissement sémantique de document XML représenter un tableau  ce travail avoir pour objectif le construction automatique de un entrepôt thématique de donnée , à partir de document de format divers provenir du Web . le exploitation de ce entrepôt être assurer par un moteur de interrogation fonder sur un ontologie . son attention porter plus précisément sur le tableau extrait de ce document et convertir au format XML , aux tag exclusivement syntaxique . ce article présenter le transformation de ce tableau , sous forme XML , en un formalisme enrichir sémantiquement dont le plupart des tag et des valeur être un terme construire à partir de le ontologie . 	Fatiha Saïs, Hélène Gagliardi, Ollivier Haemmerlé, Nathalie Pernelle	2005	@lri.fr, @inapg.fr	1000309
706	Évaluation des algorithmes LEM et eLEM pour données continues	évaluation des algorithme LEM et eLEM pour donnée continu  très populaire et très efficace pour le estimation de paramètre de un modèle de mélange , le algorithme EM présenter le inconvénient majeur de converger parfois lentement . son application sur un tableau de grand taille devenir ainsi irréalisable . afin de remédier à ce problème , plusieurs méthode avoir être proposer . cln présenter ici le comportement de un méthode connu , LEM , et de un variante que cln avoir proposer récemment eLEM . Celles -ci permettre de accélérer le convergence de le algorithme , tout en obtenir un résultat similaire à celui -ci . dans ce travail , cln clr concentrer sur le aspect classification , et cln illustrer le bon comportement de son variante sur un donnée continu simulé et réel . 	François-Xavier Jollois, Mohamed Nadif	2005	@univ-paris5.fr, @univ-metz.fr	1000231
707	Expériences de classification d'une collection de documents XML de structure homogène	expérience de classification de un collection de document XML de structure homogène  ce article présent différent expérience de classification de document XML de structure homogène , en vue de expliquer et de valider un présentation organisationnel pré-existant . le problème concerner le choix des élément et mots utiliser pour le classification et son impact sur le typologie induire . pour cela cln combiner un sélection structurel baser sur le nature des élément XML et un sélection linguistique baser sur un typage syntaxique des mots . cln illustrer ce principe sur le collection des rapport de activité 2003 des équipe de recherche de le Inria en chercher un groupement de équipe ( Thèmes ) à partir du contenu de différent party de ce rapport . cln comparer son premier résultat avec le thème de recherche officiel de le Inria . 	Thierry Despeyroux, Yves Lechevallier, Brigitte Trousse, Anne-Marie Vercoustre	2005	@inria.fr	1000243
708	Expérimentations sur un modèle de recherche d'information utilisant les liens hypertextes des pages Web	expérimentation sur un modèle de recherche de information utiliser le lien hypertexte des page Web  le fonction de correspondance , qui permettre de sélectionner et de classer le document par rapport à un requête être un composer essentiel dans tout système de recherche de information . cln proposer de modéliser un fonction de correspondance prendre en compte à le fois le contenu et le lien hypertexte des page Web . cln avoir expérimenter son système sur le collection de test TREC- 9 , et cln conclure que pour certain type de requête , inclure le texte ancrer associer aux lien hypertexte des page dans le fonction de similarité clr avérer plus efficace . 	Bich-Liên Doan, Idir Chibane	2005	@supelec.fr, @supelec.fr	1000264
709	Extension de l'algorithme Apriori et des règles d'association aux cas des données symboliques diagrammes et intervalles	extension de le algorithme Apriori et des règle de association aux cas des donnée symbolique diagramme et intervalle  cln traiter le extension de le algorithme Apriori et des règle de association aux cas des donnée symbolique diagramme et intervalle . le méthode proposer cln permettre de découvrir un règle de association au niveau des concept . ce extension impliquer notamment un nouveau définition pour le support et le confiance afin de exploiter le structure symbolique des donnée . Au fil de le article le exemple classique du panier de le ménagère être développer . ainsi , plutôt que de extraire un règle entre différent article appartenir à un même transaction enregistrer dans un magasin comme dans le cas classique , cln extraire un règle de association au niveau des client afin de étudier son comportement de achat . 	Filipe Afonso, Edwin Diday	2005	@ceremade.dauphine.fr, @ceremade.dauphine.fr	1000348
710	Extension des bases de données inductives pour la découverte de chroniques	extension des base de donnée inductif pour le découverte de chronique  le base de donnée inductif intégrer le processus de fouille de donnée dans un base de donnée qui contenir à le fois le donnée et le connaissance induire . cln cln proposer de étendre le donnée traiter afin de permettre le extraction de motif temporel fréquent et non fréquent à partir de un ensemble de séquence de évènement . le motif temporel viser être un chronique qui permettre de exprimer un contrainte numérique sur le délai entre le occurrence de évènement . 	Alexandre Vautier, Marie-Odile Cordier, Rene Quiniou	2005	@irisa.fr	1000314
711	Extraction Bayésienne et intégration de patterns représentés suivant les K plus proches voisins pour le go 19x19	extraction Bayésienne et intégration de pattern représenter suivant le K plus proche voisins pour le go 19x19  ce article décrire le génération automatique et le utilisation de un base de pattern pour le go 19x19 . le représentation utiliser être celui des K plus proche voisins . le pattern être engendrer en parcourir un party de professionnel . le probabilité de appariement et de jeu des pattern être également estimer à ce moment là . le base créer être intégrer dans un programme existant , Indigo . soit cln être utiliser comme un livre de ouverture en début de partie , soit comme un extension des base pré-existant du générateur de coup du programme . en terme de niveau de jeu , le gain résulter être estimer à 15 point en moyenne . 	Bruno Bouzy, Guillaume Chaslot	2005	@univ-paris5.fr, @ec-lille.fr	1000212
712	Extraction bilingue de termes médicaux dans un corpus  parallèle anglais/français	extraction bilingue de terme médical dans un corpus parallèle anglais  français  le Catalogue et Index des Sites Médicaux Francophones ( CISMeF ) recenser le principal ressource institutionnel de santé en français . le description de ce ressource , puis son accès par le utilisateur , clr faire grâce à le terminologie CISMeF , fonder sur le thésaurus américain Medical Subject Headings ( MeSH ) . le version français du MeSH comprendre tout le descripteur MeSH , mais un nombreux synonyme américain rester à traduire . afin de enrichir le terminologie , cln proposer ici un méthode de traduction automatique de ce synonyme . pour ce faire , cln avoir constituer deux corpus parallèle anglais  français du domaine médical . après alignement semi-automatique des corpus paragraphe à paragraphe , cln avoir procéder automatiquement à le appariement bilingue des terme . pour cela , le lexique constituer des descripteur MeSH américain et de son traduction en français avoir fournir le couple amorce qui avoir servir de point de départ à le propagation syntaxique des lien de appariement . 217 synonyme avoir pouvoir être traduire , avec un précision de 70 \pourcent . 	Aurélie Névéol, Sylwia Ozdowska	2005	@insa-rouen.fr, @stics, @univ-tlse2.fr	1000413
713	Extraction de la localisation des termes pour le classement des documents	extraction de le localisation des terme pour le classement des document  trouver et classer le document pertinent par rapport à un requête être fondamental dans le domaine de le recherche de information . son étude reposer sur le localisation des terme dans le document . cln poser le hypothèse que plus le occurrence des terme de un requête clr retrouver proche dans un document alors plus ce dernier devoir être positionner en tête de le liste de réponse . cln présenter deux variante de son modèle à zone de influence , le premier être baser sur un notion de proximité flou et le seconde sur un notion de pertinence local . 	Annabelle Mercier, Michel Beigbeder	2005	@emse.fr	1000269
714	Extraction de règles d'association quantitatives application à des données médicales	extraction de règle de association quantitatif application à un donnée médical  le extraction de règle de association être devenir aujourde hui un tâche populaire en fouille de donnée . cependant , le algorithme Apriori et son variante rester dédier aux base de donnée renfermer un information catégorique . cln proposer dans ce article QuantMiner , qui être un outil que cln avoir développer dans le but de extraire un règle de association gérer variable catégorique et numérique . le outil que cln proposer reposer sur un algorithme génétique permettre de découvrir de façon dynamique le intervalle des variable numérique apparaître dans le règle . cln présenter également un application réel de son outil sur un donnée médical relative à le maladie de le athérosclérose et donner un résultat de son expérience pour le description et le caractérisation de ce maladie . 	Cyril Nortet, Ansaf Salleb-Aouissi, Teddy Turmeaux, Christel Vrain	2005	@lifo.univ, @irisa.fr	1000352
715	Extraction de termes centrée autour de l'expert	extraction de terme centrer autour de le expert  cln développer un logiciel , Exit , capable de aider un expert à extraire un terme que ilimp trouver pertinent dans un texte de spécialité . tout être mettre en place pour faciliter le travail de le expert afin que ilimp pouvoir consacrer son temps à le seul reconnaissance des terme pertinent . pour cela , différent mesure statistique et un nombreux option de extraction être disponible dans Exit . afin de utiliser au mieux le connaissance de le expert , son approche être semi-automatique . de plus , le expert construire des terme pouvoir inclure un terme précédemment extrait ce qui rendre itératif et constructif son processus de formation des terme . enfin , le ergonomie du logiciel avoir profiter un enseignement tirer lors de son utilisation pour un compétition international de extraction de connaissance . 	Thomas Heitz, Mathieu Roche, Yves Kodratoff	2005	@lri.fr	1000425
716	Forage distribué des données : une comparaison entre l'agrégation d'échantillons et l'agrégation de règles	forage distribuer des donnée : un comparaison entre le agrégation de échantillon et le agrégation de règle  pour cld attaquer au problème du forage de très grand base de donnée distribuer , cln proposer de étudier deux approche . le premier être de télécharger seulement un échantillon de chaque base de donnée puis de cll effectuer le forage . le deuxième approche être de miner à distance chaque base de donnée indépendamment , puis de télécharger le modèle résultant , sous forme de règle de classification , dans un site central où le agrégation de ce dernier être réaliser . dans ce article , cln présenter un vue de ensemble des technique de échantillonnage le plus commun . cln présenter ensuite ce nouveau technique de forage distribuer des donnée où le mécanique de agrégation être baser sur un coefficient de confiance attribuer à chaque règle et sur de très petit échantillon de chaque base de donnée . le coefficient de confiance de un règle être calculer par un moyens statistique en utiliser le théorème limite central . en conclusion , cln présenter un comparaison entre le meilleur technique de échantillonnage que cln avoir trouver dans le littérature , et son approche de forage distribuer des donnée ( FDD ) baser sur le agrégation de modèle . 	Mohamed Aounallah, Sébastien Quirion, Guy W. Mineau	2005	@ift.ulaval.ca, @ift.ulaval.ca, @gel.ulaval.ca	1000211
717	Fouille de graphes et découverte de règles d'association : application à l'analyse d'images de document	fouille de graphe et découverte de règle de association : application à le analyse de image de document  ce article présenter un méthode permettre le découverte non supervisé de motif fréquent représentatif de symbole sur un image de document . le symbole être considérer comme un entité graphique porteur de information et le image de document être représenter par un graphe relationnel attribuer . dans un premier temps , le méthode réaliser le découverte de sous-graphe disjoint fréquent et faire correspondre pour chacun de lui un symbole différent . un recherche des règle de association entre ce symbole permettre alors de accéder à un partie des connaissance du domaine décrire par ce symbole . le objectif à terme être de utiliser le symbole découvert pour le classification ou le recherche de image dans un flux hétérogène de document là ou un approche superviser ne être pas envisageable . 	Eugen Barbu, Pierre Héroux, Sébastien Adam, Éric Trupin	2005	@univ-rouen.fr	1000341
718	Fouille de textes pour orienter la construction d'une ressource terminologique	fouille de texte pour orienter le construction de un ressource terminologique  le finalité de ce papier être de analyser le apport de technique de fouille de donnée textuel à un méthodologie de construction de ontologie à partir de texte . le domaine de application de ce expérimentation être celui de le accidentologie routier . dans ce contexte , le résultat des technique de fouille de donnée textuel être utiliser pour orienter le construction de un ressource terminologique à partir de procès-verbal de accident . le méthode TERMINAE et le outil du même nom offrir le cadre général pour le modélisation de le ressource . le papier présent le technique de fouille employer et le intégration des résultat des fouille dans le différent étape du processus de construction de le ressource . 	Valentina Ceausu, Sylvie Desprès	2005	@univ-paris5.fr, @univ-paris5.fr	1000261
719	Hiérarchisation des règles d'association en fouille de textes	hiérarchisation des règle de association en fouille de texte  le extraction de règle de association être souvent exploiter comme méthode de fouille de donnée . cependant , un des limite de ce approche venir du très grand nombre de règle extraire et de le difficulté pour le analyste à appréhender le totalité de ce règle . cln proposer donc de pallier ce problème en structurer le ensemble des règle de association en hiérarchie . le structuration des règle clr faire à deux niveau . un niveau global qui avoir pour objectif de construire un hiérarchie structurer le règle extraire des donnée . cln définir donc un premier type de subsomption entre règle issue de le subsomption dans le treillis de Galois . le second niveau correspondre à un analyse local des règle et générer pour un règle donner un hiérarchie de généralisation de ce règle qui reposer sur un connaissance complémentaire exprimer dans un modèle terminologique . ce niveau faire appel à un second type de subsomption inspirer de le subsomption en programmation logique inductif . cln définir ce deu type de subsomption , développer un exemple montrer le intérêt de le approche pour le analyste et étudier le propriété formel des hiérarchie ainsi proposer . 	Rokia Bendaoud, Yannick Toussaint, Amedeo Napoli	2005	@loria.fr	1000268
720	Intégration efficace des arbres de décision dans les SGBD : utilisation des index bitmap	intégration efficace des arbre de décision dans le SGBD : utilisation des index bitmap  cln présenter dans ce article un nouveau approche de fouille qui permettre de appliquer un algorithme de construction de arbre de décision en répondre à deux objectif : ( 1 ) traiter un base volumineux , ( 2 ) en un temps de traitement acceptable . le premier objectif être atteindre en intégrer ce algorithme au coeur des SGBD , en utiliser uniquement le outil fournir par ce dernier . toutefois , le temps de traitement demeurer long , en raison des nombreux lecture de le base . cln montrer que , grâce aux index bitmap , cln réduire à le fois le taille de le base de apprentissage et le temps de traitement . pour valider son approche , cln avoir implémenter le méthode ID3 sous forme de un procédure stocker dans le SGBD Oracle . 	Cécile Favre, Fadila Bentayeb	2005	@univ-lyon2.fr	1000281
721	L'automate textuel pour la prise en compte de l'évolution du texte	le automate textuel pour le prise en compte de le évolution du texte  ilimp ne être plus à rappeler que le corpus textuel , être tel que ilimp être actuellement , intraitable à le échelle que son croissance cld confirmer le obligation de utiliser un outil automatique de traitement . ce article clr intéresser plus particulièrement à le caractérisation de texte et par là même à celui de auteur . A le heure actuel , tout le méthode existant travailler sur le document finir , sans admettre que un cheminement exister entre le début du document et son fin . cln proposer un méthode tentant de apporter ce notion de évolution textuel en traiter le texte par un automate et le évaluation choisir . puis cln présenter un résultat valider par un expert , obtenir sur un corpus de entretien sociologique . 	Hubert Marteau, Nicole Vincent	2005	@univ-tours.fr, @univ-paris5.fr	1000276
722	La démarche ontologique pour la gestion des compétences et des connaissances	le démarche ontologique pour le gestion des compétence et des connaissance  " le gestion des ressource humain reposer de un part sur le connaissance des individu et de son compétence et de autre part sur le connaissance de le organisation et de son métier . . ce être par le " " mettre en correspondance " " de ce connaissance que ilimp être possible de améliorer le emploi , de valoriser le connaissance et le compétence individuel et de mieux gérer le organisation . . ce mise en correspondance nécessiter un représentation explicite des connaissance , ce qui permettre de répondre à un nouveau besoin : annuaire de compétence , gestion des projet et des retour de expérience , identification des connaissance à risque , etc. cln voir dans le cadre de ce article le intérêt de le approche ontologique tant de un point de vue méthodologique pour le clarification des notion mettre en jeu dans le cadre de le GPECC ( Gestion Prévisionnelle des Emplois des Compétences et des connaissance ) que pour le construction , le représentation et le maintenance des référentiel des compétence , un connaissance et des métier . . cln permettre en particulier un gestion de le information par le terminologie et le sens métier propre à le organisation . " 	Christophe Roche, Charles Foveau, Samah Reguigui	2005	@univ-savoi, @ontologos-corp.com, @ontologos-corp.com	1000299
723	Logiciel d'aide à l'étiquetage morpho-syntaxique de  textes de spécialité	logiciel de aide à le étiquetage morpho- syntaxique de texte de spécialité  le compréhension de texte de spécialité nécessiter un étiquetage morpho- syntaxique de bon qualité . or , lorsque le texte étudier être issir de domaine spécifique et peu usiter , ilimp être rare de disposer de dictionnaire et autre ressource lexical fiable . le logiciel que cln proposer permettre de utiliser un étiquetage réaliser par un étiqueteur généraliste , puis de améliorer ce étiquetage en intégrer un connaissance de expert du domaine étudier . grâce au logiciel développer , ilimp être relativement aisé pour un expert du domaine de détecter un erreur de étiquetage et de mettre en place des règle de ré-étiquetage . ce règle pouvoir être obtenir de deux manière différent : ( 1 ) soit en utiliser un langage de programmation permettre de exprimer un règle complexe de ré-étiquetage , ( 2 ) soit par apprentissage automatique des règle à partir de exemple corriger au moyen de un interface dédier . ce apprentissage proposer un nouveau règle à le expert , acquérir automatiquement . 	Ahmed Amrani, Jérôme Azé, Yves Kodratoff	2005	@esiea.fr, @lri.fr	1000421
724	Manipulation et fusion de données multidimensionnelles	manipulation et fusion de donnée multidimensionnel  ce article définir un algèbre permettre de manipuler un table dimensionnel extraire de un base de donnée multidimensionnel . le algèbre intégrer un noyau minimum de opérateur unaire permettre de effectuer le analyse décisionnel par combinaison de opérateur . ce algèbre intégrer un opérateur binaire permettre le fusion de table dimensionnel faciliter le corrélation des sujet analyser . 	Franck Ravat, Olivier Teste, Gilles Zurfluh	2005	@irit.fr	1000286
725	Méthode de construction d'ontologie de termes à partir du treillis de l'iceberg de Galois	méthode de construction de ontologie de terme à partir du treillis de le iceberg de Galois  " le approche présenter dans ce article avoir pour objectif le construction de un ontologie à partir du treillis de le iceberg de Galois . . cln entendre par ontologie un ensemble de terme structurer entre lui par un ensemble de lien de divers type . . dans son cas de étude , ce ontologie constituer un support de connaissance " " documentaire " " . . en effet , cln pouvoir être utiliser dans divers application en recherche de Information ( RI ) , tel que le indexation automatique et le expansion de requête ainsi que en text-mining . . le méthode de construction que cln proposer être fonder sur le analyse formel de concept ( AFC ) et plus précisément , le structure du treillis de le iceberg de Galois . . en utiliser ce structure hiérarchique partiellement ordonner , cln présenter un translation direct des relation laticiel vers celui ontologique . . cln proposer ainsi de enrichir le ontologie dériver par un règle associatif générique entre terme , découvrir dans le cadre de un processus de text-mining . " 	Cherif Chiraz Latiri, Mehdi Mtir, Sadok Ben Yahia	2005	@gnet.tn, @fst.rnu.tn, @voila.fr	1000304
726	Mining Frequent Queries in Star Schemes	le extraction de tout le requête fréquent dans un base de donnée relationnel être un problème di±cile , même si le cln ne considérer que un requête conjonctif . cln montrer que ce problème devenir possible dans le cas suivant : le schéma de le base être un schéma en étoile , et le donnée satisfaire un ensemble de dépendance fonctionnel et de contrainte référentiel . de plus , le schéma en étoile être approprié pour le entrepôt de donnée et que le dépendance fonctionnel et le contrainte référentiel être le contrainte le plus usuel dans le base de donnée . en considérer le modèle des instance faible , cln montrer que le requête fréquent exprimer par sélection-projection pouvoir être extraire par un algorithme de type Apriori . 	Tao-Yuan Jen, Dominique Laurent, Nicolas Spyratos, Oumar Sy	2005	@dept-info.u, @lri.fr, @ugb.sn	1000283
727	Modélisation de connaissances pour un système de médiation	modélisation de connaissance pour un système de médiation  travailler sur le élaboration de un méthodologie de développement de système de médiation intégrer dans un système coopératif , cln avoir proposer un architecture à 3 composant : le premier concerner le coopération , le second le assistance et le troisième être relatif aux connaissance nécessaire aux 2 précédent . dans ce article cln présenter plus particulièrement le point de vue des connaissance . ce connaissance être de 2 nature : un connaissance statique , sur le domaine par exemple , et des connaissance acquérir pendant le utilisation coopératif du système , notamment le mémoire des activité et le description des acte de résolution de problème . pour illustrer ce modélisation de connaissance , cln cld intéresser aux activité coopératif de suivi , de gestion et de évaluation de projet de étudiant , assister par le outil iPédagogique . 	Victoria Eugenia Ospina, Alain-Jérôme Fougères, Manuel Zacklad	2005	@utbm.fr, @utt.fr	1000383
728	Modélisation des individus et de leurs relations pour l'aide à l'intégration des individus dans l'organisation	modélisation des individu et de son relation pour le aide à le intégration des individu dans le organisation  le objectif de ce papier être de présenter un contribution à le modélisation des individu et de son relation pour permettre le aide à le intégration des acteur dans un organisation . cln étudier en particulier le cas du remplacement de un acteur ( « turn-over » ) . dans ce cadre , cln proposer un modèle regrouper un ensemble de donnée relative à un individu , aux relation que celui -ci entretenir avec le autre acteur et à son espace informationnel . le étude porter sur le mise en oeuvre de mécanisme de aide fournir à un acteur le moyens de son intégration : le mise à disposition de un image des espace informationnel et relationnel de son prédécesseur ainsi que le mise en relation de le acteur avec le autre acteur de le organisation . ce étude être mener en partenariat avec un expert en GRH . 	Marie-Françoise Canut, Max Chevalier, André Péninou, Florence Sedes	2005	@iut-blagnac.fr, @iut-blagnac.fr, @irit.fr, @irit.fr	1000392
729	Modélisation des interactions entre individus avec AgentUML	modélisation des interaction entre individu avec AgentUML  pour faciliter le étude de certain phénomène , un outil de simulation avoir être créer dans un nombreux domaine . le étude du comportement humain à jusque là échapper à ce tendance . Aujourd' hui , le système multi-agent coupler aux avancée des science humain fournir le base nécessaire à le élaboration de ce type de outil . ce article clr inscrire ainsi dans ce dynamique avec le objectif de développer un outil de simulation du comportement de individu traumatiser crânien sur un chaîne de production . ce outil devoir permettre le collecte de le connaissance relative au système étudier et fournir un aide à le décision pour le responsable de le entreprise . ce article proposer un modélisation des interaction entre individu dans le formalisme AgentUML . un implémentation du modèle au sein de un outil de simulation fonctionnel et le résultat obtenir être également présenter . A terme , le but être le production de donnée de simulation exploitable par un technique de ECD . 	Stéphane Daviet, Fabrice Guillet, Henri Briand, Adina Magda Florea, Vincent Philippé	2005	@kowesis.fr, @univ-nantes.fr, @cs.pub.ro	1000399
730	Modélisation d'objets mobiles dans un entrepôt de données	modélisation de objet mobile dans un entrepôt de donnée  le gestion de objet mobile avoir connaître un regain de intérêt ce dernier année , particulièrement dans le but de gérer et de prédire le localisation de objet mobile . cependant , ilimp cll avoir peu de recherche sur le exploitation de historique de base de objet mobile . le premier étape dans ce processus être le mise en oeuvre de un entrepôt de objet mobile . seulement , le modèle de entrepôt existant ne permettre pas de traiter directement ce type de donnée complexe . ce article présenter un approche original pour pallier ce problème . ce approche offrir le puissance de le algèbre OLAP sur tout combinaison de donnée classique , spatial et-ou temporel et mobile . cln avoir être valider par un prototype et appliquer à le analyse de le mobilité urbaine1 . le résultat de le expérimentation montrer le validité de le approche et le test de performance son efficacité . 	Tao Wan, Karine Zeitouni	2005	@prism.uvsq.fr, @prism.uvsq.fr	1000284
731	Modélisation d'un agent émotionnel en UML et RDF	modélisation de un agent émotionnel en UML et RDF  pouvoir extraire de le connaissance à partir de un plate-forme de simulation être aujourde hui envisageable en conjuguer le avancée obtenir en Intelligence Artificielle autour un système multi-agent et le méthode de formalisation et de extraction des connaissance . ce être donc dans un cadre général de gestion des connaissance que cln proposer de modéliser un agent artificiel doter de connaissance et de émotion . pour cela , un expertise psychologique avoir être recueillir et formaliser de manière à être stocker dans un base de connaissance sous forme de règle et de classe en UML et RDF . le implémentation du modèle permettre de entrevoir le perspective de un tel simulation : enrichissement par un donnée issu de simulation , découverte de nouveau connaissance par le application de processus de ECD . 	Hélène Desmier, Fabrice Guillet, Adina Magda Florea, Henri Briand, Vincent Philippé	2005	@performanse.fr, @univ-nantes.fr, @cs.pub.ro	1000406
732	Motifs séquentiels flous : un peu, beaucoup, passionément	motif séquentiel flou : un peu , beaucoup , passionément  le plupart des base de donnée issu du monde réel être constituer de donnée numérique et historié ( donnée de capteur , donnée scientifique , donnée démographique ) . dans ce cadre le algorithme de extraction de motif séquentiel , se cln être adapter au caractère temporel des donnée ne permettre pas le traitement de donnée numérique . être donner être alors pré-traiter pour cla transformer en donnée binaire , ce qui entraîner un perte de information . un algorithme avoir donc être proposer pour traiter le donnée numérique sous forme de intervalle et de intervalle flou notamment . en ce qui concerner le recherche de motif séquentiel fonder sur un intervalle flou , le deu méthode de le littérature ne être pas satisfaisant car incomplet être dans le traitement des séquence être dans le calcul du support . 	Céline Fiot, Anne Laurent, Maguelonne Teisseire	2005		1000357
733	Notion de sémantiques bien-formées pour les règles	notion de sémantique bien-formée pour le règle  le notion de règle entre attribut être très général , aller un règle de association en fouille de donnée aux dépendance fonctionnel ( DF ) en base de donnée . malgré ce diversité , le syntaxe des règle être toujours le même , seul son sémantique différer . pour un sémantique donner , en fonction des propriété induire , un technique algorithmique être mettre en oeuvre pour découvrir le règle à partir un donnée . A partir de un ensemble de règle , ilimp être aussi utile en pratique de raisonner sur ce règle , comme cela être le cas par exemple avec le axiome de Armstrong pour le dépendance fonctionnel . dans ce article , cln proposer un cadre qui permettre de clr assurer que un sémantique donner pour le règle être bien-formée , i.eès le axiome de Armstrong être juste et complet pour ce sémantique . le proposition faire dans ce papier provenir du contexte applicatif de le analyse de donnée de biopuce . A partir de plusieurs sémantique pour le donnée de expression de gène , cln montrer comment ce sémantique clr intégrer dans le cadre présenter . 	Marie Agier, Jean-Marc Petit	2005		1000207
734	Outil de classification et de visualisation de grands volumes de données mixtes	outil de classification et de visualisation de grand volume de donnée mixte  cln avoir concevoir un outil de classification de donnée original que cln détailler dans le présent article . ce outil comporter un module de création de résumé et un module de affichage . le module de visualisation permettre un lecture aisé des résumé grâce à un interface graphique évoluer permettre le présentation et le exploration des résumé sous forme de un hiérarchie de profil ou de un tableau de profil . chaque profil donner de manière clair le information relative au résumé de donnée correspondant . le lecture de le hiérarchie et du tableau être aussi grandement faciliter par le choix de un ordre optimal pour le présentation des variable et des résumé . 	Christophe Candillier, Noureddine Mouaddib	2005	@univ-nantes.fr, @univ-nantes.fr	1000369
735	Prise en compte des « Points de Vue » pour l'annotation d'un processus d'Extraction de Connaissances à partir de Données	prendre en compte des « point de Vue » pour le annotation de un processus de extraction de connaissance à partir de Données  dans ce article cln proposer un nouveau approche qui rendre expliciter le notion de point de vue dans un analyse multivues issue de un processus de extraction de connaissance à partir de Données ( ECD ) . par point de vue , cln entendre le vision particulier de un analyste lors de son processus ECD , vision référer à un corps de connaissance qui cld être spécifique . cln chercher , de un part , à faciliter le réutilisabilité et le adaptabilité du processus , et de autre part à garder un trace des point de vue sous-jacent aux analyse faire . le processus de ECD être voir comme un processus de génération et de transformation de vue qui être annoter par un métadonné pour garder le sémantique de le connaissance extraire . un positionnement de son approche vis-à-vis un travaux méthodologique du processus de ECD être donner . un élément de modélisation du processus ECD baser sur le point de vue être décrire au niveau ontologique . enfin , cln illustrer son approche sur le analyse des usages de un site web à partir un fichier logarithme , selon le point de vue fiabilité . 	Hicham Behja, Brigitte Trousse, Abdelaziz Marzak	2005	@inria.fr, @hotmail.com	1000263
736	Problématiques de gestion de connaissances dans le cadre de l'enseignement à distance sur l'Internet.	problématique de gestion de connaissance dans le cadre de le enseignement à distance sur le Internet .  le développement des réseau à haut-débit et de le Internet fournir un nouveau support à le enseignement à distance . Aujourd' hui , de nombreux acteur dans le domaine de le enseignement avoir mettre en place des dispositif de formation en ligne . celui -ci clr composer généralement de un sélection de matériaux organisé et présenter de manière à suivre un programme pédagogique particulier , de mécanisme de communication entre apprenant et enseignant , et de outil de suivi des apprenant . le plate-forme de enseignement à distance devenir de plus en plus générique , un nouveau modèle avoir être définir , standardiser ou normalis és , permettre le formalisation de méta-donné pédagogique ou tenter de évaluer le connaissance acquérir par le apprenant . en cld appuyer sur ce modèle , cln proposer de construire un base de connaissance , associer notamment le terme des domaine enseigner en relation à sémantique pédagogique . le exploitation de ce base de connaissance fournir un premier niveau de aide à le ingénierie pédagogique , en particulier lorsque le volume de contenu en ligne être important . un inférence mettre en jeu ce connaissance permettre alors un meilleur suivi du dispositif de enseignement . 	Romain Dailly, Christian Chervet, Rémi Lehn, Henri Briand	2005	@univ-nantes.fr	1000389
737	Raisonnement en gestion des compétences	raisonnement en gestion des compétence  cln cln intéresser au raisonnement sur le compétence des ressource humain pour simplifier son gestion . dans ce article , cln proposer un méthode de raisonnement pour le aide à le identification des compétence de un individu . un processus de knowledge-mining définir par analogie avec le extraction de règle de association en knowledge-mining être proposer afin de induire un base de règle à partir de un base de connaissance sur le domaine . de plus , un prototype avoir être développer pour expérimenter son approche sur un exemple académique . 	Emmanuel Blanchard, Mounira Harzallah, Henri Briand	2005	@univ-nantes.fr, @univ-nantes.fr	1000385
738	Réécriture de requêtes multimédias : approche basée sur l'usage d'une ontologie	réécriture de requête multimédia : approche baser sur le usage de un ontologie  cln proposer dans ce article un stratégie de réécriture de requête sur un donnée multimédia décrire moyennant le standard MPEG- 7 . ce standard clr baser sur XML schéma qui permettre de décrire le structure des donnée . cependant , aucun sémantique ne être assigner à ce structure . cln proposer de étendre ce standard de un ontologie permettre de exprimer le connaissance du domaine . ainsi , le ontologie être utiliser durant le indexation des donnée multimédia et le réécriture de requête . le but de le réécriture de requête être de transformer un requête initial en un ou plusieurs requête équivalent ou sémantiquement proche compte tenir des connaissance représenter dans le ontologie . 	Samira Hammiche, Salima Benbernou, Mohand-Said Hacid	2005	@univ-lyon1.fr	1000306
739	Règles de propagation pour la création d'ontologies d'annotation de ressources	règle de propagation pour le création de ontologie de annotation de ressource  le annotation clr distinguer de le indexation automatique par le utilisation de un ou plusieurs ontologie qui définir un domaine global de référence permettre de cadrer et de normaliser le annotation effectuer , par ailleurs un ressource annoter devoir le être non pas par un liste de mots clef , mais bien par un ou plusieurs ontologie . malheureusement , ilimp être peu réaliste de penser que le centaine de million de ressource mettre à disposition sur le Web pouvoir être annoter par son auteur . pour résoudre ce problème , son démarche consister à indexer le document en clr baser sur le ontologie global et ensuite propager le annotation en utiliser un document déjà annoter pour annoter un autre document référencer par celui -ci . le propagation des annotation suivre un règle que cln proposer dans ce article . le illustration être effectuer sur un corpus de livre dont le thème relever de le informatique . 	Lylia Abrouk, Pierre Pompidor, Danièle Hérin, Michel Sala	2005	@lirmm.fr	1000305
740	Réponses coopératives dans l'interrogation de documents RDF	réponse coopératif dans le interrogation de document RDF  le développement du Web Sémantique avoir conduire à le élaboration de standard pour le représentation des connaissance sur le Web . RDF , comme un de ce standard , être devenir un recommandation du W3C. même clr ilimp avoir être concevoir pour être interprétable par le homme et le machine ( encodage XML , triplet , graphe étiqueté ) , RDF ne avoir pas être fournir avec un service de interrogation et de raisonnement . le plupart des travaux concernant le interrogation de document RDF clr être concentrer sur le usage de technique issue de le programmation logique et sur un extension de SQL . cln porter un nouveau regard sur le technique de interrogation et de raisonnement sur le document RDF et cln montrer que le sémantique des terme OSF ( Order Sorted Features ) être compatible avec le représentation isomorphique ( triplet ) des proposition RDF . ce transformation permettre le ordonnancement des ressource en ontologie et , à travers ceci , un meilleur mécanisme de réponse ( par approximation et recouvrement ) aux interrogation de document RDF . 	Adrian Tanasescu, Mohand-Said Hacid	2005	@univ-lyon1.fr	1000307
741	Restructuration automatique de documents dans les corpus semi-structurés hétérogènes	restructuration automatique de document dans le corpus semi-structuré hétérogène  le interrogation de grand base de document semi-structuré ( type XML ) être un problème ouvert important . en effet , pour interroger un document dont le schéma être nouveau , un système devoir pouvoir être adapter le requête poser au document , soit adapter le document pour pouvoir cld appliquer le requête . cln cld positionner ici dans le cadre de le restructuration de document qui consister à transformer un document semi-structuré issir de divers source dans un schéma de médiation connaître . cln proposer un cadre statistique général à le problématique de le restructuration de document et détailler un instance de un modèle stochastique de document structurer appliquer à ce problématique . cln détailler enfin un ensemble de expérience effectuer sur le document du corpus INEX afin de mesurer le capacité de son modèle . 	Guillaume Wisniewski, Ludovic Denoyer, Patrick Gallinari	2005	@lip6.fr	1000260
742	Sélection de modèles par des méthodes à noyaux pour la classification de données séquentielles	sélection de modèle par un méthode à noyau pour le classification de donnée séquentiel  ce travail concerner le développement de méthode de classification discriminant pour un donnée séquentiel . quelque technique avoir être proposer pour étendre aux séquence le méthode discriminant , comme le machine à vecteur support , par nature plus adapté aux donnée en dimension fixe . cln permettre de classifier un séquence complet mais pas de réaliser le segmentation , qui consister à reconnaître le séquence de unité , phonème ou lettre par exemple , correspondre à un signal . en utiliser un correspondance donner  modèle cln transformer le problème de le apprentissage des modèle à partir de donnée par un problème de sélection de modèle , qui pouvoir être attaquer via un méthode du type machine à vecteur support . cln proposer et évaluer divers noyau pour cela et fournir un résultat expérimental pour deux problème de classification . 	Trinh Minh Tri Do, Thierry Artières, Patrick Gallinari	2005	@lip6.fr	1000236
743	Semi-supervised incremental clustering of categorical data	" le clustering semi-supervisé combiner le apprentissage superviser et non- superviser pour produire meilleur clustering . . dans le phase initial superviser de le algorithme , un échantillon de apprentissage être produire par sélection aléatoire . . cln supposer que le exemple de le échantillon de apprentissage être étiqueter par un attribut de classe . . Puis , un algorithme incrémentiel développer pour le donnée catégorique être utiliser pour produire un ensemble de cluster pur ( tel que le exemple de chaque cluster avoir le même étiquette ) , qui servir de " " seeding clusters " " pour le deuxième phase non- supervisé de le algorithme . . dans ce phase , le algorithme incrémentiel être appliquer aux donnée non étiqueté . . le qualité du clustering être évaluer par le index de Gini moyen des cluster . . le expérience démontrer que un très bon clustering pouvoir être obtenir avec un petit échantillon de apprentissage . " 	Dan A. Simovici, Natima Singla	2005	@cs.umb.edu, @cs.umb.edu	1000246
744	SEQTREE, un outil de fouille de données séquentielles par visualisation	SEQTREE , un outil de fouille de donnée séquentiel par visualisation  dans ce article , cln présenter un outil de visualisation de séquence modéliser par un arbre de suffixe probabiliste ( Prediction suffix trees - PST ) . ce type de arbre permettre de représenter un chaîne de Markov de ordre variable . dans différent application , ilimp clr être avérer plus efficace que un chaîne de Markov de ordre fixer avec un coût calculatoire moindre . pour ce raison , ilimp cld avoir paraître intéressant de exploiter le caractère arborescent de ce mode de représentation non seulement de un point de vue algorithmique , mais aussi de un point de vue visuel . 	Christine Largeron	2005		1000430
745	SSC : Statistical Subspace Clustering	ce article clr placer dans le cadre du subspace clustering , dont le problématique être double : identifier simultanément le cluster et le sous-espace spécifique dans lequel chacun être définir , et caractériser chaque cluster par un nombre minimal de dimension , permettre ainsi un présentation des résultat compréhensible par un expert du domaine de application . le méthode proposer jusque à présent pour ce tâche avoir le défaut de clr restreindre à un cadre numérique . le objectif de ce article être de proposer un algorithme de subspace clustering capable de traiter un donnée décrire à le fois par un attribut continu et des attribut catégoriel . cln présenter un méthode baser sur le algorithme classique EM mais opérer sur un modelé simplifier des donnée et suivre de un technique original de sélection de attribut pour ne garder que le dimension pertinent de chaque cluster . le expérimentation présenter ensuite , mener sur un base de donnée aussi bien artificiel que réel , montrer que son algorithme présent des résultat robuste en terme de qualité de le classification et de compréhensibilité des cluster obtenir . 	Laurent Candillier, Isabelle Tellier, Fabien Torre, Olivier Bousquet	2005	@univ-lille3.fr, @pertinence.com	1000241
746	SVM et visualisation pour la fouille de grands ensembles de données	SVM et visualisation pour le fouille de grand ensemble de donnée  cln présenter un algorithme de SVM et des méthode graphique pour le traitement de grand ensemble de donnée . pour pouvoir traiter de tel ensemble de donnée , cln utiliser un représentation des donnée de plus haut niveau ( sous forme symbolique ) . le algorithme de séparateur à vaste marge ( SVM ) être adapter pour pouvoir traiter ce nouveau type de donnée . cln construire un nouveau noyau RBF ( Radial Basis Function ) que le algorithme utiliser à le fois pour le classification , le régression et le détection de individu atypique dans un donnée de type intervalle . cln utiliser ensuite un méthode de visualisation interactif ( lui aussi adapté au cas des variable de type intervalle ) pour expliquer le résultat obtenir par le SVM . le méthode être évaluer sur un ensemble de donnée symbolique existant ou créer artificiellement . 	Thanh-Nghi Do, François Poulet	2005	@esiea-ouest.fr	1000372
747	TANAGRA : un logiciel gratuit pour l'enseignement et la recherche	tanagra : un logiciel gratuit pour le enseignement et le recherche  tanagra être un logiciel « open source » librement accessible sur le web , ilimp tenter de concilier deux type de utilisation . de un part , en proposer un interface suffisamment convivial , ilimp être accessible aux utilisateur non spécialiste qui vouloir effectuer un étude sur un donnée réel . de autre part , en définir un architecture simplifier à le extrême , le effort de développement porter sur le essentiel , à savoir le mise au point et le intégration de algorithme de fouille de donnée , le chercheur pouvoir ainsi mener un expérimentation sur le méthode . dans ce article , cln présenter le principal fonctionnalité du logiciel en essayer de cla positionner sur le échiquier des ( très ) nombreux logiciel diffuser actuellement . 	Ricco Rakotomalala	2005	@univ-lyon2.fr	1000435
748	Tendances dans les expressions de gènes :  application à l'analyse du transcriptome  de Plasmodium Falciparum	tendance dans le expression de gène : application à le analyse du transcriptome de Plasmodium Falciparum  le étude de le expression des gène être depuis quelque année révolutionner par le puce à ADN . le méthode habituellement mettre en oeuvre pour analyser ce donnée clr appuyer sur un algorithme de partitionnement , comme le clustering hiérarchique , et sur un hypothèse communément admettre qui associer à un ensemble de profil de expression similaire , un fonction identique . ce analyse étudier le ensemble des gène sans distinction . le approche que cln proposer deux catégorie de gène : connu ou putatif . pour chaque gène ne avoir pas un information rattaché , cln étudier son voisinage afin de cll trouver un motif fréquent ( itemsets ) . ensuite , le Analyse être guider par le interprétation biologique afin de faire émerger un propriété intéressant . un premier jeu de test sur Plasmodium Falciparum ( agent de le Malaria ) cln avoir permettre de mettre en évidence , en cld intéressant aux item relatif à le glycolyse , un transporteur de nucléoside qui intervenir au niveau énergétique dans le phase ring ( précoce ) du parasite . 	Philippe Collet, Vincent Derozier, Gérard Dray, François Trousset, Pascal Poncelet, Michel Crampes	2005	@ema.fr	1000411
749	Un automate pour la génération complète ou partielle des concepts du treillis de Galois	un automate pour le génération complet ou partiel des concept du treillis de Galois  " ce article clr situer dans le domaine de le analyse formel de concept et du treillis de concept ( treillis de Galois ) lequel être un cadre théorique intéressant pour le regroupement conceptuel des donnée et le génération des règle de association . . puisque le prospection de donnée ( data mining ) être utiliser comme support à le prise de décision par un analyste rarement intéresser par le liste exhaustif ( souvent très long ) des concept et des règle , le élaboration de un solution approximatif être dans le plupart des cas un compromis satisfaisant et relativement moins coûteux que un solution exhaustif . . dans ce article , cln proposer un approche appelé CIGA ( Closed Itemset Generation using an Automata ) de génération partiel ou complet de concept par le construction et le parcours de un automate à états fini . . le génération des concept permettre le identification des " " itemsets " " fermer fréquent , étape crucial pour le extraction des règle de association . " 	Ganaël Jatteau, Rokia Missaoui, Madenda Sarifuddin	2005	@uqo.ca	1000229
750	Un critère d'évaluation pour la sélection de variables	un critère de évaluation pour le sélection de variable  ce article aborder le problème de le sélection de variable dans le cadre de le classification superviser . le méthode de sélection reposer sur un algorithme de recherche et un critère de évaluation pour mesurer le pertinence des sous-ensemble potentiel de variable . cln présenter un nouveau critère de évaluation fonder sur un mesure de ambigüité . ce mesure être fonder sur un combinaison de étiquette représenter le degré de spécificité ou de appartenance aux classe en présence . le test mener sur un nombreux jeu de donnée réel et artificiel montrer que son méthode être capable de sélectionner le variable pertinent et de augmenter dans le plupart des cas le taux de bon classement . 	Dahbia Semani, Carl Frélicot, Pierre Courtellemont	2005	@univ-lr.fr	1000218
751	Un système d'aide à la navigation dans des hypermédias	un système de aide à le navigation dans un hypermédia  avec le développement de Internet et de application hypermédias , le construction et le exploitation de profil ou modèle des utilisateur devenir capital dans un nombreux domaine . pouvoir cibler un utilisateur de un hypermédia ou de un site web afin de cld proposer ce que ilimp attendre devenir essentiel , par exemple lorsque le cln vouloir cld présenter le produit que ilimp être le plus susceptible de acheter , ou bien plus généralement à chaque fois que le cln vouloir éviter de noyer le utilisateur dans un flot de information . cln présenter un système de aide à le navigation , intégrer un système de modélisation du comportement de navigation et un stratège qui mettre en oeuvre , en fonction du comportement détecter , un aide viser à recommander un lien particulier . 	Julien Blanchard, Bertrand Petitjean, Thierry Artières, Patrick Gallinari	2005	@lip6.fr	1000272
752	Une approche filtre pour la sélection de variables en apprentissage non supervisé	un approche filtre pour le sélection de variable en apprentissage non superviser  " le sélection de Variable ( SV ) constituer un technique efficace pour réduire le dimension des espace de apprentissage et clr avérer être un méthode essentiel pour le pré-traitement de donnée afin de supprimer le variable bruiter et-ou inutile . . peu de méthode de SV avoir être proposer dans le cadre de le apprentissage non superviser , et , le plupart de entre lui , être un méthode dire " " enveloppe " " nécessiter le utilisation de un algorithme de apprentissage pour évaluer le sous ensemble de variable . . or , le approche " " enveloppe " " être largement mal adapter à un utilisation lors de cas " " réel " " . . en effet , de un part ce méthode ne être pas indépendant vis à vis des algorithme de apprentissage non superviser qui nécessiter le plus souvent de fixer un certain nombre de paramètre ; ; mais surtout , ilimp ne exister pas un critère bien adapter à le évaluation de le qualité de apprentissage non superviser dans un sous espace différent . . cln proposer et évaluer dans ce papier un méthode " " filtre " " et donc indépendant des algorithme de apprentissage non superviser . . ce méthode clr appuyer sur deux indice permettre de évaluer le adéquation entre deux ensemble de variable ( entre deux sous espace ) . " 	Pierre-Emmanuel Jouve, Nicolas Nicoloyannis	2005	@univ-lyon2.fr, @univ-lyon2.fr	1000209
753	Une méthode d'évaluation de la pertinence des pages Web dans WebSum	un méthode de évaluation de le pertinence des page Web dans WebSum  dans ce article cln présenter un méthode de évaluation de le pertinence des page Web retourner par un moteur de recherche . 	Olfa Jenhani el Jed	2005	@irit.fr	1000312
754	Usage non classificatoire d'arbres de classification : enseignements d'une analyse de la participation féminine à l'emploi en Suisse	usage non classificatoire de arbre de classification : enseignement de un analyse de le participation féminin à le emploi en Suisse  ce article présenter un application en grandeur réel des arbre de classification dans un contexte non classificatoire . le arbre générer viser à mettre en lumière le différence régional dans le façon dont le femme décider de son participation au marché du travail . le accent être donc mettre sur le capacité descriptif plutôt que prédictif des arbre . le application porter sur un donnée relative à le participation féminin au marché du travail issu du recensement Suisse de le population de le an 2000 . ce vaste ensemble de donnée avoir être analyser en deux phase . un premier arbre exploratoire avoir mettre en évidence le nécessité de procéder à un étude séparer pour le non mère , le mère marié ou veuve , et le mère célibataire ou divorcé . cln cld limiter ici aux résultat de ce dernier groupe , pour lequel cln avoir générer un arbre séparer pour chacun des trois région linguistique principal . le arbre obtenir faire apparaître un différence culturel fondamental entre région . Du point de vue méthodologique , le principal difficulté de ce usage non classificatoire des arbre concerner son validation , puisque le taux de erreur de classification généralement retenir perdre tout son sens dans ce contexte . cln commenter ce aspect et illustrer le usage de alternatif plus pertinent et facilement calculable . 	Gilbert Ritschard, Pau Origoni, Fabio B. Losa	2005	@ti.ch, @ti.ch, @unige.ch	1000172
755	Utilisation des technologies XML pour la formalisation de l'ontologie de modèles e-business	utilisation des technologie XML pour le formalisation de le ontologie de modèle e-business  son travail de recherche consister à représenter le ontologie des modèle e-business e-BMO par le langage BM²L spécifier sur le base de un méta-modèle XML . BM²L être comparer à un autre langage de définition de ontologie à savoir , RDF ( S ) , DAML + OIL et OWL et ce , selon un framework établir sur le spécificité de ce ontologie . aussi , introduire cln un application Web e-BMH pour le conception et le exploitation des modèle e-business conformément à le ontologie . 	Rim Djedidi Hannachi, Sarra Ben Lagha, Mohamed Ben Ahmed	2005	@alinto.com, @unil.ch, @riadi.rnu.tn	1000311
756	Validation statistique des cartes de Kohonen en apprentissage supervisé	validation statistique des carte de Kohonen en apprentissage superviser  en apprentissage superviser , le prédiction de le classe être le but ultime . plus largement , cln attendre de un bon méthodologie de apprentissage que cln permettre un représentation des donnée susceptible de faciliter le navigation de le utilisateur dans le base de exemple et de aider au choix des exemple et des variable pertinent tout en assurer un pré-diction de qualité dont cln comprendre le ressort . différent travaux avoir montrer le aptitude des graphe de voisinage issir des prédicteur à fonder un tel méthodologie , ainsi le graphe des voisins relatif de Toussaint . cependant , le complexité de son construction , en O ( n3 ) , rester élever . dans le cas de donnée volumineux , cln proposer de substituer aux graphe de voisinage le carte de Kohonen construire sur le prédicteur . après un bref rappel du principe des carte de Kohonen en apprentissage non superviser , cln montrer comment celui -ci pouvoir fonder un stratégie de apprentissage optimiser . cln proposer ensuite de évaluer le qualité de ce stratégie par un statistique original qui être étroitement corréler au taux de erreur en généralisation . différent expérimentation montrer le faisabilité de ce approche . cln disposer alors de un critère fiable pour sélectionner le individu et le attribut pertinent . 	Elie Prudhomme, Stéphane Lallich	2005	@univ-lyon2.fr, @univ-lyon2.fr	1000217
757	Visualisation de la perception d'un site web par ses utilisateurs.	visualisation de le perception de un site web par son utilisateur .  cln proposer dans ce article un méthode de visualisation de le activité des utilisateur de un site web qui permettre de évaluer qualitativement le adéquation entre son architecture logique et le perception de celui -ci par le internaute . cln travailler sur le parcours des internaute sur le site étudier , après reconstruction de celui -ci grâce aux fichier log des serveur concerner . cln utiliser le structure logique des site étudier pour simplifier le représentation des parcours , en ne tenir pas compter de le ordre de visite des catégorie sémantique du site . le parcours simplifié être utiliser pour calculer un dissimilarité entre le catégorie sémantique qui être ensuite représenter dans un plan par Multi Dimensional Scaling . cln compléter ce visualisation de ensemble par un représentation de le arbre couvrir minimal des catégorie sémantique qui permettre de mieux appréhender certain interaction . cln illustrer le intérêt de le méthode en le appliquer au site de le INRIA . 	Fabrice Rossi, Yves Lechevallier, Aïcha El Golli	2005	@inria.fr	1000381
758	« La connaissance de la connaissance » : une réflexion sur la triangulation des analyses textuelles à partir d'un corpus spécialisé en gouvernance d'entreprise	« le connaissance de le connaissance » : un réflexion sur le triangulation des analyse textuel à partir de un corpus spécialiser en gouvernance de entreprise  suite à le survenue récent de scandale financier , le synthèse des idée mobilisable en gouvernance de entreprise sembler désormais essentiel si le cln vouloir sécuriser le investisseur . dans ce perspective , le présent projet de recherche consister à mettre en oeuvre un panel de outil de analyse de donnée textuel ( Alceste , Syntex , Tropes-Zoom  Decision Explorer , Wordmapper , Weblex ) afin de évaluer le moyens dont pouvoir disposer un analyste désireux de extraire un connaissance contenir dans un ensemble de article académique . le qualité de représentation du corpus dans son globalité être tout de abord tester . le étude être ensuite centrer sur le concept même de connaissance , mobiliser dans le théorie de le gouvernance des entreprise . le convergence et le complémentarité des approche méthodologique être alors expliciter . ilimp cll être de même pour ce qui concerner le capacité de extraction de un connaissance pertinent à partir un texte étudier . 	Stéphane Trébucq	2005	@u-bordeaux4.fr	1000274
759	A Galois connecion semantics-based approach for deriving generic bases of association rules	" le augmentation vertigineux de le taille des donnée ( textuel ou transactionnel ) être un défi constant pour le " " scalabilité " " des technique de extraction des connaissance . . dans ce papier , cln présenter un approche pour le dérivation des base générique de règle associatif . . le principal caract éristique de ce approche être le suivant . . de un part , le introduction de un structure de donnée appelé " " Trie-itemset " " pour le stockage de le relation en entrée . . de autre part , cln utiliser un méthode " " diviser pour régner " " pour réduire le coût de construction de structure partiellement ordonner , à partir desquelles le base générique de règle être directement extraire . " 	Sadok Ben Yahia, Narjes Doggaz, Yahya Slimani, Jihem Rezgui	2004	@fst.rnu.tn, @yahoo.fr	1001033
760	A metric approach to supervised discretization	cln présenter un nouveau approche à le discrétisation superviser des attribut continu qui clr servir de le espace métrique des partition de un ensemble finir . cln discuter deux nouveau idée fondamental : un généralisation des technique de discrétisation de Fayyad-Irani baser sur un distance sur un partition , dériver de le entropie généraliser de Daroczy , et un nouveau critère géométrique pour arrêter le algorithme de discrétisation . le arbre de décision résultant être plus petit , avoir moins de feuille , et montrer un niveau plus élevé de exactitude établir par le validation croisé stratifier . 	Dan A. Simovici, Richard Butterworth	2004	@cs.umb.edu, @cs.umb.edu	1000966
761	A robust method for partitioning the values of categorical attributes	dans le domaine de le apprentissage superviser , le méthode de groupage des modalité de un attribut symbolique permettre de construire un nouveau attribut synthétique conserver au maximum le valeur informationnel de le attribut initial et diminuer le nombre de modalité . cln proposer ici un généralisation de le algorithme de discrétisation Khiops pour le problème du groupage des modalité . le algorithme proposer permettre de contrôler avoir priorir le risque de sur-apprentissage et de améliorer significativement le robustesse des groupage produire . ce caractéristique de robustesse avoir être obtenir en étudier le statistique des variation du critère du Khi2 lors de regroupement de ligne de un tableau de contingence et en modéliser le comportement statistique de le algorithme Khiops . un expérimentation intensif avoir permettre de valider ce approche et avoir montrer que le méthode de groupage Khiops aboutir à un groupage performant , à le fois en terme de qualité prédictif et de faible nombre de groupe . 	Marc Boullé	2004	@francetelecom.com	1000950
762	Accélération de EM pour données qualitatives : études comparative de différentes versions	accélération de EM pour donnée qualitatif : étude comparatif de différent version  le algorithme EM être très populaire et très efficace pour le estimation de paramètre de un modèle de mélange . le inconvénient majeur de ce algorithme être le lenteur de son convergence . son application sur un tableau de grand taille pouvoir ainsi prendre énormément de temps . afin de remédier à ce problème , cln étudier ici le comportement de plusieurs variante connaître de EM , ainsi que un nouveau méthode . Celles -ci permettre de accélérer le convergence de le algorithme , tout en obtenir un résultat similaire à celui -ci . dans ce travail , cln clr concentrer sur le aspect classification . cln réaliser un étude comparatif entre le différent variante sur un donnée simulé et réel et proposer un stratégie de utilisation de son méthode qui clr avérer très efficace . 	Mohamed Nadif, François-Xavier Jollois	2004	@univ-metz.fr	1001019
763	Acquisition de données vs gestion de connaissances  patrimoniales : le cas des vestiges du théâtre antique d'Arles	acquisition de donnée vs gestion de connaissance patrimonial : le cas des vestige du théâtre antique de Arles  que? cll avoir te ilimp de commun aujourde hui entre le acquisition de donnée 3D , le gestion de information patrimonial , ou encore le modélisation tridimensionnel en temps réel ? bien peu , force être de cla constater , si ce ne être que le édifice patrimonial servir là souvent de terrain de expérimentation . pourtant , ilimp ne savoir être réduire à ce seul statut : ilimp être objet de connaissance dont le étude devoir bénéficier un différent jeu de technologie . son proposition , expérimenter sur un vestige du théâtre antique de Arles , place ce édifice au centre de un dispositif viser à intégrer , au sein de un système de information architectural 3D en devenir , le résultat de différent phase de son étude . un jeu de connaissance formaliser sur le édifice servir de dénominateur commun depuis le acquisition de donnée 3D jusque à le représentation dans un maquette temps réel pour le toile . ce maquette devenir outil de navigation dans le jeu de information et de savoir qui caractériser le édifice . 	Jean-Yves Blaise, Francesca De Domenico, Livio De Luca, Iwona Dudek	2004	@gamsau.map.archi.fr	1001149
764	Analyse d'information relationnelle par des graphes interactifs de grandes tailles	analyse de information relationnel par un graphe interactif de grand taille  le découverte de connaissance à partir un important masse de donnée hétérogène déboucher le plus souvent sur le analyse relationnel . le recherche de information stratégique clr appuyer en effet sur le lien fonctionnel et sémantique entre document , acteur , terminologie et concept de un domaine sans oublier le paramètre temps . un nombreux méthode être proposer pour identifier , analyser et visualiser le mécanisme mettre à jour : analyse relationnel , classification superviser et non superviser , analyse factoriel , analyse sémantique , carte , dendogramme , ... mais ce approche demander souvent un expertise non négligeable pour être comprendre et ne clr adresser donc pas aux non initié . par contre , le vue de un graphe mettre en relation un ou deux classe de élément interdépendant être directement assimilable par tout le monde . cln proposer donc un ensemble de visualisation interactif de graphe dont le manipulation devoir permettre un découverte de connaissance intuitif et baser sur un langage graphique naturel . cln illustrer son propos de nombreux exemple tirer de cas réel de analyse stratégique qui avoir permettre de évaluer ce approche sur un panel très large de donnée . 	Saïd Karouach, Bernard Dousset	2004	@irit.fr	1001086
765	Annotation automatique de documents XML	annotation automatique de document XML  cln proposer dans ce article un mécanisme automatique de annotation de document . ce mécanisme clr appuyer sur un opération de composition permettre de créer un nouveau document à partir de document existant et sur un algorithme permettre de inférer le annotation de un document composer à partir de annotation de son party . son modèle être illustrer par un étude de cas consacrer à le mise en commun de document pédagogique au format XML , dans un environnement coopératif de enseignement à distance . cln décrire un prototype permettre de annoter ce document , et de engendrer un description RDF contenir le annotation . 	Birahim Gueye, Philippe Rigaux, Nicolas Spyratos	2004	@lri.fr	1001138
766	Apprentissage incrémental des profils dans un système de filtrage d'information	apprentissage incrémental des profil dans un système de filtrage de information  ce article présenter un méthode de apprentissage des profil dans le système de filtrage de information . le processus de apprentissage être effectuer de un manière incrémental au fur et à mesure que le information être filtrer et juger par le utilisateur . un expérimentation effectuer sur un collection de test de référence TREC , montrer que le méthode permettre effectivement le amélioration des profil . 	Mohand Boughanem, Hamid Tebri, Mohamed Tmar	2004		1001123
767	Approche binaire pour la génération de fortes règles d'association	approche binaire pour le génération de fort règle de association  dans ce papier , cln proposer un nouveau méthode de extraction des règle de association dans un base de donnée relationnel baser sur le technologie des arbre de Peano ( Ptree ) . le structure de donnée utiliser pour représenter le base de donnée être un ensemble de Ptrees de base représenter chacun un vecteur binaire et tout ce Ptrees être stocker dans un fichier binaire . cln montrer que le structure Ptree combiné avec le technique de réduction appelé élagage par support minimum produire un règle de association fort et réduire considérablement le temps de construction de le association . en effet , son approche présent le avantage de ne pas effectuer un parcours coûteux de le base de donnée . ce approche avoir être tester à travers un prototype que cln avoir implémenter . le résultat expérimental montrer que le règle de association fort être générer dans un temps minimum comparativement à un autre travaux . 	Thabet Slimani, Boutheina Ben Yaghlane, Khaled Mellouli	2004	@issatm.rnu.tn, @ihec.rnu.tn, @ihec.rnu.tn	1001052
768	Approche innovante pour la recherche et l'extractin coopérative et dynamique d'informations sur Internet	approche innovant pour le recherche et le extractin coopératif et dynamique de information sur Internet  ilimp exister de nombreux technique qui permettre de classifier le document textuel en fonction de le intérêt de un utilisateur ( kNN , SVM , ... ) . malheureusement , le intégration de ce méthode dans le plate-forme de textmining être souvent très statique au cours du temps . le but de ce article être de présenter un plate-forme de textmining dans lequel le donnée hétérogène être représenter uniformément selon un formalisme XML  TEI et où le utilisateur pouvoir interagir sur le processus de récupération et de analyse de ce donnée . pour cela , le module de traitement être représenter par un agent fonctionner sur le plate-forme MadKit et le apprentissage clr faire par un méthode dériver de VSM et TFIDF utiliser un principe de liste noir pondérer permettre le reconnaissance de document indésirable . le dynamique de le plate-forme reposer principalement sur le possibilité de ajouter à le volée des agent de traitement et de pouvoir modifier le ordre et le paramètre de analyse des document . 	Xavier Denis, Gaële Simon, Nicolas Chanchevrier	2004	@operamail.com, @univ-lehavre.fr, @tiscali.fr	1001129
769	BELUGA : un outil pour l'analyse dynamique des connaissances de la littérature scientifique d'un domaine. Première application au cas des maladies à prions	beluga : un outil pour le analyse dynamique des connaissance de le littérature scientifique de un domaine . premier application au cas des maladie à prion  un projet ciblé sur le étude du domaine des maladie à prion à permis de formaliser un méthodologie commun , sociologique et informatique , de compréhension de son dynamique par le analyse thématique . cln avoir créer un plate forme de indexation de notice bibliographique dont le but être de extraire un association évoluer à travers des intervalle de temps . Beluga proposer un chaîne de traitement baser sur le indexation des document en unité de base : référence , auteur , terme simple et composé , organisme . le outil être fonder sur un double approche de apprentissage et de visualisation qui automatiser le processus de extraction de groupe de auteur et de terme , et permettre à le utilisateur de revenir aux donnée documentaire source . le analyse diachronique de corpus de document électronique cln permettre de analyser comment le terminologie être structurer en thématique émergent . 	Nicolas Turenne, Marc Barbier	2004	@jouy.inra.fr, @grignon.inra.fr	1001096
770	BooLoader : un chargeur efficace dédié aux bases de transactions denses	BooLoader : un chargeur efficace dédier aux base de transaction dense  cln cln intéresser à le représentation et au chargement de base de transaction en mémoire . pour cela , cln proposer de utiliser un format condensé fonder sur le diagramme de décision binaire et cln présenter un algorithme que cln avoir implanter en un système baptiser BooLoader , pour charger un base de transaction . cln donner également un résultat expérimental de son système sur un base épars et dense . 	Zahir Maazouzi, Ansaf Salleb-Aouissi, Christel Vrain	2004	@lifo.univ	1000898
771	Caractérisation de signatures complexes dans des familles de protéines distantes	caractérisation de signature complexe dans un famille de protéine distant  le identification de signature de protéine être un problème majeur pour le découverte de nouveau membre dans un famille de protéine connaître . le concept de signature qui permettre de caractériser ce famille être généralement baser sur le définition de motif commun . ilimp clr avérer que le famille de protéine connaître . le concept de signature qui permettre de caractériser ce famille être généralement baser sur le définition de motif commun . ilimp clr avérer que le famille distant être trop hétérogène pour que cln pouvoir identifier le région conserver à partir un algorithme classique de le bioinformatique . cln proposer un approche génétique pour le découverte de motif hiérarchique ; le algorithme suivre un démarche descendant en clr appuyer dans un premier phase sur le classe physico- chimique des acide aminé . le signature être ensuite définir par un séquence des motif ainsi obtenir . cln être extraire au moyen de un algorithme de découverte de itemsets séquentiel où le motif jouer le rôle de item . un dernier étape consister à fouiller dans ce base de itemsets pour ne cll retenir que un ensemble réduit de signature . plusieurs stratégie être proposer pour déterminer un ensemble optimal de signature qui respecter un contrainte de complétude , de cardinalité et de spécificité . cln appliquer son démarche sur le famille des cytokine . le analyse de le base de protéine SCOP avoir montrer que le groupe de signature que cln avoir extraire cible spécifiquement ce famille de intérêt . 	Jérôme Mikolajczak, Gérard Ramstein, Yannick Jacques	2004	@nantes.inserm.fr, @nantes.inserm.fr, @univ-nantes.fr	1001049
772	Caractérisation globale de l'exécution de jobs	caractérisation global de le exécution de job  le caractérisation global de le exécution de job passer par le exploitation de mesure recueillir sur le machine en production . afin de répondre à le problématique , ilimp être nécessaire de tenir compte des différent type de donnée , ainsi que de le dualité de le caractérisation : statique et dynamique . un solution technique répondre aux contrainte être proposer . cln reposer sur le utilisation de SVM afin de détecter un phase , et à un niveau supérieur , à un réseau bayésien afin de automatiser le analyse de modèle de Markov enrichir . celui -ci être introduire comme le base formel et synthétique de description du comportement du job , aussi bien sur un système batch , que parallèle . enfin , le résultat obtenir à le aide de un prototype être discuter . 	Fabrice Gadaud, Guillaume Duquesnay	2004	@cgg.com	1001161
773	Classer pour découvrir : une nouvelle méthode d'analyse du comportement de tous les utilisateurs d'un site Web	classer pour découvrir : un nouveau méthode de analyse du comportement de tout le utilisateur de un site Web  " le analyse du comportement des utilisateur de un site Web être un domaine riche et complexe . . le grand nombre de méthode de extraction de connaissance appliquer aux logs Web , ainsi que le diversité du type de ce méthode en être un preuve . . cependant , compter tenir de ce complexité , cln poser dans ce article le question suivant : : Est ilimp possible de combiner un méthode existant pour proposer un analyse qui tirer profit des résultat de plusieurs spécialité et extraire par exemple des comportement fréquent minoritaire ? ? son étude à donc porter sur un nouveau approche hybride ( issue de le classification neuronal et de le recherche de motif séquentiel ) viser à classer le navigation des utilisateur de un site ( à le aide de son résumé sémantique ) puis , pour chaque classe de navigation , de cll extraire le comportement fréquent . . son objectif être 1 ) de pallier le limite de le extraction de motif fréquent par rapport à le quantité de donnée à traiter et aussi par rapport à le qualité des résultat et 2 ) de pallier le limite de un premier méthode de analyse du comportement appelé " " diviser pour Découvrir " " , que cln avoir proposer en 2003 . . cln avoir mener un expérimentation sur le log HTTP des site INRIA . . le résultat obtenir confirmer le bien fonder de son approche voir à vis de le état de le article " 	Doru Tanasa, Brigitte Trousse, Florent Masseglia	2004		1001146
774	Contrôle du risque multiple pour la sélection de règles d'association significatives	contrôle du risque multiple pour le sélection de règle de association significatif  le algorithme de extraction de règle de association parcourir efficacement le treillis des itemsets pour constituer un base de règle admissible à un seuil de support et de confiance , mais donner un multitude de règle peu exploitable . cln suggérer de épurer un tel base en éliminer le règle non statistiquement significatif . le multitude de test pratiquer conduire mécaniquement à multiplier le règle sélectionner à tort . après avoir présenter un procédure issu de le biostatistique qui contrôler non pas le risque , mais le nombre de faux découverte , cln proposer BS  DF , un algorithme original fonder sur le bootstrat qui sélectionner le règle significatif en contrôler le nombre de faux découverte . un expérimentation montrer le efficacité de ce procédure . 	Elie Prudhomme, Stéphane Lallich, Olivier Teytaud	2004	@univ-lyon2.fr, @univ-lyon2.fr, @artelys.com	1001046
775	Découverte de régularités pour l'intégration de  données semi structurées	découverte de régularité pour le intégration de donnée semi structurer  ce article présenter le utilisation de un technique de fouille de donnée pour aider à le spécification de vue sur un source XML . son langage de vue permettre de intégrer un donnée XML provenir de source hétérogène . cependant , le définition de motif sur le source permettre de spécifier le donnée à extraire être souvent difficile , car le structure des donnée ne être pas toujours connaître . cln proposer de extraire le structure fréquent dans le donnée des source pour spécifier un motif pertinent à utiliser dans le spécification des vue . 	Pierre-Alain Laur, Xavier Baril	2004	@lirmm.fr	1001139
776	Étude de textes par leur image	étude de texte par son image  cln proposer un méthode automatique de comparaison de texte reposer sur un technique de transformation de un texte en un image de taille donner et le analyse à le aide des outil de le géométrie fractal . cln présenter un application à le étude de un corpus de 90 texte long . 	Hubert Marteau, Alexandre Lefevre, Nicole Vincent	2004	@univ-tours.fr, @univ-paris5.fr	1001095
777	Étude expérimentale de mesures de qualité de règles d'association	étude expérimental de mesure de qualité de règle de association  le validation des connaissance extraire de un processus de ECD par un expert métier nécessiter de filtrer ce connaissance . pour ce faire , un nombreux mesure avoir être proposer , chacun répondre à un besoin spécifique . ce mesure présenter un caractéristique varié et parfois contradictoire que ilimp convier alors de examiner . arguer du fait que le sélection des bon connaissance passer aussi par le utilisation de un ensemble de mesure adapté au contexte , cln présenter dans ce article un étude expérimental de différent mesure . ce étude être mettre en regard de un étude formel synthétiser le qualité des mesure . 	Benoît Vaillant, Philippe Lenca, Stéphane Lallich	2004	@enst	1001056
778	Extraction de processus fonctionnels en génétique des  microbes à partir de résumés MEDLINE	extraction de processus fonctionnel en génétique des microbe à partir de résumé MEDLINE  après le ère du décodage des génome , le biologiste être de plus en plus confronter à le intégration de myriade de connaissance parcellaire , stocker majoritairement sous forme textuel . cln montrer , à travers un exemple concret , que le conjonction de deux chaîne de traitement faire appel de façon modéré à le expertise humain offrir au biologiste un aide utile pour parcourir ce littérature , à partir de un structuration sans avoir priori de son corpus ; ilimp clr agir ici de résumé Medline indexer par le gène et protéine que cln citer , et que le algorithme structure ( sans superviseur ) en principal voie métabolique et de régulation présent dans le corpus choisi. 1 ) un chaîne de indexation par le nom de gène et protéine inclure un expert pour valider , 2 ) un environnement interactif de clustering thématique attribuer un valeur graduer de centralité dans chaque thème aux résumé comme aux nom , comme à tout autre variable illustratif ( autre terme bio. , MeSH , ... ) . 	Alain Lelu, Philippe Bessières, Alain Zasadzinski, Dominique Besagni	2004	@jouy.inra.fr, @jouy.inra.fr, @inist.fr, @inist.fr	1001107
779	Fonctionnement d'un Système Informatique d'Aide à la Décision (SIAD)	fonctionnement de un système informatique de aide à le Décision ( SIAD )  ce article présent le fonctionnement de un SIAD : alimentation , traitement des donnée qui cla alimenter , production des résultat , outil de consultation mettre à le disposition des utilisateur , exploitation éditorial . 	Michel Volle	2004	@volle.com	1000886
780	Fonctions d'oubli dans les entrpôts de données	fonction de oubli dans le entrpôt de donnée  le entrepôt de donnée stocker un quantité de donnée de plus en plus massif , en particulier du fait de le constitution de historique . cln proposer ici un solution pour éviter le saturation des entrepôt de donnée . cln définir un langage de spécification de fonction de oubli des donnée le plus ancien , permettre de déterminer ce qui devoir être présent dans le entrepôt de donnée à chaque instant . ce spécification de fonction de oubli clr traduire par un opération de résumé par agrégation , et par un opération de suppression des donnée ancien réaliser de façon mécanique à chaque pas de mise à jour . le communication présent tout de abord un description syntaxique du langage de spécification des fonction de oubli . le contrainte à vérifier pour assurer le cohérence du langage être ensuite décrire . enfin , cln proposer un structure de donnée adapté au stockage des donnée nécessaire à le gestion des fonction de oubli . 	Aliou Boly, Georges Hébrail, Marie-Luce Picard	2004	@enst.fr, @enst.fr, @edf.fr	1000891
781	Fouille dans la structure de documents XML	fouille dans le structure de document XML  le prolifération des document XML appeler un technique approprié pour extraire et exploiter le information contenir dans ce document . cln distinguer deux approche de fouille : xml Content Mining porter sur le contenu et xml Structure Lining qui avoir trait à le structure des document . combiner ce deu approche être très intéressant . le information contenir dans le structure orienter le fouille sur le contenu . cln présenter le premier étape de ce démarche : un nouveau méthode de extraction des règle de association à partir de le structure des document XML qui permettre de gérer le aspect hiérarchique de ce document tout en améliorer le mécanisme de extraction grâce à le création de un structure spécial représenter le hiérarchie des balise rencontrer . 	Amandine Duffoux, Omar Boussaid, Stéphane Lallich, Fadila Bentayeb	2004	@univ-lyon2.fr	1001134
782	Fouille de grands ensembles de données avec un boosting proximal SVM	fouille de grand ensemble de donnée avec un boosting proximal SVM  le SVM ( support vector machine ) avoir montrer son efficacité dans plusieurs domaine de application . le apprentissage des SVM clr ramener à résoudre un programme quadratique , dont le mise en oeuvre être en général coûteux en temps . un reformulation plus récent des SVM ( proximal SVM ) , proposer par Fung et Mangasarian , ne nécessiter que le résolution de un système linéaire , ce algorithme de PSVM être plus efficace et permettre de traiter un donnée dont le nombre de individu être très important ( 109 ) et le nombre de attribut plus restreint ( 104 ) . cln proposer de utiliser le formule de Sherman-Morrison-Woodbury pour adapter le PSVM à le fouille de ensemble de donnée dont le nombre de attribut être très important et le nombre de individu plus restreindre sur un matériel standard . puis cln présenter un algorithme de boosting de PSVM pour classifier un donnée de très grand taille en nombre de individu et de attribut . cln évaluer le performance du nouveau algorithme sur le ensemble de donnée de le UCI , Twonorm , Ringnorm , Reuters- 21578 et Ndc . 	Thanh-Nghi Do, François Poulet	2004	@esiea-ouest.fr	1001011
783	Identification de blocs homogènes sur des données continues	identification de bloc homogène sur un donnée continu  contrairement aux méthode usuel de classification ne chercher généralement que un seul partition , soit un instance , soit un attribut , le méthode de classification croisé et de classification direct fournir un bloc de donnée liant des instance à un attribut . le premier consister à chercher simultanément un partition en ligne et un partition en colonne . le seconde , lui , clr appliquer directement sur le donnée , et permettre de obtenir un bloc de donnée homogène de tout taille , ainsi que un hiérarchie de classe en ligne et en colonne . combiner le avantage des deu méthode , cln présenter ici un méthodologie permettre de travailler sur un grand base de donnée . 	François-Xavier Jollois, Mohamed Nadif	2004	@univ-metz.fr	1001015
784	Induction extensionnelle : définition et application à l'acquisition de concepts à partir de textes	induction extensionnel : définition et application à le acquisition de concept à partir de texte  " lorsque des outil inductif être inclure dans un système de acquisition des connaissance , cln dire que le cln construire un système apprenti . . ce être dans le but de soulager le charge de travail de le expert du domaine que ce forme de apprentissage comporter un outil inductif . . le difficulté tenir en ce que le énumération des connaissance expert produire un donnée peu bruiter mais très incomplet que le itération successif de induction aller compléter , toutefois en cll ajouter un grand quantité de bruit . . ilimp cll résulter que cln devoir utiliser un procédure inductif spécial , adapté à le apprentissage par croissance de noyau de connaissance supervisé . . en particulier , pour résoudre le problème difficile de le reconnaissance de concept dans le texte , cln avoir définir un forme de apprentissage qui intégrer le apprentissage à partir de instance et le système apprenti , que cln nommer " " Induction Extensionnelle " " , un oxymoron qui souligner que malgré le absence de création de un modèle expliciter , un induction prendre effectivement place . " 	Yves Kodratoff	2004	@lri.fr	1001017
785	Intégration efficace de méthodes  de fouille de données dans les SGBD	intégration efficace de méthode de fouille de donnée dans le SGBD  ce article présenter un nouveau approche permettre de appliquer un algorithme de fouille , en particulier de apprentissage superviser , à un grand base de donnée et en un temps de traitement acceptable . ce objectif être atteindre en intégrer ce algorithme dans un SGBD . ainsi , cln ne être limiter que par le taille du disque et plus par celui de le mémoire . cependant , le entrées-sortie nécessaire pour accéder à le base engendrer un temps de traitement long . cln proposer donc dans ce article un méthode original pour réduire le taille de le base de apprentissage en construire son table de contingence . le algorithme de apprentissage être alors adapter pour clr appliquer à le table de contingence . afin de valider son approche , cln avoir implémenter le méthode de construction de arbre de décision ID3 et montrer que le utilisation de le table de contingence permettre de obtenir un temps de traitement équivalent à celui des logiciel classique . 	Cédric Udréa, Fadila Bentayeb, Jérôme Darmont, Omar Boussaid	2004	@univ-lyon2.fr	1000899
786	Interrogation de sources biomédicales : prise en compte des préférences de l'utilisateur	interrogation de source biomédical : prise en compte des préférence de le utilisateur  cln cln placer dans le cadre de un projet de constitution de un plate-forme intégratif de donnée biomédical pour le étude génomique des cancer . le plate-forme comporter , entre autre , un certain nombre de scénario de analyse qui être proposer à le utilisateur . A chaque étape de un scénario que ilimp avoir choisir de réaliser pour le besoin de son étude , le utilisateur pouvoir être amener à poser un requête nécessiter de accéder à différent source et ilimp devoir alors choisir le source pertinent . cln proposer un guide à le utilisateur sous forme de un algorithme de sélection de source adapter à son requête et à son préférence . pour cela , cln explorer quelque spécificité des banque de donnée biomédical et définir différent critère de préférence utile pour le biologiste . cln illustrer son démarche avec un exemple de requête biomédical . 	Sarah Cohen Boulakia, Christine Froidevaux, Séverine Lair	2004	@lri.fr, @curie.fr	1000893
787	Maintenance de bases de connaissances terminologiques	maintenance de base de connaissance terminologique  le acquisition des connaissance terminologique de le entreprise clr faire souvent à partir un texte que cln utiliser . dans le cadre de ce travail , le base de connaissance terminologique reposer sur le modélisation des concepts-métier sous le forme de un ontologie . le problème de le maintenance de ce base et de ce ontologie devoir alors être traiter . dans ce article , après avoir donner un définition de un base de connaissance terminologique ( BCT ) et des problème de diachronie , cln présenter son modèle et son méthode de acquisition des connaissance terminologique de le entreprise . cln exposer alors son proposition pour maintenir au cours du temps le base de connaissance terminologique ainsi construire . cln illustrer ce travail sur un base de connaissance terminologique sur le cinéma de animation en décrire le problème de le maintenance dans un reconstitution historique de différent états de ce base lors de le apparition des technique numérique de animation . 	Daniel Beauchêne, Christophe Roche, Cécile Million-Rousseau	2004	@univ-savoi, @univ-savoi, @ontologos-corp.com	1000910
788	Mediating the Semantic Web	ce article développer un extension de un architecture de médiation pour intégrer le Web sémantique . plus précisément , XLive être un médiateur tout XML développer à PRiSM . ilimp permettre de exécuter un XQuery sur un source de donnée hétérogène . après un rapide présentation de XLive et du Web sémantique , un architecture à trois niveau de ontologie et de schéma être introduire pour connecter un adaptateur pour le Web sémantique . ce architecture viser à intégrer un source de type Web service de information conformément à un ontologie global de référence . cln conduire à étendre XLive avec le support de vue , un outil de conception de vue et de mapping , et des adaptateur pour le Web service . 	Georges Gardarin, Tuyet-Tram Dang-Ngoc	2004	@gardarin.org, @prism.uvsq.fr	1000883
789	Mesurer la qualité des règles et de leurs contraposées avec le taux informationnel TIC	mesurer le qualité des règle et de son contraposé avec le taux informationnel TIC  le validation des connaissance être le un des étape le plus problématique de un processus de découverte de règle de association . pour que le décideur ( expert des donnée ) pouvoir trouver un connaissance intéressant dans le grand quantité de règle produire par le algorithme de fouille de donnée , ilimp être nécessaire de mesurer le qualité des règle . cln insérer dans le cadre de le analyse statistique implicatif , cln proposer dans ce article de évaluer le règle en considérer son contenu informationnel à travers un nouveau indice de qualité fonder sur le entropie de Shannon : tic ( taux Informationnel moduler par le Contraposée ) . ce indice avoir le avantage de être bien adapter à le sémantique des règle , puisque de un part ilimp respecter son caractère asymétrique et de autre part ilimp tirer profit de son contraposé . par ailleurs , ce être à son connaissance le seul mesure de qualité de règle qui intégrer à le fois indépendance et déséquilibre , ce est-à-direr qui permettre de rejeter simultanément le règle entre variable corréler négativement et le règle qui posséder plus de contre-exemple que de exemple . un comparaison de TIC avec le J-mesure , le information mutuel , le indice de Gini , et le confiance être réaliser sur un simulation numérique . 	Julien Blanchard, Fabrice Guillet, Régis Gras, Henri Briand	2004	@univ-nantes.fr	1001035
790	Mesurer les usages d'internet	mesurer le usages de internet  cln rendre compter de un démarche mettre en place pour construire un représentation fin des usages de internet et de son évolution , en procéder à du traitement secondaire de donnée de trafic , provenir de panel représentatif de internaute . après avoir présenter le caractéristique des cohorte étudier et le différent mode de enrichissement des donnée de trafic mettre en place , cln présenter quelque résultat construire à partir de ce donnée enrichi , et en particulier un segmentation des internaute construire sur le base de le entrelacement des pratique de communication et de navigation . 	Valérie Beaudouin	2004	@francetelecom.com	1000887
791	Mise en oeuvre des méthodes de fouille de données spatiales alternatives et performances	mise en oeuvre des méthode de fouille de donnée spatial alternatif et performance  le fouille de donnée spatial nécessiter le analyse des interaction dans le espace . ce interaction pouvoir être matérialiser dans un table de distance , ramener ainsi le fouille de donnée spatial à le analyse multitable . or , le méthode de fouille de donnée traditionnel considérer un seul table en entrée où chaque tuple être un observation à analyser . un simple jointure entre ce table ne résoudre pas le problème et fausser le résultat en raison du comptage multiple des observation . cln proposer trois alternatif de fouille de donnée multi-table dans le cadre de le fouille des donnée spatial . le premier consister à interroger à le volée le différent table et modifier en dur le algorithme existant . le seconde être un optimisation de le premier qui pré-calculer le jointure et adapter le algorithme existant . le troisième réorganiser le donnée dans un table unique en compléter - et non en joindre -le table de analyse par le donnée présent dans le autre table , ensuite appliquer un algorithme standard sans modification . ce article présent ce trois alternatif . ilimp décrire son implémentation pour le classification supervisé et comparer son performance . 	Nadjim Chelghoum, Karine Zeitouni	2004	@prism.uvsq.fr, @prism.uvsq.fr	1001003
792	Modèle de gestion intégrée des compétences et connaissances	modèle de gestion intégré des compétence et connaissance  le compétence et le connaissance être deux concept qui cld sembler fortement conjoindre , cependant , cln être rarement étudier et gérer ensemble . cln chercher donc à identifier le lien et frontière qui pouvoir exister entre lui . ceci avoir pour objectif de développer un modèle de représentation et de gestion , intégrer aux connaissance et aux compétence . dans ce article , être tout de abord présenter , un synthèse sur le concept de compétence et de connaissance . ensuite , le modèle et outil de gestion de ce concept être exposer . Puis , le modèle CKIM ( Competency and Knowledge Integrated Model ) développer , être définir . le utilité de ce modèle et son exploitation être discuter en quatrième partie . le dernier partie représenter un prototype de implantation du modèle CKIM réaliser sur le serveur de connaissance ATHANOR . 	Nathalie Vergnaud, Mounira Harzallah, Henri Briand	2004	@univ-nantes.fr	1000915
793	Modèle topologique pour l'interrogation des bases d'images	modèle topologique pour le interrogation des base de image  cln proposer dans ce article un modèle topologique de représentation de base de image . chaque image être représenter à le aide de un vecteur de caractéristique dans R^p et figurer comme noeud dans un graphe de voisinage . le exploration du graphe correspondre à le navigation dans le base de donnée , le voisins de un noeud représenter un image similaire . afin de pouvoir traiter un requête , cln définir un modèle topologique . le image requêter être représenter par un vecteur de caractéristique dans R^p et insérer dans le graphe en mettre à jour localement le relation de voisinage . ce travail clr positionner dans le domaine de le fouille de donnée complexe . 	Mihaela Scuturici, Jérémy Clech, Vasile-Marian Scuturici, Djamel Abdelkader Zighed	2004	@univ-lyon2.fr	1001092
794	Modélisation dynamique et temporelle de l'utilisateur pour un filtrage personnalisé de documents textuels	modélisation dynamique et temporel de le utilisateur pour un filtrage personnaliser de document textuel  le apprentissage efficace du profil utilisateur être un challenge car ilimp évoluer sans cesse . dans ce article cln proposer un nouveau approche pour le apprentissage du profil long-terme de le utilisateur pour le filtrage de document textuel . dans ce cadre , le document consulter être classer de manière dynamique et cln analyser le répartition dans le temps des classe de document afin de déterminer le mieux possible le classe de intérêt de le utilisateur . le étude empirique confirmer le pertinence de son approche pour un meilleur personnalisation de document . 	Rachid Arezki, Abdenour Mokrane, Pascal Poncelet, Gérard Dray, David William Pearson	2004	@ema.fr	1001122
795	MUSETTE : a framework for knowledge capture from experience	cln présenter dans ce article un nouveau approche de modélisation de le expérience de utilisation de un système informatique , avec pour objectif de réutiliser ce expérience en contexte pour assister le utilisateur à effectuer son tâche . Quatre scénario illustrer ce approche . 	Pierre-Antoine Champin, Yannick Prié, Alain Mille	2004	@liris.cnrs.fr	1000912
796	OpAC : Opérateur d'analyse en ligne basé sur une technique de fouilles de données	OpAC : opérateur de analyse en ligne baser sur un technique de fouille de donnée  le analyse en ligne OLAP ( On-Line Analysis Processing ) et le fouille de donnée ( Data Mining ) être deux champs de recherche qui avoir connaître , depuis quelque année , un évolution parallèle et indépendant . un récent étude avoir montrer le importance et le intérêt de le association entre ce deu domaine scientifique . A le heure actuel , cln assister à le accroissement du besoin de un analyse en ligne plus élaboré . cln penser que le couplage entre OLAP et le fouille de donnée pouvoir apporter un réponse à ce besoin . dans ce article , cln proposer de adopter ce couplage en vue de créer un nouveau opérateur , baptiser OpAC ( opérateur de agrégation par classification ) , de analyse en ligne des donnée multidimensionnel . OpAC consister particulièrement en le agrégation sémantique des modalité de un dimension de un cube de donnée en clr baser sur le technique de le classification ascendant hiérarchique . 	Riadh Ben Messaoud, Sabine Rabaseda, Omar Boussaid, Fadila Bentayeb	2004	@univ-lyon2.fr	1000889
797	Outil de représentation des évolutions de communautés d'intérêts	outil de représentation des évolution de communauté de intérêt  ce article présenter un système de visualisation permettre le observation des comportement collectif implicite . ilimp clr agir de reconnaître et de représenter un communauté à partir un connexion Internet des utilisateur : le utilisateur être répartir en communauté en fonction des similarité entre un liste de terme établir sur le analyse des document consulter par chacun de lui . le étude être rendre dynamique par le comparaison des communauté reconnaître sur un période de temps connexe . le outil décrire ci après offre deu représentation différent de ce communauté : un vision des liaison thématique entre le utilisateur sur chaque période étudier et un vue comparatif des communauté reconnaître sur tout le durée de le étude . 	Anne Lavallard, Luigi Lancieri	2004	@francetelecom.com, @francetelecom.com	1001140
798	PoBOC : un algorithme de 	PoBOC : un algorithme de  " cln décrire le algorithme PoBOC ( Pole-Based Overlapping Clustering ) qui générer un ensemble de cluster non- disjoint ( ou " " softclusters " " ) présenter sous forme de un hiérarchie de concept à partir de le seul matrice de similarité sur le donnée considérer . . cln évaluer le approche sur deux situation de apprentissage : le classification par apprentissage de règle et le organisation de donnée plus complexe et peu structurer tel que le donnée textuel . . le validation des méthode de clustering être un étape difficile résoudre le plus souvent par un évaluation de expert . . le deu application proposer permettre de valider le méthode de organisation selon deux point de vue : de un part quantitativement en évaluer le influence de le méthode pour le classification , de autre part en permettre un analyse " " humain " " du résultat dans le cas des donnée textuel . . cln mettre en évidence le intérêt de PoBOC comparativement à un autre approche de apprentissage non- superviser . " 	Guillaume Cleuziou, Lionel Martin, Christel Vrain	2004	@lifo.univ	1001007
799	Recherche ciblée de documents sur le web	recherche ciblé de document sur le web  le langage de requête mots -clé pour le web manquer souvent de précision lorsque ilimp clr agir de rechercher un document particulier difficilement caractérisable par un simple mots -clé ( exemple : des cours java ou des photo de formule 1 ) . cln proposer un langage multi-critère de type attribut-valeur pour augmenter le précision de le recherche de document sur le web . cln avoir expérimentalement montrer le gain de précision de le recherche de document baser sur ce langage . 	Amar-Djalil Mezaour	2004	@lri.fr	1001124
800	Recherche dans de grandes bases d'images fixes : une nouvelle approche guidée par les règles d'association	recherche dans un grand base de image fixe : un nouveau approche guider par le règle de association  " un base de image fixe pouvoir être décrire de plusieurs façon , notamment par un descripteur visuel global de couleur , de texture , ou de forme . . le requête le plus fréquent impliquer et combiner le résultat de plusieurs type de descripteur : par exemple , " " retrouver tout le image avoir un couleur et un texture semblable à celui de un image requête donner " " . . pour retrouver plus efficacement et plus rapidement un image dans un grand base , cln exploiter un combinaison approprié de descripteur et étudier le intérêt des règle de association entre cluster de descripteur pour accélérer le temps de réponse à un requête sur un grand base de image fixe . " 	Anicet Kouomou Choupo, Annie Morin, Laure Berti-Equille	2004	@irisa.fr	1000895
801	Recherche de règles d'association hiérarchiques par une approche anthropocentrée	recherche de règle de association hiérarchique par un approche anthropocentré  le extraction de connaissance dans le base de Données être devenir , pour le banque , un alternatif au problème lier à le quantité de donnée qui être stocker et qui ne cesser de augmenter . ceci aboutir à un paradoxe puisque ilimp falloir mieux cibler le clientèle susceptible de être intéresser par un offre en utiliser un méthode qui ne permettre plus de traiter le nombre croissant de enregistrement des base de donnée . son travaux clr situer dans le continuité de un étude que cln avoir réaliser sur le recherche de règle de association appliquer au marketing bancaire . en effet , un premier résultat encourageant cln avoir conduire à approfondir son travaux vers un recherche de règle de association hiérarchique utiliser non plus un approche automatique mais un approche anthropocentré . ilimp clr agir de un approche dans lequel le expert faire partie intégrant du processus en jouer le rôle de heuristique évolutif . ce article présenter le résultat de son démarche de recherche . 	Olivier Couturier, Engelbert Mephu Nguifo, Brigitte Noiret	2004	@cepdc.caisse-epargne.fr	1001154
802	Réduction du coût d'évaluation d'une règle relationnelle	réduction du coût de évaluation de un règle relationnel  un nombreux tâche en fouille de Données viser à extraire un connaissance exprimer sous le forme de un ensemble de règle . le algorithme dédier à ce tâche engendrer un règle dont le adéquation aux donnée devoir être évaluer . cln clr placer dans le cadre où ce évaluation être réaliser directement en lancer un requête de dénombrement sur le base de donnée , et où ce base être relationnel . le requête compter le donnée qui clr apparier avec le règle , calcul qui pouvoir être extrêmement coûteux . dans ce article , cln étudier le impact de un approche de échantillonnage viser à réduire le coût de le évaluation des règle relationnel en tenir compte des spécificité structurel des requête induire . 	Agnès Braud, Teddy Turmeaux	2004	@fct.unl.pt, @lifo.univ	1001039
803	Règles d'identification et méthodes de visualisation d'objets architecturaux	règle de identification et méthode de visualisation de objet architectural  dans le étude du patrimoine bâti , le gestion de information poser aujourde hui un problème de interfaçage non trivial , notamment par le masse , le diversité , le complexité et le caractère hétérogène des contenu . le représentation tridimensionnel du tissu urbain à différent échelle ( de le ville au corpus architectural ) , parce que cln localiser spatialement le information à délivrer et le attache à le morphologie de le édifice , apparaître comme un des réponse possible . ce réponse sembler par ailleurs bien adapter aux problématique spécifique de le analyse architectural du patrimoine que être par exemple le restitution de édifice disparaître ( et le notion de incertitude qui clr cll attacher ) ou le réemploi de élément de corpus . pourtant , le représentation tridimensionnel dans son champagne de application être aujourde hui loin de remplir ce rôle . son contribution viser à discuter quelque un des pré-requis qui cld sembler clr imposer à le lumière de son expérience pour faire de le maquette 3D un outil de investigation des connaissance sur le édifice . 	Iwona Dudek, Jean-Yves Blaise	2004	@gamsau.map.archi.fr	1001157
804	Régression linéaire symbolique avec variables taxonomiques	régression linéaire symbolique avec variable taxonomique  le présent papier concerner le extension des méthode classique de régression linéaire aux cas des donnée symbolique et faire suite à un précédent travaux de Billard et Diday sur le régression linéaire avec variable intervalle et histogramme . dans ce papier , cln présenter un méthode de régression avec variable taxonomique . le variable taxonomique être un variable organiser en arbre exprimer plusieurs niveau de généralité ( le ville être regrouper en région qui être lui-même regrouper en pays ) . le méthode proposer être tester sur donnée simulé . finalement , cln observer que ce méthode cld permettre de utiliser le régression linéaire pour étudier un concept et pour réduire le nombre de donnée afin de améliorer le résultat obtenir par rapport à un régression classique . 	Filipe Afonso, Lynne Billard, Edwin Diday	2004	@ceremade.dauphine.fr, @ceremade.dauphine.fr, @stat.uga.edu	1001000
805	Relations entre gènes impliqués dans les cancers de la thyroïde	relation entre gène impliquer dans le cancer de le thyroïde  un relation entre gène et protéine impliquer dans le cancer de le thyroïde avoir être mettre en évidence par le analyse de un important corpus de résumé de le base de donnée bibliographique Medline . un approche pluridisciplinaire ( biologiste , clinicien , linguiste et chercheur en science de le information ) avoir permettre le indexation automatique et le analyse de ce corpus . le indexation contrôler , structurer en classe sémantique , à partir un vaste ressource hétérogène ( le base biomédical et génétique UMLS et LocusLink ) , prendre en compte le spécificité des terme : nomenclature biochimique , acronyme de gène , aberration chromosomique ou encore variante linguistique de terme . le deu méthode de classification complémentaire appliquer révéler un réseau lexical dense de gène concurrent autour de trois principal pathologie de le thyroïde : le cancer médullaire , papillaire et des dysfonctionnement du système immunitaire . le développement apporter aux outil de visualisation interactif du serveur VISA de le INIST faciliter lecture et navigation au sein des document . 	Jean Royauté, Claire François, Alain Zasadzinski, Dominique Besagni, Philippe Dessen, Sylvaine Le Minor, Marie-Thérèse Maunoury	2004	@lif.univ-mrs.fr, @inist.fr, @igr.fr	1001119
806	Représentation condensée de motifs émergents	représentation condenser de motif émergent  le motif émergent être un association de caractéristique fortement présent dans un classe et rare dans le autre . cln faire ressortir le distinction entre classe et clr révéler particulièrement efficace pour construire un classifieur et apporter un aide au diagnostic . à cause de le fort combinatoire du problème , le recherche et le représentation des motif émergent rester un tâche complexe pour un grand base de donnée . cln proposer ici un représentation condensé exact des motif émergent ( i.e. , le motif et son taux de croissance être directement obtenir depuis le représentation condensé ) . le idée principal être de clr appuyer sur le récent résultat relatif aux représentation condenser de motif fermé fréquent . à partir de ce représentation , cln donner aussi un méthode aisé à mettre en oeuvre pour obtenir le motif émergent avoir le meilleur taux de croissance . ce motif , appelé motif émergent fort , avoir être exploiter avec succès dans un collaboration avec le société Philips . 	Arnaud Soulet, Bruno Crémilleux, François Rioult	2004	@unicaen.fr	1001022
807	Représentation de graphes par ACP granulaire	représentation de graphe par ACP granulaire  " le extraction de information de grand graphe reposer le plus souvent sur son représentation dans un espace de dimension réduit et cln utiliser généralement un méthode factoriel appliquer à un mesure de dissimilarité calculer à partir un matrice associer du graphe ou le analyse spectral de son Laplacien discret . . Efficaces pour dégager le structure global , ce représentation être parfois peu exploitable dès lors que le cln clr intéresser à un perspective du graphe à partir de certain sommet privilégié . . or le information rechercher avoir souvent un caractère " " local " " . . pour représenter le graphe du point de vue de un ou plusieurs sommet sélectionner , cln proposer un méthode de Analyse en Composantes Principales " " granulaire " " consister à appliquer un A.C.P. " " filtrer " " à un tableau de proximité . . le visualisation de un graphe de dictionnaire dont le mesure de proximité être obtenir à partir de un algorithme original illustrer son propos . " 	Bruno Gaume, Louis Ferré	2004		1001083
808	Résumé de cubes de données multidimensionnelles à l'aide de règles floues	résumer de cube de donnée multidimensionnel à le aide de règle flou  dans le contexte des entrepôt de donnée , et des magasin de donnée multidimensionnel , le outil OLAP fournir un moyens aux utilisateur de naviguer dans son donnée afin de cll découvrir un information pertinent . cependant , le donnée à traiter son souvent très volumineux et ne permettre pas un exploration systématique et exhaustif . ilimp clr agir donc de développer un traitement automatiser faciliter le visualisation et le navigation dans le donnée . dans ce article , cln étudier un méthode original permettre de construire et de identifier de manière automatique et efficace des bloc de donnée similaire présent dans le cube de donnée pouvoir être exprimer sous le forme de règle . ce méthode être fonder sur le utilisation combiné de un algorithme par niveau ( de type Apriori ) et de le théorie des sous-ensemble flou . ce théorie cld permettre en effet de pallier le problème poser par le fait que le bloc de donnée calculer par son algorithme pouvoir clr recouvrir . 	Yeow Wei Choong, Anne Laurent, Dominique Laurent, Pierre Maussion	2004	@help.edu.my, @help.edu.my, @lirmm.fr, @dept-info.u	1000904
809	Sélection rapide en apprentissage supervisé	sélection rapide en apprentissage superviser  le sélection de variable ( SdV ) permettre de réduire le espace de représentation des donnée . ce processus être de plus en plus critique en raison de le augmentation de le taille des base de donnée . traditionnellement , le méthode de SdV nécessiter plusieurs accès au jeu de donnée , ce qui pouvoir représenter un part relativement important du temps de exécution de ce algorithme . cln proposer un nouveau méthode efficient et rapide ( ne nécessiter que un unique accès aux donnée ) . ce méthode utiliser le algorithme génétique ainsi que un mesure de validité de classification non supervisé ( cnute ) . 	Nicolas Nicoloyannis, Gaëlle Legrand, Pierre-Emmanuel Jouve	2004	@univ-lyon2.fr, @univ-lyon2.fr	1000953
810	Sous-ensembles flous définis sur une ontologie	sous-ensemble flou définir sur un ontologie  " le sous-ensemble flou pouvoir être utiliser pour représenter un valeur imprécis , comme un intervalle aux limite mal définir . . cln pouvoir également servir à le expression de préférence dans le critère de sélection de requête en base de donnée . . en représentation des connaissance , le utilisation de hiérarchie de type être largement répandu afin de modéliser le relation existant entre le type de objet de un domaine donné . . cln cln intéresser aux sous-ensemble flou dont le domaine de définition être un hiérarchie de élément partiellement ordonner par le relation " " sorte de " " , que cln appeler ontologie . . cln introduire le notion de sous-ensemble flou définir sur un partie de le ontologie , puis son forme développé définir sur le ensemble de le ontologie , que cln appeler extension du sous-ensemble flou . . un classe de équivalence de sous-ensemble flou définir sur un ontologie pouvoir être caractériser par un représentant unique que cln appeler sous-ensemble flou minimal . . cln conclure par un exemple de application dans un système de information relatif à le prévention du risque micro- biologique en sécurité alimentaire . " 	Rallou Thomopoulos, Patrice Buche, Ollivier Haemmerlé	2004	@inapg.fr	1000914
811	Un algorithme de génération des itemsets fermés pour la fouille de données	un algorithme de génération des itemsets fermer pour le fouille de donnée  le traitement de grand volume de donnée être un problème pour le extraction de connaissance . le fouille de donnée nécessiter un méthode de résolution efficace . le treillis de concept ( treillis de Galois ) être un outil utile pour le analyse de donnée . un travaux en classification et sur le règle de association avoir permettre de accroître son intérêt . plusieurs algorithme de génération cln être proposer , parmi lequel NextClosure être le un des meilleur pour traiter un donnée de grand taille . mais le complexité de NextClosure rester malgré tout très élevé . aussi cln proposer un nouveau algorithme efficace nommer ScalingNextClosure , et baser sur un méthode de partitionnement de donnée pour générer de manière indépendant le itemsets fermé de chaque partition . le résultat expérimental montrer que ce technique de partitionnement améliorer efficacement NextClosure . 	Engelbert Mephu Nguifo, Huaiguo Fu	2004	@univ-artois.fr	1001062
812	Une méthode pour l'appropriation de savoir-faire, capitalisé avec MASK	un méthode pour le appropriation de savoir-faire , capitaliser avec MASK  le gestion expliciter un savoir et savoir-faire occuper un place de plus en plus important dans le organisation . le construction de mémoires de entreprise dans un but de préservation et de partage être devenir un pratique assez courant . cependant , cln oublier trop suivre que le efficacité de ce activité être étroitement lier aux capacité de appropriation et de apprentissage des acteur de le organisation . dans ce article , cln proposer un démarche général de accompagnement permettre de faciliter le processus de appropriation des mémoires de entreprise construire avec le méthode MASK , en exploiter un technique de ingénierie pédagogique . 	Oswaldo Castillo, Nada Matta, Jean-Louis Ermine	2004	@utt.fr, @int-evry.fr	1000911
813	Utilisation des graphes de proximité dans le cadre de l'apprentissage basé sur les voisins	utilisation des graphe de proximité dans le cadre de le apprentissage baser sur le voisins  " le classification suivre le plus proche voisins être un règle simple et attractif , baser sur un définition paramétrique du voisinage . . le graphe des proximité , quand à lui , induire un notion plus souple de voisinage . . ilimp clr agir ici de effectuer le substitution . . le variante obtenir , peu tester dans le bibliographie , avoir être soumettre à un expérimentation intensif , sur base de donnée de le UCI et de France télécommunications . . cln avoir ainsi considérer divers type de prétraitement un donnée et plusieurs catégorie de graphe . . de plus , cln avoir caractériser le effet du " " piège de le dimension " " sur le comportement théorique de tout le graphe présenter , un quantification empirique du phénomène avoir être réaliser . . ilimp ressortir de son étude que le utilisation du voisinage de Gabriel provoquer un amélioration en moyenne et que le prétraitement baser sur le statistique de rang être le plus adéquat . . Quoiqu' ilimp arriver , un précaution devoir être prendre en grand dimension . " 	Sylvain Ferrandiz, Marc Boullé	2004	@francetelecom.com, @francetelecom.com	1001061
814	Validation de graphes conceptuels	validation de graphe conceptuel  " le travaux mener en validation des connaissance viser à améliorer le qualité des base de connaissance . . le modèle des graphe conceptuel être un modèle de représentation des connaissance de le famille des réseau sémantique , fonder sur le théorie des graphe et sur le logique du premier ordre . . cln proposer un solution pour valider sémantiquement un base de connaissance composer de graphe conceptuel . . le validation sémantique de un base de connaissance consister à confronter son connaissance à un contrainte certifier fiable . . cln proposer de utiliser un contrainte descriptif , exprimer sous forme de graphe conceptuel , qui permettre de poser un condition sur le représentation de certain connaissance dans le base . . ce contrainte introduire un notion de cardinalité , et être soit minimal , soit maximal . . cln permettre respectivement de exprimer " " si A , alors au moins ou au plus n fois B " " . . le satisfaction de ce contrainte par un base de connaissance reposer sur le utilisation de le opération de base du modèle des graphe conceptuel : le projection . " 	Juliette Dibie-Barthélemy, Ollivier Haemmerlé, Eric Salvat	2004		1000913
815	Veille technologique assistée par la Fouille de Textes	veille technologique assisté par le fouille de texte  le domaine de le veille technologique viser à récolter , traiter , et analyser un information scientifique et technique utile aux acteur économique . dans ce article cln proposer de utiliser un technique de fouille de texte pour automatiser le processus de traitement des donnée issu de base de texte scientifique . toutefois , le veille introduire un difficulté inhabituel par rapport aux domaine de application classique des technique de fouille de texte , puisque au lieu de rechercher de le connaissance fréquent cacher dans le donnée , ilimp falloir rechercher de le connaissance inattendu . le mesure usuel de extraction de le connaissance à partir de texte devoir de ce fait être revoir . pour ce faire , cln avoir développer le système UnexpectedMiner dans lequel de nouveau mesure permettre de estimer le caractère inattendu de un document . son système être évaluer sur un base de article dans le domaine de le apprentissage automatique . 	François Jacquenet, Christine Largeron, Stéphanie Chapaux	2004		1001097
816	Vers un entrepôt de données pour la gestion des risques naturels	vers un entrepôt de donnée pour le gestion des risque naturel  le entrepôt de donnée être le un des plus important développement dans le domaine des système de information . cln permettre de intégrer un donnée de plusieurs source , souvent très volumineux , distribuer et hétérogène . dans ce article , cln examiner le possibilité de utiliser le technique de entrepôt de donnée dans le gestion des risque naturel . cln présenter un modèle conceptuel pour le entrepôt proposer , avec le présence de format et type varié de donnée tel que un donnée géographique et multimédia . cln proposer également un opération OLAP pour le navigation des information stocker dans le cube de donnée . 	Hicham Hajji, Nourdine Badji, Jean-Pierre Asté	2004	@univ-lyon1.fr, @gipea.fr	1001163
