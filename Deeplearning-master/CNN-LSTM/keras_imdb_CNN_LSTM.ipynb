{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_imdb_CNN_LSTM.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "21UFN4o4GAU-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "c96f3e9e-c40e-4416-a4bc-06f4617b781b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524362864875,
          "user_tz": -330,
          "elapsed": 142984,
          "user": {
            "displayName": "Mohamed Noordeen",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105498845634494432337"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''Train a recurrent convolutional network on the IMDB sentiment\n",
        "classification task.\n",
        "\n",
        "Gets to 0.8498 test accuracy after 2 epochs. 41s/epoch on K520 GPU.\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.datasets import imdb\n",
        "\n",
        "# Embedding\n",
        "max_features = 200\n",
        "maxlen = 100\n",
        "embedding_size = 128\n",
        "\n",
        "# Convolution\n",
        "kernel_size = 5\n",
        "filters = 64\n",
        "pool_size = 4\n",
        "\n",
        "# LSTM\n",
        "lstm_output_size = 70\n",
        "\n",
        "# Training\n",
        "batch_size = 30\n",
        "epochs = 2\n",
        "\n",
        "'''\n",
        "Note:\n",
        "batch_size is highly sensitive.\n",
        "Only 2 epochs are needed as the dataset is very small.\n",
        "'''\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print('Build model...')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(MaxPooling1D(pool_size=pool_size))\n",
        "model.add(LSTM(lstm_output_size))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n",
            "Build model...\n",
            "Train...\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/2\n",
            " 9510/25000 [==========>...................] - ETA: 32s - loss: 0.6042 - acc: 0.6627"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 62s 2ms/step - loss: 0.5660 - acc: 0.7025 - val_loss: 0.5492 - val_acc: 0.7171\n",
            "Epoch 2/2\n",
            " 7680/25000 [========>.....................] - ETA: 35s - loss: 0.5239 - acc: 0.7366"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 61s 2ms/step - loss: 0.5172 - acc: 0.7423 - val_loss: 0.5075 - val_acc: 0.7440\n",
            "25000/25000 [==============================] - 12s 467us/step\n",
            "Test score: 0.5074702569127083\n",
            "Test accuracy: 0.7439600000143051\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}