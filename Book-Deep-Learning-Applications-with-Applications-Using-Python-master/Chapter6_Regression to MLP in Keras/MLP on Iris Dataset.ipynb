{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP on iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and Prepare Data\n",
    "datatrain = pd.read_csv('iris_train.csv')\n",
    "#change string value to numeric\n",
    "\n",
    "#Assigning numeric values to the classes of the dataset.\n",
    "datatrain.set_value(datatrain['class']=='Iris-setosa',['class'],0)\n",
    "datatrain.set_value(datatrain['class']=='Iris-versicolor',['class'],1)\n",
    "datatrain.set_value(datatrain['class']=='Iris-virginica',['class'],2)\n",
    "datatrain = datatrain.apply(pd.to_numeric)\n",
    "#change dataframe to array\n",
    "datatrain_array = datatrain.as_matrix()\n",
    "#Splitting the data and the target and storing it in two different variables.\n",
    "# split x and y (feature and target)\n",
    "xtrain = datatrain_array[:,:4]\n",
    "ytrain = datatrain_array[:,4]\n",
    "#change target format\n",
    "ytrain = np_utils.to_categorical(ytrain) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a squential Keras model\n",
    "Multilayer perceptron model, with one hidden layer.\n",
    "Input layer : 4 neuron, represents the feature of Iris(Sepal Length etc)\n",
    "Hidden layer : 10 neuron, activation using ReLU\n",
    "Output layer : 3 neuron, represents the class of Iris, Softmax Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(output_dim=10, input_dim=4))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=3))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "#Compile the model and choose an optimizer and loss function for training and optimizing your data.\n",
    "#optimizer = stochastic gradient descent with no batch-size\n",
    "#loss function = categorical cross entropy\n",
    "#learning rate = default from keras.optimizer.SGD, 0.01\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "135/135 [==============================] - 3s - loss: 2.7825 - acc: 0.3333     \n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s - loss: 2.3695 - acc: 0.3333     \n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s - loss: 1.9826 - acc: 0.3333     \n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s - loss: 1.7489 - acc: 0.3333     \n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s - loss: 1.5356 - acc: 0.3333     \n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s - loss: 1.3635 - acc: 0.3333     \n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s - loss: 1.2773 - acc: 0.3481     \n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s - loss: 1.2119 - acc: 0.6296     \n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s - loss: 1.1693 - acc: 0.6667     \n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s - loss: 1.1352 - acc: 0.6667     \n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s - loss: 1.1040 - acc: 0.6667     \n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s - loss: 1.0758 - acc: 0.6593     \n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s - loss: 1.0542 - acc: 0.6667     \n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s - loss: 1.0314 - acc: 0.6667     \n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s - loss: 1.0171 - acc: 0.6667     \n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s - loss: 1.0033 - acc: 0.6667     \n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s - loss: 0.9870 - acc: 0.6667     \n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s - loss: 0.9750 - acc: 0.6593     \n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s - loss: 0.9682 - acc: 0.6444     \n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s - loss: 0.9653 - acc: 0.6593     \n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s - loss: 0.9612 - acc: 0.6741     \n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s - loss: 0.9533 - acc: 0.6296     \n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s - loss: 0.9503 - acc: 0.6444     \n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s - loss: 0.9443 - acc: 0.6000     \n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s - loss: 0.9415 - acc: 0.6519     \n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s - loss: 0.9362 - acc: 0.6296     \n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s - loss: 0.9334 - acc: 0.6593     \n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s - loss: 0.9275 - acc: 0.6296     \n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s - loss: 0.9233 - acc: 0.6296     \n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s - loss: 0.9186 - acc: 0.6593     \n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s - loss: 0.9144 - acc: 0.6741     \n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s - loss: 0.9108 - acc: 0.6593     \n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s - loss: 0.9068 - acc: 0.7259     \n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s - loss: 0.9028 - acc: 0.7333     \n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s - loss: 0.8971 - acc: 0.6444     \n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s - loss: 0.8942 - acc: 0.6667     \n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s - loss: 0.8877 - acc: 0.6667     \n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s - loss: 0.8828 - acc: 0.6815     \n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s - loss: 0.8779 - acc: 0.6667     \n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s - loss: 0.8735 - acc: 0.6889     \n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s - loss: 0.8685 - acc: 0.6741     \n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s - loss: 0.8648 - acc: 0.7259     \n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s - loss: 0.8595 - acc: 0.6667     \n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s - loss: 0.8557 - acc: 0.6667     \n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s - loss: 0.8499 - acc: 0.6741     \n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s - loss: 0.8482 - acc: 0.8000     \n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s - loss: 0.8485 - acc: 0.8667     \n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s - loss: 0.8385 - acc: 0.8444     \n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s - loss: 0.8341 - acc: 0.8519     \n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s - loss: 0.8290 - acc: 0.8741     \n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s - loss: 0.8212 - acc: 0.7333     \n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s - loss: 0.8170 - acc: 0.6963     \n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s - loss: 0.8139 - acc: 0.6667     \n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s - loss: 0.8097 - acc: 0.6667     \n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s - loss: 0.8027 - acc: 0.6667     \n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s - loss: 0.8017 - acc: 0.6667     \n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s - loss: 0.7935 - acc: 0.6667     \n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s - loss: 0.7874 - acc: 0.6815     \n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s - loss: 0.7834 - acc: 0.8000     \n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s - loss: 0.7781 - acc: 0.7037     \n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s - loss: 0.7759 - acc: 0.8741     \n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s - loss: 0.7695 - acc: 0.8444     \n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s - loss: 0.7642 - acc: 0.8444     \n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s - loss: 0.7577 - acc: 0.7407     \n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s - loss: 0.7537 - acc: 0.6741     \n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s - loss: 0.7539 - acc: 0.6667     \n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s - loss: 0.7434 - acc: 0.6889     \n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s - loss: 0.7406 - acc: 0.8593     \n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s - loss: 0.7380 - acc: 0.9111     \n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s - loss: 0.7340 - acc: 0.9333     \n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s - loss: 0.7252 - acc: 0.8444     \n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s - loss: 0.7209 - acc: 0.6815     \n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s - loss: 0.7169 - acc: 0.6667     \n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s - loss: 0.7101 - acc: 0.7407     \n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s - loss: 0.7050 - acc: 0.7407     \n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s - loss: 0.7011 - acc: 0.6815     \n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s - loss: 0.6966 - acc: 0.6963     \n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s - loss: 0.6929 - acc: 0.6815     \n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s - loss: 0.6885 - acc: 0.6889     \n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s - loss: 0.6848 - acc: 0.9259     \n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s - loss: 0.6782 - acc: 0.7333     \n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s - loss: 0.6737 - acc: 0.7407     \n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s - loss: 0.6697 - acc: 0.7704     \n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s - loss: 0.6663 - acc: 0.8889     \n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s - loss: 0.6609 - acc: 0.7704     \n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s - loss: 0.6565 - acc: 0.7556     \n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s - loss: 0.6531 - acc: 0.7185     \n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s - loss: 0.6487 - acc: 0.7556     \n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s - loss: 0.6484 - acc: 0.6741     \n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s - loss: 0.6433 - acc: 0.6741     \n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s - loss: 0.6369 - acc: 0.8815     \n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s - loss: 0.6331 - acc: 0.8963     \n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s - loss: 0.6285 - acc: 0.7556     \n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s - loss: 0.6248 - acc: 0.8074     \n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s - loss: 0.6215 - acc: 0.8815     \n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s - loss: 0.6174 - acc: 0.8370     \n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s - loss: 0.6167 - acc: 0.9407     \n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s - loss: 0.6149 - acc: 0.9481     \n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s - loss: 0.6113 - acc: 0.9556     \n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s - loss: 0.6020 - acc: 0.9111     \n",
      "15/15 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "#Train the model using the ‘model.fit’ function.\n",
    "model.fit(xtrain, ytrain, nb_epoch=100, batch_size=120)\n",
    "## Evaluate on test data\n",
    "#load and Prepare Data\n",
    "datatest = pd.read_csv('iris_test.csv')\n",
    "\n",
    "#change string value to numeric\n",
    "datatest.set_value(datatest['class']=='Iris-setosa',['class'],0)\n",
    "datatest.set_value(datatest['class']=='Iris-versicolor',['class'],1)\n",
    "datatest.set_value(datatest['class']=='Iris-virginica',['class'],2)\n",
    "datatest = datatest.apply(pd.to_numeric)\n",
    "#change dataframe to array\n",
    "datatest_array = datatest.as_matrix()\n",
    "#split x and y (feature and target)\n",
    "xtest= datatest_array[:,:4]\n",
    "ytest = datatest_array[:,4]\n",
    "#get prediction\n",
    "classes = model.predict_classes(xtest, batch_size=120)\n",
    "#get accuration\n",
    "accuration = np.sum(classes == ytest)/30.0 * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuration : 43.3333333333%\n",
      "Prediction :\n",
      "[0 0 0 0 0 2 2 2 2 2 2 1 2 1 1]\n",
      "Target :\n",
      "[0 0 0 0 0 2 2 2 2 2 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Printing the accuracy generated by the model\n",
    "print(\"Test Accuration : \" + str(accuration) + '%')\n",
    "print(\"Prediction :\")\n",
    "print(classes)\n",
    "print(\"Target :\")\n",
    "print(np.asarray(ytest,dtype=\"int32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
