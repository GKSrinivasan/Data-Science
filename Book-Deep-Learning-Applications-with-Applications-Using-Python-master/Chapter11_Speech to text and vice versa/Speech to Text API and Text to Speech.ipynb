{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech to text using PocketSphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphinx thinks you said and i were simeon\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "AUDIO_FILE = \"audio.wav\"\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    " audio = r.record(source) \n",
    "\n",
    "try:\n",
    "   print(\"Sphinx thinks you said \" + r.recognize_sphinx(audio))\n",
    "except sr.UnknownValueError:\n",
    "   print(\"Sphinx could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "  print(\"Sphinx error; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphinx thinks you said and i were simeon\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "# obtain path to \"sample.wav\" in the same folder as this script\n",
    "from os import path\n",
    "AUDIO_FILE = \"audio.wav\"\n",
    "\n",
    "# use the audio file as the audio source\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "    audio = r.record(source) # read the entire audio file\n",
    "\n",
    "# recognize speech using Sphinx\n",
    "try:\n",
    "    print(\"Sphinx thinks you said \" + r.recognize_sphinx(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sphinx could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Sphinx error; {0}\".format(e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "\n",
    "def record_audio(RECORD_SECONDS, WAVE_OUTPUT_FILENAME):\n",
    "    #--------- SETTING PARAMS FOR OUR AUDIO FILE ------------#\n",
    "    FORMAT = pyaudio.paInt16    # format of wave\n",
    "    CHANNELS = 2                # no. of audio channels\n",
    "    RATE = 44100                # frame rate\n",
    "    CHUNK = 1024                # frames per audio sample\n",
    "    #--------------------------------------------------------#\n",
    "     \n",
    "    # creating PyAudio object\n",
    "    audio = pyaudio.PyAudio()\n",
    "     \n",
    "    # open a new stream for microphone\n",
    "    # It creates a PortAudio Stream Wrapper class object\n",
    "    stream = audio.open(format=FORMAT,channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "\n",
    "    #----------------- start of recording -------------------#\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    # list to save all audio frames\n",
    "    frames = []\n",
    "\n",
    "    for i in range(int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        # read audio stream from microphone\n",
    "        data = stream.read(CHUNK)\n",
    "        # append audio data to frames list\n",
    "        frames.append(data)\n",
    "\n",
    "    #------------------ end of recording --------------------#   \n",
    "    print(\"Finished recording.\")\n",
    "      \n",
    "    stream.stop_stream()    # stop the stream object\n",
    "    stream.close()          # close the stream object\n",
    "    audio.terminate()       # terminate PortAudio\n",
    "\n",
    "    #------------------ saving audio ------------------------#\n",
    "\n",
    "    # create wave file object\n",
    "    waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "\n",
    "    # settings for wave file object\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "\n",
    "    # closing the wave file object\n",
    "    waveFile.close()\n",
    "\n",
    "\n",
    "def read_audio(WAVE_FILENAME):\n",
    "    # function to read audio(wav) file\n",
    "    with open(WAVE_FILENAME, 'rb') as f:\n",
    "        audio = f.read()\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Google Speech recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Speech Recognition thinks you said I am fine what's your name\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # for testing purposes, we're just using the default API key\n",
    "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "    # instead of `r.recognize_google(audio)`\n",
    "    print(\"Google Speech Recognition thinks you said \" + r.recognize_google(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Finished recording.\n",
      "\n",
      "You said: hello ladies\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "# Wit speech API endpoint\n",
    "API_ENDPOINT = 'https://api.wit.ai/speech'\n",
    "\n",
    "# Wit.ai api access token\n",
    "wit_access_token = 'ERGSGTLIC3RLAUEFTULLKIXRUUA3GOXG'\n",
    "\n",
    "\n",
    "def RecognizeSpeech(AUDIO_FILENAME, num_seconds = 5):\n",
    "    \n",
    "    # record audio of specified length in specified audio file\n",
    "    record_audio(num_seconds, AUDIO_FILENAME)\n",
    "    \n",
    "    # reading audio\n",
    "    audio = read_audio(AUDIO_FILENAME)\n",
    "    \n",
    "    # defining headers for HTTP request\n",
    "    headers = {'authorization': 'Bearer ' + wit_access_token,\n",
    "               'Content-Type': 'audio/wav'}\n",
    "\n",
    "    # making an HTTP post request\n",
    "    resp = requests.post(API_ENDPOINT, headers = headers,\n",
    "                         data = audio)\n",
    "    \n",
    "    # converting response content to JSON format\n",
    "    data = json.loads(resp.content)\n",
    "    \n",
    "    # get text from data\n",
    "    text = data['_text']\n",
    "    \n",
    "    # return the text\n",
    "    return text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text =  RecognizeSpeech('audio.wav', 4)\n",
    "    print(\"\\nYou said: {}\".format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Wit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIT_AI_KEY = \"ERGSGTLIC3RLAUEFTULLKIxxxxxxxxx\" # Wit.ai keys are 32-character uppercase alphanumeric strings\n",
    "try:\n",
    "    print(\"Wit.ai thinks you said \" + r.recognize_wit(audio, key=WIT_AI_KEY))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Wit.ai could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Wit.ai service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using Houndify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Houndify thinks you said the simplest method is to mix the mets in with basah or some other grease and smear it on the news of the animal from time to time naturally it will lick the grease off and in this way will swallow the medicine\n"
     ]
    }
   ],
   "source": [
    "HOUNDIFY_CLIENT_ID = \"b-9VDL3PODB71WdPRfWxxxxxxx\" # Houndify client IDs are Base64-encoded strings\n",
    "HOUNDIFY_CLIENT_KEY = \"QfT5TZnRa8Qak1xlIxDCMpTtDE1twGDZwSHyrrxxxxxxx\" # Houndify client keys are Base64-encoded strings\n",
    "try:\n",
    "    print(\"Houndify thinks you said \" + r.recognize_houndify(audio, client_id=HOUNDIFY_CLIENT_ID, client_key=HOUNDIFY_CLIENT_KEY))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Houndify could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Houndify service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using IBM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBM Speech to Text thinks you said the simplest method is to mix the medicine with buster or some other grease and smear it on the news of the animal from time to time \n",
      "naturally it will lick the grease off and in this way will swallow the medicine \n"
     ]
    }
   ],
   "source": [
    "IBM_USERNAME = \"5e988030-2be8-49f0-b1dxxxxxxxxxxxx\" # IBM Speech to Text usernames are strings of the form XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n",
    "IBM_PASSWORD = \"wAMhrtxxxx7bg\" # IBM Speech to Text passwords are mixed-case alphanumeric strings\n",
    "try:\n",
    "    print(\"IBM Speech to Text thinks you said \" + r.recognize_ibm(audio, username=IBM_USERNAME, password=IBM_PASSWORD))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"IBM Speech to Text could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from IBM Speech to Text service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USing BING API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Bing Voice Recognition thinks you said The simplest method is to mix the mix with butter or some other Greece and spirits on the news of the animal from time to time natural grease off and in this way will swallow them edson.\n"
     ]
    }
   ],
   "source": [
    "BING_KEY = \"1159d85fdf0a464f97591a6e121e7020\" # Microsoft Bing Voice Recognition API keys 32-character lowercase hexadecimal strings\n",
    "try:\n",
    "    print(\"Microsoft Bing Voice Recognition thinks you said \" + r.recognize_bing(audio, key=BING_KEY))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Microsoft Bing Voice Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Microsoft Bing Voice Recognition service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text To speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from win32com.client import constants, Dispatch\n",
    "Msg = \"Hi this is a test\"\n",
    "speaker = Dispatch(\"SAPI.SpVoice\")  #Create SAPI SpVoice Object\n",
    "speaker.Speak(Msg)                  #Process TTS\n",
    "del speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from comtypes.client import CreateObject\n",
    "   \n",
    "engine = CreateObject(\"SAPI.SpVoice\")\n",
    "stream = CreateObject(\"SAPI.SpFileStream\")\n",
    "from comtypes.gen import SpeechLib \n",
    "infile = \"textfile.txt\"\n",
    "outfile = \"audio.wav\"\n",
    "stream.Open(outfile, SpeechLib.SSFMCreateForWrite)\n",
    "engine.AudioOutputStream = stream\n",
    "f = open(infile, 'r')\n",
    "theText = f.read()\n",
    "f.close()\n",
    "engine.speak(theText)\n",
    "stream.Close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Generating comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4\n",
      "# Generating comtypes.gen._00020430_0000_0000_C000_000000000046_0_2_0\n",
      "# Generating comtypes.gen.stdole\n",
      "# Generating comtypes.gen.SpeechLib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from comtypes.client import CreateObject\n",
    "\n",
    "text=\"Hi there, how are you?\"\n",
    "engine = CreateObject(\"SAPI.SpVoice\")\n",
    "stream = CreateObject(\"SAPI.SpFileStream\")\n",
    "from comtypes.gen import SpeechLib\n",
    "stream.Open('audio.mp3', SpeechLib.SSFMCreateForWrite)\n",
    "engine.AudioOutputStream = stream\n",
    "engine.speak(text)\n",
    "stream.Close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
